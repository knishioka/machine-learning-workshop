---
name: ml-weekly-report
description: æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®é€±æ¬¡æ€§èƒ½ãƒ¬ãƒãƒ¼ãƒˆã‚’è‡ªå‹•ç”Ÿæˆã€‚å®šæœŸçš„ãªãƒ¢ãƒ‡ãƒ«ç›£è¦–ã€æ€§èƒ½ãƒˆãƒ¬ãƒ³ãƒ‰ã€ãƒ‡ãƒ¼ã‚¿ãƒ‰ãƒªãƒ•ãƒˆã€ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆã‚’æ¨™æº–ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§ãƒ¬ãƒãƒ¼ãƒˆåŒ–ã—ã¾ã™ã€‚
---

# ML Weekly Report

ã“ã®ã‚¹ã‚­ãƒ«ã¯ã€æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®é‹ç”¨çŠ¶æ³ã‚’å®šæœŸçš„ã«ãƒ¬ãƒãƒ¼ãƒˆã™ã‚‹ãŸã‚ã®è‡ªå‹•åŒ–ãƒ„ãƒ¼ãƒ«ã§ã™ã€‚æ±ºã¾ã£ãŸãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§é€±æ¬¡ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã—ã€ã‚¹ãƒ†ãƒ¼ã‚¯ãƒ›ãƒ«ãƒ€ãƒ¼ã¸ã®å ±å‘Šã‚’åŠ¹ç‡åŒ–ã—ã¾ã™ã€‚

## When to Use

ä»¥ä¸‹ã®ã‚ˆã†ãªå ´åˆã«ã“ã®ã‚¹ã‚­ãƒ«ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ï¼š
- æœ¬ç•ªç’°å¢ƒã§ç¨¼åƒä¸­ã®MLãƒ¢ãƒ‡ãƒ«ã®å®šæœŸãƒ¬ãƒãƒ¼ãƒˆãŒå¿…è¦
- é€±æ¬¡/æœˆæ¬¡ã§ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ã‚’å ±å‘Šã™ã‚‹ç¾©å‹™ãŒã‚ã‚‹
- ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’è¿½è·¡ã—ãŸã„
- ãƒ‡ãƒ¼ã‚¿ãƒ‰ãƒªãƒ•ãƒˆã‚„ç•°å¸¸ã‚’å®šæœŸçš„ã«ãƒã‚§ãƒƒã‚¯ã—ãŸã„
- ã‚¹ãƒ†ãƒ¼ã‚¯ãƒ›ãƒ«ãƒ€ãƒ¼ã¸ã®å®šå‹ãƒ¬ãƒãƒ¼ãƒˆãŒå¿…è¦

## Instructions

### 1. ãƒ¬ãƒãƒ¼ãƒˆè¨­å®šã®ç¢ºèª

ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ä»¥ä¸‹ã‚’ç¢ºèªï¼š
- ãƒ¬ãƒãƒ¼ãƒˆå¯¾è±¡ã®ãƒ¢ãƒ‡ãƒ«ã¯ï¼Ÿï¼ˆè¤‡æ•°å¯ï¼‰
- ãƒ¬ãƒãƒ¼ãƒˆæœŸé–“ã¯ï¼Ÿï¼ˆé€±æ¬¡ã€æœˆæ¬¡ãªã©ï¼‰
- ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã¯ï¼Ÿï¼ˆãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã€MLflowãªã©ï¼‰
- å‡ºåŠ›å½¢å¼ã¯ï¼Ÿï¼ˆMarkdownã€HTMLã€PDFã€PowerPointãªã©ï¼‰
- å«ã‚ã‚‹ã¹ãæŒ‡æ¨™ã¯ï¼Ÿï¼ˆç²¾åº¦ã€ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ã€ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆãªã©ï¼‰

### 2. ãƒ¬ãƒãƒ¼ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ

```markdown
# æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«é€±æ¬¡ãƒ¬ãƒãƒ¼ãƒˆ

**ãƒ¬ãƒãƒ¼ãƒˆæœŸé–“**: {start_date} ã€œ {end_date}
**ä½œæˆæ—¥**: {report_date}
**æ‹…å½“è€…**: {owner}

---

## ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ã‚µãƒãƒªãƒ¼

- ç·äºˆæ¸¬æ•°: {total_predictions:,}
- å¹³å‡ç²¾åº¦: {avg_accuracy:.2%}
- ã‚·ã‚¹ãƒ†ãƒ ç¨¼åƒç‡: {uptime:.2%}
- é‡å¤§ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆ: {critical_incidents}

### ä¸»è¦ãªç™ºè¦‹äº‹é …
- âœ… {positive_finding_1}
- âš ï¸ {attention_needed_1}
- ğŸš¨ {critical_issue_1}

---

## ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ã‚µãƒãƒªãƒ¼

### ç²¾åº¦ãƒ¡ãƒˆãƒªã‚¯ã‚¹

| ãƒ¢ãƒ‡ãƒ« | ç²¾åº¦ | å‰é€±æ¯” | ç›®æ¨™å€¤ | ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ |
|--------|------|--------|--------|-----------|
| {model_1} | {accuracy_1} | {change_1} | {target_1} | {status_1} |
| {model_2} | {accuracy_2} | {change_2} | {target_2} | {status_2} |

### ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹

| ãƒ¡ãƒˆãƒªã‚¯ã‚¹ | ä»Šé€± | å‰é€± | å¤‰åŒ– |
|-----------|------|------|------|
| å¹³å‡ãƒ¬ã‚¤ãƒ†ãƒ³ã‚· (ms) | {latency_current} | {latency_prev} | {latency_change} |
| ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ (req/s) | {throughput_current} | {throughput_prev} | {throughput_change} |
| ã‚¨ãƒ©ãƒ¼ç‡ (%) | {error_rate_current} | {error_rate_prev} | {error_rate_change} |

---

## ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ

### ç²¾åº¦ã®æ¨ç§»
![Accuracy Trend](accuracy_trend.png)

### äºˆæ¸¬æ•°ã®æ¨ç§»
![Prediction Volume](prediction_volume.png)

### ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ã®æ¨ç§»
![Latency Trend](latency_trend.png)

---

## ãƒ‡ãƒ¼ã‚¿ãƒ‰ãƒªãƒ•ãƒˆåˆ†æ

### ç‰¹å¾´é‡åˆ†å¸ƒã®å¤‰åŒ–

| ç‰¹å¾´é‡ | ãƒ‰ãƒªãƒ•ãƒˆæ¤œå‡º | KSãƒ†ã‚¹ãƒˆ på€¤ | ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ |
|--------|-------------|--------------|-----------|
| {feature_1} | {drift_1} | {pvalue_1} | {action_1} |
| {feature_2} | {drift_2} | {pvalue_2} | {action_2} |

### ãƒ‰ãƒªãƒ•ãƒˆå¯è¦–åŒ–
![Feature Drift](feature_drift.png)

---

## ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆãƒ»ç•°å¸¸

### é‡å¤§åº¦åˆ¥ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆ

- ğŸš¨ **Critical** (P0): {p0_count} ä»¶
- âš ï¸ **High** (P1): {p1_count} ä»¶
- ğŸ’¡ **Medium** (P2): {p2_count} ä»¶
- â„¹ï¸ **Low** (P3): {p3_count} ä»¶

### ä¸»è¦ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆè©³ç´°

#### [{incident_severity}] {incident_title}
- **ç™ºç”Ÿæ—¥æ™‚**: {incident_datetime}
- **å½±éŸ¿ç¯„å›²**: {incident_impact}
- **æ ¹æœ¬åŸå› **: {incident_root_cause}
- **å¯¾å¿œçŠ¶æ³**: {incident_status}
- **å¯¾ç­–**: {incident_action}

---

## æ”¹å–„ææ¡ˆ

1. **{recommendation_1_title}**
   - èƒŒæ™¯: {recommendation_1_background}
   - ææ¡ˆ: {recommendation_1_proposal}
   - æœŸå¾…åŠ¹æœ: {recommendation_1_impact}

2. **{recommendation_2_title}**
   - èƒŒæ™¯: {recommendation_2_background}
   - ææ¡ˆ: {recommendation_2_proposal}
   - æœŸå¾…åŠ¹æœ: {recommendation_2_impact}

---

## æ¬¡é€±ã®äºˆå®š

- [ ] {next_week_action_1}
- [ ] {next_week_action_2}
- [ ] {next_week_action_3}

---

## ä»˜éŒ²

### è©³ç´°ãƒ¡ãƒˆãƒªã‚¯ã‚¹
- è©³ç´°ãªçµ±è¨ˆæƒ…å ±ã¯æ·»ä»˜ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‚ç…§

### å‚è€ƒãƒªãƒ³ã‚¯
- MLflowãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰: {mlflow_url}
- Grafanaãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰: {grafana_url}
- ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆç®¡ç†: {incident_url}
```

### 3. ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚³ãƒ¼ãƒ‰

```python
from datetime import datetime, timedelta
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path

class WeeklyMLReport:
    """é€±æ¬¡MLãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚¯ãƒ©ã‚¹"""

    def __init__(self, start_date, end_date):
        self.start_date = start_date
        self.end_date = end_date
        self.report_date = datetime.now()
        self.output_dir = Path(f"reports/weekly_{self.report_date.strftime('%Y%m%d')}")
        self.output_dir.mkdir(parents=True, exist_ok=True)

    def load_data(self, data_source):
        """
        ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‹ã‚‰ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’èª­ã¿è¾¼ã‚€

        Parameters:
        -----------
        data_source : str or dict
            ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã€DBæ¥ç¶šæƒ…å ±ã€MLflow URI ãªã©ï¼‰
        """
        # ä¾‹: ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã®èª­ã¿è¾¼ã¿
        if isinstance(data_source, str) and data_source.endswith('.csv'):
            df = pd.read_csv(data_source)
            df['timestamp'] = pd.to_datetime(df['timestamp'])
            df = df[(df['timestamp'] >= self.start_date) &
                    (df['timestamp'] <= self.end_date)]
            return df

        # ä¾‹: MLflowã‹ã‚‰ã®èª­ã¿è¾¼ã¿
        elif isinstance(data_source, dict) and 'mlflow_uri' in data_source:
            import mlflow
            mlflow.set_tracking_uri(data_source['mlflow_uri'])
            # MLflowã‹ã‚‰ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’å–å¾—ã™ã‚‹å®Ÿè£…
            pass

        return None

    def calculate_metrics(self, df):
        """ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’è¨ˆç®—"""
        metrics = {}

        # ç·äºˆæ¸¬æ•°
        metrics['total_predictions'] = len(df)

        # ç²¾åº¦ãƒ¡ãƒˆãƒªã‚¯ã‚¹ï¼ˆå®Ÿéš›ã®å€¤ãŒã‚ã‚‹å ´åˆï¼‰
        if 'actual' in df.columns and 'predicted' in df.columns:
            metrics['avg_accuracy'] = (df['actual'] == df['predicted']).mean()

        # ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·çµ±è¨ˆ
        if 'latency_ms' in df.columns:
            metrics['avg_latency'] = df['latency_ms'].mean()
            metrics['p95_latency'] = df['latency_ms'].quantile(0.95)
            metrics['p99_latency'] = df['latency_ms'].quantile(0.99)

        # ã‚¨ãƒ©ãƒ¼ç‡
        if 'status' in df.columns:
            metrics['error_rate'] = (df['status'] == 'error').mean()

        # æ—¥åˆ¥ã®ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ
        df['date'] = df['timestamp'].dt.date
        metrics['daily_throughput'] = df.groupby('date').size().mean()

        return metrics

    def compare_with_previous_week(self, current_metrics, previous_df):
        """å‰é€±ã¨ã®æ¯”è¼ƒ"""
        previous_metrics = self.calculate_metrics(previous_df)

        comparison = {}
        for key in current_metrics:
            if key in previous_metrics:
                current = current_metrics[key]
                previous = previous_metrics[key]
                change = current - previous
                change_pct = (change / previous * 100) if previous != 0 else 0

                comparison[key] = {
                    'current': current,
                    'previous': previous,
                    'change': change,
                    'change_pct': change_pct
                }

        return comparison

    def plot_trends(self, df):
        """ãƒˆãƒ¬ãƒ³ãƒ‰ã‚°ãƒ©ãƒ•ã®ç”Ÿæˆ"""

        df['date'] = pd.to_datetime(df['timestamp']).dt.date

        # 1. ç²¾åº¦ã®æ¨ç§»ï¼ˆæ—¥åˆ¥ï¼‰
        if 'actual' in df.columns and 'predicted' in df.columns:
            daily_accuracy = df.groupby('date').apply(
                lambda x: (x['actual'] == x['predicted']).mean()
            )

            plt.figure(figsize=(12, 6))
            plt.plot(daily_accuracy.index, daily_accuracy.values, marker='o')
            plt.axhline(y=0.9, color='r', linestyle='--', label='ç›®æ¨™å€¤ (90%)')
            plt.title('æ—¥åˆ¥ç²¾åº¦æ¨ç§»')
            plt.xlabel('æ—¥ä»˜')
            plt.ylabel('ç²¾åº¦')
            plt.legend()
            plt.xticks(rotation=45)
            plt.grid(True, alpha=0.3)
            plt.tight_layout()
            plt.savefig(self.output_dir / 'accuracy_trend.png', dpi=300)
            plt.close()

        # 2. äºˆæ¸¬æ•°ã®æ¨ç§»
        daily_volume = df.groupby('date').size()

        plt.figure(figsize=(12, 6))
        plt.bar(daily_volume.index, daily_volume.values)
        plt.title('æ—¥åˆ¥äºˆæ¸¬æ•°æ¨ç§»')
        plt.xlabel('æ—¥ä»˜')
        plt.ylabel('äºˆæ¸¬æ•°')
        plt.xticks(rotation=45)
        plt.grid(True, alpha=0.3, axis='y')
        plt.tight_layout()
        plt.savefig(self.output_dir / 'prediction_volume.png', dpi=300)
        plt.close()

        # 3. ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ã®æ¨ç§»
        if 'latency_ms' in df.columns:
            daily_latency = df.groupby('date')['latency_ms'].agg(['mean', 'quantile'])

            plt.figure(figsize=(12, 6))
            plt.plot(daily_latency.index, daily_latency['mean'],
                    marker='o', label='å¹³å‡')
            plt.fill_between(daily_latency.index,
                            daily_latency['mean'] - daily_latency['mean'].std(),
                            daily_latency['mean'] + daily_latency['mean'].std(),
                            alpha=0.3)
            plt.title('æ—¥åˆ¥ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·æ¨ç§»')
            plt.xlabel('æ—¥ä»˜')
            plt.ylabel('ãƒ¬ã‚¤ãƒ†ãƒ³ã‚· (ms)')
            plt.legend()
            plt.xticks(rotation=45)
            plt.grid(True, alpha=0.3)
            plt.tight_layout()
            plt.savefig(self.output_dir / 'latency_trend.png', dpi=300)
            plt.close()

    def detect_drift(self, current_df, reference_df, features):
        """ãƒ‡ãƒ¼ã‚¿ãƒ‰ãƒªãƒ•ãƒˆã®æ¤œå‡º"""
        from scipy import stats

        drift_results = []

        for feature in features:
            if feature not in current_df.columns or feature not in reference_df.columns:
                continue

            # KSæ¤œå®š
            statistic, p_value = stats.ks_2samp(
                reference_df[feature].dropna(),
                current_df[feature].dropna()
            )

            drift_detected = p_value < 0.05
            action = "è¦èª¿æŸ»" if drift_detected else "æ­£å¸¸"

            drift_results.append({
                'feature': feature,
                'drift_detected': 'âš ï¸ Yes' if drift_detected else 'âœ… No',
                'p_value': f"{p_value:.4f}",
                'action': action
            })

        return pd.DataFrame(drift_results)

    def generate_report(self, data, template_vars):
        """ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""

        # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®èª­ã¿è¾¼ã¿ã¨å¤‰æ•°ã®ç½®æ›
        template = """
# æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«é€±æ¬¡ãƒ¬ãƒãƒ¼ãƒˆ

**ãƒ¬ãƒãƒ¼ãƒˆæœŸé–“**: {start_date} ã€œ {end_date}
**ä½œæˆæ—¥**: {report_date}

## ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ã‚µãƒãƒªãƒ¼

- ç·äºˆæ¸¬æ•°: {total_predictions:,}
- å¹³å‡ç²¾åº¦: {avg_accuracy:.2%}
- ã‚·ã‚¹ãƒ†ãƒ ç¨¼åƒç‡: {uptime:.2%}

... (æ®‹ã‚Šã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ)
"""

        report_content = template.format(**template_vars)

        # Markdownãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜
        report_path = self.output_dir / 'weekly_report.md'
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(report_content)

        print(f"ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã—ã¾ã—ãŸ: {report_path}")

        return report_path

    def convert_to_html(self, markdown_path):
        """Markdownã‚’HTMLã«å¤‰æ›"""
        try:
            import markdown

            with open(markdown_path, 'r', encoding='utf-8') as f:
                md_content = f.read()

            html_content = markdown.markdown(
                md_content,
                extensions=['tables', 'fenced_code', 'toc']
            )

            # CSSã‚¹ã‚¿ã‚¤ãƒ«ã‚’è¿½åŠ 
            styled_html = f"""
<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <style>
        body {{
            font-family: 'Segoe UI', Arial, sans-serif;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            line-height: 1.6;
        }}
        table {{
            border-collapse: collapse;
            width: 100%;
            margin: 20px 0;
        }}
        th, td {{
            border: 1px solid #ddd;
            padding: 12px;
            text-align: left;
        }}
        th {{
            background-color: #4CAF50;
            color: white;
        }}
        img {{
            max-width: 100%;
            height: auto;
        }}
        h1 {{ color: #333; border-bottom: 3px solid #4CAF50; padding-bottom: 10px; }}
        h2 {{ color: #555; border-bottom: 2px solid #ddd; padding-bottom: 8px; margin-top: 30px; }}
        h3 {{ color: #666; }}
    </style>
</head>
<body>
{html_content}
</body>
</html>
"""

            html_path = markdown_path.with_suffix('.html')
            with open(html_path, 'w', encoding='utf-8') as f:
                f.write(styled_html)

            print(f"HTMLãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã—ã¾ã—ãŸ: {html_path}")
            return html_path

        except ImportError:
            print("markdown ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“")
            print("ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«: pip install markdown")
            return None


# ä½¿ç”¨ä¾‹
def generate_weekly_report():
    """é€±æ¬¡ãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ"""

    # ãƒ¬ãƒãƒ¼ãƒˆæœŸé–“ã®è¨­å®š
    end_date = datetime.now()
    start_date = end_date - timedelta(days=7)

    # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå™¨ã®åˆæœŸåŒ–
    reporter = WeeklyMLReport(start_date, end_date)

    # ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
    current_data = reporter.load_data('logs/predictions.csv')
    previous_data = reporter.load_data('logs/predictions_previous_week.csv')

    # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®è¨ˆç®—
    current_metrics = reporter.calculate_metrics(current_data)
    comparison = reporter.compare_with_previous_week(current_metrics, previous_data)

    # ã‚°ãƒ©ãƒ•ã®ç”Ÿæˆ
    reporter.plot_trends(current_data)

    # ãƒ‰ãƒªãƒ•ãƒˆæ¤œå‡º
    features = ['feature1', 'feature2', 'feature3']
    drift_df = reporter.detect_drift(current_data, previous_data, features)

    # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆå¤‰æ•°ã®æº–å‚™
    template_vars = {
        'start_date': start_date.strftime('%Y-%m-%d'),
        'end_date': end_date.strftime('%Y-%m-%d'),
        'report_date': datetime.now().strftime('%Y-%m-%d %H:%M'),
        'total_predictions': current_metrics['total_predictions'],
        'avg_accuracy': current_metrics.get('avg_accuracy', 0),
        'uptime': 0.999,  # å®Ÿéš›ã®ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‹ã‚‰å–å¾—
        # ... ãã®ä»–ã®å¤‰æ•°
    }

    # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    report_path = reporter.generate_report(current_data, template_vars)

    # HTMLå¤‰æ›
    reporter.convert_to_html(report_path)

    return report_path
```

### 4. è‡ªå‹•åŒ–ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

```python
# weekly_report_automation.py
"""
é€±æ¬¡ãƒ¬ãƒãƒ¼ãƒˆã®è‡ªå‹•ç”Ÿæˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ

cronã‚„GitHub Actionsã§å®šæœŸå®Ÿè¡Œã™ã‚‹

# crontab ã®ä¾‹ï¼ˆæ¯é€±æœˆæ›œæ—¥ 9:00 ã«å®Ÿè¡Œï¼‰
0 9 * * 1 cd /path/to/project && python weekly_report_automation.py
"""

import logging
from datetime import datetime
from pathlib import Path

# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('weekly_report.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

def main():
    try:
        logger.info("é€±æ¬¡ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚’é–‹å§‹")

        # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        report_path = generate_weekly_report()

        logger.info(f"ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå®Œäº†: {report_path}")

        # ã‚ªãƒ—ã‚·ãƒ§ãƒ³: ãƒ¡ãƒ¼ãƒ«é€ä¿¡
        # send_email_report(report_path)

        # ã‚ªãƒ—ã‚·ãƒ§ãƒ³: Slackã«é€šçŸ¥
        # send_slack_notification(report_path)

        return True

    except Exception as e:
        logger.error(f"ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {str(e)}", exc_info=True)
        return False

if __name__ == '__main__':
    success = main()
    exit(0 if success else 1)
```

## Best Practices

1. **ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®æ¨™æº–åŒ–**: ãƒãƒ¼ãƒ å…¨ä½“ã§å…±é€šã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’ä½¿ç”¨
2. **è‡ªå‹•åŒ–**: cronã€GitHub Actionsã€Airflowãªã©ã§å®šæœŸå®Ÿè¡Œ
3. **ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†**: ãƒ¬ãƒãƒ¼ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚‚Gitã§ç®¡ç†
4. **é€šçŸ¥è¨­å®š**: é‡è¦ãªæŒ‡æ¨™ãŒé–¾å€¤ã‚’è¶…ãˆãŸå ´åˆã¯å³åº§ã«é€šçŸ¥
5. **ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–**: éå»ã®ãƒ¬ãƒãƒ¼ãƒˆã‚’ä¿å­˜ã—ã¦æ¯”è¼ƒå¯èƒ½ã«

## Examples

### Example 1: ã‚·ãƒ³ãƒ—ãƒ«ãªé€±æ¬¡ãƒ¬ãƒãƒ¼ãƒˆ

```python
from weekly_ml_report import WeeklyMLReport
from datetime import datetime, timedelta

# ä»Šé€±ã®ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ
end_date = datetime.now()
start_date = end_date - timedelta(days=7)

reporter = WeeklyMLReport(start_date, end_date)
report_path = generate_weekly_report()
print(f"ãƒ¬ãƒãƒ¼ãƒˆ: {report_path}")
```

### Example 2: è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã®ãƒ¬ãƒãƒ¼ãƒˆ

```python
models = ['model_a', 'model_b', 'model_c']

for model_name in models:
    reporter = WeeklyMLReport(start_date, end_date)
    data = reporter.load_data(f'logs/{model_name}_predictions.csv')
    # ... ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
```

## Notes

- **ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼**: ãƒ¬ãƒãƒ¼ãƒˆã«æ©Ÿå¯†ãƒ‡ãƒ¼ã‚¿ãŒå«ã¾ã‚Œãªã„ã‚ˆã†æ³¨æ„
- **ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚º**: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ‹ãƒ¼ã‚ºã«åˆã‚ã›ã¦ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’èª¿æ•´
- **ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹**: å¤§é‡ãƒ‡ãƒ¼ã‚¿ã®å ´åˆã¯é›†è¨ˆæ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨
- **ã‚¢ãƒ©ãƒ¼ãƒˆ**: ç•°å¸¸å€¤ã¯è‡ªå‹•çš„ã«ãƒã‚¤ãƒ©ã‚¤ãƒˆ
