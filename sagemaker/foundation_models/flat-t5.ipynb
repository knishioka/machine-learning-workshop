{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9085a0a4-ab16-4f69-8701-a95c5236bb48",
   "metadata": {},
   "source": [
    "# Flan-t5-xlのデモ\n",
    "\n",
    "- [Flan-t5-xlのモデル](https://huggingface.co/google/flan-t5-xl)\n",
    "- [参考にしたサンプルのnotebook](https://github.com/aws/amazon-sagemaker-examples/blob/main/introduction_to_amazon_algorithms/jumpstart-foundation-models/text2text-generation-flan-t5.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d296fa2d-7546-4f2c-9a9a-f6bf47a9df82",
   "metadata": {},
   "source": [
    "## flan-t5が動くイメージのURIを取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87f7a836-62dc-4508-a160-47a608532e42",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'763104351884.dkr.ecr.us-east-1.amazonaws.com/huggingface-pytorch-inference:1.10.2-transformers4.17.0-gpu-py38-cu113-ubuntu20.04'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sagemaker import image_uris\n",
    "\n",
    "\n",
    "model_id, model_version, = (\n",
    "    \"huggingface-text2text-flan-t5-xl\",\n",
    "    \"*\",\n",
    ")\n",
    "\n",
    "inference_instance_type = \"ml.p3.2xlarge\"\n",
    "\n",
    "deploy_image_uri = image_uris.retrieve(\n",
    "    region=None,\n",
    "    framework=None,  # automatically inferred from model_id\n",
    "    image_scope=\"inference\",\n",
    "    model_id=model_id,\n",
    "    model_version=model_version,\n",
    "    instance_type=inference_instance_type\n",
    ")\n",
    "\n",
    "deploy_image_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aad2d33-f088-4e32-96d5-d57231960303",
   "metadata": {},
   "source": [
    "## flat-5のモデルのURIを取得\n",
    "model_id と model_version はimageと合わせる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc6f4c0b-367c-40a5-a338-e8da68da325b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://jumpstart-cache-prod-us-east-1/huggingface-infer/infer-huggingface-text2text-flan-t5-xl.tar.gz'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sagemaker import model_uris\n",
    "from sagemaker.utils import name_from_base\n",
    "\n",
    "\n",
    "# Retrieve the model uri.\n",
    "model_uri = model_uris.retrieve(\n",
    "    model_id=model_id, model_version=model_version, model_scope=\"inference\"\n",
    ")\n",
    "\n",
    "model_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8be81ce-43d0-4f93-8047-67e7e315b9c4",
   "metadata": {},
   "source": [
    "## モデルの作成\n",
    "ここでは、まだモデルはデプロイされていない。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db8a86b9-f457-40c6-aaa9-9e053d1b4012",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.model import Model\n",
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.session import Session\n",
    "\n",
    "\n",
    "sagemaker_session = Session()\n",
    "aws_role = sagemaker_session.get_caller_identity_arn()\n",
    "\n",
    "endpoint_name = name_from_base(f\"flat-t5-{model_id}\")\n",
    "\n",
    "model = Model(\n",
    "    image_uri=deploy_image_uri,\n",
    "    model_data=model_uri,\n",
    "    role=aws_role,\n",
    "    predictor_cls=Predictor,\n",
    "    name=endpoint_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa0305b-5cd9-4f38-a61a-3226494fca9a",
   "metadata": {},
   "source": [
    "## モデルをデプロイ\n",
    "endpointが作成され、推論を実施できるようになる。\n",
    "実行には時間がかかる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70ec9e64-4913-4393-81e3-f76d5b2704c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------!"
     ]
    }
   ],
   "source": [
    "import sagemaker, boto3, json\n",
    "\n",
    "\n",
    "model_predictor = model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=inference_instance_type,\n",
    "    predictor_cls=Predictor,\n",
    "    endpoint_name=endpoint_name,\n",
    "    volume_size=30,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f173c60-8229-4a18-b3ed-2e294e92a155",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Endpointとやり取りする関数の作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8399145d-3855-43fc-a778-f08246ada45f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def query_endpoint(encoded_text, endpoint_name):\n",
    "    # endpoint インプットとなるtextをなげる.\n",
    "    client = boto3.client(\"runtime.sagemaker\")\n",
    "    response = client.invoke_endpoint(\n",
    "        EndpointName=endpoint_name, ContentType=\"application/x-text\", Body=encoded_text\n",
    "    )\n",
    "    return response\n",
    "\n",
    "\n",
    "def parse_response(query_response):\n",
    "    # endpointから返ってきた結果から作成されたテキストを抽出する.\n",
    "    model_predictions = json.loads(query_response[\"Body\"].read())\n",
    "    generated_text = model_predictions[\"generated_text\"]\n",
    "    return generated_text\n",
    "\n",
    "\n",
    "def generate_text(text):\n",
    "    # flat-t5を使ってテキストを生成する.\n",
    "    query_response = query_endpoint(text.encode(\"utf-8\"), endpoint_name=endpoint_name)\n",
    "    generated_text = parse_response(query_response)\n",
    "    return f\"入力: {text}\\n出力: {generated_text}\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9fa7851-e938-456a-8307-fe26aa376a80",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "入力: Translate to Spanish:  I'm Ken.\n",
      "出力: Soy Ken.\n",
      "\n",
      "入力: A step by step recipe to make bolognese pasta\n",
      "出力: Step 1: Preheat oven to 375 degrees F. Place ground beef in a large\n",
      "\n",
      "入力: 元気ですか？\n",
      "出力: ?\n",
      "\n",
      "入力: \n",
      "Review: This moive is so great and once again dazzles and delights us\n",
      "this movie review sentence negative or positive?\n",
      "出力: positive\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text1 = \"Translate to Spanish:  I'm Ken.\"\n",
    "text2 = \"A step by step recipe to make bolognese pasta\"\n",
    "text3 = \"元気ですか？\"\n",
    "text4 = \"\"\"\n",
    "Review: This moive is so great and once again dazzles and delights us\n",
    "this movie review sentence negative or positive?\"\"\"\n",
    "\n",
    "\n",
    "for text in [text1, text2, text3, text4]:\n",
    "    print(generate_text(text))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3efbf9-9a75-4cab-b94d-4871622026d1",
   "metadata": {},
   "source": [
    "## モデルとエンドポイントの削除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35327164-037d-42fe-a27d-308b94b92188",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_predictor.delete_model()\n",
    "model_predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
