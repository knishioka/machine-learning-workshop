# Macã§ã®Local Fine-tuningã‚¬ã‚¤ãƒ‰

## ğŸ“± Macã§ã®fine-tuningå¯èƒ½æ€§

### âœ… å¯èƒ½ãªã‚±ãƒ¼ã‚¹

#### 1. **Apple Silicon Mac (M1/M2/M3)ã®å ´åˆ**

Apple Siliconã‚’æ­è¼‰ã—ãŸMacã§ã¯ã€MLXãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ä½¿ç”¨ã—ã¦fine-tuningãŒå¯èƒ½ã§ã™ã€‚

```bash
# MLXã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
pip install mlx mlx-lm

# å°è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã®fine-tuningä¾‹
python -m mlx_lm.lora \
  --model mistralai/Mistral-7B-v0.1 \
  --adapter-path ./adapters \
  --data ./data.jsonl \
  --train
```

**ãƒ¡ãƒªãƒƒãƒˆ:**
- GPUãªã—ã§ã‚‚å‹•ä½œ
- é›»åŠ›åŠ¹ç‡ãŒè‰¯ã„
- çµ±åˆãƒ¡ãƒ¢ãƒªã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

**åˆ¶é™:**
- å¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ï¼ˆ70B+ï¼‰ã¯å›°é›£
- å­¦ç¿’é€Ÿåº¦ã¯GPUã‚ˆã‚Šé…ã„
- ãƒ¡ãƒ¢ãƒªä¸Šé™ï¼ˆ8GB/16GB/32GBï¼‰

#### 2. **CPUãƒ™ãƒ¼ã‚¹ã®fine-tuning**

å°è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ãªã‚‰CPUã§ã‚‚å¯èƒ½ï¼š

```python
# transformersã‚’ä½¿ç”¨ã—ãŸä¾‹
from transformers import (
    AutoModelForCausalLM,
    AutoTokenizer,
    TrainingArguments,
    Trainer
)

# 1Bä»¥ä¸‹ã®å°è¦æ¨¡ãƒ¢ãƒ‡ãƒ«
model = AutoModelForCausalLM.from_pretrained(
    "TinyLlama/TinyLlama-1.1B-Chat-v1.0",
    device_map="cpu",
    load_in_8bit=True  # ãƒ¡ãƒ¢ãƒªå‰Šæ¸›
)
```

### âš ï¸ åˆ¶é™äº‹é …

| é …ç›® | Intel Mac | Apple Silicon Mac |
|------|-----------|------------------|
| å¯¾å¿œãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚º | ~1B | ~7B |
| å­¦ç¿’é€Ÿåº¦ | éå¸¸ã«é…ã„ | é…ã„ |
| ãƒ¡ãƒ¢ãƒªè¦ä»¶ | 16GB+ | 16GB+ |
| æ¨å¥¨ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ | CPUç‰ˆPyTorch | MLX |

## ğŸ› ï¸ å®Ÿè·µçš„ãªMac fine-tuningã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

### æ–¹æ³•1: MLX-LMã‚’ä½¿ç”¨ï¼ˆM1/M2/M3 Macæ¨å¥¨ï¼‰

```bash
# 1. ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
conda create -n mlx-finetune python=3.10
conda activate mlx-finetune
pip install mlx mlx-lm

# 2. ãƒ‡ãƒ¼ã‚¿æº–å‚™
cat > training_data.jsonl << EOF
{"text": "### Human: Pythonã§ãƒªã‚¹ãƒˆã‚’é€†é †ã«ã™ã‚‹æ–¹æ³•ã¯ï¼Ÿ\n### Assistant: reversed()é–¢æ•°ã€ã‚¹ãƒ©ã‚¤ã‚¹[::-1]ã€ã¾ãŸã¯reverse()ãƒ¡ã‚½ãƒƒãƒ‰ãŒä½¿ãˆã¾ã™ã€‚"}
{"text": "### Human: gitã§ã‚³ãƒŸãƒƒãƒˆã‚’å–ã‚Šæ¶ˆã™ã«ã¯ï¼Ÿ\n### Assistant: git reset --soft HEAD~1 ã§ã‚³ãƒŸãƒƒãƒˆã‚’å–ã‚Šæ¶ˆã—ã€å¤‰æ›´ã¯ä¿æŒã•ã‚Œã¾ã™ã€‚"}
EOF

# 3. Fine-tuningå®Ÿè¡Œ
python -m mlx_lm.lora \
  --model mlx-community/Llama-3.2-1B-4bit \
  --data ./training_data.jsonl \
  --adapter-path ./lora_adapters \
  --iters 100
```

### æ–¹æ³•2: é‡å­åŒ–ãƒ¢ãƒ‡ãƒ«ã§ã®QLoRA

```python
# qlora_mac.py
import torch
from transformers import (
    AutoModelForCausalLM,
    AutoTokenizer,
    BitsAndBytesConfig,
    TrainingArguments
)
from peft import LoraConfig, get_peft_model

# 4bité‡å­åŒ–è¨­å®š
bnb_config = BitsAndBytesConfig(
    load_in_4bit=True,
    bnb_4bit_quant_type="nf4",
    bnb_4bit_compute_dtype=torch.float16,
    bnb_4bit_use_double_quant=True
)

# ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ï¼ˆ1Bä»¥ä¸‹æ¨å¥¨ï¼‰
model = AutoModelForCausalLM.from_pretrained(
    "TinyLlama/TinyLlama-1.1B-Chat-v1.0",
    quantization_config=bnb_config,
    device_map="auto"
)

# LoRAè¨­å®š
lora_config = LoraConfig(
    r=8,  # ä½ãƒ©ãƒ³ã‚¯
    lora_alpha=16,
    target_modules=["q_proj", "v_proj"],
    lora_dropout=0.1
)

model = get_peft_model(model, lora_config)
```

### æ–¹æ³•3: Unsloth on Macï¼ˆå®Ÿé¨“çš„ï¼‰

```bash
# Rosetta 2çµŒç”±ã§x86ç‰ˆã‚’ä½¿ç”¨ï¼ˆM1/M2/M3ï¼‰
arch -x86_64 /usr/bin/python3 -m pip install unsloth

# ã¾ãŸã¯ã€ã‚ˆã‚Šè»½é‡ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒ
pip install torch torchvision torchaudio
pip install transformers datasets accelerate peft bitsandbytes
```

## ğŸ“Š å®Ÿè¡Œæ™‚é–“ã®ç›®å®‰

| ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚º | Intel Mac | M1 Mac | M2/M3 Mac | æ¯”è¼ƒ: RTX 4090 |
|------------|-----------|---------|-----------|----------------|
| 1B params | 4-6æ™‚é–“ | 2-3æ™‚é–“ | 1-2æ™‚é–“ | 10åˆ† |
| 3B params | 12-18æ™‚é–“ | 6-8æ™‚é–“ | 4-6æ™‚é–“ | 30åˆ† |
| 7B params | éæ¨å¥¨ | 24æ™‚é–“+ | 12-18æ™‚é–“ | 1æ™‚é–“ |

## ğŸ¯ Mac fine-tuningã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹

### 1. **ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’å°ã•ãä¿ã¤**
```python
# 100-500ã‚µãƒ³ãƒ—ãƒ«ç¨‹åº¦ã«åˆ¶é™
train_dataset = dataset.select(range(500))
```

### 2. **ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’æœ€å°ã«**
```python
training_args = TrainingArguments(
    per_device_train_batch_size=1,  # æœ€å°
    gradient_accumulation_steps=8,   # ä»£ã‚ã‚Šã«ç´¯ç©
    fp16=True,                      # ãƒ¡ãƒ¢ãƒªå‰Šæ¸›
)
```

### 3. **ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜**
```python
# ä¸­æ–­ã«å‚™ãˆã¦é »ç¹ã«ä¿å­˜
training_args = TrainingArguments(
    save_steps=50,
    save_total_limit=2,
    resume_from_checkpoint=True
)
```

### 4. **ãƒ¡ãƒ¢ãƒªç›£è¦–**
```bash
# Activity Monitorã§ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’ç›£è¦–
# ã¾ãŸã¯
sudo powermetrics --samplers smc | grep -i "temperature"
```

## ğŸ”„ Ollamaã¸ã®GGUFå¤‰æ›

Fine-tuningå¾Œã€Ollamaã§ä½¿ç”¨ã™ã‚‹ã«ã¯ï¼š

```bash
# 1. PyTorchãƒ¢ãƒ‡ãƒ«ã‚’GGUFå¤‰æ›
python convert.py model_path --outfile model.gguf --outtype q4_0

# 2. Ollamaã§ä½¿ç”¨
ollama create my-mac-model -f Modelfile
```

## ğŸ’¡ æ¨å¥¨äº‹é …

### Macã§fine-tuningã™ã‚‹å ´åˆ:
- **å°è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ï¼ˆ1-3Bï¼‰**ã«é™å®š
- **å°‘é‡ã®ãƒ‡ãƒ¼ã‚¿ï¼ˆ<1000ã‚µãƒ³ãƒ—ãƒ«ï¼‰**ã§å®Ÿé¨“
- **MLX**ï¼ˆApple Siliconï¼‰ã¾ãŸã¯**QLoRA**ã‚’ä½¿ç”¨
- **å¤œé–“å®Ÿè¡Œ**ã‚’æ¨å¥¨ï¼ˆé•·æ™‚é–“ã‹ã‹ã‚‹ãŸã‚ï¼‰

### æœ¬æ ¼çš„ãªfine-tuningãŒå¿…è¦ãªå ´åˆ:
- **Google Colab**ï¼ˆç„¡æ–™GPUï¼‰
- **Runpod**ã‚„**Vast.ai**ï¼ˆæ™‚é–“èª²é‡‘GPUï¼‰
- **AWS/GCP**ã®GPUã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹

## ğŸš¨ æ³¨æ„äº‹é …

1. **ç™ºç†±ç®¡ç†**: é•·æ™‚é–“ã®å®Ÿè¡Œã§MacãŒé«˜æ¸©ã«ãªã‚‹å¯èƒ½æ€§
2. **é›»æºæ¥ç¶š**: ãƒãƒƒãƒ†ãƒªãƒ¼ã§ã®å®Ÿè¡Œã¯é¿ã‘ã‚‹
3. **ä»–ã®ä½œæ¥­**: fine-tuningä¸­ã¯ä»–ã®é‡ã„ä½œæ¥­ã‚’é¿ã‘ã‚‹
4. **ã‚¹ãƒªãƒ¼ãƒ—é˜²æ­¢**: `caffeinate -i python train.py`

## ğŸš€ å®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ

### è‡ªå‹•ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
```bash
# ç’°å¢ƒæ§‹ç¯‰ï¼ˆåˆå›ã®ã¿ï¼‰
cd ollama/fine_tuning
./scripts/setup_mac_env.sh

# ä»®æƒ³ç’°å¢ƒæœ‰åŠ¹åŒ–
source venv/bin/activate
source .env
```

### Fine-tuningå®Ÿè¡Œ
```bash
# MLXä½¿ç”¨ï¼ˆApple Siliconæ¨å¥¨ï¼‰
python scripts/mac_local_fine_tuning.py --method mlx

# PyTorchä½¿ç”¨ï¼ˆIntel Mac/ä»£æ›¿æ‰‹æ³•ï¼‰
python scripts/mac_local_fine_tuning.py --method pytorch

# ã‚«ã‚¹ã‚¿ãƒ è¨­å®š
python scripts/mac_local_fine_tuning.py \
  --method mlx \
  --iterations 200 \
  --output-dir ./my_model
```

## ã¾ã¨ã‚

Macã§ã®Local fine-tuningã¯**å¯èƒ½ã ãŒåˆ¶é™ãŒå¤šã„**ã§ã™ã€‚

- **ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ”ãƒ³ã‚°**: Macä¸Šã§å°è¦æ¨¡å®Ÿé¨“ âœ…
- **æœ¬ç•ªfine-tuning**: ã‚¯ãƒ©ã‚¦ãƒ‰GPUæ¨å¥¨ â­
- **Ollamaä½¿ç”¨**: fine-tuningå¾Œã®ãƒ¢ãƒ‡ãƒ«ã¯å•é¡Œãªãå‹•ä½œ âœ…

å°è¦æ¨¡ãªå®Ÿé¨“ã‚„PoCï¼ˆæ¦‚å¿µå®Ÿè¨¼ï¼‰ã«ã¯Macã§ã‚‚ååˆ†ã§ã™ãŒã€å®Ÿç”¨çš„ãªfine-tuningã«ã¯GPUç’°å¢ƒã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚

### æä¾›ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
- `scripts/setup_mac_env.sh`: ç’°å¢ƒè‡ªå‹•ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
- `scripts/mac_local_fine_tuning.py`: Macç”¨fine-tuningã‚¹ã‚¯ãƒªãƒ—ãƒˆ