{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import time\n",
    "\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langsmith import Client\n",
    "from langsmith.evaluation import (\n",
    "    EvaluationResult,\n",
    "    EvaluationResults,\n",
    "    RunEvaluator,\n",
    "    evaluate,\n",
    ")\n",
    "\n",
    "from langchain.agents import create_sql_agent\n",
    "from langchain.agents.agent_toolkits import SQLDatabaseToolkit\n",
    "from langchain.agents.agent_types import AgentType\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a SQLite database and add some sample data\n",
    "db_path = \"sample.db\"\n",
    "conn = sqlite3.connect(db_path)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Create a sample table\n",
    "db_schema = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS users (\n",
    "    id INTEGER PRIMARY KEY,\n",
    "    name TEXT NOT NULL,\n",
    "    age INTEGER,\n",
    "    email TEXT\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "cursor.execute(db_schema)\n",
    "\n",
    "# Insert some sample data\n",
    "sample_data = [\n",
    "    (1, \"Alice\", 28, \"alice@email.com\"),\n",
    "    (2, \"Bob\", 35, \"bob@email.com\"),\n",
    "    (3, \"Charlie\", 42, \"charlie@email.com\"),\n",
    "    (4, \"David\", 31, \"david@email.com\"),\n",
    "]\n",
    "cursor.executemany(\n",
    "    \"INSERT OR REPLACE INTO users (id, name, age, email) VALUES (?, ?, ?, ?)\",\n",
    "    sample_data,\n",
    ")\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQLiteコネクト用のtoolを作成\n",
    "db = SQLDatabase.from_uri(f\"sqlite:///{db_path}\")\n",
    "llm = ChatOpenAI(temperature=0, model=\"gpt-4\")\n",
    "toolkit = SQLDatabaseToolkit(db=db, llm=llm)\n",
    "\n",
    "agent = create_sql_agent(\n",
    "    llm=llm,\n",
    "    toolkit=toolkit,\n",
    "    agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataset in LangSmith (if not already created)\n",
    "client = Client()\n",
    "dataset_name = \"Text-to-SQL Evaluation Dataset\"\n",
    "client.delete_dataset(dataset_name=dataset_name)\n",
    "dataset = client.create_dataset(dataset_name)\n",
    "instruction = \"Generate the SQL query based on the given natural language query.\"\n",
    "\n",
    "# Add examples to the dataset\n",
    "examples = [\n",
    "    {\n",
    "        \"input\": f\"{instruction}\\nquestion: How many users are in the database?\\db schema: {db_schema}\",\n",
    "        \"expected_output\": \"SELECT COUNT(*) FROM users;\",\n",
    "    },\n",
    "    {\n",
    "        \"input\": f\"{instruction}\\nWhat is the average age of users?\\ndb schema: {db_schema}\",\n",
    "        \"expected_output\": \"SELECT AVG(age) FROM users;\",\n",
    "    },\n",
    "    {\n",
    "        \"input\": f\"{instruction}\\nList all users older than 30\\ndb schema: {db_schema}\",\n",
    "        \"expected_output\": \"SELECT * FROM users WHERE age > 30;\",\n",
    "    },\n",
    "    {\n",
    "        \"input\": f\"{instruction}\\nWhat is the email of the oldest user?\\ndb schema: {db_schema}\",\n",
    "        \"expected_output\": \"SELECT email FROM users WHERE age = (SELECT MAX(age) FROM users);\",\n",
    "    },\n",
    "]\n",
    "\n",
    "for example in examples:\n",
    "    client.create_example(\n",
    "        inputs={\"query\": example[\"input\"]},\n",
    "        outputs={\"expected_sql\": example[\"expected_output\"]},\n",
    "        dataset_id=dataset.id,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_query_plan(query):\n",
    "    \"\"\"\n",
    "    クエリの実行計画を取得する関数です。\n",
    "\n",
    "    Args:\n",
    "        query (str): 実行計画を取得したいクエリ\n",
    "\n",
    "    Returns:\n",
    "        list: クエリの実行計画の結果を含むリスト\n",
    "\n",
    "    Examples:\n",
    "        >>> query = \"SELECT * FROM users\"\n",
    "        >>> get_query_plan(query)\n",
    "        [('0', '0', '0', 'SCAN TABLE users')]\n",
    "\n",
    "    Raises:\n",
    "        None\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(f\"EXPLAIN QUERY PLAN {query}\")\n",
    "    plan = cursor.fetchall()\n",
    "    conn.close()\n",
    "    return plan\n",
    "\n",
    "\n",
    "def measure_execution_time(query: str) -> float:\n",
    "    \"\"\"\n",
    "    クエリの実行時間を計測する関数です。\n",
    "\n",
    "    Args:\n",
    "        query (str): 実行するクエリ文\n",
    "\n",
    "    Returns:\n",
    "        float: クエリの実行時間（秒単位）\n",
    "\n",
    "    Examples:\n",
    "        >>> query = \"SELECT * FROM table\"\n",
    "        >>> execution_time = measure_execution_time(query)\n",
    "        >>> print(execution_time)\n",
    "        0.123456789\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "    start_time = time.time()\n",
    "    cursor.execute(query)\n",
    "    end_time = time.time()\n",
    "    conn.close()\n",
    "    return end_time - start_time\n",
    "\n",
    "\n",
    "def calculate_efficiency_score(query_plan: list, execution_time: float) -> float:\n",
    "    \"\"\"\n",
    "    クエリの効率スコアを計算します。\n",
    "\n",
    "    Args:\n",
    "        query_plan (list): クエリの実行計画を表すリスト\n",
    "        execution_time (float): クエリの実行時間（秒単位）\n",
    "\n",
    "    Returns:\n",
    "        float: 計算された効率スコア（0.1から1.0の範囲）\n",
    "\n",
    "    Raises:\n",
    "        None\n",
    "\n",
    "    Examples:\n",
    "        >>> query_plan = [(\"SCAN TABLE\", \"users\"), (\"USE TEMP B-TREE\", \"index\")]\n",
    "        >>> execution_time = 0.05\n",
    "        >>> calculate_efficiency_score(query_plan, execution_time)\n",
    "        0.72\n",
    "    \"\"\"\n",
    "    # This is a simple heuristic and can be improved\n",
    "    score = 1.0\n",
    "    for step in query_plan:\n",
    "        if \"SCAN TABLE\" in step[3]:\n",
    "            score *= 0.8  # フルテーブルスキャンをペナルティとして適用\n",
    "        if \"USE TEMP B-TREE\" in step[3]:\n",
    "            score *= 0.9  # 一時的なBツリーの使用をペナルティとして適用\n",
    "\n",
    "    # 実行時間が長い場合にペナルティを適用\n",
    "    if execution_time > 0.1:  # 必要に応じてこの閾値を調整してください\n",
    "        score *= 0.9\n",
    "\n",
    "    return max(0.1, min(score, 1.0))  # スコアが0.1から1.0の範囲になるように調整"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLMでSQLクエリを評価するカスタム評価器を作成\n",
    "class LLMSQLEvaluator(RunEvaluator):\n",
    "    def __init__(self):\n",
    "        self.llm = ChatOpenAI(temperature=0, model=\"gpt-4\")\n",
    "        self.prompt = PromptTemplate(\n",
    "            input_variables=[\"query\", \"generated_sql\", \"expected_sql\", \"db_schema\"],\n",
    "            template=\"\"\"\n",
    "            You are an expert SQL reviewer. Your task is to evaluate the generated SQL query against the expected SQL query for a given natural language question. Consider the database schema provided.\n",
    "\n",
    "            Database Schema:\n",
    "            {db_schema}\n",
    "\n",
    "            Natural Language Query: {query}\n",
    "            Generated SQL: {generated_sql}\n",
    "            Expected SQL: {expected_sql}\n",
    "\n",
    "            Please evaluate the generated SQL based on the following criteria:\n",
    "            1. Correctness: Does the generated SQL correctly answer the natural language query?\n",
    "            2. Efficiency: Is the generated SQL optimized and efficient?\n",
    "            3. Readability: Is the generated SQL easy to read and understand?\n",
    "\n",
    "            Provide a score from 0 to 1 (0 being the worst, 1 being the best) for each criterion, and an overall score.\n",
    "            Also, provide a brief explanation for your evaluation.\n",
    "\n",
    "            Format your response as follows:\n",
    "            Correctness Score: [score]\n",
    "            Efficiency Score: [score]\n",
    "            Readability Score: [score]\n",
    "            Overall Score: [score]\n",
    "            Explanation: [your explanation]\n",
    "            \"\"\",\n",
    "        )\n",
    "        self.chain = LLMChain(llm=self.llm, prompt=self.prompt)\n",
    "\n",
    "    def evaluate_run(self, run, example) -> EvaluationResult:\n",
    "        \"\"\"\n",
    "        モデルの実行結果を評価します。\n",
    "\n",
    "        Args:\n",
    "            run (Run): 実行結果を含むオブジェクト\n",
    "            example (Example): 入力と出力の情報を含むオブジェクト\n",
    "\n",
    "        Returns:\n",
    "            EvaluationResult: 評価結果を表すオブジェクト\n",
    "        \"\"\"\n",
    "        query = example.inputs.get(\"query\", \"\")\n",
    "        generated_sql = run.outputs.get(\"output\", \"\")\n",
    "        expected_sql = example.outputs.get(\"expected_sql\", \"\")\n",
    "        db_schema = db.get_table_info()\n",
    "\n",
    "        evaluation = self.chain.run(\n",
    "            query=query,\n",
    "            generated_sql=generated_sql,\n",
    "            expected_sql=expected_sql,\n",
    "            db_schema=db_schema,\n",
    "        )\n",
    "\n",
    "        # Parse the evaluation results\n",
    "        lines = evaluation.strip().split(\"\\n\")\n",
    "        scores = {}\n",
    "        for line in lines:\n",
    "            if \"Score:\" in line:  # スコアを取得\n",
    "                key, value = line.split(\":\")\n",
    "                scores[key.strip()] = float(value.strip())\n",
    "\n",
    "        explanation = lines[-1].replace(\"Explanation:\", \"\").strip()\n",
    "\n",
    "        results = [\n",
    "            EvaluationResult(\n",
    "                key=\"overall\",\n",
    "                score=scores.get(\"Overall Score\", 0),\n",
    "                comment=f\"Overall: {explanation}\",\n",
    "            ),\n",
    "            EvaluationResult(\n",
    "                key=\"correctness\",\n",
    "                score=scores.get(\"Correctness Score\", 0),\n",
    "            ),\n",
    "            EvaluationResult(\n",
    "                key=\"efficiency\",\n",
    "                score=scores.get(\"Efficiency Score\", 0),\n",
    "            ),\n",
    "            EvaluationResult(\n",
    "                key=\"readability\",\n",
    "                score=scores.get(\"Readability Score\", 0),\n",
    "            ),\n",
    "        ]\n",
    "\n",
    "        # Return EvaluationResults object\n",
    "        return EvaluationResults(results=results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ken/.pyenv/versions/3.11.5/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 0.3.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'SQL Generation Evaluation-1cf8aeb5' at:\n",
      "https://smith.langchain.com/o/bd14a154-65e7-52b4-bdce-b9a16d5e3513/datasets/70455170-f24a-4f92-8df6-1f11808bf089/compare?selectedSessions=6af9d660-5e67-40fe-bf89-99f2dbb19966\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be9bea6aa5db4ba88d7a1f7d533fb5fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SQL Agent Executor chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SQL Agent Executor chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SQL Agent Executor chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SQL Agent Executor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ken/.pyenv/versions/3.11.5/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n",
      "/Users/ken/.pyenv/versions/3.11.5/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n",
      "/Users/ken/.pyenv/versions/3.11.5/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n",
      "/Users/ken/.pyenv/versions/3.11.5/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mTo answer this question, I need to write a SQL query that counts the number of users in the 'users' table.\n",
      "Action: sql_db_query_checker\n",
      "Action Input: SELECT COUNT(*) FROM users\u001b[0m\u001b[32;1m\u001b[1;3mTo answer this question, I need to write an SQL query that calculates the average age of users from the 'users' table.\n",
      "\n",
      "Action: sql_db_query_checker\n",
      "Action Input: SELECT AVG(age) FROM users\u001b[0m\u001b[32;1m\u001b[1;3mTo answer this question, I need to write an SQL query that selects all users from the 'users' table where the age is greater than 30.\n",
      "\n",
      "Action: sql_db_query_checker\n",
      "Action Input: SELECT * FROM users WHERE age > 30\u001b[0m\u001b[36;1m\u001b[1;3mSELECT COUNT(*) FROM users\u001b[0m\u001b[36;1m\u001b[1;3mSELECT AVG(age) FROM users\u001b[0m\u001b[36;1m\u001b[1;3mSELECT * FROM users WHERE age > 30\u001b[0m\u001b[32;1m\u001b[1;3mTo find the email of the oldest user, I need to find the user with the highest age in the users table. I can do this by sorting the table by age in descending order and selecting the first result. \n",
      "\n",
      "Action: sql_db_query_checker\n",
      "Action Input: SELECT email FROM users ORDER BY age DESC LIMIT 1;\u001b[0m\u001b[32;1m\u001b[1;3mThe SQL query is correct.\n",
      "Final Answer: SELECT COUNT(*) FROM users\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThe SQL query is correct and ready to be executed.\n",
      "Final Answer: SELECT AVG(age) FROM users\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3mSELECT email FROM users ORDER BY age DESC LIMIT 1;\u001b[0m\u001b[32;1m\u001b[1;3mThe SQL query is correct and ready to be executed.\n",
      "Final Answer: SELECT * FROM users WHERE age > 30\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThe SQL query is correct and ready to be executed.\n",
      "\n",
      "Action: sql_db_query\n",
      "Action Input: SELECT email FROM users ORDER BY age DESC LIMIT 1;\u001b[0m\u001b[36;1m\u001b[1;3m[('charlie@email.com',)]\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: The email of the oldest user is charlie@email.com.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Define the target function\n",
    "def target_function(x):\n",
    "    return agent.run(x[\"query\"])\n",
    "\n",
    "\n",
    "# Run evaluation\n",
    "results = evaluate(\n",
    "    target_function,\n",
    "    dataset.name,\n",
    "    evaluators=[LLMSQLEvaluator()],\n",
    "    experiment_prefix=\"SQL Generation Evaluation\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation complete. Run ID: 0160e45a-dcba-417a-a42e-77594a0f8813\n",
      "View results at: https://smith.langchain.com/o/bd14a154-65e7-52b4-bdce-b9a16d5e3513/projects/p/dc1fff1d-e827-4ee4-b948-e71e0914f7dd/r/0160e45a-dcba-417a-a42e-77594a0f8813?poll=true\n",
      "Evaluation complete. Run ID: b197da5a-78f4-44d8-af0d-2b12645c3072\n",
      "View results at: https://smith.langchain.com/o/bd14a154-65e7-52b4-bdce-b9a16d5e3513/projects/p/dc1fff1d-e827-4ee4-b948-e71e0914f7dd/r/b197da5a-78f4-44d8-af0d-2b12645c3072?poll=true\n",
      "Evaluation complete. Run ID: 5c007a49-4f67-482d-a6bf-ec6030b9e82d\n",
      "View results at: https://smith.langchain.com/o/bd14a154-65e7-52b4-bdce-b9a16d5e3513/projects/p/dc1fff1d-e827-4ee4-b948-e71e0914f7dd/r/5c007a49-4f67-482d-a6bf-ec6030b9e82d?poll=true\n",
      "Evaluation complete. Run ID: 963880ed-71d8-424d-a1d9-bc325c42e04b\n",
      "View results at: https://smith.langchain.com/o/bd14a154-65e7-52b4-bdce-b9a16d5e3513/projects/p/dc1fff1d-e827-4ee4-b948-e71e0914f7dd/r/963880ed-71d8-424d-a1d9-bc325c42e04b?poll=true\n"
     ]
    }
   ],
   "source": [
    "for res in results:\n",
    "    print(f\"Evaluation complete. Run ID: {res['run'].id}\")\n",
    "    print(f\"View results at: {client.get_run_url(run=res['run'])}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
