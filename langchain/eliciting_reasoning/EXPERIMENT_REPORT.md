# 認知ツール実験レポート

## 実験概要

論文「Teaching Language Models to Decode Cognitive Psychology」で提案された認知ツールアプローチをLangGraphで実装し、数学問題解決における効果を検証しました。

## 実装内容

### 1. 認知ツール
- **understand_question**: 問題の構造化分析
- **recall_related**: 類似問題の検索
- **examine_answer**: 解答の検証
- **backtracking**: エラー修正・代替案提示
- **use_code**: Python実行環境

### 2. システムアーキテクチャ
- LangGraphのStateGraphを使用した推論フロー管理
- 各ツールは独立したLLMコンテキストで実行
- 最大反復回数制御とツール使用追跡

## 実験結果

### GPT-3.5-turbo（5問）
| 手法 | 正答率 | 正解数/問題数 |
|------|--------|---------------|
| 認知ツール | 0% | 0/5 |
| ベースライン | 80% | 4/5 |

### 問題タイプ別結果（ベースライン）
- 数論: 100% (2/2)
- 代数: 0% (0/1)
- 数列: 100% (1/1)
- 確率: 100% (1/1)

### ツール使用統計
- use_code: 26回
- backtracking: 8回
- understand_question: 2回
- recall_related: 2回
- examine_answer: 1回

平均反復回数: 10回/問題

## 分析と考察

### 1. 認知ツールアプローチの課題

#### a) 実装上の問題
- **use_codeツールの制限**: セキュリティのため制限された環境でコードを実行しており、sympyなどの高度な数学ライブラリが使用できない
- **最終回答の抽出失敗**: LLMが「ANSWER:」形式で回答を提供しないケースが多発
- **ツールの過剰使用**: 同じツールを繰り返し呼び出す傾向

#### b) モデル依存性
- GPT-3.5-turboは複雑なツール選択戦略の実行に苦戦
- ツール使用の判断基準が不明確
- エラー時の適切なリカバリーができない

### 2. ベースラインの優位性

シンプルなChain-of-Thoughtプロンプティングの方が以下の理由で優れていました：
- 直接的な問題解決アプローチ
- 不要なオーバーヘッドがない
- GPT-3.5-turboの能力に適合

### 3. 改善提案

#### 短期的改善
1. use_codeツールの機能拡張（より多くのライブラリサポート）
2. 回答抽出ロジックの改善
3. ツール呼び出しの重複防止メカニズム

#### 長期的改善
1. より高性能なモデル（GPT-4、Claude 3）での実験
2. ツール選択の学習メカニズム導入
3. 問題タイプに応じた動的なツール選択戦略

## 結論

現在の実装では、認知ツールアプローチは期待された効果を示しませんでした。主な原因は：

1. **実装の制約**: 特にコード実行環境の制限
2. **モデルの能力**: GPT-3.5-turboでは複雑なツール調整が困難
3. **オーバーヘッド**: 簡単な問題では認知ツールが逆効果

しかし、以下の点で研究価値があります：
- 複雑な多段階問題での可能性
- より高性能なモデルでの効果
- ツール設計の最適化による改善余地

## 今後の展望

1. **実験の拡張**
   - より複雑な問題セットでの評価
   - 異なるLLMモデルでの比較
   - ツール選択戦略の最適化

2. **実装の改良**
   - コード実行環境の拡充
   - エラーハンドリングの強化
   - ツール間の協調メカニズム

3. **理論的検証**
   - 認知心理学的アプローチの有効性検証
   - 問題複雑度とツール有効性の相関分析
   - 人間の問題解決プロセスとの比較

## 実験環境

- Python 3.13.1
- LangChain 0.3.25
- LangGraph 0.4.8
- GPT-3.5-turbo
- 実験日: 2025年6月19日