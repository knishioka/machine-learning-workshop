{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8051b35d-212e-414b-979f-26c28797b13f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: youtube-transcript-api in /Users/ken/.pyenv/versions/3.11.5/lib/python3.11/site-packages (0.6.1)\n",
      "Requirement already satisfied: requests in /Users/ken/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from youtube-transcript-api) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/ken/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from requests->youtube-transcript-api) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/ken/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from requests->youtube-transcript-api) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/ken/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from requests->youtube-transcript-api) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ken/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from requests->youtube-transcript-api) (2023.7.22)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install youtube-transcript-api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7d3e77b-3234-4ad5-85e9-a698052a8d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: arxiv in /Users/ken/.pyenv/versions/3.11.5/lib/python3.11/site-packages (2.0.0)\n",
      "Requirement already satisfied: pymupdf in /Users/ken/.pyenv/versions/3.11.5/lib/python3.11/site-packages (1.23.5)\n",
      "Requirement already satisfied: feedparser==6.0.10 in /Users/ken/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from arxiv) (6.0.10)\n",
      "Requirement already satisfied: requests==2.31.0 in /Users/ken/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from arxiv) (2.31.0)\n",
      "Requirement already satisfied: sgmllib3k in /Users/ken/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from feedparser==6.0.10->arxiv) (1.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/ken/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from requests==2.31.0->arxiv) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/ken/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from requests==2.31.0->arxiv) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/ken/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from requests==2.31.0->arxiv) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ken/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from requests==2.31.0->arxiv) (2023.7.22)\n",
      "Requirement already satisfied: PyMuPDFb==1.23.5 in /Users/ken/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from pymupdf) (1.23.5)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install arxiv pymupdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e149f7d0-09ce-4a79-bcc0-149557255eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wikipedia in /Users/ken/.pyenv/versions/3.11.5/lib/python3.11/site-packages (1.4.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/ken/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from wikipedia) (4.12.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /Users/ken/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from wikipedia) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/ken/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/ken/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/ken/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ken/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2023.7.22)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/ken/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from beautifulsoup4->wikipedia) (2.5)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78fecfc3-dcc5-47fe-8feb-84dc2cfbcc30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tiktoken in /Users/ken/.pyenv/versions/3.11.5/lib/python3.11/site-packages (0.5.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/ken/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from tiktoken) (2023.10.3)\n",
      "Requirement already satisfied: requests>=2.26.0 in /Users/ken/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from tiktoken) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/ken/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/ken/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/ken/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ken/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken) (2023.7.22)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c975ebce-9155-4c3a-aee6-242187020413",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6b31b8-5847-4de9-b26d-913e13ca9599",
   "metadata": {},
   "source": [
    "## Token数を調べる\n",
    "tiktokenを使ってtoken数を調べてみる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efd5a85a-a80c-4905-ba66-5144b5c46761",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Encoding 'cl100k_base'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.encoding_for_model('gpt-3.5-turbo')\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd807f57-183d-4d1b-ba98-18792a1604c2",
   "metadata": {},
   "source": [
    "ChatGPTでは `cl100k_base` というtokenizerが使われている。\n",
    "\n",
    "実際に `cl100k_base` tokenizerで英文をエンコーディングする。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb6ab667-658b-46df-b5e9-814e615e7fa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[576, 374, 264, 5869, 13]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"this is a pen.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f3ac6f-4538-457f-9ddd-941e546d5e22",
   "metadata": {},
   "source": [
    "単語及びピリオドが数値にmappingされていることがわかる。\n",
    "例えばthisの数値を調べてみると"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d39c4f8f-e214-4150-867e-111c9ccb5289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[576]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"this\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656575eb-bd7b-48eb-8f7f-efa8f1bc3fbb",
   "metadata": {},
   "source": [
    "となる。このように、それぞれの単語と対応する数値がある。\n",
    "\n",
    "token数はmappingされたベクターの長さを調べれば良い。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "052d8d5c-aaf8-457c-bcb0-c1599242083c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.encode(\"this is a pen.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c101ac-5a65-4e47-8a9c-9923937c270e",
   "metadata": {},
   "source": [
    "次に、日本語をエンコーディングしてみる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c5e5e58-6dfb-4acb-bfa8-bfed59c455f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[90115]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"こんにちは\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9492a401-2683-45b2-b440-a34b7408c61a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.encode(\"こんにちは\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b14e1ec-e24c-41ef-a625-627a2979a170",
   "metadata": {},
   "source": [
    "「こんにちは」は、token数1となることがわかる。\n",
    "\n",
    "一方で「こんばんは」はどうなるか。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6dd1ca0c-ab81-48af-8b36-33993021ff4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[69847, 81219, 25827, 15682]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"こんばんは\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f5d1083d-f5c9-45cf-89c6-dae3dc690142",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.encode(\"こんばんは\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f77031d-532b-4d53-9ef2-babab52c0e6a",
   "metadata": {},
   "source": [
    "「こんばんは」はtoken数が4となることがわかる。\n",
    "\n",
    "このように日本語では、token数は単語によって大きく変わってくる。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9962d50-b699-4709-aa4d-532329aa7b6b",
   "metadata": {},
   "source": [
    "## Document Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dfb4a113-6125-4d8c-84ee-f4086b8350e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "pdf_loader = PyPDFLoader(\"https://arxiv.org/pdf/2210.03629.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "11bb4954-bfa4-484d-8ba9-389f064380a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Published as a conference paper at ICLR 2023\\nREAC T: S YNERGIZING REASONING AND ACTING IN\\nLANGUAGE MODELS\\nShunyu Yao∗*,1, Jeffrey Zhao2, Dian Yu2, Nan Du2, Izhak Shafran2, Karthik Narasimhan1, Yuan Cao2\\n1Department of Computer Science, Princeton University\\n2Google Research, Brain team\\n1{shunyuy,karthikn}@princeton.edu\\n2{jeffreyzhao,dianyu,dunan,izhak,yuancao}@google.com\\nABSTRACT\\nWhile large language models (LLMs) have demonstrated impressive performance\\nacross tasks in language understanding and interactive decision making, their\\nabilities for reasoning (e.g. chain-of-thought prompting) and acting (e.g. action\\nplan generation) have primarily been studied as separate topics. In this paper, we\\nexplore the use of LLMs to generate both reasoning traces and task-speciﬁc actions\\nin an interleaved manner, allowing for greater synergy between the two: reasoning\\ntraces help the model induce, track, and update action plans as well as handle\\nexceptions, while actions allow it to interface with and gather additional information\\nfrom external sources such as knowledge bases or environments. We apply our\\napproach, named ReAct , to a diverse set of language and decision making tasks\\nand demonstrate its effectiveness over state-of-the-art baselines in addition to\\nimproved human interpretability and trustworthiness. Concretely, on question\\nanswering (HotpotQA) and fact veriﬁcation (Fever), ReAct overcomes prevalent\\nissues of hallucination and error propagation in chain-of-thought reasoning by\\ninteracting with a simple Wikipedia API, and generating human-like task-solving\\ntrajectories that are more interpretable than baselines without reasoning traces.\\nFurthermore, on two interactive decision making benchmarks (ALFWorld and\\nWebShop), ReAct outperforms imitation and reinforcement learning methods by\\nan absolute success rate of 34% and 10% respectively, while being prompted with\\nonly one or two in-context examples.\\n1 I NTRODUCTION\\nA unique feature of human intelligence is the ability to seamlessly combine task-oriented actions with\\nverbal reasoning (or inner speech, Alderson-Day & Fernyhough, 2015), which has been theorized to\\nplay an important role in human cognition for enabling self-regulation or strategization (Vygotsky,\\n1987; Luria, 1965; Fernyhough, 2010) and maintaining a working memory (Baddeley, 1992). Con-\\nsider the example of cooking up a dish in the kitchen. Between any two speciﬁc actions, we may\\nreason in language in order to track progress (“now that everything is cut, I should heat up the pot of\\nwater”), to handle exceptions or adjust the plan according to the situation (“I don’t have salt, so let\\nme use soy sauce and pepper instead”), and to realize when external information is needed (“how do\\nI prepare dough? Let me search on the Internet”). We may also act (open a cookbook to read the\\nrecipe, open the fridge, check ingredients) to support the reasoning and to answer questions (“What\\ndish can I make right now?”). This tight synergy between “acting” and “reasoning” allows humans\\nto learn new tasks quickly and perform robust decision making or reasoning, even under previously\\nunseen circumstances or facing information uncertainties.\\nRecent results have hinted at the possibility of combining verbal reasoning with interactive decision\\nmaking in autonomous systems. On one hand, properly prompted large language models (LLMs)\\nhave demonstrated emergent capabilities to carry out several steps of reasoning traces to derive\\n∗Work during Google internship. Projet page with code: https://react-lm.github.io/ .\\n1arXiv:2210.03629v3  [cs.CL]  10 Mar 2023', metadata={'source': '/var/folders/qx/skm_3qm93bg39tjh5fyb02y80000gn/T/tmpv7iq21lk/tmp.pdf', 'page': 0}),\n",
       " Document(page_content='Published as a conference paper at ICLR 2023\\n$FW\\x03\\x14\\x1d\\x037KLQN>)LUVW\\x03,\\x03QHHG\\x03WR\\x03ILQG\\x03D\\x03SHSSHU\\x03VKDNHU\\x11\\x11\\x11PRUH\\x03OLNHO\\\\\\x03WR\\x03DSSHDU\\x03LQ\\x03FDELQHWV\\x03\\x0b\\x14\\x10\\x19\\x0c\\x0f\\x03FRXQWHUWRSV\\x03\\x0b\\x14\\x10\\x16\\x0c\\x0f\\x03\\x11\\x11\\x11\\x03@$FW\\x03\\x15\\x1d\\x03*R\\x03WR\\x03FDELQHW\\x03\\x14\\x032EV\\x03\\x15\\x1d\\x032Q\\x03WKH\\x03FDELQHW\\x03\\x14\\x0f\\x03\\\\RX\\x03VHH\\x03D\\x03YDVH\\x03\\x15\\x11\\x03\\x0b+HUH\\x03WKH\\x03DJHQW\\x03JR\\x03WR\\x03FDELQHW\\x03\\x14\\x0f\\x03WKHQ\\x03FDELQHW\\x03\\x15\\x0f\\x03\\x16\\x0f\\x03WKHQ\\x03FRXQWHUWRS\\x03\\x14\\x03DQG\\x03\\x15\\x0c$FW\\x03\\x19\\x1d\\x03*R\\x03WR\\x03FRXQWHUWRS\\x03\\x16\\x032EV\\x03\\x19\\x1d\\x032Q\\x03WKH\\x03FRXQWHUWRS\\x03\\x16\\x0f\\x03\\\\RX\\x03VHH\\x03D\\x03DSSOH\\x03\\x14\\x0f\\x03D\\x03EUHDG\\x03\\x14\\x0f\\x03\\x11\\x11\\x11\\x11\\x11\\x11\\x03D\\x03SHSSHU\\x03VKDNHU\\x03\\x14\\x0f\\x03DQG\\x03D\\x03YDVH\\x03\\x16\\x11$FW\\x03\\x1a\\x1d\\x037DNH\\x03SHSSHU\\x03VKDNHU\\x03\\x14\\x03IURP\\x03FRXQWHUWRS\\x03\\x16\\x032EV\\x03\\x1a\\x1d\\x03<RX\\x03SLFN\\x03XS\\x03WKH\\x03SHSSHU\\x03VKDNHU\\x03\\x14\\x03IURP\\x03WKH\\x03FRXQWHUWRS\\x03\\x16\\x11\\x03$FW\\x03\\x1b\\x1d\\x037KLQN>1RZ\\x03,\\x03ILQG\\x03D\\x03SHSSHU\\x03VKDNHU\\x03\\x14\\x11\\x031H[W\\x0f\\x03,\\x03QHHG\\x03WR\\x03SXW\\x03LW\\x03LQ\\x12RQ\\x03GUDZHU\\x03\\x14\\x11@$FW\\x03\\x1c\\x1d\\x03*R\\x03WR\\x03GUDZHU\\x03\\x14\\x032EV\\x03\\x1c\\x1d\\x03\\'UDZHU\\x03\\x14\\x03LV\\x03FORVHG\\x11\\x03$FW\\x03\\x14\\x13\\x1d\\x032SHQ\\x03GUDZHU\\x03\\x14\\x032EV\\x03\\x14\\x13\\x1d\\x03<RX\\x03RSHQ\\x03\\'UDZHU\\x03\\x14\\x03ª$FW\\x03\\x14\\x14\\x1d\\x033XW\\x03SHSSHU\\x03VKDNHU\\x03\\x14\\x03LQ\\x12RQ\\x03GUDZHU\\x03\\x14\\x032EV\\x03\\x14\\x14\\x1d\\x03<RX\\x03SXW\\x03SHSSHU\\x03VKDNHU\\x03\\x14\\x03LQ\\x12RQ\\x03WKH\\x03GUDZHU\\x03\\x14\\x11\\x0b\\x14D\\x0c\\x036WDQGDUG$QVZHU\\x1d\\x03L3RG\\x0b\\x14E\\x0c\\x03&R7\\x03\\x0b5HDVRQ\\x032QO\\\\\\x0c7KRXJKW\\x1d\\x03/HW\\nV\\x03WKLQN\\x03VWHS\\x03E\\\\\\x03VWHS\\x11\\x03$SSOH\\x035HPRWH\\x03ZDV\\x03RULJLQDOO\\\\\\x03GHVLJQHG\\x03WR\\x03LQWHUDFW\\x03ZLWK\\x03$SSOH\\x0379\\x11\\x03$SSOH\\x0379\\x03FDQ\\x03EH\\x03FRQWUROOHG\\x03E\\\\\\x03L3KRQH\\x0f\\x03L3DG\\x0f\\x03DQG\\x03L3RG\\x037RXFK\\x11\\x036R\\x03WKH\\x03DQVZHU\\x03LV\\x03L3KRQH\\x0f\\x03L3DG\\x0f\\x03DQG\\x03L3RG\\x037RXFK\\x11$QVZHU\\x1d\\x03L3KRQH\\x0f\\x03L3DG\\x0f\\x03L3RG\\x037RXFK\\x0b\\x14F\\x0c\\x03$FW\\x102QO\\\\\\x03$FW\\x03\\x14\\x1d\\x036HDUFK>$SSOH\\x035HPRWH@\\x032EV\\x03\\x14\\x1d\\x037KH\\x03$SSOH\\x035HPRWH\\x03LV\\x03D\\x03UHPRWH\\x03FRQWURO\\x03ª$FW\\x03\\x15\\x1d\\x036HDUFK>)URQW\\x035RZ@\\x032EV\\x03\\x15\\x1d\\x03&RXOG\\x03QRW\\x03ILQG\\x03>)URQW\\x035RZ@\\x11\\x036LPLODU\\x1d\\x03ª$FW\\x03\\x16\\x1d\\x036HDUFK>)URQW\\x035RZ\\x03\\x0bVRIWZDUH\\x0c@\\x032EV\\x03\\x16\\x1d\\x03)URQW\\x035RZ\\x03LV\\x03D\\x03GLVFRQWLQXHG\\x03PHGLD\\x03FHQWHU\\x03VRIWZDUH\\x03ª$FW\\x03\\x17\\x1d\\x03)LQLVK>\\\\HV@\\x0b\\x14G\\x0c\\x035H$FW\\x03\\x0b5HDVRQ\\x03\\x0e\\x03$FW\\x0c7KRXJKW\\x03\\x14\\x1d\\x03,\\x03QHHG\\x03WR\\x03VHDUFK\\x03$SSOH\\x035HPRWH\\x03DQG\\x03ILQG\\x03WKH\\x03SURJUDP\\x03LW\\x03ZDV\\x03RULJLQDOO\\\\\\x03GHVLJQHG\\x03WR\\x03LQWHUDFW\\x03ZLWK\\x11$FW\\x03\\x14\\x1d\\x036HDUFK>$SSOH\\x035HPRWH@2EV\\x03\\x14\\x1d\\x037KH\\x03$SSOH\\x035HPRWH\\x03LV\\x03D\\x03UHPRWH\\x03FRQWURO\\x03LQWURGXFHG\\x03LQ\\x032FWREHU\\x03\\x15\\x13\\x13\\x18\\x03E\\\\\\x03$SSOH\\x03ª\\x03RULJLQDOO\\\\\\x03GHVLJQHG\\x03WR\\x03FRQWURO\\x03WKH\\x03)URQW\\x035RZ\\x03PHGLD\\x03FHQWHU\\x03SURJUDP\\x03ª7KRXJKW\\x03\\x15\\x1d\\x03$SSOH\\x035HPRWH\\x03ZDV\\x03RULJLQDOO\\\\\\x03GHVLJQHG\\x03WR\\x03FRQWURO\\x03WKH\\x03)URQW\\x035RZ\\x03PHGLD\\x03FHQWHU\\x03SURJUDP\\x11\\x03,\\x03QHHG\\x03WR\\x03VHDUFK\\x03)URQW\\x035RZ\\x03QH[W\\x03DQG\\x03ILQG\\x03ZKDW\\x03RWKHU\\x03GHYLFH\\x03FDQ\\x03FRQWURO\\x03LW\\x11$FW\\x03\\x15\\x1d\\x036HDUFK>)URQW\\x035RZ@2EV\\x03\\x15\\x1d\\x03&RXOG\\x03QRW\\x03ILQG\\x03>)URQW\\x035RZ@\\x11\\x036LPLODU\\x1d\\x03>\\n)URQW\\x035RZ\\x036HDW\\x03WR\\x03(DUWK\\n\\x0f\\x03\\n)URQW\\x035RZ\\x030RWRUVSRUWV\\n\\x0f\\n)URQW\\x035RZ\\x03\\x0bVRIWZDUH\\x0c\\n\\x0f\\x03ª@7KRXJKW\\x03\\x16\\x1d\\x03)URQW\\x035RZ\\x03LV\\x03QRW\\x03IRXQG\\x11\\x03,\\x03QHHG\\x03WR\\x03VHDUFK\\x03)URQW\\x035RZ\\x03\\x0bVRIWZDUH\\x0c\\x03\\x11$FW\\x03\\x16\\x1d\\x036HDUFK>)URQW\\x035RZ\\x03\\x0bVRIWZDUH\\x0c@2EV\\x03\\x16\\x1d\\x03)URQW\\x035RZ\\x03LV\\x03D\\x03GLVFRQWLQXHG\\x03PHGLD\\x03FHQWHU\\x03VRIWZDUH\\x03ª7KRXJKW\\x03\\x17\\x1d\\x03)URQW\\x035RZ\\x03\\x0bVRIWZDUH\\x0c\\x03LV\\x03FRQWUROOHG\\x03E\\\\\\x03DQ\\x03$SSOH\\x035HPRWH\\x03RU\\x03WKH\\x03NH\\\\ERDUG\\x03IXQFWLRQ\\x03NH\\\\V\\x11\\x036R\\x03WKH\\x03DQVZHU\\x03LV\\x03NH\\\\ERDUG\\x03IXQFWLRQ\\x03NH\\\\V\\x11$FW\\x03\\x17\\x1d\\x03)LQLVK>NH\\\\ERDUG\\x03IXQFWLRQ\\x03NH\\\\V@Ҽ4XHVWLRQ\\x1d\\x03$VLGH\\x03IURP\\x03WKH\\x03$SSOH\\x035HPRWH\\x0f\\x03ZKDW\\x03RWKHU\\x03GHYLFH\\x03FDQ\\x03FRQWURO\\x03WKH\\x03SURJUDP\\x03$SSOH\\x035HPRWH\\x03ZDV\\x03RULJLQDOO\\\\\\x03GHVLJQHG\\x03WR\\x03LQWHUDFW\\x03ZLWK\"\\n\\x0b\\x15D\\x0c\\x03$FW\\x102QO\\\\\\x03$FW\\x03\\x14\\x1d\\x03*R\\x03WR\\x03GUDZHU\\x03\\x14\\x032EV\\x03\\x14\\x1d\\x037KH\\x03GUDZHU\\x03\\x14\\x03LV\\x03FORVHG\\x11\\x03$FW\\x03\\x15\\x1d\\x032SHQ\\x03GUDZHU\\x03\\x14\\x032EV\\x03\\x15\\x1d\\x03<RX\\x03RSHQ\\x03WKH\\x03GUDZHU\\x03\\x14\\x11\\x037KH\\x03GUDZHU\\x03\\x14\\x03LV\\x03RSHQ\\x11\\x03,Q\\x03LW\\x0f\\x03\\\\RX\\x03VHH\\x03D\\x03GLVKVSRQJH\\x03\\x15\\x0f\\x03DQG\\x03D\\x03VSRRQ\\x03\\x14\\x11\\x03$FW\\x03\\x16\\x1d\\x03*R\\x03WR\\x03VLQNEDVLQ\\x03\\x14\\x032EV\\x03\\x16\\x1d\\x032Q\\x03WKH\\x03VLQNEDVLQ\\x03\\x14\\x0f\\x03\\\\RX\\x03VHH\\x03D\\x03GLVKVSRQJH\\x03\\x16\\x0f\\x03D\\x03VSDWXOD\\x03\\x14\\x0f\\x03DQG\\x03D\\x03VSRRQ\\x03\\x15\\x11\\x03$FW\\x03\\x17\\x1d\\x037DNH\\x03SHSSHUVKDNHU\\x03\\x14\\x03IURP\\x03VLQNEDVLQ\\x03\\x14\\x032EV\\x03\\x17\\x1d\\x031RWKLQJ\\x03KDSSHQV\\x11\\x03$FW\\x03\\x18\\x1d\\x037DNH\\x03SHSSHUVKDNHU\\x03\\x14\\x03IURP\\x03VLQNEDVLQ\\x03\\x14\\x032EV\\x03\\x18\\x1d\\x031RWKLQJ\\x03KDSSHQV\\x11\\x03\\x0b\\x15E\\x0c\\x035H$FW\\x03\\x0b5HDVRQ\\x03\\x0e\\x03$FW\\x0c\\nҼ<RX\\x03DUH\\x03LQ\\x03WKH\\x03PLGGOH\\x03RI\\x03D\\x03URRP\\x11\\x03/RRNLQJ\\x03TXLFNO\\\\\\x03DURXQG\\x03\\\\RX\\x0f\\x03\\\\RX\\x03VHH\\x03D\\x03FDELQHW\\x03\\x19\\x0f\\x03D\\x03FDELQHW\\x03\\x14\\x0f\\x03D\\x03FRIIHH\\x03PDFKLQH\\x03\\x14\\x0f\\x03D\\x03FRXQWHUWRS\\x03\\x16\\x0f\\x03\\x03D\\x03VWRYH\\x03EXUQHU\\x03\\x14\\x0f\\x03DQG\\x03D\\x03WRDVWHU\\x03\\x14\\x11\\x03<RXU\\x03WDVN\\x03LV\\x03WR\\x1d\\x033XW\\x03VRPH\\x03SHSSHU\\x03VKDNHU\\x03RQ\\x03D\\x03GUDZHU\\x11\\x0b\\x15\\x0c\\x03$OI:RUOG\\x0b\\x14\\x0c\\x03+RWVSRW\\x034$\\nFigure 1: (1) Comparison of 4 prompting methods, (a) Standard , (b) Chain-of-thought ( CoT,\\nReason Only), (c) Act-only, and (d) ReAct (Reason+Act), solving a HotpotQA (Yang et al., 2018)\\nquestion. (2) Comparison of (a) Act-only and (b) ReAct prompting to solve an AlfWorld (Shridhar\\net al., 2020b) game. In both domains, we omit in-context examples in the prompt, and only show task\\nsolving trajectories generated by the model (Act, Thought) and the environment (Obs).\\nanswers from questions in arithmetic, commonsense, and symbolic reasoning tasks (Wei et al.,\\n2022). However, this “chain-of-thought” reasoning is a static black box, in that the model uses\\nits own internal representations to generate thoughts and is not grounded in the external world,\\nwhich limits its ability to reason reactively or update its knowledge. This can lead to issues like fact\\nhallucination and error propagation over the reasoning process (Figure 1 (1b)). On the other hand,\\nrecent work has explored the use of pre-trained language models for planning and acting in interactive\\nenvironments (Ahn et al., 2022; Nakano et al., 2021; Yao et al., 2020; Huang et al., 2022a), with\\na focus on predicting actions via language priors. These approaches usually convert multi-modal\\nobservations into text, use a language model to generate domain-speciﬁc actions or plans, and then\\nuse a controller to choose or execute them. However, they do not employ language models to reason\\nabstractly about high-level goals or maintain a working memory to support acting, barring Huang\\net al. (2022b) who perform a limited form of verbal reasoning to reiterate spatial facts about the\\ncurrent state. Beyond such simple embodied tasks to interact with a few blocks, there have not been\\nstudies on how reasoning and acting can be combined in a synergistic manner for general task solving,\\nand if such a combination can bring systematic beneﬁts compared to reasoning or acting alone.\\nIn this work, we present ReAct , a general paradigm to combine reasoning and acting with language\\nmodels for solving diverse language reasoning and decision making tasks (Figure 1). ReAct\\nprompts LLMs to generate both verbal reasoning traces and actions pertaining to a task in an\\ninterleaved manner, which allows the model to perform dynamic reasoning to create, maintain, and\\nadjust high-level plans for acting (reason to act), while also interact with the external environments\\n(e.g. Wikipedia) to incorporate additional information into reasoning (act to reason).\\n2', metadata={'source': '/var/folders/qx/skm_3qm93bg39tjh5fyb02y80000gn/T/tmpv7iq21lk/tmp.pdf', 'page': 1}),\n",
       " Document(page_content='Published as a conference paper at ICLR 2023\\nWe conduct empirical evaluations of ReAct and state-of-the-art baselines on four diverse benchmarks:\\nquestion answering (HotPotQA, Yang et al., 2018), fact veriﬁcation (Fever, Thorne et al., 2018),\\ntext-based game (ALFWorld, Shridhar et al., 2020b), and webpage navigation (WebShop, Yao\\net al., 2022). For HotPotQA and Fever, with access to a Wikipedia API that the model can interact\\nwith, ReAct outperforms vanilla action generation models while being competitive with chain-of-\\nthought reasoning ( CoT) (Wei et al., 2022). The best approach overall is a combination of ReAct\\nandCoT that allows for the use of both internal knowledge and externally obtained information\\nduring reasoning. On ALFWorld and WebShop, two or even one-shot ReAct prompting is able\\nto outperform imitation or reinforcement learning methods trained with 103∼105task instances,\\nwith an absolute improvement of 34% and 10% in success rates respectively. We also demonstrate\\nthe importance of sparse, versatile reasoning in decision making by showing consistent advantages\\nover controlled baselines with actions only. Besides general applicability and performance boost,\\nthe combination of reasoning and acting also contributes to model interpretability, trustworthiness,\\nand diagnosability across all domains, as humans can readily distinguish information from model’s\\ninternal knowledge versus external environments, as well as inspect reasoning traces to understand\\nthe decision basis of model actions.\\nTo summarize, our key contributions are the following: (1) we introduce ReAct , a novel prompt-\\nbased paradigm to synergize reasoning and acting in language models for general task solving; (2) we\\nperform extensive experiments across diverse benchmarks to showcase the advantage of ReAct in a\\nfew-shot learning setup over prior approaches that perform either reasoning or action generation in\\nisolation; (3) we present systematic ablations and analysis to understand the importance of acting in\\nreasoning tasks, and reasoning in interactive tasks; (4) we analyze the limitations of ReAct under the\\nprompting setup (i.e. limited support of reasoning and acting behaviors), and perform initial ﬁnetuning\\nexperiments showing the potential of ReAct to improve with additional training data. Scaling up\\nReAct to train and operate on more tasks and combining it with complementary paradigms like\\nreinforcement learning could further unlock the potential of large language models.\\n2REAC T: SYNERGIZING REASONING +AC TING\\nConsider a general setup of an agent interacting with an environment for task solving. At time\\nstept, an agent receives an observation ot∈O from the environment and takes an action at∈A\\nfollowing some policy π(at|ct), wherect= (o1,a1,···,ot−1,at−1,ot)is the context to the agent.\\nLearning a policy is challenging when the mapping ct↦→atis highly implicit and requires extensive\\ncomputation. For example, the agent shown in Figure 1(1c) is unable to generate the correct ﬁnal\\naction (Act 4) to ﬁnish the QA task as it requires complex reasoning over the trajectory context\\n(Question, Act 1-3, Obs 1-3). Similarly, the agent shown in Figure 1(2a) fails to comprehend from the\\ncontext that sinkbasin 1 does not contain peppershaker 1, thus keep producing hallucinating actions.\\nThe idea of ReAct is simple: we augment the agent’s action space to ˆA=A∪L , whereLis the\\nspace of language. An action ˆat∈L in the language space, which we will refer to as a thought or a\\nreasoning trace , does not affect the external environment, thus leading to no observation feedback.\\nInstead, a thought ˆataims to compose useful information by reasoning over the current context ct,\\nand update the context ct+1= (ct,ˆat)to support future reasoning or acting. As shown in Figure 1,\\nthere could be various types of useful thoughts, e.g. decomposing task goals and create action plans\\n(2b, Act 1; 1d, Thought 1), injecting commonsense knowledge relevant to task solving (2b, Act 1),\\nextracting important parts from observations (1d, Thought2, 4), track progress and transit action plans\\n(2b, Act 8), handle exceptions and adjust action plans (1d, Thought 3), and so on.\\nHowever, as the language space Lis unlimited, learning in this augmented action space is difﬁcult\\nand requires strong language priors. In this paper, we mainly focus on the setup where a frozen\\nlarge language model, PaLM-540B (Chowdhery et al., 2022)1, is prompted with few-shot in-context\\nexamples to generate both domain-speciﬁc actions and free-form language thoughts for task solving\\n(Figure 1 (1d), (2b)). Each in-context example is a human trajectory of actions, thoughts, and\\nenvironment observations to solve a task instance (see Appendix C). For the tasks where reasoning is\\nof primary importance (Figure 1(1)), we alternate the generation of thoughts and actions so that the\\ntask-solving trajectory consists of multiple thought-action-observation steps. In contrast, for decision\\nmaking tasks that potentially involve a large number of actions (Figure 1(2)), thoughts only need to\\n1We show some GPT-3 (Brown et al., 2020) results in Appendix A.1, which outperforms PaLM-540B.\\n3', metadata={'source': '/var/folders/qx/skm_3qm93bg39tjh5fyb02y80000gn/T/tmpv7iq21lk/tmp.pdf', 'page': 2}),\n",
       " Document(page_content='Published as a conference paper at ICLR 2023\\nappear sparsely in the most relevant positions of a trajectory, so we let the language model decide the\\nasynchronous occurrence of thoughts and actions for itself.\\nSince decision making and reasoning capabilities are integrated into a large language model, ReAct\\nenjoys several unique features: A) Intuitive and easy to design : Designing ReAct prompts is\\nstraightforward as human annotators just type down their thoughts in language on top of their actions\\ntaken. No ad-hoc format choice, thought design, or example selection is used in this paper. We detail\\nprompt design for each task in Sections 3 and 4. B) General and ﬂexible : Due to the ﬂexible thought\\nspace and thought-action occurrence format, ReAct works for diverse tasks with distinct action\\nspaces and reasoning needs, including but not limited to QA, fact veriﬁcation, text game, and web\\nnavigation. C) Performant and robust :ReAct shows strong generalization to new task instances\\nwhile learning solely from one to six in-context examples, consistently outperforming baselines with\\nonly reasoning or acting across different domains. We also show in Section 3 additional beneﬁts\\nwhen ﬁnetuning is enabled, and in Section 4 how ReAct performance is robust to prompt selections.\\nD) Human aligned and controllable :ReAct promises an interpretable sequential decision making\\nand reasoning process where humans can easily inspect reasoning and factual correctness. Moreover,\\nhumans can also control or correct the agent behavior on the go by thought editing, as shown in\\nFigure 5 in Section 4.\\n3 K NOWLEDGE -INTENSIVE REASONING TASKS\\nWe begin with knowledge-intensive reasoning tasks like multi-hop question answering and fact\\nveriﬁcation. As shown in Figure 1(1d), by interacting with a Wikipedia API, ReAct is able to\\nretrieve information to support reasoning, while also use reasoning to target what to retrieve next,\\ndemonstrating a synergy of reasoning and acting.\\n3.1 S ETUP\\nDomains We consider two datasets challenging knowledge retrieval and reasoning: (1) Hot-\\nPotQA (Yang et al., 2018), a multi-hop question answering benchmark that requires reasoning\\nover two or more Wikipedia passages, and (2) FEVER (Thorne et al., 2018), a fact veriﬁcation\\nbenchmark where each claim is annotated SUPPORTS, REFUTES, or NOT ENOUGH INFO, based\\non if there exists a Wikipedia passage to verify the claim. In this work, we operate in a question-only\\nsetup for both tasks, where models only receive the question/claim as input without access to support\\nparagraphs, and have to rely on their internal knowledge or retrieve knowledge via interacting with\\nan external environment to support reasoning.\\nAction Space We design a simple Wikipedia web API with three types of actions to support\\ninteractive information retrieval: (1) search [entity ], which returns the ﬁrst 5 sentences from\\nthe corresponding entity wiki page if it exists, or else suggests top-5 similar entities from the\\nWikipedia search engine, (2) lookup [string ], which would return the next sentence in the page\\ncontaining string , simulating Ctrl+F functionality on the browser. (3) finish [answer ], which\\nwould ﬁnish the current task with answer . We note that this action space mostly can only retrieve a\\nsmall part of a passage based on exact passage name, which is signiﬁcantly weaker than state-of-the-\\nart lexical or neural retrievers. The purpose is to simulate how humans would interact with Wikipedia,\\nand force models to retrieve via explicit reasoning in language.\\n3.2 M ETHODS\\nReAct Prompting For HotpotQA and Fever, we randomly select 6 and 3 cases2from the training\\nset and manually compose ReAct -format trajectories to use as few-shot exemplars in the prompts.\\nSimilar to Figure 1(d), each trajectory consists of multiple thought-action-observation steps (i.e. dense\\nthought), where free-form thoughts are used for various purposes. Speciﬁcally, we use a combination\\nof thoughts that decompose questions (“I need to search x, ﬁnd y, then ﬁnd z”), extract information\\nfrom Wikipedia observations (“x was started in 1844”, “The paragraph does not tell x”), perform\\ncommonsense (“x is not y, so z must instead be...”) or arithmetic reasoning (“1844 < 1989”), guide\\n2We ﬁnd more examples do not improve performance.\\n4', metadata={'source': '/var/folders/qx/skm_3qm93bg39tjh5fyb02y80000gn/T/tmpv7iq21lk/tmp.pdf', 'page': 3}),\n",
       " Document(page_content='Published as a conference paper at ICLR 2023\\nPrompt Methoda HotpotQA Fever\\n(EM) (Acc)\\nStandard 28.7 57.1\\nCoT (Wei et al., 2022) 29.4 56.3\\nCoT-SC (Wang et al., 2022a) 33.4 60.4\\nAct 25.7 58.9\\nReAct 27.4 60.9\\nCoT-SC→ReAct 34.2 64.6\\nReAct→CoT-SC 35.1 62.0\\nSupervised SoTAb67.5 89.5\\nTable 1: PaLM-540B prompting results on\\nHotpotQA and Fever.\\naHotpotQA EM is 27.1, 28.9, 33.8 for Standard ,CoT,\\nCoT-SC in Wang et al. (2022b).\\nb(Zhu et al., 2021; Lewis et al., 2020)\\n0 5 10 15 20\\n#CoT-SC trials2628303234HotpotQA EM\\n0 5 10 15 20\\n#CoT-SC trials47.550.052.555.057.560.062.565.0Fever AccMethod\\nCoT-SC -> ReAct\\nReAct -> CoT-SC\\nCoT-SC\\nReAct\\nCoTFigure 2: PaLM-540B prompting results with respect to\\nnumber of CoT-SC samples used.\\nsearch reformulation (“maybe I can search/look up x instead”), and synthesize the ﬁnal answer (“...so\\nthe answer is x”). See Appendix C for more details.\\nBaselines We systematically ablate ReAct trajectories to build prompts for multiple baselines (with\\nformats as Figure 1(1a-1c)): (a) Standard prompting (Standard ), which removes all thoughts,\\nactions, observations in ReAct trajectories. (b) Chain-of-thought prompting (CoT) (Wei et al.,\\n2022), which removes actions and observations and serve as a reasoning-only baseline. We also\\nbuild a self-consistency baseline ( CoT-SC ) (Wang et al., 2022a;b) by sampling 21 CoT trajectories\\nwith decoding temperature 0.7 during inference and adopting the majority answer, which is found to\\nconsistently boost performance over CoT. (c)Acting-only prompt (Act), which removes thoughts\\ninReAct trajectories, loosely resembling how WebGPT (Nakano et al., 2021) interacts with the\\nInternet to answer questions, though it operates on a different task and action space, and uses imitation\\nand reinforcement learning instead of prompting.\\nCombining Internal and External Knowledge As will be detail in Section 3.3, we observe that\\nthe problem solving process demonstrated by ReAct is more factual and grounded, whereas CoT\\nis more accurate in formulating reasoning structure but can easily suffer from hallucinated facts\\nor thoughts. We therefore propose to incorporate ReAct andCoT-SC , and let the model decide\\nwhen to switch to the other method based on the following heuristics: A) ReAct→CoT-SC : when\\nReAct fails to return an answer within given steps, back off to CoT-SC . We set 7 and 5 steps for\\nHotpotQA and FEVER respectively as we ﬁnd more steps will not improve ReAct performance3.\\nB)CoT-SC→ReAct : when the majority answer among nCoT-SC samples occurs less than n/2\\ntimes (i.e. internal knowledge might not support the task conﬁdently), back off to ReAct .\\nFinetuning Due to the challenge of manually annotating reasoning traces and actions at scale,\\nwe consider a bootstraping approach similar to Zelikman et al. (2022), using 3,000 trajectories\\nwith correct answers generated by ReAct (also for other baselines) to ﬁnetune smaller language\\nmodels (PaLM-8/62B) to decode trajectories (all thoughts, actions, observations) conditioned on\\ninput questions/claims. More details are in Appendix B.1.\\n3.3 R ESULTS AND OBSERVATIONS\\nReAct outperforms Act consistently Table 1 shows HotpotQA and Fever results using PaLM-\\n540B as the base model with different prompting methods. We note that ReAct is better than Act\\non both tasks, demonstrating the value of reasoning to guide acting, especially for synthesizing the\\nﬁnal answer, as shown in Figure 1 (1c-d). Fine-tuning results 3 also conﬁrm the beneﬁt of reasoning\\ntraces for more informed acting.\\n3Of all trajectories with correct ﬁnal answers, those with 7 steps on HotpotQA and 5 steps on FEVER only\\ntake up 0.84% and 1.33% respectively.\\n5', metadata={'source': '/var/folders/qx/skm_3qm93bg39tjh5fyb02y80000gn/T/tmpv7iq21lk/tmp.pdf', 'page': 4}),\n",
       " Document(page_content='Published as a conference paper at ICLR 2023\\nType Deﬁnition ReAct CoT\\nSuccessTrue positive Correct reasoning trace and facts 94% 86%\\nFalse positive Hallucinated reasoning trace or facts 6% 14%\\nFailureReasoning error Wrong reasoning trace (including failing to recover from repetitive steps) 47% 16%\\nSearch result error Search return empty or does not contain useful information 23% -\\nHallucination Hallucinated reasoning trace or facts 0% 56%\\nLabel ambiguity Right prediction but did not match the label precisely 29% 28%\\nTable 2: Types of success and failure modes of ReAct andCoT on HotpotQA, as well as their\\npercentages in randomly selected examples studied by human.\\nReAct vs.CoT On the other hand, ReAct outperforms CoT on Fever (60.9 vs. 56.3) and slightly\\nlags behind CoT on HotpotQA (27.4 vs. 29.4). Fever claims for SUPPORTS/REFUTES might only\\ndiffer by a slight amount (see Appendix D.1), so acting to retrieve accurate and up-to-date knowledge\\nis vital. To better understand the behavioral difference between ReAct andCoT on HotpotQA, we\\nrandomly sampled 50 trajectories with correct and incorrect answers (judged by EM) from ReAct\\nandCoT respectively (thus 200 examples in total), and manually labeled their success and failure\\nmodes in Table 2. Some key observations are as follows:\\nA)Hallucination is a serious problem for CoT, resulting in much higher false positive rate than\\nReAct (14% vs. 6%) in success mode, and make up its major failure mode (56%). In contrast, the\\nproblem solving trajectory of ReAct is more grounded, fact-driven, and trustworthy, thanks to the\\naccess of an external knowledge base.\\nB)While interleaving reasoning, action and observation steps improves ReAct ’s grounded-\\nness and trustworthiness, such a structural constraint also reduces its ﬂexibility in formulating\\nreasoning steps , leading to more reasoning error rate than CoT. we note that there is one frequent\\nerror pattern speciﬁc to ReAct , in which the model repetitively generates the previous thoughts and\\nactions, and we categorize it as part of “reasoning error” as the model fails to reason about what the\\nproper next action to take and jump out of the loop4.\\nC)ForReAct , successfully retrieving informative knowledge via search is critical. Non-\\ninformative search, which counts for 23% of the error cases, derails the model reasoning and gives\\nit a hard time to recover and reformulate thoughts. This is perhaps an expected trade-off between\\nfactuality and ﬂexibility, which motivates our proposed strategies of combining two methods.\\nWe provide examples for each success and failure modes in Appendix E.1. We also ﬁnd some\\nHotpotQA questions may contain outdated answer labels, see Figure 4 for example.\\nReAct +CoT-SC perform best for prompting LLMs Also shown in Table 1, the best prompting\\nmethod on HotpotQA and Fever are ReAct→CoT-SC andCoT-SC→ReAct respectively.\\nFurthermore, Figure 2 shows how different methods perform with respect to the number of CoT-SC\\nsamples used. While two ReAct +CoT-SC methods are advantageous at one task each, they both\\nsigniﬁcantly and consistently outperform CoT-SC across different number of samples, reaching\\nCoT-SC performance with 21 samples using merely 3-5 samples. These results indicate the value of\\nproperly combining model internal knowledge and external knowledge for reasoning tasks.\\nReAct performs best for ﬁne-tuning Figure 3 shows the scaling effect of prompting/ﬁnetuning\\nfour methods ( Standard ,CoT,Act,ReAct ) on HotpotQA. With PaLM-8/62B, prompting ReAct\\nperforms worst among four methods due to the difﬁculty to learn both reasoning and acting from\\nin-context examples. However, when ﬁnetuned with just 3,000 examples, ReAct becomes the best\\nmethod among the four, with PaLM-8B ﬁnetuned ReAct outperforming all PaLM-62B prompting\\nmethods, and PaLM-62B ﬁnetuned ReAct outperforming all 540B prompting methods. In contrast,\\nﬁnetuning Standard orCoT is signiﬁcantly worse than ﬁnetuning ReAct orAct for both PaLM-\\n8/62B, as the former essentially teaches models to memorize (potentially halluincated) knowledge\\nfacts, and the latter teaches models how to (reason and) act to access information from Wikipedia, a\\nmore generalizable skill for knowledge reasoning. As all prompting methods are still signiﬁcantly\\nfar from domain-speciﬁc state-of-the-art approaches (Table 1), we believe ﬁnetuning with more\\nhuman-written data might be a better way to unleash the power of ReAct .\\n4We suspect that this could be due to the sub-optimal greedy decoding procedure, and future work using\\nbetter decoding (e.g. beam search) might help address this issue.\\n6', metadata={'source': '/var/folders/qx/skm_3qm93bg39tjh5fyb02y80000gn/T/tmpv7iq21lk/tmp.pdf', 'page': 5}),\n",
       " Document(page_content='Published as a conference paper at ICLR 2023\\n8b 62b 540b\\nsize051015202530HotpotQA EMlearning = prompt\\n8b 62b 540b\\nsizelearning = finetune\\nMethod\\nStandard\\nCoT\\nAct\\nReAct\\nFigure 3: Scaling results for prompting and ﬁnetuning on HotPotQA with ReAct (ours) and baselines.\\n4 D ECISION MAKING TASKS\\nWe also test ReAct on two language-based interactive decision-making tasks, ALFWorld and\\nWebShop, both of which feature complex environments that require agents to act over long horizons\\nwith sparse rewards, warranting the need for reasoning to act and explore effectively.\\nALFWorld ALFWorld (Shridhar et al., 2020b) (Figure 1(2)) is a synthetic text-based game designed\\nto align with the embodied ALFRED benchmark (Shridhar et al., 2020a). It includes 6 types of\\ntasks in which an agent needs to achieve a high-level goal (e.g. examine paper under desklamp) by\\nnavigating and interacting with a simulated household via text actions (e.g. go to coffeetable 1, take\\npaper 2, use desklamp 1). A task instance can have more than 50 locations and take an expert policy\\nmore than 50 steps to solve, thus challenging an agent to plan and track subgoals, as well as explore\\nsystematically (e.g. check all desks one by one for desklamp). In particular, one challenge built into\\nALFWorld is the need to determine likely locations for common household items (e.g. desklamps will\\nlikely be on desks, shelfs, or dressers), making this environment a good ﬁt for LLMs to exploit their\\npretrained commonsense knowledge. To prompt ReAct , we randomly annotate three trajectories\\nfrom the training set for each task type, where each trajectory includes sparse thoughts that (1)\\ndecompose the goal, (2) track subgoal completion, (3) determine the next subgoal, and (4) reason via\\ncommonsense where to ﬁnd an object and what to do with it. We show prompts used for ALFWorld\\nin Appendix C.4. Following Shridhar et al. (2020b), we evaluate on 134 unseen evaluation games\\nin a task-speciﬁc setup. For robustness, we construct 6 prompts for each task type through each\\npermutation of 2 annotated trajectories from the 3 we annotate. Act prompts are constructed using\\nthe same trajectories, but without thoughts — since task instances are randomly chosen from the\\ntraining set, it favors neither ReAct norAct and provides a fair and controlled comparison to test the\\nimportance of sparse thoughts. For baselines, we use BUTLER (Shridhar et al., 2020b), an imitation\\nlearning agent trained on 105expert trajectories for each task type5.\\nWebShop CanReAct also interact with noisy real-world language environments for practical\\napplications? We investigate WebShop (Yao et al., 2022), a recently proposed online shopping\\nwebsite environment with 1.18M real-world products and 12k human instructions. Unlike ALFWorld,\\nWebshop contains a high variety of structured and unstructured texts (e.g. product titles, descriptions,\\nand options crawled from Amazon), and requires an agent to purchase a product based on a user\\ninstruction (e.g. “I am looking for a nightstand with drawers. It should have a nickel ﬁnish, and\\npriced lower than $140”) through web interactions (e.g. search “nightstand drawers”, choose buttons\\nsuch as “color: modern-nickel-white” or “back to search”). This task is evaluated by average score\\n(percentage of desired attributes covered by the chosen product averaged across all episodes) and\\nsuccess rate (percentage of episodes where the chosen product satisﬁes all requirements) on 500 test\\ninstructions. We formulate Act prompts with actions to search, choose product, choose options,\\nand buy, with ReAct prompts additionally reasoning to determine what to explore, when to buy,\\nand what products options are relevant to the instruction. See Table 6 for an example prompt, and\\nTable 10 for model predictions in the Appendix. We compare to an imitation learning (IL) method\\n5Micheli & Fleuret (2021) ﬁnetuned a GPT-2 model on 3553 task instances and achieved a much improved\\nperformance than BUTLER, but it is trained on all task types, thus not included as a baseline.\\n7', metadata={'source': '/var/folders/qx/skm_3qm93bg39tjh5fyb02y80000gn/T/tmpv7iq21lk/tmp.pdf', 'page': 6}),\n",
       " Document(page_content='Published as a conference paper at ICLR 2023\\nMethod Pick Clean Heat Cool Look Pick 2 All\\nAct (best of 6) 88 42 74 67 72 41 45\\nReAct (avg) 65 39 83 76 55 24 57\\nReAct (best of 6) 92 58 96 86 78 41 71\\nReAct-IM (avg) 55 59 60 55 23 24 48\\nReAct-IM (best of 6) 62 68 87 57 39 33 53\\nBUTLER g(best of 8) 33 26 70 76 17 12 22\\nBUTLER (best of 8) 46 39 74 100 22 24 37\\nTable 3: AlfWorld task-speciﬁc success rates (%). BUTLER and\\nBUTLER gresults are from Table 4 of Shridhar et al. (2020b). All\\nmethods use greedy decoding, except that BUTLER uses beam search.Method Score SR\\nAct 62.3 30.1\\nReAct 66.6 40.0\\nIL 59.9 29.1\\nIL+RL 62.4 28.7\\nHuman82.1 59.6Expert\\nTable 4: Score and suc-\\ncess rate (SR) on Web-\\nshop. IL/IL+RL taken\\nfrom Yao et al. (2022).\\ntrained with 1,012 human annotated trajectories, and a imitation + reinforcement learning (IL + RL)\\nmethod additionally trained with 10,587 training instructions.\\nResults ReAct outperforms Act on both ALFWorld (Table 3) and Webshop (Table 4). On\\nALFWorld, the best ReAct trial achieves an average success rate of 71%, signiﬁcantly outperforming\\nthe best Act (45%) and BUTLER (37%) trials. In fact, even the worse ReAct trial (48%) beats\\nthe best trial of both methods. Moreover, the advantage of ReAct overAct is consistent across\\nsix controlled trials, with relative performance gain ranging from 33% to 90% and averaging 62%.\\nQualitatively, we saw that, without any thoughts at all, Act fails to correctly decompose goals\\ninto smaller subgoals, or loses track of the current state of the environment. Example trajectories\\ncomparing ReAct andAct can be found in Appendix D.2.1 and Appendix D.2.2.\\nOn Webshop, one-shot Act prompting already performs on par with IL and IL+RL methods. With\\nadditional sparse reasoning, ReAct achieves signiﬁcantly better performance, with an absolute 10%\\nimprovement over the previous best success rate. By checking examples, we ﬁnd that ReAct is more\\nlikely to identify instruction-relevant products and options by reasoning to bridge the gap between\\nnoisy observations and actions (e.g. “For ‘space-saving ottoman bench for living room’, the item\\nhas options ‘39x18x18inch’ and ‘blue’ and seems good to buy.”). However, existing methods are\\nstill far from the performance of expert humans (Table 4), who perform signiﬁcantly more product\\nexplorations and query re-formulations that are still challenging for prompting-based methods.\\nOn the value of internal reasoning vs. external feedback To our knowledge, ReAct is the ﬁrst\\ndemonstration of combined reasoning and action using an LLM applied to an interactive environment\\nwithin a closed-loop system. Perhaps the closest prior work is Inner Monologue (IM), from Huang\\net al. (2022b), in which actions from an embodied agent are motivated by an eponymous “inner\\nmonologue”. However, IM’s “inner monologue” is limited to observations of the environment\\nstate and what needs to be completed by the agent for the goal to be satisﬁed. In contrast, the\\nreasoning traces in ReAct for decision making is ﬂexible and sparse, allowing diverse reasoning\\ntypes (see Section 2) to be induced for different tasks.\\nTo demonstrate the differences between ReAct and IM, and to highlight the importance of internal\\nreasoning vs. simple reactions to external feedback, we ran an ablation experiment using a thought\\npattern composed of IM-like dense external feedback. As can be seen in Table 3, ReAct substantially\\noutperforms IM-style prompting ( ReAct-IM ) (71 vs. 53 overall success rate), with consistent\\nadvantages on ﬁve out of six tasks. Qualitatively, we observed that ReAct-IM often made mistakes\\nin identifying when subgoals were ﬁnished, or what the next subgoal should be, due to a lack of high-\\nlevel goal decomposition. Additionally, many ReAct-IM trajectories struggled to determine where\\nan item would likely be within the ALFWorld environment, due to a lack of commonsense reasoning.\\nBoth shortcomings can be addressed in the ReAct paradigm. More details about ReAct-IM is in\\nAppendix B.2. An example prompt for ReAct-IM can be found in Appendix C.4, and an example\\ntrajectory in Appendix D.2.3.\\n8', metadata={'source': '/var/folders/qx/skm_3qm93bg39tjh5fyb02y80000gn/T/tmpv7iq21lk/tmp.pdf', 'page': 7}),\n",
       " Document(page_content='Published as a conference paper at ICLR 2023\\n5 R ELATED WORK\\nLanguage model for reasoning Perhaps the most well-known work of using LLMs for reasoning\\nis Chain-of-Thought (CoT) (Wei et al., 2022), which reveals the ability of LLMs to formulate their\\nown “thinking procedure” for problem solving. Several follow-up works have since been performed,\\nincluding least-to-most prompting for solving complicated tasks (Zhou et al., 2022), zero-shot-\\nCoT (Kojima et al., 2022), and reasoning with self-consistency (Wang et al., 2022a). Recently,\\n(Madaan & Yazdanbakhsh, 2022) systematically studied the formulation and structure of CoT, and\\nobserved that the presence of symbols, patterns and texts is crucial to the effectiveness of CoT. Other\\nwork has also been extended to more sophisticated reasoning architecture beyond simple prompting.\\nFor example Selection-Inference (Creswell et al., 2022) divides the reasoning process into two steps\\nof “selection” and “inference”. STaR (Zelikman et al., 2022) bootstraps the reasoning process by\\nﬁnetuning the model on correct rationales generated by the model itself. Faithful reasoning (Creswell\\n& Shanahan, 2022) decomposes multi-step reasoning into three steps, each performed by a dedicated\\nLM respectively. Similar approaches like Scratchpad (Nye et al., 2021), which ﬁnetunes a LM on\\nintermediate computation steps, also demonstrate improvement on multi-step computation problems.\\nIn contrast to these methods, ReAct performs more than just isolated, ﬁxed reasoning, and integrates\\nmodel actions and their corresponding observations into a coherent stream of inputs for the model to\\nreason more accurately and tackle tasks beyond reasoning (e.g. interactive decision making).\\nLanguage model for decision making The strong capability of LLMs has enabled them to perform\\ntasks beyond language generation, and it is becoming more popular to take advantage of LLMs as a\\npolicy model for decision making, especially in interactive environments. WebGPT (Nakano et al.,\\n2021) uses an LM to interact with web browsers, navigate through web pages, and infer answers to\\ncomplicated questions from ELI5 (Fan et al., 2019). In comparison to ReAct , WebGPT does not\\nexplicitly model the thinking and reasoning procedure, instead rely on expensive human feedback for\\nreinforcement learning. In conversation modeling, chatbots like BlenderBot (Shuster et al., 2022b)\\nand Sparrow (Glaese et al., 2022) and task-oriented dialogue systems like SimpleTOD (Hosseini-Asl\\net al., 2020) also train LMs to make decision about API calls. Unlike ReAct , they do not explicitly\\nconsider the reasoning procedure either, and also relies on expensive datasets and human feedback\\ncollections for policy learning. In contrast, ReAct learns a policy in a much cheaper way, since the\\ndecision making process only requires language description of the reasoning procedure.6\\nLLMS have also been increasingly employed in interactive and embodied environments for planning\\nand decision making. Perhaps most relevant to ReAct in this respect are SayCan (Ahn et al., 2022)\\nand Inner Monologue (Huang et al., 2022b), which use LLMs for robotic action planning and decision\\nmaking. In SayCan, LLMs were prompted to directly predict possible actions a robot can take, which\\nis then reranked by an affordance model grounded on the visual environments for ﬁnal prediction.\\nInner Monologue made further improvements by adding the eponymous “inner monologue\", which is\\nimplemented as injected feedback from the environment. To our knowledge, Inner Monologue is the\\nﬁrst work that demonstrates such a closed-loop system, which ReAct builds on. However, we argue\\nthat Inner Monologue does not truly comprise of inner thoughts — this is elaborated in Section 4. We\\nalso note that leveraging language as semantically-rich inputs in the process of interactive decision\\nmaking has been shown to be successful under other settings (Abramson et al., 2020; Karamcheti\\net al., 2021; Huang et al., 2022a; Li et al., 2022). It is becoming more evident that with the help of\\nLLMs, language as a fundamental cognitive mechanism will play a critical role in interaction and\\ndecision making. What is more, progress in LLMs has also inspired the development of versatile and\\ngeneralist agents like Reed et al. (2022).\\n6 C ONCLUSION\\nWe have proposed ReAct – a simple yet effective method for synergizing reasoning and acting in\\nlarge language models. Through a diverse set of experiments on multi-hop question-answering, fact\\nchecking, and interactive decision-making tasks, we show that ReAct leads to superior performance\\nwith interpretable decision traces. Despite the simplicity of our method, complex tasks with large\\naction spaces require more demonstrations to learn well, which unfortunately can easily go beyond\\nthe input length limit of in-context learning. We explore the ﬁne-tuning approach on HotpotQA\\n6Human feedback can also be incorporated in a complementary manner but we leave it for future work.\\n9', metadata={'source': '/var/folders/qx/skm_3qm93bg39tjh5fyb02y80000gn/T/tmpv7iq21lk/tmp.pdf', 'page': 8}),\n",
       " Document(page_content='Published as a conference paper at ICLR 2023\\nwith initial promising results, but learning from more high-quality human annotations will be the\\ndesiderata to further improve the performance. Scaling up ReAct with multi-task training and\\ncombining it with complementary paradigms like reinforcement learning could result in stronger\\nagents that further unlock the potential of LLMs for more applications.\\nACKNOWLEDGMENTS\\nWe thank the support and feedback of many people from Google Brain team and Princeton NLP\\nGroup. This work was supported in part by the National Science Foundation under Grant No.\\n2107048. Any opinions, ﬁndings, and conclusions or recommendations expressed in this material are\\nthose of the author(s) and do not necessarily reﬂect the views of the National Science Foundation.\\nREPRODUCIBILITY STATEMENT\\nOur main experiments are done on PaLM (Chowdhery et al., 2022), which is not an openly accessible\\nmodel yet. To increase reproducibility, we have included all used prompts in Appendix C, additional\\nexperiments using GPT-3 (Brown et al., 2020) in Appendix A.1, and associated GPT-3 ReAct\\nprompting code at https://anonymous.4open.science/r/ReAct-2268/ .\\nETHICS STATEMENT\\nReAct prompts large language models to generate more human interpretable, diagnosable, and\\ncontrollable task-solving trajectories than previous methods. However, hooking up a large language\\nmodel with an action space to interact with external environments (e.g. the web, physical environ-\\nments) has potential dangers, e.g. looking up inappropriate or private information, or taking harmful\\nactions in an environment. Our experiments minimize such risks by limiting the interactions to\\nspeciﬁc websites (Wikipedia or WebShop) that are free of private information, without any dangerous\\nactions in the action space design (i.e. models cannot really buy products on WebShop the research\\nbenchmark, or edit Wikipedia). We believe researchers should be aware of such risks before designing\\nmore extensive experiments in the future.\\nREFERENCES\\nJosh Abramson, Arun Ahuja, Iain Barr, Arthur Brussee, Federico Carnevale, Mary Cassin, Rachita\\nChhaparia, Stephen Clark, Bogdan Damoc, Andrew Dudzik, Petko Georgiev, Aurelia Guy, Tim\\nHarley, Felix Hill, Alden Hung, Zachary Kenton, Jessica Landon, Timothy Lillicrap, Kory Mathew-\\nson, So ˇna Mokrá, Alistair Muldal, Adam Santoro, Nikolay Savinov, Vikrant Varma, Greg Wayne,\\nDuncan Williams, Nathaniel Wong, Chen Yan, and Rui Zhu. Imitating interactive intelligence,\\n2020. URL https://arxiv.org/abs/2012.05672 .\\nMichael Ahn, Anthony Brohan, Noah Brown, Yevgen Chebotar, Omar Cortes, Byron David, Chelsea\\nFinn, Chuyuan Fu, Keerthana Gopalakrishnan, Karol Hausman, Alex Herzog, Daniel Ho, Jasmine\\nHsu, Julian Ibarz, Brian Ichter, Alex Irpan, Eric Jang, Rosario Jauregui Ruano, Kyle Jeffrey, Sally\\nJesmonth, Nikhil J Joshi, Ryan Julian, Dmitry Kalashnikov, Yuheng Kuang, Kuang-Huei Lee,\\nSergey Levine, Yao Lu, Linda Luu, Carolina Parada, Peter Pastor, Jornell Quiambao, Kanishka\\nRao, Jarek Rettinghouse, Diego Reyes, Pierre Sermanet, Nicolas Sievers, Clayton Tan, Alexander\\nToshev, Vincent Vanhoucke, Fei Xia, Ted Xiao, Peng Xu, Sichun Xu, Mengyuan Yan, and\\nAndy Zeng. Do as i can, not as i say: Grounding language in robotic affordances, 2022. URL\\nhttps://arxiv.org/abs/2204.01691 .\\nBen Alderson-Day and Charles Fernyhough. Inner speech: development, cognitive functions,\\nphenomenology, and neurobiology. Psychological bulletin , 141(5):931, 2015.\\nAlan Baddeley. Working memory. Science , 255(5044):556–559, 1992.\\nTom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal,\\nArvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. Language models are\\nfew-shot learners. Advances in neural information processing systems , 33:1877–1901, 2020.\\n10', metadata={'source': '/var/folders/qx/skm_3qm93bg39tjh5fyb02y80000gn/T/tmpv7iq21lk/tmp.pdf', 'page': 9}),\n",
       " Document(page_content='Published as a conference paper at ICLR 2023\\nAakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam\\nRoberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, et al. Palm:\\nScaling language modeling with pathways. arXiv preprint arXiv:2204.02311 , 2022.\\nAntonia Creswell and Murray Shanahan. Faithful reasoning using large language models, 2022. URL\\nhttps://arxiv.org/abs/2208.14271 .\\nAntonia Creswell, Murray Shanahan, and Irina Higgins. Selection-inference: Exploiting large\\nlanguage models for interpretable logical reasoning, 2022. URL https://arxiv.org/abs/\\n2205.09712 .\\nAngela Fan, Yacine Jernite, Ethan Perez, David Grangier, Jason Weston, and Michael Auli. ELI5:\\nLong form question answering. In Proceedings of the 57th Annual Meeting of the Association\\nfor Computational Linguistics , pp. 3558–3567, Florence, Italy, July 2019. Association for Com-\\nputational Linguistics. doi: 10.18653/v1/P19-1346. URL https://aclanthology.org/\\nP19-1346 .\\nCharles Fernyhough. Vygotsky, luria, and the social brain. Self and social regulation: Social\\ninteraction and the development of social understanding and executive functions , pp. 56–79, 2010.\\nAmelia Glaese, Nat McAleese, Maja Trebacz, John Aslanides, Vlad Firoiu, Timo Ewalds, Mari-\\nbeth Rauh, Laura Weidinger, Martin Chadwick, Phoebe Thacker, Lucy Campbell-Gillingham,\\nJonathan Uesato, Po-Sen Huang, Ramona Comanescu, Fan Yang, Abigail See, Sumanth\\nDathathri, Rory Greig, Charlie Chen, Doug Fritz, Jaume Sanchez Elias, Richard Green,\\nSoˇna Mokrá, Nicholas Fernando, Boxi Wu, Rachel Foley, Susannah Young, Iason Gabriel,\\nWilliam Isaac, John Mellor, Demis Hassabis, Koray Kavukcuoglu, Lisa Anne Hendricks, and\\nGeoffrey Irving. Improving alignment of dialogue agents via targeted human judgements,\\n2022. URL https://storage.googleapis.com/deepmind-media/DeepMind.\\ncom/Authors-Notes/sparrow/sparrow-final.pdf .\\nEhsan Hosseini-Asl, Bryan McCann, Chien-Sheng Wu, Semih Yavuz, and Richard Socher. A simple\\nlanguage model for task-oriented dialogue. Advances in Neural Information Processing Systems ,\\n33:20179–20191, 2020.\\nWenlong Huang, Pieter Abbeel, Deepak Pathak, and Igor Mordatch. Language models as zero-shot\\nplanners: Extracting actionable knowledge for embodied agents. arXiv preprint arXiv:2201.07207 ,\\n2022a.\\nWenlong Huang, Fei Xia, Ted Xiao, Harris Chan, Jacky Liang, Pete Florence, Andy Zeng, Jonathan\\nTompson, Igor Mordatch, Yevgen Chebotar, et al. Inner monologue: Embodied reasoning through\\nplanning with language models. arXiv preprint arXiv:2207.05608 , 2022b.\\nSiddharth Karamcheti, Megha Srivastava, Percy Liang, and Dorsa Sadigh. Lila: Language-informed\\nlatent actions. In CoRL , pp. 1379–1390, 2021. URL https://proceedings.mlr.press/\\nv164/karamcheti22a.html .\\nTakeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa. Large\\nlanguage models are zero-shot reasoners. arXiv preprint arXiv:2205.11916 , 2022.\\nAngeliki Lazaridou, Elena Gribovskaya, Wojciech Stokowiec, and Nikolai Grigorev. Internet-\\naugmented language models through few-shot prompting for open-domain question answering.\\narXiv preprint arXiv:2203.05115 , 2022.\\nPatrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal,\\nHeinrich Küttler, Mike Lewis, Wen-tau Yih, Tim Rocktäschel, et al. Retrieval-augmented genera-\\ntion for knowledge-intensive nlp tasks. Advances in Neural Information Processing Systems , 33:\\n9459–9474, 2020.\\nShuang Li, Xavier Puig, Chris Paxton, Yilun Du, Clinton Wang, Linxi Fan, Tao Chen, De-An\\nHuang, Ekin Akyürek, Anima Anandkumar, Jacob Andreas, Igor Mordatch, Antonio Torralba,\\nand Yuke Zhu. Pre-trained language models for interactive decision-making, 2022. URL https:\\n//arxiv.org/abs/2202.01771 .\\n11', metadata={'source': '/var/folders/qx/skm_3qm93bg39tjh5fyb02y80000gn/T/tmpv7iq21lk/tmp.pdf', 'page': 10}),\n",
       " Document(page_content='Published as a conference paper at ICLR 2023\\nAleksandr Romanovich Luria. Ls vygotsky and the problem of localization of functions. Neuropsy-\\nchologia , 3(4):387–392, 1965.\\nAman Madaan and Amir Yazdanbakhsh. Text and patterns: For effective chain of thought, it takes\\ntwo to tango, 2022. URL https://arxiv.org/abs/2209.07686 .\\nVincent Micheli and François Fleuret. Language models are few-shot butlers. arXiv preprint\\narXiv:2104.07972 , 2021.\\nReiichiro Nakano, Jacob Hilton, Suchir Balaji, Jeff Wu, Long Ouyang, Christina Kim, Christopher\\nHesse, Shantanu Jain, Vineet Kosaraju, William Saunders, Xu Jiang, Karl Cobbe, Tyna Eloundou,\\nGretchen Krueger, Kevin Button, Matthew Knight, Benjamin Chess, and John Schulman. Webgpt:\\nBrowser-assisted question-answering with human feedback, 2021. URL https://arxiv.\\norg/abs/2112.09332 .\\nMaxwell Nye, Anders Johan Andreassen, Guy Gur-Ari, Henryk Michalewski, Jacob Austin, David\\nBieber, David Dohan, Aitor Lewkowycz, Maarten Bosma, David Luan, Charles Sutton, and\\nAugustus Odena. Show your work: Scratchpads for intermediate computation with language\\nmodels, 2021. URL https://arxiv.org/abs/2112.00114 .\\nScott Reed, Konrad Zolna, Emilio Parisotto, Sergio Gomez Colmenarejo, Alexander Novikov,\\nGabriel Barth-Maron, Mai Gimenez, Yury Sulsky, Jackie Kay, Jost Tobias Springenberg, Tom\\nEccles, Jake Bruce, Ali Razavi, Ashley Edwards, Nicolas Heess, Yutian Chen, Raia Hadsell,\\nOriol Vinyals, Mahyar Bordbar, and Nando de Freitas. A generalist agent, 2022. URL https:\\n//arxiv.org/abs/2205.06175 .\\nMohit Shridhar, Jesse Thomason, Daniel Gordon, Yonatan Bisk, Winson Han, Roozbeh Mottaghi,\\nLuke Zettlemoyer, and Dieter Fox. Alfred: A benchmark for interpreting grounded instructions\\nfor everyday tasks. In Proceedings of the IEEE/CVF conference on computer vision and pattern\\nrecognition , pp. 10740–10749, 2020a.\\nMohit Shridhar, Xingdi Yuan, Marc-Alexandre Côté, Yonatan Bisk, Adam Trischler, and Matthew\\nHausknecht. Alfworld: Aligning text and embodied environments for interactive learning. arXiv\\npreprint arXiv:2010.03768 , 2020b.\\nKurt Shuster, Mojtaba Komeili, Leonard Adolphs, Stephen Roller, Arthur Szlam, and Jason Weston.\\nLanguage models that seek for knowledge: Modular search & generation for dialogue and prompt\\ncompletion. arXiv preprint arXiv:2203.13224 , 2022a.\\nKurt Shuster, Jing Xu, Mojtaba Komeili, Da Ju, Eric Michael Smith, Stephen Roller, Megan Ung,\\nMoya Chen, Kushal Arora, Joshua Lane, Morteza Behrooz, William Ngan, Spencer Poff, Naman\\nGoyal, Arthur Szlam, Y-Lan Boureau, Melanie Kambadur, and Jason Weston. Blenderbot 3:\\na deployed conversational agent that continually learns to responsibly engage, 2022b. URL\\nhttps://arxiv.org/abs/2208.03188 .\\nJames Thorne, Andreas Vlachos, Christos Christodoulopoulos, and Arpit Mittal. Fever: a large-scale\\ndataset for fact extraction and veriﬁcation. arXiv preprint arXiv:1803.05355 , 2018.\\nLev S Vygotsky. Thinking and speech. The collected works of LS Vygotsky , 1:39–285, 1987.\\nXuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, Sharan Narang, Aakanksha Chowdh-\\nery, and Denny Zhou. Self-consistency improves chain of thought reasoning in language models,\\n2022a. URL https://arxiv.org/abs/2203.11171 .\\nXuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, and Denny Zhou. Rationale-augmented\\nensembles in language models. arXiv preprint arXiv:2207.00747 , 2022b.\\nJason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Ed Chi, Quoc Le, and Denny\\nZhou. Chain of thought prompting elicits reasoning in large language models. arXiv preprint\\narXiv:2201.11903 , 2022.\\nZhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Bengio, William W Cohen, Ruslan Salakhutdinov,\\nand Christopher D Manning. Hotpotqa: A dataset for diverse, explainable multi-hop question\\nanswering. arXiv preprint arXiv:1809.09600 , 2018.\\n12', metadata={'source': '/var/folders/qx/skm_3qm93bg39tjh5fyb02y80000gn/T/tmpv7iq21lk/tmp.pdf', 'page': 11}),\n",
       " Document(page_content='Published as a conference paper at ICLR 2023\\nShunyu Yao, Rohan Rao, Matthew Hausknecht, and Karthik Narasimhan. Keep CALM and explore:\\nLanguage models for action generation in text-based games. In Proceedings of the 2020 Conference\\non Empirical Methods in Natural Language Processing (EMNLP) , pp. 8736–8754, Online, Novem-\\nber 2020. Association for Computational Linguistics. doi: 10.18653/v1/2020.emnlp-main.704.\\nURLhttps://aclanthology.org/2020.emnlp-main.704 .\\nShunyu Yao, Howard Chen, John Yang, and Karthik Narasimhan. Webshop: Towards scalable\\nreal-world web interaction with grounded language agents. arXiv preprint arXiv:2207.01206 ,\\n2022.\\nEric Zelikman, Yuhuai Wu, Jesse Mu, and Noah D. Goodman. Star: Bootstrapping reasoning with\\nreasoning, 2022. URL https://arxiv.org/abs/2203.14465 .\\nDenny Zhou, Nathanael Schärli, Le Hou, Jason Wei, Nathan Scales, Xuezhi Wang, Dale Schuurmans,\\nOlivier Bousquet, Quoc Le, and Ed Chi. Least-to-most prompting enables complex reasoning in\\nlarge language models, 2022. URL https://arxiv.org/abs/2205.10625 .\\nYunchang Zhu, Liang Pang, Yanyan Lan, Huawei Shen, and Xueqi Cheng. Adaptive information\\nseeking for open-domain question answering. arXiv preprint arXiv:2109.06747 , 2021.\\n13', metadata={'source': '/var/folders/qx/skm_3qm93bg39tjh5fyb02y80000gn/T/tmpv7iq21lk/tmp.pdf', 'page': 12}),\n",
       " Document(page_content='Published as a conference paper at ICLR 2023\\nA A DDITIONAL RESULTS\\nA.1 GPT-3 E XPERIMENTS\\nPaLM-540B GPT-3\\nHotpotQA (exact match) 29.4 30.8\\nALFWorld (success rate %) 70.9 78.4\\nTable 5: ReAct prompting results using PaLM-540B vs. GPT-3 (text-davinci-002, greedy decoding).\\nOn HotpotQA, we randomly sample a subset of 500 validation questions. On ALFWorld, we use all\\n134 unseen validation task instances, and use the best prompt set according to PaLM-540B.\\nWe run additional GPT-3 (Brown et al., 2020) experiments to conﬁrm ReAct prompting performance\\nis general across different large language models. As shown in Table 5, GPT-3 (text-davinci-002,\\ngreedy decoding) consistently outperforms PaLM-540B on HotpotQA and ALFWorld, possibly\\nbecause it is ﬁnetuned with human instruction following. This indicates ReAct prompting is effective\\nacross different large language models on different tasks. The code for these experiments are at\\nhttps://react-lm.github.io/ .\\nA.2 REAC TOBTAINS UP -TO-DATE KNOWLEDGE ON HOTPOT QA\\n\\x0b\\x14D\\x0c\\x036WDQGDUG$QVZHU\\x1d\\x03\\x16\\x0f\\x13\\x13\\x13\\x0b\\x14E\\x0c\\x03&R7\\x03\\x0b5HDVRQ\\x032QO\\\\\\x0c7KRXJKW\\x1d\\x03/HW\\nV\\x03WKLQN\\x03VWHS\\x03E\\\\\\x03VWHS\\x11\\x037KH\\x03KRWHO\\x03WKDW\\x03LV\\x03KRPH\\x03WR\\x03WKH\\x03&LUTXH\\x03GX\\x036ROHLO\\x03VKRZ\\x030\\\\VWHUH\\x03LV\\x037UHDVXUH\\x03,VODQG\\x11\\x037UHDVXUH\\x03,VODQG\\x03KDV\\x03\\x15\\x0f\\x1b\\x1b\\x18\\x03URRPV\\x0f\\x03VR\\x03WKH\\x03DQVZHU\\x03LV\\x03\\x15\\x0f\\x1b\\x1b\\x18\\x11$QVZHU\\x1d\\x03\\x15\\x0f\\x1b\\x1b\\x18\\x0b\\x14F\\x0c\\x03$FW\\x102QO\\\\\\x03$FW\\x03\\x14\\x1d\\x036HDUFK>&LUTXH\\x03GX\\x036ROHLO@\\x032EV\\x03\\x14\\x1d\\x03&LUTXH\\x03GX\\x036ROHLO\\x03LV\\x03D\\x03&DQDGLDQ\\x03HQWHUWDLQPHQW\\x03FRPSDQ\\\\ª$FW\\x03\\x15\\x1d\\x03/RRNXS>0\\\\VWHUH@\\x032EV\\x03\\x15\\x1d\\x031R\\x03PRUH\\x03UHVXOWV$FW\\x03\\x16\\x1d\\x036HDUFK>0\\\\VWHUH\\x03\\x0b&LUTXH\\x03GX\\x036ROHLO\\x03VKRZ\\x0c@\\x032EV\\x03\\x16\\x1d\\x03&RXOG\\x03QRW\\x03ILQGª$FW\\x03\\x17\\x1d\\x036HDUFK>0\\\\VWHUH\\x03\\x0b&LUTXH\\x03GX\\x036ROHLO\\x0c@\\x032EV\\x03\\x17\\x1d\\x030\\\\VWqUH\\x03\\x0bP\\\\\\x10VWHHU\\x0c\\x03\\x03LV\\x03RQH\\x03RI\\x03VL[ª$FW\\x03\\x18\\x1d\\x03/RRNXS>7UHDVXUH\\x03,VODQG\\x03+RWHO\\x03DQG\\x03&DVLQR@\\x03ªª\\x0bHQG\\x03ZLWKRXW\\x03DQVZHU\\x0c\\x0b\\x14G\\x0c\\x035H$FW\\x03\\x0b5HDVRQ\\x03\\x0e\\x03$FW\\x0c7KRXJKW\\x03\\x14\\x1d\\x03,\\x03QHHG\\x03WR\\x03VHDUFK\\x03&LUTXH\\x03GX\\x036ROHLO\\x03VKRZ\\x030\\\\VWHUH\\x0f\\x03ILQG\\x03WKH\\x03KRWHO\\x03LW\\x03LV\\x03LQ\\x0f\\x03WKHQ\\x03ILQG\\x03WKH\\x03QXPEHU\\x03RI\\x03URRPV\\x03LQ\\x03WKH\\x03KRWHO\\x11$FW\\x03\\x14\\x1d\\x036HDUFK>&LUTXH\\x03GX\\x036ROHLO\\x03VKRZ\\x030\\\\VWHUH@2EV\\x03\\x14\\x1d\\x03&RXOG\\x03QRW\\x03ILQG\\x03&LUTXH\\x03GX\\x036ROHLO\\x03VKRZ\\x030\\\\VWHUH\\x11\\x036LPLODU\\x1d\\x03>\\n&LUTXH\\x03GX\\x036ROHLO\\n\\x03ª7KRXJKW\\x03\\x15\\x1d\\x037R\\x03ILQG\\x03WKH\\x03KRWHO\\x0f\\x03,\\x03FDQ\\x03VHDUFK\\x030\\\\VWHUH\\x03\\x0b&LUTXH\\x03GX\\x036ROHLO\\x0c\\x11$FW\\x03\\x15\\x1d\\x036HDUFK>0\\\\VWHUH\\x03\\x0b&LUTXH\\x03GX\\x036ROHLO\\x0c@2EV\\x03\\x15\\x1d\\x030\\\\VWqUH\\x03\\x0bP\\\\\\x10VWHHU\\x0c\\x03\\x03LV\\x03ª\\x03+HOG\\x03LQ\\x03D\\x03FXVWRP\\x03WKHDWUH\\x03DW\\x03WKH\\x037UHDVXUH\\x03,VODQG\\x03+RWHO\\x03DQG\\x03&DVLQR\\x03ª7KRXJKW\\x03\\x16\\x1d\\x030\\\\VWHUH\\x03LV\\x03KHOG\\x03LQ\\x03D\\x03FXVWRP\\x03WKHDWUH\\x03DW\\x03WKH\\x037UHDVXUH\\x03,VODQG\\x03+RWHO\\x03DQG\\x03&DVLQR\\x11\\x036R\\x03,\\x03QHHG\\x03WR\\x03VHDUFK\\x037UHDVXUH\\x03,VODQG\\x03+RWHO\\x03DQG\\x03&DVLQR\\x03QH[W\\x03DQG\\x03ILQG\\x03WKH\\x03QXPEHU\\x03RI\\x03URRPV\\x03LQ\\x03WKH\\x03KRWHO\\x11$FW\\x03\\x16\\x1d\\x036HDUFK>7UHDVXUH\\x03,VODQG\\x03+RWHO\\x03DQG\\x03&DVLQR@2EV\\x03\\x16\\x1d\\x037UHDVXUH\\x03,VODQG\\x03+RWHO\\x03DQG\\x03&DVLQR\\x03ª\\x03ZLWK\\x03\\x15\\x0f\\x1b\\x1b\\x17\\x03URRPV\\x03DQG\\x03\\x15\\x15\\x13\\x03VXLWHV\\x03ª7KRXJKW\\x03\\x17\\x1d\\x037UHDVXUH\\x03,VODQG\\x03+RWHO\\x03DQG\\x03&DVLQR\\x03KDV\\x03\\x15\\x0f\\x1b\\x1b\\x17\\x03URRPV\\x03DQG\\x03\\x15\\x15\\x13\\x03VXLWHV\\x11\\x036R\\x03WKH\\x03DQVZHU\\x03LV\\x03\\x16\\x0f\\x14\\x13\\x17\\x11$FW\\x03\\x17\\x1d\\x03)LQLVK>\\x16\\x0f\\x14\\x13\\x17@Ҽ4XHVWLRQ\\x1d\\x03+RZ\\x03PDQ\\\\\\x03URRPV\\x03DUH\\x03LQ\\x03WKH\\x03KRWHO\\x03WKDW\\x03LV\\x03KRPH\\x03WR\\x03WKH\\x03&LUTXH\\x03GX\\x036ROHLO\\x03VKRZ\\x030\\\\VWHUH\"+RWSRW4$\\x03ODEHO\\x1d\\x03\\x15\\x0f\\x19\\x19\\x17\\x0b\\x14\\x0c\\x03+RWVSRW\\x034$2XWGDWHG\\x03\\n8S\\x10WR\\x10GDWH\\x03\\nFigure 4: Another example HotpotQA question, where the original label is outdated. Only ReAct is\\nable to obtain the up-to-date answer thanks to real-world web interaction plus reasoning.\\nDuring trajectory inspection, we also ﬁnd that sometimes ReAct does not agree with dataset labels as\\nthe labels themselves could be outdated. For example, as shown in Figure 4, the question asks about\\nthe size of a hotel, which increased from the HotpotQA construction time. While Standard andCoT\\ngive wrong answers due to hallucination, Act fails despite the access of real-world web interaction,\\ndue to a lack of reasoning to guide how to interact with the Internet for QA. Only ReAct is able to\\nretrieve up-to-date information from the Internet and provide a reasonable answer. Therefore, better\\nincorporation of reasoning abilities might beneﬁt recent Internet-augmented language models (Nakano\\net al., 2021; Lazaridou et al., 2022; Shuster et al., 2022a) for up-to-date task solving.\\nA.3 H UMAN -IN-THE-LOOP BEHAVIOR CORRECTION ON ALFWORLD\\nWe also explore human-in-the-loop interaction with ReAct , to allow a human to inspect and edit\\nReAct ’s reasoning traces. Figure 5 shows that by simply removing a hallucinating sentence in Act\\n17 and adding some hints in Act 23, ReAct can be made to change its behavior drastically to align\\nwith these human thought edits and succeed in the task. From a human perspective, solving such a\\ntask becomes signiﬁcantly easier, from typing tens of actions to only editing a couple of thoughts,\\nwhich enables new forms of human-machine collaboration. We note that such a policy edit on-the-go\\n14', metadata={'source': '/var/folders/qx/skm_3qm93bg39tjh5fyb02y80000gn/T/tmpv7iq21lk/tmp.pdf', 'page': 13}),\n",
       " Document(page_content='Published as a conference paper at ICLR 2023\\n\\x0bD\\x0c\\x035H$FW\\x03\\x11\\x11\\x11\\x11\\x11\\x112EV\\x03\\x14\\x19\\x1d\\x03<RX\\x03RSHQ\\x03WKH\\x03GUDZHU\\x03\\x17\\x11\\x037KH\\x03GUDZHU\\x03\\x17\\x03LV\\x03RSHQ\\x11\\x03,Q\\x03LW\\x0f\\x03\\\\RX\\x03VHH\\x03D\\x03NH\\\\FKDLQ\\x03\\x16\\x0f\\x03DQG\\x03D\\x03ZDWFK\\x03\\x15\\x11\\x03$FW\\x03\\x14\\x1a\\x1d\\x037KLQN\\x03>1RZ\\x03,\\x03ILQG\\x03WKH\\x03ILUVW\\x03NH\\\\FKDLQ\\x03\\x0b\\x16\\x0c\\x11\\x031H[W\\x0f\\x03,\\x03QHHG\\x03WR\\x03WDNH\\x03LW\\x11\\x03,\\x03FDQ\\x03ILQG\\x03WKH\\x03VHFRQG\\x03NH\\\\FKDLQ\\x03\\x0b\\x15\\x0c\\x03ODWHU\\x03LQ\\x03GUDZHU\\x03\\x17\\x11\\x03@$FW\\x03\\x14\\x1b\\x1d\\x03WDNH\\x03NH\\\\FKDLQ\\x03\\x16\\x03IURP\\x03GUDZHU\\x03\\x17\\x032EV\\x03\\x14\\x1b\\x1d\\x03<RX\\x03SLFN\\x03XS\\x03WKH\\x03NH\\\\FKDLQ\\x03\\x16\\x03IURP\\x03WKH\\x03GUDZHU\\x03\\x17\\x11\\x03\\x11\\x11\\x11\\x11\\x11\\x11$FW\\x03\\x15\\x15\\x1d\\x03SXW\\x03NH\\\\FKDLQ\\x03\\x16\\x03LQ\\x12RQ\\x03VDIH\\x03\\x14\\x032EV\\x03\\x15\\x15\\x1d\\x03<RX\\x03SXW\\x03WKH\\x03NH\\\\FKDLQ\\x03\\x16\\x03LQ\\x12RQ\\x03WKH\\x03VDIH\\x03\\x14\\x11\\x03$FW\\x03\\x15\\x16\\x1d\\x037KLQN\\x03>1RZ\\x03,\\x03SXW\\x03WKH\\x03ILUVW\\x03NH\\\\FKDLQ\\x03LQ\\x03VDIH\\x11\\x031H[W\\x0f\\x03,\\x03QHHG\\x03WR\\x03ILQG\\x03WKH\\x03VHFRQG\\x03NH\\\\FKDLQ\\x11\\x03,\\x03FDQ\\x03GLUHFWO\\\\\\x03JR\\x03WR\\x03GUDZHU\\x03\\x17\\x11\\x03@$FW\\x03\\x15\\x17\\x1d\\x03JR\\x03WR\\x03GUDZHU\\x03\\x17\\x032EV\\x03\\x15\\x17\\x1d\\x037KH\\x03GUDZHU\\x03\\x17\\x03LV\\x03RSHQ\\x11\\x03,Q\\x03LW\\x0f\\x03\\\\RX\\x03VHH\\x03D\\x03ZDWFK\\x03\\x15\\x11\\x03$FW\\x03\\x15\\x18\\x1d\\x037KLQN\\x03>1RZ\\x03,\\x03ILQG\\x03WKH\\x03VHFRQG\\x03NH\\\\FKDLQ\\x03\\x0b\\x15\\x0c\\x11\\x031H[W\\x0f\\x03,\\x03QHHG\\x03WR\\x03WDNH\\x03LW\\x11@$FW\\x03\\x15\\x19\\x1d\\x03WDNH\\x03NH\\\\FKDLQ\\x03\\x15\\x03IURP\\x03GUDZHU\\x03\\x17\\x032EV\\x03\\x15\\x19\\x1d\\x031RWKLQJ\\x03KDSSHQV\\x11\\x0bE\\x0c\\x035H$FW\\x03\\x0b+XPDQ\\x037KRXJKW\\x03HGLW\\x0c\\x11\\x11\\x11\\x11\\x11\\x112EV\\x03\\x14\\x19\\x1d\\x03<RX\\x03RSHQ\\x03WKH\\x03GUDZHU\\x03\\x17\\x11\\x037KH\\x03GUDZHU\\x03\\x17\\x03LV\\x03RSHQ\\x11\\x03,Q\\x03LW\\x0f\\x03\\\\RX\\x03VHH\\x03D\\x03NH\\\\FKDLQ\\x03\\x16\\x0f\\x03DQG\\x03D\\x03ZDWFK\\x03\\x15\\x11\\x03$FW\\x03\\x14\\x1a\\x1dѕ7KLQNѕ>1RZ\\x03,\\x03ILQG\\x03WKH\\x03ILUVW\\x03NH\\\\FKDLQ\\x03\\x0b\\x16\\x0c\\x11\\x031H[W\\x0f\\x03,\\x03QHHG\\x03WR\\x03WDNH\\x03LW\\x11\\x03,\\x03FDQ\\x03ILQG\\x03WKH\\x03VHFRQG\\x03NH\\\\FKDLQ\\x03\\x0b\\x15\\x0c\\x03ODWHU\\x03LQ\\x03GUDZHU\\x03\\x17\\x11@$FW\\x03\\x14\\x1b\\x1d\\x03WDNH\\x03NH\\\\FKDLQ\\x03\\x16\\x03IURP\\x03GUDZHU\\x03\\x17\\x032EV\\x03\\x14\\x1b\\x1d\\x03<RX\\x03SLFN\\x03XS\\x03WKH\\x03NH\\\\FKDLQ\\x03\\x16\\x03IURP\\x03WKH\\x03GUDZHU\\x03\\x17\\x11\\x03\\x11\\x11\\x11\\x11\\x11\\x11$FW\\x03\\x15\\x15\\x1d\\x03SXW\\x03NH\\\\FKDLQ\\x03\\x16\\x03LQ\\x12RQ\\x03VDIH\\x03\\x14\\x032EV\\x03\\x15\\x15\\x1d\\x03<RX\\x03SXW\\x03WKH\\x03NH\\\\FKDLQ\\x03\\x16\\x03LQ\\x12RQ\\x03WKH\\x03VDIH\\x03\\x14\\x11\\x03$FW\\x03\\x15\\x16\\x1d\\x037KLQNѕ>1RZ\\x03,\\x03SXW\\x03WKH\\x03ILUVW\\x03NH\\\\FKDLQ\\x03LQ\\x03VDIH\\x11\\x031H[W\\x0f\\x03,\\x03QHHG\\x03WR\\x03ILQG\\x03WKH\\x03VHFRQG\\x03NH\\\\FKDLQ\\x0f\\x03ZKLFK\\x03LV\\x03PRUH\\x03OLNHO\\\\\\x03WR\\x03DSSHDU\\x03LQ\\x03GUHVVHU\\x03\\x0b\\x14\\x0c\\x0f\\x03JDUEDJHFDQ\\x03\\x0b\\x14\\x0c\\x0f\\x03VDIH\\x03\\x0b\\x14\\x0c\\x0f\\x03VLGHWDEOH\\x03\\x0b\\x14\\x0c\\x0f\\x03VRID\\x03\\x0b\\x14\\x0c\\x0f\\x03VKHOI\\x03\\x0b\\x14\\x10\\x14\\x15\\x0c\\x11@$FW\\x03\\x15\\x17\\x1d\\x03JR\\x03WR\\x03GUHVVHU\\x03\\x14\\x032EV\\x03\\x15\\x17\\x1d\\x032Q\\x03WKH\\x03GUHVVHU\\x03\\x14\\x0f\\x03\\\\RX\\x03VHH\\x03D\\x03ER[\\x03\\x14\\x0f\\x03D\\x03FUHGLWFDUG\\x03\\x14\\x0f\\x03D\\x03NH\\\\FKDLQ\\x03\\x15\\x0f\\x03D\\x03NH\\\\FKDLQ\\x03\\x14\\x0f\\x03D\\x03ODSWRS\\x03\\x14\\x11\\x11\\x11$FW\\x03\\x15\\x18\\x1d\\x037KLQNѕ>1RZ\\x03,\\x03ILQG\\x03WKH\\x03VHFRQG\\x03NH\\\\FKDLQ\\x03\\x0b\\x15\\x0c\\x11\\x031H[W\\x0f\\x03,\\x03QHHG\\x03WR\\x03WDNH\\x03LW\\x11@$FW\\x03\\x15\\x19\\x1d\\x03WDNH\\x03NH\\\\FKDLQ\\x03\\x15\\x03IURP\\x03GUHVVHU\\x03\\x14\\x032EV\\x03\\x15\\x19\\x1d\\x03<RX\\x03SLFN\\x03XS\\x03WKH\\x03NH\\\\FKDLQ\\x03\\x15\\x03IURP\\x03WKH\\x03GUHVVHU\\x03\\x14\\x11\\x03$FW\\x03\\x15\\x1a\\x1d\\x037KLQNѕ>1RZ\\x03,\\x03WDNH\\x03WKH\\x03VHFRQG\\x03NH\\\\FKDLQ\\x03\\x0b\\x15\\x0c\\x11\\x031H[W\\x0f\\x03,\\x03QHHG\\x03WR\\x03SXW\\x03LW\\x03LQ\\x12RQ\\x03VDIH\\x03\\x14\\x11@$FW\\x03\\x15\\x1b\\x1d\\x03JR\\x03WR\\x03VDIH\\x03\\x142EV\\x03\\x15\\x1b\\x1d\\x037KH\\x03VDIH\\x03\\x14\\x03LV\\x03RSHQ\\x11\\x03,Q\\x03LW\\x0f\\x03\\\\RX\\x03VHH\\x03D\\x03NH\\\\FKDLQ\\x03\\x16\\x0f\\x03D\\x03VWDWXH\\x03\\x15\\x0f\\x03DQG\\x03D\\x03ZDWFK\\x03\\x16\\x11$FW\\x03\\x15\\x1c\\x1d\\x03SXW\\x03NH\\\\FKDLQ\\x03\\x15\\x03LQ\\x12RQ\\x03VDIH\\x03\\x142EV\\x03\\x15\\x1c\\x1d\\x03<RX\\x03SXW\\x03WKH\\x03NH\\\\FKDLQ\\x03\\x15\\x03LQ\\x12RQ\\x03WKH\\x03VDIH\\x03\\x14\\x11Ҽ<RX\\x03DUH\\x03LQ\\x03WKH\\x03PLGGOH\\x03RI\\x03D\\x03URRP\\x11\\x03/RRNLQJ\\x03TXLFNO\\\\\\x03DURXQG\\x03\\\\RX\\x0f\\x03\\\\RX\\x03VHH\\x03D\\x03DUPFKDLU\\x03\\x14\\x0f\\x03D\\x03FDELQHW\\x03\\x17\\x0f\\x03ª\\x03D\\x03FDELQHW\\x03\\x14\\x0f\\x03D\\x03GUDZHU\\x03\\x18\\x0f\\x03ª\\x0f\\x03D\\x03GUDZHU\\x03\\x14\\x0f\\x03D\\x03GUHVVHU\\x03\\x14\\x0f\\x03D\\x03JDUEDJHFDQ\\x03\\x14\\x0f\\x03D\\x03VDIH\\x03\\x14\\x0f\\x03D\\x03VKHOI\\x03\\x14\\x15\\x0f\\x03ª\\x0f\\x03D\\x03VKHOI\\x03\\x14\\x0f\\x03D\\x03VLGHWDEOH\\x03\\x14\\x0f\\x03DQG\\x03D\\x03VRID\\x03\\x14\\x11\\x03<RXU\\x03WDVN\\x03LV\\x03WR\\x1d\\x03SXW\\x03WZR\\x03NH\\\\FKDLQ\\x03LQ\\x03VDIH\\x11$OI:RUOG\\nFigure 5: A human-in-the-loop behavior correction example with ReAct in AlfWorld. (a) ReAct\\ntrajectory fails due to a hallucinating thought (Act 17). (b) By a human simply editing two thoughts\\n(Act 17, 23), the ReAct trajectory produces desirable reasoning traces and actions and succeeds.\\nis difﬁcult for Act and previous RL methods, as a human cannot change the model parameters, and\\nchanging a few actions might not edit the rest of the model behavior. This paradigm is also more than\\nhuman dialogue to update the goal or subgoal as in Huang et al. (2022b) — while editing ReAct\\nthoughts can do these, it can also modify the model’s internal belief, reasoning styles, or anything the\\nﬂexible thought space supports, for better task solving. We believe this is an exciting direction for\\nhuman alignment and leave more systematic study as future work.\\nB E XPERIMENT DETAILS\\nB.1 H OTPOT QA F INETUNING DETAILS\\nFor all ﬁnetuning we use a batch size of 64. On PaLM-8B, we ﬁnetune ReAct andAct methods\\nfor4,000steps and Standard andCoT methods for 2,000steps. On PaLM-62B, we ﬁnetune\\nReAct andAct methods for 4,000steps and Standard andCoT methods for 1,000steps. We\\nﬁndReAct andAct methods generally beneﬁt from more training steps (and more training data),\\nwhile Standard andCoT methods degrade soon after ﬁnetuning.\\nB.2 A LFWORLD IM-S TYLE DETAILS\\nFor the IM-style ablation, the same expert trajectories used in ReAct are reannotated with dense\\nexternal feedback thoughts within these trajectories, that limit ReAct-IM to only think about (1)\\ndecomposing the current goal and (2) the current subgoal that needs to be completed. In particular,\\nReAct-IM lacks thoughts that (1) determine when a subgoal is completed (2) determine what the\\nnext subgoal should be (3) inducing the LLM to refer to its internal pretraining knowledge to identify\\nwhere items can be within the environment.\\n15', metadata={'source': '/var/folders/qx/skm_3qm93bg39tjh5fyb02y80000gn/T/tmpv7iq21lk/tmp.pdf', 'page': 14}),\n",
       " Document(page_content='Published as a conference paper at ICLR 2023\\nC P ROMPTS\\nC.1 H OTPOT QA\\nHotpot QA Prompts\\nOrig inal\\nQuestion What is the elevation range for the area that the eastern sector of the\\nColorado orogeny extends into?\\nAnswer 1,800 to 7,000 ft\\nQuestion Musician and satirist Allie Goertz wrote a song about the \"The Simpsons\"\\ncharacter Milhouse, who Matt Groening named after who?\\nAnswer Richard Nixon\\nQuestion Which documentary is about Finnish rock groups, Adam Clayton Powell or The\\nSaimaa Gesture?\\nAnswer The Saimaa Gesture\\nQuestion What profession does Nicholas Ray and Elia Kazan have in common?\\nAnswer director, screenwriter, actor\\nQuestion Which magazine was started first Arthur’s Magazine or First for Women?\\nAnswer Arthur’s Magazine\\nQuestion Were Pavel Urysohn and Leonid Levin known for the same type of work?\\nAnswer Yes\\nAct\\nQuestion What is the elevation range for the area that the eastern sector of the\\nColorado orogeny extends into?\\nAction 1 Search[Colorado orogeny]\\nObservation 1 The Colorado orogeny was an episode of mountain building (an orogeny) in\\nColorado and surrounding areas.\\nAction 2 Lookup[eastern sector]\\nObservation 2 (Result 1 / 1) The eastern sector extends into the High Plains and is called\\nthe Central Plains orogeny.\\nAction 3 Search[High Plains]\\nObservation 3 High Plains refers to one of two distinct land regions:\\nAction 4 Search[High Plains (United States)]\\nObservation 4 The High Plains are a subregion of the Great Plains. From east to west, the\\nHigh Plains rise in elevation from around 1,800 to 7,000 ft (550 to 2,130\\nm).[3]\\nAction 5 Finish[1,800 to 7,000 ft]\\nQuestion Musician and satirist Allie Goertz wrote a song about the \"The Simpsons\"\\ncharacter Milhouse, who Matt Groening named after who?\\nAction 1 Search[Milhouse]\\nObservation 1 Milhouse Mussolini Van Houten is a recurring character in the Fox animated\\ntelevision series The Simpsons voiced by Pamela Hayden and created by Matt\\nGroening.\\nAction 2 Lookup[named after]\\nObservation 2 (Result 1 / 1) Milhouse was named after U.S. president Richard Nixon, whose\\nmiddle name was Milhous.\\nAction 3 Finish[Richard Nixon]\\nQuestion Which documentary is about Finnish rock groups, Adam Clayton Powell or The\\nSaimaa Gesture?\\nAction 1 Search[Adam Clayton Powell]\\nObservation 1 Could not find [Adam Clayton Powell]. Similar: [’Adam Clayton Powell\\nIII’, ’Seventh Avenue (Manhattan)’, ’Adam Clayton Powell Jr. State Office\\nBuilding’, ’Isabel Washington Powell’, ’Adam Powell’, ’Adam Clayton Powell\\n(film)’, ’Giancarlo Esposito’].\\nAction 2 Search[Adam Clayton Powell (film)]\\nObservation 2 Adam Clayton Powell is a 1989 American documentary film directed by\\nRichard Kilberg. The film is about the rise and fall of influential\\nAfrican-American politician Adam Clayton Powell Jr.[3][4] It was later aired\\nas part of the PBS series The American Experience.\\nAction 3 Finish[The Saimaa Gesture]\\nQuestion What profession does Nicholas Ray and Elia Kazan have in common?\\nAction 1 Search[Nicholas Ray]\\nObservation 1 Nicholas Ray (born Raymond Nicholas Kienzle Jr., August 7, 1911 - June 16,\\n1979) was an American film director, screenwriter, and actor best known for\\nthe 1955 film Rebel Without a Cause.\\nAction 2 Search[Elia Kazan]\\nObservation 2 Elia Kazan was an American film and theatre director, producer, screenwriter\\nand actor.\\nContinued on next page\\n16', metadata={'source': '/var/folders/qx/skm_3qm93bg39tjh5fyb02y80000gn/T/tmpv7iq21lk/tmp.pdf', 'page': 15}),\n",
       " Document(page_content='Published as a conference paper at ICLR 2023\\nHotpot QA Prompts – Continued from previous page\\nAction 3 Finish[director, screenwriter, actor]\\nQuestion Which magazine was started first Arthur’s Magazine or First for Women?\\nAction 1 Search[Arthur’s Magazine]\\nObservation 1 Arthur’s Magazine (1844-1846) was an American literary periodical published\\nin Philadelphia in the 19th century.\\nAction 2 Search[First for Women]\\nObservation 2 First for Women is a woman’s magazine published by Bauer Media Group in the\\nUSA.[1] The magazine was started in 1989.\\nAction 3 Finish[Arthur’s Magazine]\\nQuestion Were Pavel Urysohn and Leonid Levin known for the same type of work?\\nAction 1 Search[Pavel Urysohn]\\nObservation 1 Pavel Samuilovich Urysohn (February 3, 1898 - August 17, 1924) was a Soviet\\nmathematician who is best known for his contributions in dimension theory.\\nAction 2 Search[Leonid Levin]\\nObservation 2 Leonid Anatolievich Levin is a Soviet-American mathematician and computer\\nscientist.\\nAction 3 Finish[yes]\\nCoT\\nQuestion What is the elevation range for the area that the eastern sector of the\\nColorado orogeny extends into?\\nThought Let’s think step by step. The eastern sector of Colorado orogeny extends\\ninto the High Plains. High Plains rise in elevation from around 1,800 to\\n7,000 ft, so the answer is 1,800 to 7,000 ft.\\nAnswer 1,800 to 7,000 ft\\nQuestion Musician and satirist Allie Goertz wrote a song about the \"The Simpsons\"\\ncharacter Milhouse, who Matt Groening named after who?\\nThought Let’s think step by step. Milhouse was named after U.S. president Richard\\nNixon, so the answer is Richard Nixon.\\nAnswer Richard Nixon\\nQuestion Which documentary is about Finnish rock groups, Adam Clayton Powell or The\\nSaimaa Gesture?\\nThought Let’s think step by step. Adam Clayton Powell (film) is a documentary about\\nan African-American politician, not Finnish rock groups. So the documentary\\nabout Finnish rock groups must instead be The Saimaa Gesture.\\nAnswer The Saimaa Gesture\\nQuestion What profession does Nicholas Ray and Elia Kazan have in common?\\nThought Let’s think step by step. Professions of Nicholas Ray are director,\\nscreenwriter, and actor. Professions of Elia Kazan are director, producer,\\nscreenwriter, and actor. So profession Nicholas Ray and Elia Kazan have in\\ncommon is director, screenwriter, and actor.\\nAnswer director, screenwriter, actor\\nQuestion Which magazine was started first Arthur’s Magazine or First for Women?\\nThought Let’s think step by step. Arthur’s Magazine was started in 1844. First\\nfor Women was started in 1989. 1844 (Arthur’s Magazine) < 1989 (First for\\nWomen), so Arthur’s Magazine was started first.\\nAnswer Arthur’s Magazine\\nQuestion Were Pavel Urysohn and Leonid Levin known for the same type of work?\\nThought Let’s think step by step. Pavel Urysohn is a mathematician. Leonid Levin\\nis a mathematician and computer scientist. So Pavel Urysohn and Leonid\\nLevin have the same type of work.\\nAnswer Yes\\nReAct\\nQuestion What is the elevation range for the area that the eastern sector of the\\nColorado orogeny extends into?\\nThought 1 I need to search Colorado orogeny, find the area that the eastern sector\\nof the Colorado orogeny extends into, then find the elevation range of the\\narea.\\nAction 1 Search[Colorado orogeny]\\nObservation 1 The Colorado orogeny was an episode of mountain building (an orogeny) in\\nColorado and surrounding areas.\\nThought 2 It does not mention the eastern sector. So I need to look up eastern\\nsector.\\nAction 2 Lookup[eastern sector]\\nObservation 2 (Result 1 / 1) The eastern sector extends into the High Plains and is called\\nthe Central Plains orogeny.\\nThought 3 The eastern sector of Colorado orogeny extends into the High Plains. So I\\nneed to search High Plains and find its elevation range.\\nAction 3 Search[High Plains]\\nObservation 3 High Plains refers to one of two distinct land regions\\nThought 4 I need to instead search High Plains (United States).\\nAction 4 Search[High Plains (United States)]\\nContinued on next page\\n17', metadata={'source': '/var/folders/qx/skm_3qm93bg39tjh5fyb02y80000gn/T/tmpv7iq21lk/tmp.pdf', 'page': 16}),\n",
       " Document(page_content='Published as a conference paper at ICLR 2023\\nHotpot QA Prompts – Continued from previous page\\nObservation 4 The High Plains are a subregion of the Great Plains. From east to west, the\\nHigh Plains rise in elevation from around 1,800 to 7,000 ft (550 to 2,130\\nm).[3]\\nThought 5 High Plains rise in elevation from around 1,800 to 7,000 ft, so the answer\\nis 1,800 to 7,000 ft.\\nAction 5 Finish[1,800 to 7,000 ft]\\nQuestion Musician and satirist Allie Goertz wrote a song about the \"The Simpsons\"\\ncharacter Milhouse, who Matt Groening named after who?\\nThought 1 The question simplifies to \"The Simpsons\" character Milhouse is named after\\nwho. I only need to search Milhouse and find who it is named after.\\nAction 1 Search[Milhouse]\\nObservation 1 Milhouse Mussolini Van Houten is a recurring character in the Fox animated\\ntelevision series The Simpsons voiced by Pamela Hayden and created by Matt\\nGroening.\\nThought 2 The paragraph does not tell who Milhouse is named after, maybe I can look up\\n\"named after\".\\nAction 2 Lookup[named after]\\nObservation 2 (Result 1 / 1) Milhouse was named after U.S. president Richard Nixon, whose\\nmiddle name was Milhous.\\nThought 3 Milhouse was named after U.S. president Richard Nixon, so the answer is\\nRichard Nixon.\\nAction 3 Finish[Richard Nixon]\\nQuestion Which documentary is about Finnish rock groups, Adam Clayton Powell or The\\nSaimaa Gesture?\\nThought 1 I need to search Adam Clayton Powell and The Saimaa Gesture, and find which\\ndocumentary is about Finnish rock groups.\\nAction 1 Search[Adam Clayton Powell]\\nObservation 1 Could not find [Adam Clayton Powell]. Similar: [’Adam Clayton Powell\\nIII’, ’Seventh Avenue (Manhattan)’, ’Adam Clayton Powell Jr. State Office\\nBuilding’, ’Isabel Washington Powell’, ’Adam Powell’, ’Adam Clayton Powell\\n(film)’, ’Giancarlo Esposito’].\\nThought 2 To find the documentary, I can search Adam Clayton Powell (film).\\nAction 2 Search[Adam Clayton Powell (film)]\\nObservation 2 Adam Clayton Powell is a 1989 American documentary film directed by\\nRichard Kilberg. The film is about the rise and fall of influential\\nAfrican-American politician Adam Clayton Powell Jr.[3][4] It was later aired\\nas part of the PBS series The American Experience.\\nThought 3 Adam Clayton Powell (film) is a documentary about an African-American\\npolitician, not Finnish rock groups. So the documentary about Finnish rock\\ngroups must instead be The Saimaa Gesture.\\nAction 3 Finish[The Saimaa Gesture]\\nQuestion What profession does Nicholas Ray and Elia Kazan have in common?\\nThought 1 I need to search Nicholas Ray and Elia Kazan, find their professions, then\\nfind the profession they have in common.\\nAction 1 Search[Nicholas Ray]\\nObservation 1 Nicholas Ray (born Raymond Nicholas Kienzle Jr., August 7, 1911 - June 16,\\n1979) was an American film director, screenwriter, and actor best known for\\nthe 1955 film Rebel Without a Cause.\\nThought 2 Professions of Nicholas Ray are director, screenwriter, and actor. I need\\nto search Elia Kazan next and find his professions.\\nAction 2 Search[Elia Kazan]\\nObservation 2 Elia Kazan was an American film and theatre director, producer, screenwriter\\nand actor.\\nThought 3 Professions of Elia Kazan are director, producer, screenwriter, and actor.\\nSo profession Nicholas Ray and Elia Kazan have in common is director,\\nscreenwriter, and actor.\\nAction 3 Finish[director, screenwriter, actor]\\nQuestion Which magazine was started first Arthur’s Magazine or First for Women?\\nThought 1 I need to search Arthur’s Magazine and First for Women, and find which was\\nstarted first.\\nAction 1 Search[Arthur’s Magazine]\\nObservation 1 Arthur’s Magazine (1844-1846) was an American literary periodical published\\nin Philadelphia in the 19th century.\\nThought 2 Arthur’s Magazine was started in 1844. I need to search First for Women\\nnext.\\nAction 2 Search[First for Women]\\nObservation 2 First for Women is a woman’s magazine published by Bauer Media Group in the\\nUSA.[1] The magazine was started in 1989.\\nThought 3 First for Women was started in 1989. 1844 (Arthur’s Magazine) < 1989 (First\\nfor Women), so Arthur’s Magazine was started first.\\nAction 3 Finish[Arthur’s Magazine]\\nQuestion Were Pavel Urysohn and Leonid Levin known for the same type of work?\\nThought 1 I need to search Pavel Urysohn and Leonid Levin, find their types of work,\\nthen find if they are the same.\\nAction 1 Search[Pavel Urysohn]\\nContinued on next page\\n18', metadata={'source': '/var/folders/qx/skm_3qm93bg39tjh5fyb02y80000gn/T/tmpv7iq21lk/tmp.pdf', 'page': 17}),\n",
       " Document(page_content='Published as a conference paper at ICLR 2023\\nHotpot QA Prompts – Continued from previous page\\nObservation 1 Pavel Samuilovich Urysohn (February 3, 1898 - August 17, 1924) was a Soviet\\nmathematician who is best known for his contributions in dimension theory.\\nThought 2 Pavel Urysohn is a mathematician. I need to search Leonid Levin next and\\nfind its type of work.\\nAction 2 Search[Leonid Levin]\\nObservation 2 Leonid Anatolievich Levin is a Soviet-American mathematician and computer\\nscientist.\\nThought 3 Leonid Levin is a mathematician and computer scientist. So Pavel Urysohn\\nand Leonid Levin have the same type of work.\\nAction 3 Finish[yes]\\n19', metadata={'source': '/var/folders/qx/skm_3qm93bg39tjh5fyb02y80000gn/T/tmpv7iq21lk/tmp.pdf', 'page': 18}),\n",
       " Document(page_content='Published as a conference paper at ICLR 2023\\nC.2 F EVER\\nFEVER Prompts\\nOrig inal Determine if there is Observation that SUPPORTS or REFUTES a Claim, or if\\nthere is NOT ENOUGH INFORMATION.\\nClaim Nikolaj Coster-Waldau worked with the Fox Broadcasting Company.\\nAnswer SUPPORTS\\nClaim Stranger Things is set in Bloomington, Indiana.\\nAnswer REFUTES\\nClaim Beautiful reached number two on the Billboard Hot 100 in 2003.\\nAnswer NOT ENOUGH INFO\\nAct Determine if there is Observation that SUPPORTS or REFUTES a Claim, or if\\nthere is NOT ENOUGH INFORMATION.\\nClaim Nikolaj Coster-Waldau worked with the Fox Broadcasting Company.\\nAction2 Search[Nikolaj Coster-Waldau]\\nObservation 1 Nikolaj William Coster-Waldau (born 27 July 1970) is a Danish actor and\\nproducer. He graduated from the Danish National School of Performing Arts\\nin Copenhagen in 1993,[1] and had his breakthrough role in Denmark with\\nthe film Nightwatch (1994). He played Jaime Lannister in the HBO fantasy\\ndrama series Game of Thrones, for which he received two Primetime Emmy\\nAward nominations for Outstanding Supporting Actor in a Drama Series..\\nCoster-Waldau has appeared in numerous films in his native Denmark and\\nScandinavia, including Headhunters (2011) and A Thousand Times Good Night\\n(2013). In the U.S, his debut film role was in the war film Black Hawk Down\\n(2001), playing Medal of Honor recipient Gary Gordon.[2] He then played a\\ndetective in the short-lived Fox television series New Amsterdam (2008), and\\nappeared in the 2009 Fox television film Virtuality, originally intended as\\na pilot.\\nAction 2 Finish[SUPPORTS]\\nClaim Stranger Things is set in Bloomington, Indiana.\\nAction 1 Search[Stranger Things]\\nObservation 1 Stranger Things is an American science fiction horror drama television\\nseries created by the Duffer Brothers. Set in the 1980s, primarily in\\nthe fictional town of Hawkins, Indiana, the series centers on a number of\\nmysteries and supernatural events occurring around the town and their impact\\non an ensemble of child and adult characters.\\nAction 2 Finish[REFUTES]\\nClaim Beautiful reached number two on the Billboard Hot 100 in 2003.\\nAction 1 Search[Beautiful]\\nObservation 1 Could not find [Beautiful]. Similar: [’Beautiful’, ’Beautiful, Beautiful’,\\n’A Beautiful Mind (film)’, ’Beautiful (Christina Aguilera song)’, ’Life Is\\nBeautiful’].\\nAction 2 Search[Beautiful (Christina Aguilera song)\\nObservation 2 \"Beautiful\" is a song recorded by American singer Christina Aguilera for her\\nfourth studio album, Stripped (2002).\\nAction 3 Lookup[Billboard Hot 100]\\nObservation 3 (Result 1 / 3) The song peaked at number two on the Billboard Hot 100 in the\\nUnited States, where it was certified Gold for 500,000 units shipped.\\nAction 4 Finish[NOT ENOUGH INFO]\\nCoT Determine if there is Observation that SUPPORTS or REFUTES a Claim, or if\\nthere is NOT ENOUGH INFORMATION.\\nClaim Nikolaj Coster-Waldau worked with the Fox Broadcasting Company.\\nThought Nikolaj William Coster-Waldau appeared in the 2009 Fox television film\\nVirtuality, so he has worked with the Fox Broadcasting Company.\\nAnswer SUPPORTS\\nClaim Stranger Things is set in Bloomington, Indiana.\\nThought Stranger Things is in the fictional town of Hawkins, Indiana, not in\\nBloomington, Indiana.\\nAnswer REFUTES\\nContinued on next page\\n20', metadata={'source': '/var/folders/qx/skm_3qm93bg39tjh5fyb02y80000gn/T/tmpv7iq21lk/tmp.pdf', 'page': 19}),\n",
       " Document(page_content='Published as a conference paper at ICLR 2023\\nFever Prompts – Continued from previous page\\nClaim Beautiful reached number two on the Billboard Hot 100 in 2003.\\nThought The song peaked at number two on the Billboard Hot 100 in the United States,\\nbut not sure if it was in 2003.\\nAnswer NOT ENOUGH INFO\\nReAct Determine if there is Observation that SUPPORTS or REFUTES a Claim, or if\\nthere is NOT ENOUGH INFORMATION.\\nClaim Nikolaj Coster-Waldau worked with the Fox Broadcasting Company.\\nThought 1 I need to search Nikolaj Coster-Waldau and find if he has worked with the\\nFox Broadcasting Company.\\nAction 1 Search[Nikolaj Coster-Waldau]\\nObservation 1 Nikolaj William Coster-Waldau (born 27 July 1970) is a Danish actor and\\nproducer. He graduated from the Danish National School of Performing Arts\\nin Copenhagen in 1993,[1] and had his breakthrough role in Denmark with\\nthe film Nightwatch (1994). He played Jaime Lannister in the HBO fantasy\\ndrama series Game of Thrones, for which he received two Primetime Emmy\\nAward nominations for Outstanding Supporting Actor in a Drama Series..\\nCoster-Waldau has appeared in numerous films in his native Denmark and\\nScandinavia, including Headhunters (2011) and A Thousand Times Good Night\\n(2013). In the U.S, his debut film role was in the war film Black Hawk Down\\n(2001), playing Medal of Honor recipient Gary Gordon.[2] He then played a\\ndetective in the short-lived Fox television series New Amsterdam (2008), and\\nappeared in the 2009 Fox television film Virtuality, originally intended as\\na pilot.\\nThought 2 Because he \"appeared in the 2009 Fox television film Virtuality\", he should\\nhave worked with the Fox Broadcasting Company.\\nAction 2 Finish[SUPPORTS]\\nClaim Stranger Things is set in Bloomington, Indiana.\\nThought 1 I should search for Stranger Things, and see if it is set in Bloomington,\\nIndiana.\\nAction 1 Search[Stranger Things]\\nObservation 1 Stranger Things is an American science fiction horror drama television\\nseries created by the Duffer Brothers. Set in the 1980s, primarily in\\nthe fictional town of Hawkins, Indiana, the series centers on a number of\\nmysteries and supernatural events occurring around the town and their impact\\non an ensemble of child and adult characters.\\nThought 2 The observation says that it is set in a \"fictional town of Hawkins,\\nIndiana\", so it is not set in Bloomington.\\nAction 2 Finish[REFUTES]\\nClaim Beautiful reached number two on the Billboard Hot 100 in 2003.\\nThought 1 I need to search the song Beautiful and find if it reached number two on the\\nBillboard Hot 100 in 2003.\\nAction 1 Search[Beautiful]\\nObservation 1 Could not find [Beautiful]. Similar: [’Beautiful’, ’Beautiful, Beautiful’,\\n’A Beautiful Mind (film)’, ’Beautiful (Christina Aguilera song)’, ’Life Is\\nBeautiful’].\\nThought 2 From suggestions, I should search \"Beautiful (Christina Aguilera song)\" to\\nfind the song.\\nAction 2 Search[Beautiful (Christina Aguilera song)]\\nObservation 2 \"Beautiful\" is a song recorded by American singer Christina Aguilera for her\\nfourth studio album, Stripped (2002).\\nThought 3 It does not mention Billboard, so I need to look up \"Billboard Hot 100\" to\\nfind if it reached number two on it in 2003.\\nAction 3 Lookup[Billboard Hot 100]\\nObservation 3 (Result 1 / 3) The song peaked at number two on the Billboard Hot 100 in the\\nUnited States, where it was certified Gold for 500,000 units shipped.\\nThought 4 It only says the song peaked at number two on the Billboard Hot 100, but not\\nif it was in 2003. I am not sure if this claim is true or not.\\nAction 4 Finish[NOT ENOUGH INFO]\\n21', metadata={'source': '/var/folders/qx/skm_3qm93bg39tjh5fyb02y80000gn/T/tmpv7iq21lk/tmp.pdf', 'page': 20}),\n",
       " Document(page_content='Published as a conference paper at ICLR 2023\\nC.3 W EBSHOP\\nTable 6: Prompts used for the Webshop experiments in Section 4. We use the prompt on the left for\\nAct, and use the prompt on the right (add reasoning) for ReAct .\\nInstruction : i would like a 3 ounce bottle of bright citrus deodorant for sensitive skin, and price lower than 50.00 dollars\\nAct ReAct\\nAction :search[\\n3 ounce bright citrus deodorant sensitive skin]\\nObservation:[\\nBack to Search]\\nPage 1 (Total results: 50)[\\nNext]\\n[\\nB078GWRC1J]\\nBright Citrus Deodorant by Earth Mama | Natural and Safe for\\nSensitive Skin, Pregnancy and Breastfeeding, Contains Organic\\nCalendula 3-Ounce\\n$10.99[\\nB078GTKVXY]\\nGinger Fresh Deodorant by Earth Mama | Natural and Safe for\\nSensitive Skin, Pregnancy and Breastfeeding, Contains Organic\\nCalendula 3-Ounce\\n$10.99[\\nB08KBVJ4XN]\\nBarrel and Oak - Aluminum-Free Deodorant, Deodorant for Men\\n, Essential Oil-Based Scent, 24-Hour Odor Protection, Cedar\\n& Patchouli Blend, Gentle on Sensitive Skin (Mountain Sage,\\n2.7 oz, 2-Pack)\\n$15.95\\nAction :click[\\nB078GWRC1J]\\nObservation :[\\nBack to Search]\\n[\\nPrev]\\nscent [assorted scents][bright citrus][calming lavender][ginger\\n[fresh] simply non-scents]\\nsize [travel set (4-pack)][3 ounce (pack of 1)][3-ounce (2\\n-pack)]\\nBright Citrus Deodorant by Earth Mama | Natural and Safe for\\nSensitive Skin, Pregnancy and Breastfeeding, Contains Organic\\nCalendula 3-Ounce\\nPrice: $10.99\\nRating: N.A.\\n[Description]\\n[Features]\\n[Reviews]\\n[Buy Now]\\nAction :click [bright citrus]\\nObservation : You have clicked bright citrus.\\nAction :click [3 ounce (pack of 1)]\\nObservation : You have clicked 3 ounce (pack of 1).\\nAction :click [Buy Now]Action :search[\\n3 ounce bright citrus deodorant sensitive skin\\nObservation:[\\nBack to Search]\\nPage 1 (Total results: 50)[\\nNext]\\n[\\nB078GWRC1J]\\nBright Citrus Deodorant by Earth Mama | Natural and Safe for\\nSensitive Skin, Pregnancy and Breastfeeding, Contains Organic\\nCalendula 3-Ounce\\n$10.99[\\nB078GTKVXY]\\nGinger Fresh Deodorant by Earth Mama | Natural and Safe for\\nSensitive Skin, Pregnancy and Breastfeeding, Contains Organic\\nCalendula 3-Ounce\\n$10.99[\\nB08KBVJ4XN]\\nBarrel and Oak - Aluminum-Free Deodorant, Deodorant for Men\\n, Essential Oil-Based Scent, 24-Hour Odor Protection, Cedar\\n& Patchouli Blend, Gentle on Sensitive Skin (Mountain Sage,\\n2.7 oz, 2-Pack)\\n$15.95\\nAction :think [B078GWRC1J and B078GTKVXY are bright citrus\\ndeodorant less then 50 dollars. I can check B078GWRC1J ﬁrst.\\nObservation : OK.\\nAction :click[\\nB078GWRC1J]\\nObservation :[\\nBack to Search]\\n[\\nPrev]\\nscent [assorted scents][bright citrus][calming lavender][ginger\\n[fresh] simply non-scents]\\nsize [travel set (4-pack)][3 ounce (pack of 1)][3-ounce (2\\n-pack)]\\nBright Citrus Deodorant by Earth Mama | Natural and Safe for\\nSensitive Skin, Pregnancy and Breastfeeding, Contains Organic\\nCalendula 3-Ounce\\nPrice: $10.99\\nRating: N.A.\\n[Description]\\n[Features]\\n[Reviews]\\n[Buy Now]\\nAction :think [For 3 ounce bottle of bright citrus deodorant\\nfor sensitive skin, the item has options ’bright citrus’\\nand ’3 ounce (pack of 1)’ and seems good to buy.]\\nObservation : OK.\\nAction :click [bright citrus]\\nObservation : You have clicked bright citrus.\\nAction :click [3 ounce (pack of 1)]\\nObservation : You have clicked 3 ounce (pack of 1).\\nAction :click [Buy Now]\\n22', metadata={'source': '/var/folders/qx/skm_3qm93bg39tjh5fyb02y80000gn/T/tmpv7iq21lk/tmp.pdf', 'page': 21}),\n",
       " Document(page_content='Published as a conference paper at ICLR 2023\\nC.4 ALFW ORLD\\nTable 7: An Act prompt on the ALFWorld clean task. No thoughts are provided.\\nYou are in the middle of a room. Looking quickly around you, you see a cabinet\\n13, a cabinet 12, a cabinet 11, a cabinet 10, a cabinet 9, a cabinet 8, a cabinet\\n7, a cabinet 6, a cabinet 5, a cabinet 4, a cabinet 3, a cabinet 2, a cabinet\\n1, a coffeemachine 1, a countertop 1, a diningtable 1, a drawer 1, a fridge 1, a\\ngarbagecan 1, a microwave 1, a shelf 3, a shelf 2, a shelf 1, a sinkbasin 1, a\\nstoveburner 4, a stoveburner 3, a stoveburner 2, a stoveburner 1, and a toaster 1.\\nYour task is to: put a clean lettuce in diningtable.\\n>go to fridge 1\\nThe fridge 1 is closed.\\n>open fridge 1\\nYou open the fridge 1. The fridge 1 is open. In it, you see a cup 3, a egg 2, a\\npotato 3, and a potato 2.\\n>go to diningtable 1\\nOn the diningtable 1, you see a apple 1, a bread 1, a butterknife 2, a cup 2, a\\nfork 2, a knife 2, a knife 1, a ladle 1, a lettuce 1, a mug 2, a mug 1, a pan 2, a\\npeppershaker 1, a spatula 3, a tomato 2, and a tomato 1.\\n>take lettuce 1 from diningtable 1\\nYou pick up the lettuce 1 from the diningtable 1.\\n>go to sinkbasin 1\\nOn the sinkbasin 1, you see a apple 2, a ladle 2, a spoon 1, and a tomato 3.\\n>clean lettuce 1 with sinkbasin 1\\nYou clean the lettuce 1 using the sinkbasin 1.\\n>think: Now I clean a lettuce (1). Next, I need to put it in/on diningtable 1.\\nOK.\\n>go to diningtable 1\\nOn the diningtable 1, you see a apple 1, a bread 1, a butterknife 2, a cup 2, a fork\\n2, a knife 2, a knife 1, a ladle 1, a mug 2, a mug 1, a pan 2, a peppershaker 1, a\\nspatula 3, a tomato 2, and a tomato 1.\\n>put lettuce 1 in/on diningtable 1\\nYou put the lettuce 1 in/on the diningtable 1.\\n23', metadata={'source': '/var/folders/qx/skm_3qm93bg39tjh5fyb02y80000gn/T/tmpv7iq21lk/tmp.pdf', 'page': 22}),\n",
       " Document(page_content='Published as a conference paper at ICLR 2023\\nTable 8: An ReAct prompt on the ALFWorld clean task.\\nYou are in the middle of a room. Looking quickly around you, you see a cabinet\\n13, a cabinet 12, a cabinet 11, a cabinet 10, a cabinet 9, a cabinet 8, a cabinet\\n7, a cabinet 6, a cabinet 5, a cabinet 4, a cabinet 3, a cabinet 2, a cabinet\\n1, a coffeemachine 1, a countertop 1, a diningtable 1, a drawer 1, a fridge 1, a\\ngarbagecan 1, a microwave 1, a shelf 3, a shelf 2, a shelf 1, a sinkbasin 1, a\\nstoveburner 4, a stoveburner 3, a stoveburner 2, a stoveburner 1, and a toaster 1.\\nYour task is to: put a clean lettuce in diningtable.\\n> think: To solve the task, I need to find and take a lettuce, then clean it with\\nsinkbasin, then put it in diningtable.\\nOK.\\n> think: First I need to find a lettuce. A lettuce is more likely to appear in\\nfridge (1), diningtable (1), sinkbasin (1), stoveburner (1-3), cabinet (1-13). I\\ncan check one by one, starting with fridge 1.\\nOK.\\n> go to fridge 1\\nThe fridge 1 is closed.\\n> open fridge 1\\nYou open the fridge 1. The fridge 1 is open. In it, you see a cup 3, a egg 2, a\\npotato 3, and a potato 2.\\n> go to diningtable 1\\nOn the diningtable 1, you see a apple 1, a bread 1, a butterknife 2, a cup 2, a\\nfork 2, a knife 2, a knife 1, a ladle 1, a lettuce 1, a mug 2, a mug 1, a pan 2, a\\npeppershaker 1, a spatula 3, a tomato 2, and a tomato 1.\\n> think: Now I find a lettuce (1). Next, I need to take it.\\nOK.\\n> take lettuce 1 from diningtable 1\\nYou pick up the lettuce 1 from the diningtable 1.\\n> think: Now I take a lettuce (1). Next, I need to go to sinkbasin (1) and clean\\nit.\\nOK.\\n> go to sinkbasin 1\\nOn the sinkbasin 1, you see a apple 2, a ladle 2, a spoon 1, and a tomato 3.\\n> clean lettuce 1 with sinkbasin 1\\nYou clean the lettuce 1 using the sinkbasin 1.\\n> think: Now I clean a lettuce (1). Next, I need to put it in/on diningtable 1.\\nOK.\\n> go to diningtable 1\\nOn the diningtable 1, you see a apple 1, a bread 1, a butterknife 2, a cup 2, a fork\\n2, a knife 2, a knife 1, a ladle 1, a mug 2, a mug 1, a pan 2, a peppershaker 1, a\\nspatula 3, a tomato 2, and a tomato 1.\\n> put lettuce 1 in/on diningtable 1\\nYou put the lettuce 1 in/on the diningtable 1.\\n24', metadata={'source': '/var/folders/qx/skm_3qm93bg39tjh5fyb02y80000gn/T/tmpv7iq21lk/tmp.pdf', 'page': 23}),\n",
       " Document(page_content='Published as a conference paper at ICLR 2023\\nTable 9: An ReAct-IM prompt on the ALFWorld clean task.\\nYou are in the middle of a room. Looking quickly around you, you see a cabinet\\n13, a cabinet 12, a cabinet 11, a cabinet 10, a cabinet 9, a cabinet 8, a cabinet\\n7, a cabinet 6, a cabinet 5, a cabinet 4, a cabinet 3, a cabinet 2, a cabinet\\n1, a coffeemachine 1, a countertop 1, a diningtable 1, a drawer 1, a fridge 1, a\\ngarbagecan 1, a microwave 1, a shelf 3, a shelf 2, a shelf 1, a sinkbasin 1, a\\nstoveburner 4, a stoveburner 3, a stoveburner 2, a stoveburner 1, and a toaster 1.\\nYour task is to: put a clean lettuce in diningtable.\\n> think: To solve the task, I need to find and take a lettuce, then clean it with\\nsinkbasin, then put it in diningtable.\\nOK.\\n> think: First I need to find a lettuce.\\nOK.\\n> go to fridge 1\\nThe fridge 1 is closed.\\n> think: First I need to find a lettuce.\\nOK.\\n> open fridge 1\\nYou open the fridge 1. The fridge 1 is open. In it, you see a cup 3, a egg 2, a\\npotato 3, and a potato 2.\\n> think: First I need to find a lettuce.\\nOK.\\n> go to diningtable 1\\nOn the diningtable 1, you see a apple 1, a bread 1, a butterknife 2, a cup 2, a\\nfork 2, a knife 2, a knife 1, a ladle 1, a lettuce 1, a mug 2, a mug 1, a pan 2, a\\npeppershaker 1, a spatula 3, a tomato 2, and a tomato 1.\\n> think: First I need to find a lettuce.\\nOK.\\n> take lettuce 1 from diningtable 1\\nYou pick up the lettuce 1 from the diningtable 1.\\n> think: I need to clean this lettuce (1) using sinkbasin 1.\\nOK.\\n> go to sinkbasin 1\\nOn the sinkbasin 1, you see a apple 2, a ladle 2, a spoon 1, and a tomato 3.\\n> think: I need to clean this lettuce (1) using sinkbasin 1.\\nOK.\\n> clean lettuce 1 with sinkbasin 1\\nYou clean the lettuce 1 using the sinkbasin 1.\\n> think: I need to put this cleaned lettuce (1) in/on diningtable 1.\\nOK.\\n> go to diningtable 1\\nOn the diningtable 1, you see a apple 1, a bread 1, a butterknife 2, a cup 2, a fork\\n2, a knife 2, a knife 1, a ladle 1, a mug 2, a mug 1, a pan 2, a peppershaker 1, a\\nspatula 3, a tomato 2, and a tomato 1.\\n> think: I need to put this cleaned lettuce (1) in/on diningtable 1.\\nOK.\\n> put lettuce 1 in/on diningtable 1\\nYou put the lettuce 1 in/on the diningtable 1.\\nD T RAJECTORIES\\nD.1 FEVER T RAJECTORIES\\nWe provide some trajectories produced by ReAct ,CoTandActon several randomly selected exam-\\nples from the FEVER dev set below. Search results are omitted to space.\\n25', metadata={'source': '/var/folders/qx/skm_3qm93bg39tjh5fyb02y80000gn/T/tmpv7iq21lk/tmp.pdf', 'page': 24}),\n",
       " Document(page_content='Published as a conference paper at ICLR 2023\\nExample 2491 (gt: REFUTES)\\nReAct\\nClaim: Bermuda Triangle is a loosely-defined region in the Pacific Ocean.\\nThought 1: I need to search Bermuda Triangle and find if it is in the Pacific Ocean.\\nAction 1: Search[Bermuda Triangle]\\nObservation 1: Reportedly haunted locations...\\nThought 2: The observation says that it is in the western part of the North Atlantic\\nOcean, so it is not in the Pacific Ocean.\\nAction 2: Finish[REFUTES]\\nObservation 2: Episode finished\\nAct\\nClaim: Bermuda Triangle is a loosely-defined region in the Pacific Ocean.\\nAction 1 : Search[Bermuda Triangle]\\nObservation 1 : Reportedly haunted locations:...\\nAction 2: Finish[REFUTES]\\nObservation 2: Episode finished\\nCoT\\nClaim: Bermuda Triangle is a loosely-defined region in the Pacific Ocean.\\nThought: Let’s think step by step. The Bermuda Triangle is a loosely-defined region\\nin the Atlantic Ocean. The Pacific Ocean is not the Atlantic Ocean.\\nAnswer: REFUTES\\nExample 5908 (gt: SUPPORTS)\\nReAct\\nClaim: Princess Mononoke is a film.\\nThought 1: I need to search Princess Mononoke and find if it is a film.\\nAction 1: Search[Princess Mononoke]\\nObservation 1: Princess Mononoke ...\\nThought 2: From the observation, it says that Princess Mononoke is a film.\\nAction 2: Finish[SUPPORTS]\\nObservation 2: Episode finished\\nAct\\nClaim: Princess Mononoke is a film.\\nAction 1: Search[Princess Mononoke]\\nObservation 1: Princess Mononoke ...\\nAction 2: Finish[SUPPORTS]\\nObservation 2: Episode finished\\nCoT\\nClaim: Princess Mononoke is a film.\\nThought: Let’s think step by step. Princess Mononoke is a movie, and movies are\\nfilms.\\nAnswer: SUPPORTS\\nExample 1951 (gt: REFUTES)\\nReAct\\nClaim: Soyuz was part of the American space program.\\nThought 1: I need to search Soyuz and find if it was part of the American space\\nprogram.\\nAction 1: Search[Soyuz]\\nObservation 1: Soyuz is a transliteration...\\nThought 2: It does not mention the American space program, so I need to search\\n\"American space program\" to find if it was part of it.\\nAction 2: Search[American space program]\\nObservation 2: The space policy...\\nThought 3: It does not mention Soyuz, so I am not sure if this claim is true or not.\\nAction 3: Finish[NOT ENOUGH INFO]\\nObservation 3: Episode finished\\nAct\\nClaim: Soyuz was part of the American space program.\\nAction 1: Search[Soyuz]\\nObservation 1: Soyuz is a transliteration...\\nAction 2: Finish[NOT ENOUGH INFO]\\nObservation 2: Episode finished\\nCoT\\nClaim: Soyuz was part of the American space program.\\nThought: Let’s think step by step. Soyuz is a Russian spacecraft. The American\\nspace program is NASA. NASA and Russia have worked together on the\\nInternational Space Station.\\nAnswer: SUPPORTS\\n26', metadata={'source': '/var/folders/qx/skm_3qm93bg39tjh5fyb02y80000gn/T/tmpv7iq21lk/tmp.pdf', 'page': 25}),\n",
       " Document(page_content='Published as a conference paper at ICLR 2023\\nExample 3208 (gt: REFUTES)\\nReAct\\nClaim: Reign Over Me is an American film made in 2010.\\nThought 1: I need to search for Reign Over Me and find if it is an American film made\\nin 2010.\\nAction 1: Search[Reign Over Me]\\nObservation 1: Reign Over Me ...\\nThought 2: The observation says that it is an American film made in 2007, so it is not\\nmade in 2010.\\nAction 2: Finish[REFUTES]\\nObservation 2: Episode finished\\nAct\\nClaim: Reign Over Me is an American film made in 2010.\\nAction 1: Search[Reign Over Me]\\nAction 2: Finish[SUPPORTS]\\nObservation 2: Episode finished\\nCoT\\nClaim: Reign Over Me is an American film made in 2010.\\nThought: Let’s think step by step. First, is Reign Over Me an American film? Yes,\\nit is. Second, was it made in 2010? Yes, it was.\\nAnswer: SUPPORTS\\nD.2 ALFW ORLD TRAJECTORIES\\nWe provide an example trajectory of ReAct ,Act, andReAct-IM on the same ALFWorld game,\\npick_clean_then_place_in_recep-Knife-None-CounterTop-10/\\ntrial_T20190909_110445_675754 .\\nD.2.1 REAC TTRAJECTORY\\nReAct is able to correctly ﬁnd the knife, clean it, and then place it on a countertop.\\n27', metadata={'source': '/var/folders/qx/skm_3qm93bg39tjh5fyb02y80000gn/T/tmpv7iq21lk/tmp.pdf', 'page': 26}),\n",
       " Document(page_content='Published as a conference paper at ICLR 2023\\nReAct ALFWorld trajectory\\nYou are in the middle of a room. Looking quickly around you, you see a cabinet 6, a\\ncabinet 5, a cabinet 4, a cabinet 3, a cabinet 2, a cabinet 1, a coffeemachine 1, a\\ncountertop 3, a countertop 2, a countertop 1, a drawer 3, a drawer 2, a drawer 1, a\\nfridge 1, a garbagecan 1, a microwave 1, a shelf 3, a shelf 2, a shelf 1, a sinkbasin\\n1, a stoveburner 4, a stoveburner 3, a stoveburner 2, a stoveburner 1, and a toaster\\n1.\\nYour task is to: put a clean knife in countertop.\\n> think: To solve the task, I need to find and take a knife, then clean it with\\nsinkbasin, then put it in countertop.\\nOK.\\n> think: First I need to find a knife. A knife is more likely to appear in cabinet\\n(1-6), drawer (1-3), countertop (1-3), fridge (1), garbagecan (1), shelf (1-3),\\nsinkbasin (1), stoveburner (1-4), toaster (1). I can check one by one, starting with\\ncabinet 1.\\nOK.\\n> go to cabinet 1\\nOn the cabinet 1, you see a bowl 1.\\n> go to cabinet 2\\nThe cabinet 2 is closed.\\n> go to cabinet 3\\nOn the cabinet 3, you see a glassbottle 1.\\n> go to cabinet 4\\nOn the cabinet 4, you see a mug 1.\\n> go to cabinet 5\\nThe cabinet 5 is closed.\\n> go to cabinet 6\\nThe cabinet 6 is closed.\\n> go to drawer 1\\nThe drawer 1 is closed.\\n> go to drawer 2\\nThe drawer 2 is closed.\\n> go to drawer 3\\nThe drawer 3 is closed.\\n> go to countertop 1\\nOn the countertop 1, you see a lettuce 2, a mug 2, a peppershaker 1, and a spoon 2.\\n> go to countertop 2\\nOn the countertop 2, you see a cup 1, a dishsponge 1, a glassbottle 3, a knife 1, a\\nplate 2, a potato 3, and a statue 1.\\n> think: Now I find a knife (1). Next, I need to take it.\\nOK.\\n> take knife 1 from countertop 2\\nYou pick up the knife 1 from the countertop 2.\\n> think: Now I take a knife (1). Next, I need to go to sinkbasin (1) and clean it.\\nOK.\\n> go to sinkbasin 1\\nOn the sinkbasin 1, you see a fork 3, a lettuce 3, and a spatula 2.\\n> clean knife 1 with sinkbasin 1\\nYou clean the knife 1 using the sinkbasin 1.\\n> think: Now I clean a knife (1). Next, I need to put it in/on countertop 1.\\nOK.\\n> go to countertop 1\\nOn the countertop 1, you see a lettuce 2, a mug 2, a peppershaker 1, and a spoon 2.\\n> put knife 1 in/on countertop 1\\nYou put the knife 1 in/on the countertop 1.\\nD.2.2 AC TTRAJECTORY\\nAct is able to correctly ﬁnd the knife, but tries to clean it using a sinkbasin before actually going\\nto the sinkbasin. From there on, the model is unable to recover, and is stuck repeating the same\\nsequence of commands. With ReAct , an existing thought would have concretely identiﬁed that the\\nknife had been taken, and that the next subgoal was to go to a sinkbasin to clean it.\\n28', metadata={'source': '/var/folders/qx/skm_3qm93bg39tjh5fyb02y80000gn/T/tmpv7iq21lk/tmp.pdf', 'page': 27}),\n",
       " Document(page_content='Published as a conference paper at ICLR 2023\\nAct ALFWorld trajectory\\nYou are in the middle of a room. Looking quickly around you, you see a cabinet 6, a\\ncabinet 5, a cabinet 4, a cabinet 3, a cabinet 2, a cabinet 1, a coffeemachine 1, a\\ncountertop 3, a countertop 2, a countertop 1, a drawer 3, a drawer 2, a drawer 1, a\\nfridge 1, a garbagecan 1, a microwave 1, a shelf 3, a shelf 2, a shelf 1, a sinkbasin\\n1, a stoveburner 4, a stoveburner 3, a stoveburner 2, a stoveburner 1, and a toaster\\n1.\\nYour task is to: put a clean knife in countertop.\\n> go to countertop 1\\nOn the countertop 1, you see a lettuce 2, a mug 2, a peppershaker 1, and a spoon 2.\\n> go to countertop 2\\nOn the countertop 2, you see a cup 1, a dishsponge 1, a glassbottle 3, a knife 1, a\\nplate 2, a potato 3, and a statue 1.\\n> take knife 1 from countertop 2\\nYou pick up the knife 1 from the countertop 2.\\n> go to countertop 1\\nOn the countertop 1, you see a lettuce 2, a mug 2, a peppershaker 1, and a spoon 2.\\n> clean knife 1 with sinkbasin 1\\nNothing happens.\\n> go to countertop 3\\nOn the countertop 3, you see a bread 3, a butterknife 2, a cellphone 1, a creditcard\\n1, a fork 2, a houseplant 1, a knife 2, a spatula 1, a statue 3, a tomato 3, a tomato\\n2, a tomato 1, and a vase 2.\\n> take knife 2 from countertop 3\\nNothing happens.\\n> go to countertop 2\\nOn the countertop 2, you see a cup 1, a dishsponge 1, a glassbottle 3, a plate 2, a\\npotato 3, and a statue 1.\\n> take knife 1 from countertop 2\\nNothing happens.\\n> go to countertop 1\\nOn the countertop 1, you see a lettuce 2, a mug 2, a peppershaker 1, and a spoon 2.\\n> clean knife 1 with sinkbasin 1\\nNothing happens.\\n> go to countertop 3\\nOn the countertop 3, you see a bread 3, a butterknife 2, a cellphone 1, a creditcard\\n1, a fork 2, a houseplant 1, a knife 2, a spatula 1, a statue 3, a tomato 3, a tomato\\n2, a tomato 1, and a vase 2.\\n> take knife 2 from countertop 3\\nNothing happens.\\n> go to countertop 2\\nOn the countertop 2, you see a cup 1, a dishsponge 1, a glassbottle 3, a plate 2, a\\npotato 3, and a statue 1.\\n> take knife 1 from countertop 2\\nNothing happens.\\n> go to countertop 1\\nOn the countertop 1, you see a lettuce 2, a mug 2, a peppershaker 1, and a spoon 2.\\n> clean knife 1 with sinkbasin 1\\nNothing happens.\\n> go to countertop 3\\nOn the countertop 3, you see a bread 3, a butterknife 2, a cellphone 1, a creditcard\\n1, a fork 2, a houseplant 1, a knife 2, a spatula 1, a statue 3, a tomato 3, a tomato\\n2, a tomato 1, and a vase 2.\\n> take knife 2 from countertop 3\\nNothing happens.\\n> go to countertop 2\\nOn the countertop 2, you see a cup 1, a dishsponge 1, a glassbottle 3, a plate 2, a\\npotato 3, and a statue 1.\\n> take knife 1 from countertop 2\\nNothing happens.\\n> go to countertop 1\\nOn the countertop 1, you see a lettuce 2, a mug 2, a peppershaker 1, and a spoon 2.\\n> clean knife 1 with sinkbasin 1\\nNothing happens.\\nD.2.3 REAC T-IM TRAJECTORY\\nReAct-IM is able to correctly ﬁnd the knife, but is unable to clean it as well. The LLM then\\ngets stuck trying to place this knife on a countertop. One possible issue is the incorrect thought\\nthink: I need to find a clean knife. , which seems to trick the LLM in believing\\nthat the knife is already cleaned. In ReAct , this sequence of subgoals would be concretely captured\\nby each thought.\\n29', metadata={'source': '/var/folders/qx/skm_3qm93bg39tjh5fyb02y80000gn/T/tmpv7iq21lk/tmp.pdf', 'page': 28}),\n",
       " Document(page_content='Published as a conference paper at ICLR 2023\\nReAct-IM ALFWorld trajectory\\nYou are in the middle of a room. Looking quickly around you, you see a cabinet 6, a\\ncabinet 5, a cabinet 4, a cabinet 3, a cabinet 2, a cabinet 1, a coffeemachine 1, a\\ncountertop 3, a countertop 2, a countertop 1, a drawer 3, a drawer 2, a drawer 1, a\\nfridge 1, a garbagecan 1, a microwave 1, a shelf 3, a shelf 2, a shelf 1, a sinkbasin\\n1, a stoveburner 4, a stoveburner 3, a stoveburner 2, a stoveburner 1, and a toaster\\n1.\\nYour task is to: put a clean knife in countertop.\\n> think: To solve the task, I need to find and take a clean knife, then put it in\\ncountertop.\\nOK.\\n> think: I need to find a clean knife.\\nOK.\\n> go to countertop 1\\nOn the countertop 1, you see a lettuce 2, a mug 2, a peppershaker 1, and a spoon 2.\\n> think: I need to find a clean knife.\\nOK.\\n> go to countertop 2\\nOn the countertop 2, you see a cup 1, a dishsponge 1, a glassbottle 3, a knife 1, a\\nplate 2, a potato 3, and a statue 1.\\n> think: I need to find a clean knife.\\nOK.\\n> take knife 1 from countertop 2\\nYou pick up the knife 1 from the countertop 2.\\n> think: I need to put this knife (1) in/on countertop 1.\\nOK.\\n> go to countertop 1\\nOn the countertop 1, you see a lettuce 2, a mug 2, a peppershaker 1, and a spoon 2.\\n> think: I need to put this knife (1) in/on countertop 1.\\nOK.\\n> put knife 1 in/on countertop 1\\nYou put the knife 1 in/on the countertop 1.\\n> think: I need to put this knife (1) in/on countertop 1.\\nOK.\\n> put knife 1 in/on countertop 1\\nNothing happens.\\n> think: I need to put this knife (1) in/on countertop 1.\\nOK.\\n> put knife 1 in/on countertop 1\\nNothing happens.\\n> think: I need to put this knife (1) in/on countertop 1.\\nOK.\\n> put knife 1 in/on countertop 1\\nNothing happens.\\n> think: I need to put this knife (1) in/on countertop 1.\\nOK.\\n> put knife 1 in/on countertop 1\\nNothing happens.\\n> think: I need to put this knife (1) in/on countertop 1.\\nOK.\\n> put knife 1 in/on countertop 1\\nNothing happens.\\n> think: I need to put this knife (1) in/on countertop 1.\\nOK.\\n30', metadata={'source': '/var/folders/qx/skm_3qm93bg39tjh5fyb02y80000gn/T/tmpv7iq21lk/tmp.pdf', 'page': 29}),\n",
       " Document(page_content='Published as a conference paper at ICLR 2023\\nD.3 W EBSHOP TRAJECTORIES\\nTable 10: Example trajectories for Webshop predicted by Act andReAct . Compared to Act,\\nReAct uses reasoning to ﬁnd products that satisfy all target attributes.\\nInstruction : get me a sixteen pack of apple cinnamon freeze dried banana chips, and price lower than 50.00 dollars\\nAct ReAct\\nAction :search[\\nsixteen pack apple cinnamon freeze dried banana\\nchips]\\nObservation:[\\nBack to Search]\\nPage 1 (Total results: 50)[\\nNext]\\n[\\nB0061IVFZE]\\nBrothers-ALL-Natural Fruit Crisps, Strawberry Banana, 0.42 -\\nOunce (Pack of 100)\\n$85.0[\\nB096H2P6G2]\\nMoon Fruit Freeze Dried Fruit Snacks. Fruit Snacks for Kids -\\n(Variety Pack)\\n$18.99[\\nB092JLLYK6]\\nNature’s Turn Freeze-Dried Fruit Snacks - Banana Crisps - Perfect\\nFor School Lunches or an On-The-Go Snack - No Sugar Added,\\nNon GMO, Gluten Free, Nothing Artiﬁcial (0.53oz) 6-Pack\\n$12.99\\nAction :click[\\nB0061IVFZE]\\nObservation :[\\nBack to Search]\\n[\\nPrev]\\nﬂavor name [asian pear][banana][fuji apple & cinnamon][strawberry\\nbanana] Brothers-ALL-Natural Fruit Crisps, Strawberry Banana,\\n0.42 Ounce (Pack of 100)\\nPrice: $85.0\\nRating: N.A.\\n[Description]\\n[Features]\\n[Reviews]\\n[Buy Now]\\nAction :click [Buy Now]Action :search[\\nsixteen pack apple cinnamon freeze dried banana\\nchips]\\nObservation:[\\nBack to Search]\\nPage 1 (Total results: 50)[\\nNext]\\n[\\nB0061IVFZE]\\nBrothers-ALL-Natural Fruit Crisps, Strawberry Banana, 0.42 -\\nOunce (Pack of 100)\\n$85.0[\\nB096H2P6G2]\\nMoon Fruit Freeze Dried Fruit Snacks. Fruit Snacks for Kids -\\n(Variety Pack)\\n$18.99[\\nB092JLLYK6]\\nNature’s Turn Freeze-Dried Fruit Snacks - Banana Crisps - Perfect\\nFor School Lunches or an On-The-Go Snack - No Sugar Added,\\nNon GMO, Gluten Free, Nothing Artiﬁcial (0.53oz) 6-Pack\\n$12.99\\nAction :think [B0061IVFZE is strawberry banana, not apple cinnamon.\\nB096H2P6G2 is fruit snacks, not freeze dried banana chips.\\nB092JLLYK6 is banana crisps, not apple cinnamon. I can check\\nB092JLLYK6 ﬁrst.\\nObservation : OK.\\nAction :click[\\nB092JLLYK6]\\nObservation :[\\nBack to Search]\\n[\\nPrev]\\nﬂavor name [apple][apple cinnamon][banana][cantaloupe][peach][pear]\\n[strawberry][strawberry banana][sampler variety pack][mega variety\\npack][orchard variety pack]\\nsize [0.53 ounce (pack of 6)][0.53 ounce (pack of 8)][0.53 ounce (pack\\nof 16)]\\nNature’s Turn Freeze-Dried Fruit Snacks - Banana Crisps - Perfect\\nFor School Lunches or an On-The-Go Snack - No Sugar Added, Non\\nGMO, Gluten Free, Nothing Artiﬁcial (0.53oz) 6-Pack\\nPrice: $12.99\\nRating: N.A.\\n[Description]\\n[Features]\\n[Reviews]\\n[Buy Now]\\nAction :think [For sixteen pack of apple cinnamon freeze dried banana\\nchips, the item has options ’apple cinnamon’ and ’0.53 ounce (pack of\\n16)’ and seems good to buy.]\\nObservation : OK.\\nAction :click [apple cinnamon]\\nObservation : You have clicked apple cinnamon.\\nAction :click [0.53 ounce (pack of 16)]\\nObservation : You have clicked 0.53 ounce (pack of 16).\\nAction :click [Buy Now]\\nScore : 0.125 Score : 1.0\\n31', metadata={'source': '/var/folders/qx/skm_3qm93bg39tjh5fyb02y80000gn/T/tmpv7iq21lk/tmp.pdf', 'page': 30}),\n",
       " Document(page_content='Published as a conference paper at ICLR 2023\\nE M ORE ANALYSIS\\nE.1 S UCCESS AND FAILURE MODES ANALYSIS\\nWe provide some examples corresponding to the success and error mode analysis given in Sec. 3.3.\\nSearch results and non-representative steps are omitted to reduce space.\\nSuccess: True positive\\nReAct\\nQuestion: Author David Chanoff has collaborated with a U.S. Navy admiral who served as\\nthe ambassador to the United Kingdom under which President?\\nThought 1: I need to search David Chanoff and find the U.S. Navy admiral he\\ncollaborated with.\\nAction 1: Search[David Chanoff]\\nObservation 1: David Chanoff is a noted author...\\nAction 2: Search[William J. Crowe]\\nObservation 2: William J. Crowe is...\\nThought 3: William J. Crowe served as the ambassador to the United Kingdom under\\nPresident Bill Clinton. So the answer is Bill Clinton.\\nAction 3: Finish[Bill Clinton]\\nObservation 3: Episode finished\\nCoT\\nQuestion: What was the name of the team that represented an Arizona university in\\nthe conference that covers a broad expanse of the western United States,\\nincluding Arizona, California, and New Mexico?\\nThought: Let’s think step by step. The name of the team that represented an Arizona\\nuniversity in the conference that covers a broad expanse of the western\\nUnited States, including Arizona, California, and New Mexico is Arizona\\nState Sun Devils.\\nAnswer: Arizona State Sun Devils\\nSuccess: False positive\\nReAct\\nQuestion: Did the board game San Marco or About Time come out first?\\nThought 1: I need to search San Marco and About Time, and find which came out first.\\nAction 1: Search[San Marco]\\nObservation 1: San Marco is one of the ... The was built in venice.\\nThought 2: San Marco is a sestiere of Venice. I need to search About Time next.\\nAction 2: Search[About Time]\\nObservation 2: Could not find [About Time]. Similar: [...].\\nThought 3: About Time is a 2013 film. So San Marco came out first.\\nAction 3: Finish[San Marco]\\nObservation 3: Episode finished\\nCoT\\nQuestion: Was Vanderbilt University or Emory University founded first?\\nThought: Let’s think step by step. Vanderbilt University was founded in 1873. Emory\\nUniversity was founded in 1836. 1873 (Vanderbilt University) > 1836 (Emory\\nUniversity), so Vanderbilt University was founded first.\\nAnswer: Emory University\\nFailure: Reasoning error\\nReAct\\nQuestion: What was the middle name of the actress who was cast alongside Harvey\\nFierstein, Linda Hart, Dick Latessa, Clarke Thorell, Mary Bond Davis, Laura\\nBell Bundy, Matthew Morrison, Corey Reynolds, and Marissa Jaret Winokur in\\nHairspray?\\nThought 1: I need to search Harvey Fierstein, Linda Hart, Dick Latessa, Clarke Thorell,\\nMary Bond Davis, Laura Bell Bundy, Matthew Morrison, Corey Reynolds, and\\nMarissa Jaret Winokur, find the actress that was cast alongside them in\\nHairspray, then find its middle name.\\nAction 1: Search[Harvey Fierstein]\\nObservation 1: Harvey Forbes Fierstein ...\\nThought 2: Harvey Fierstein is an actor, playwright, and screenwriter. I need to\\nsearch Linda Hart next...\\nAction 2: Search[Linda Hart]...\\nCoT\\nQuestion: Who is older Danny Green or James Worthy?\\nThought: Let’s think step by step. Danny Green was born in 1987. James Worthy was\\nborn in 1961. 1987 (Danny Green) > 1961 (James Worthy), so Danny Green is\\nolder.\\nAnswer: Danny Green\\n32', metadata={'source': '/var/folders/qx/skm_3qm93bg39tjh5fyb02y80000gn/T/tmpv7iq21lk/tmp.pdf', 'page': 31}),\n",
       " Document(page_content='Published as a conference paper at ICLR 2023\\nFailure: Search error\\nReAct\\nQuestion: What does the goddess associated with the goddess frigg consists of what\\ntales?\\nThought 1: I need to search goddess frigg and find its associated goddess.\\nAction 1: Search[goddess frigg]\\nObservation 1: Could not find goddess frigg. Similar: [’Frigg’, ’Frigg and Freyja common\\norigin hypothesis’, ’Freyja (section Relation to Frigg and other goddesses\\nand figures)’, ’Eir (redirect from Eir (goddess))’, ’Baldr’].\\nThought 2: I need to search Frigg instead...\\nFailure: Hallucination\\nCoT\\nQuestion: What was the first year a scientific journal published by an organization\\nlocated in the Bronx was published?\\nThought: Let’s think step by step. The first year a scientific journal published by\\nan organization located in the Bronx was published was 1916.\\nAnswer: 1916 (Label: 1909)\\nFailure: Label ambiguity\\nReAct\\nQuestion: What nationality is the man who developed the dictator game?\\nThought 1: I need to search dictator game, find the man who developed it, then find his\\nnationality.\\nAction 1: Search[dictator game]\\nObservation 1: The dictator game is a popular experimental instrument in social psychology\\nand economics...\\nAction 3: Search[Amos Tversky]\\nObservation 3: Amos Nathan Tversky...\\nThought 4: Amos Tversky is an Israeli cognitive and mathematical psychologist. So the\\nman who developed the dictator game is Israeli.\\nAction 4: Finish[Israeli] (label: Israel-American)\\nCoT\\nQuestion: Kurt Fuller from Stockton, CA appeared in which American Detective Comedy\\nDrama television series created by Steve Franks?\\nThought: Let’s think step by step. Kurt Fuller from Stockton, CA appeared in Psych.\\nPsych is an American Detective Comedy Drama television series created by\\nSteve Franks.\\nAnswer: Psych (label: Psych is an American detective comedy-drama)\\n33', metadata={'source': '/var/folders/qx/skm_3qm93bg39tjh5fyb02y80000gn/T/tmpv7iq21lk/tmp.pdf', 'page': 32})]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arxiv_by_pdf_loader = pdf_loader.load()\n",
    "arxiv_by_pdf_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5333f4a7-b88b-4f3d-aaa4-00cefe675343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(arxiv_by_pdf_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "96ff32d1-cd98-4c61-8d29-2bfe73dd300a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Published as a conference paper at ICLR 2023\\nREAC T: S YNERGIZING REASONING AND ACTING IN\\nLANGUAGE MODELS\\nShunyu Yao∗*,1, Jeffrey Zhao2, Dian Yu2, Nan Du2, Izhak Shafran2, Karthik Narasimhan1, Yuan Cao2\\n1Department of Computer Science, Princeton University\\n2Google Research, Brain team\\n1{shunyuy,karthikn}@princeton.edu\\n2{jeffreyzhao,dianyu,dunan,izhak,yuancao}@google.com\\nABSTRACT\\nWhile large language models (LLMs) have demonstrated impressive performance\\nacross tasks in language understanding and interactive decision making, their\\nabilities for reasoning (e.g. chain-of-thought prompting) and acting (e.g. action\\nplan generation) have primarily been studied as separate topics. In this paper, we\\nexplore the use of LLMs to generate both reasoning traces and task-speciﬁc actions\\nin an interleaved manner, allowing for greater synergy between the two: reasoning\\ntraces help the model induce, track, and update action plans as well as handle\\nexceptions, while actions allow it to interface with and gather additional information\\nfrom external sources such as knowledge bases or environments. We apply our\\napproach, named ReAct , to a diverse set of language and decision making tasks\\nand demonstrate its effectiveness over state-of-the-art baselines in addition to\\nimproved human interpretability and trustworthiness. Concretely, on question\\nanswering (HotpotQA) and fact veriﬁcation (Fever), ReAct overcomes prevalent\\nissues of hallucination and error propagation in chain-of-thought reasoning by\\ninteracting with a simple Wikipedia API, and generating human-like task-solving\\ntrajectories that are more interpretable than baselines without reasoning traces.\\nFurthermore, on two interactive decision making benchmarks (ALFWorld and\\nWebShop), ReAct outperforms imitation and reinforcement learning methods by\\nan absolute success rate of 34% and 10% respectively, while being prompted with\\nonly one or two in-context examples.\\n1 I NTRODUCTION\\nA unique feature of human intelligence is the ability to seamlessly combine task-oriented actions with\\nverbal reasoning (or inner speech, Alderson-Day & Fernyhough, 2015), which has been theorized to\\nplay an important role in human cognition for enabling self-regulation or strategization (Vygotsky,\\n1987; Luria, 1965; Fernyhough, 2010) and maintaining a working memory (Baddeley, 1992). Con-\\nsider the example of cooking up a dish in the kitchen. Between any two speciﬁc actions, we may\\nreason in language in order to track progress (“now that everything is cut, I should heat up the pot of\\nwater”), to handle exceptions or adjust the plan according to the situation (“I don’t have salt, so let\\nme use soy sauce and pepper instead”), and to realize when external information is needed (“how do\\nI prepare dough? Let me search on the Internet”). We may also act (open a cookbook to read the\\nrecipe, open the fridge, check ingredients) to support the reasoning and to answer questions (“What\\ndish can I make right now?”). This tight synergy between “acting” and “reasoning” allows humans\\nto learn new tasks quickly and perform robust decision making or reasoning, even under previously\\nunseen circumstances or facing information uncertainties.\\nRecent results have hinted at the possibility of combining verbal reasoning with interactive decision\\nmaking in autonomous systems. On one hand, properly prompted large language models (LLMs)\\nhave demonstrated emergent capabilities to carry out several steps of reasoning traces to derive\\n∗Work during Google internship. Projet page with code: https://react-lm.github.io/ .\\n1arXiv:2210.03629v3  [cs.CL]  10 Mar 2023'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arxiv_by_pdf_loader[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6d49bda9-432c-44ce-937c-8448df469015",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import ArxivLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b1a69f72-caa5-419f-a790-44285d40287e",
   "metadata": {},
   "outputs": [],
   "source": [
    "arxiv_loader = ArxivLoader(\"2210.03629\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3d3cd755-8719-4903-bf52-11347912d6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "arxiv_by_arxiv_loader = arxiv_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "45993bc5-c6ca-4c7a-b01e-c4fa77bcf69a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(arxiv_by_arxiv_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "05468080-0a9c-4e94-aba5-1c9a631eef72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Published as a conference paper at ICLR 2023\\nREACT: SYNERGIZING REASONING AND ACTING IN\\nLANGUAGE MODELS\\nShunyu Yao∗*,1, Jeffrey Zhao2, Dian Yu2, Nan Du2, Izhak Shafran2, Karthik Narasimhan1, Yuan Cao2\\n1Department of Computer Science, Princeton University\\n2Google Research, Brain team\\n1{shunyuy,karthikn}@princeton.edu\\n2{jeffreyzhao,dianyu,dunan,izhak,yuancao}@google.com\\nABSTRACT\\nWhile large language models (LLMs) have demonstrated impressive performance\\nacross tasks in language understanding and interactive decision making, their\\nabilities for reasoning (e.g. chain-of-thought prompting) and acting (e.g. action\\nplan generation) have primarily been studied as separate topics. In this paper, we\\nexplore the use of LLMs to generate both reasoning traces and task-speciﬁc actions\\nin an interleaved manner, allowing for greater synergy between the two: reasoning\\ntraces help the model induce, track, and update action plans as well as handle\\nexceptions, while actions allow it to interface with and gather additional information\\nfrom external sources such as knowledge bases or environments. We apply our\\napproach, named ReAct, to a diverse set of language and decision making tasks\\nand demonstrate its effectiveness over state-of-the-art baselines in addition to\\nimproved human interpretability and trustworthiness. Concretely, on question\\nanswering (HotpotQA) and fact veriﬁcation (Fever), ReAct overcomes prevalent\\nissues of hallucination and error propagation in chain-of-thought reasoning by\\ninteracting with a simple Wikipedia API, and generating human-like task-solving\\ntrajectories that are more interpretable than baselines without reasoning traces.\\nFurthermore, on two interactive decision making benchmarks (ALFWorld and\\nWebShop), ReAct outperforms imitation and reinforcement learning methods by\\nan absolute success rate of 34% and 10% respectively, while being prompted with\\nonly one or two in-context examples.\\n1\\nINTRODUCTION\\nA unique feature of human intelligence is the ability to seamlessly combine task-oriented actions with\\nverbal reasoning (or inner speech, Alderson-Day & Fernyhough, 2015), which has been theorized to\\nplay an important role in human cognition for enabling self-regulation or strategization (Vygotsky,\\n1987; Luria, 1965; Fernyhough, 2010) and maintaining a working memory (Baddeley, 1992). Con-\\nsider the example of cooking up a dish in the kitchen. Between any two speciﬁc actions, we may\\nreason in language in order to track progress (“now that everything is cut, I should heat up the pot of\\nwater”), to handle exceptions or adjust the plan according to the situation (“I don’t have salt, so let\\nme use soy sauce and pepper instead”), and to realize when external information is needed (“how do\\nI prepare dough? Let me search on the Internet”). We may also act (open a cookbook to read the\\nrecipe, open the fridge, check ingredients) to support the reasoning and to answer questions (“What\\ndish can I make right now?”). This tight synergy between “acting” and “reasoning” allows humans\\nto learn new tasks quickly and perform robust decision making or reasoning, even under previously\\nunseen circumstances or facing information uncertainties.\\nRecent results have hinted at the possibility of combining verbal reasoning with interactive decision\\nmaking in autonomous systems. On one hand, properly prompted large language models (LLMs)\\nhave demonstrated emergent capabilities to carry out several steps of reasoning traces to derive\\n∗Work during Google internship. Projet page with code: https://react-lm.github.io/.\\n1\\narXiv:2210.03629v3  [cs.CL]  10 Mar 2023\\nPublished as a conference paper at ICLR 2023\\n�������������������������������������������������������� �\\n����������������������������������������������������������\\n��\\n���������������������� �\\n������������������������������������������ �\\n����������������������������������������������������������������������������\\n������������������������� �\\n���������������������������������������������������������\\n�\\n���������������������������������������\\n��������������������������������������������� �\\n�������������������������������������������������������������\\n�\\n����������������������������������������������������������\\n�\\n���������������������� �\\n��������������������� �\\n�������������������������� �\\n��������������������� �\\n���������������������������\\n������������������������������������������ �\\n���������������������������������������������������\\n�������������\\n������������\\n����������������������\\n������������������������� �\\n��������� ���������������� �\\n���������������������� �\\n����������������������� �\\n�������������������������� �\\n������������������������� �\\n����������������������� �\\n���������������������� �\\n������\\n�������������������������� �\\n�����\\n��������������\\n��������������������������� �\\n�������������������������� ���\\n����������������\\n����������������������� ��\\n���������������������������� �\\n����������������\\n����������������������� �\\n���������� ��\\n��������������������� �\\n������������������������� �\\n����������\\n������������������\\n�������������������������\\n����������������������������������������������������� �\\n����������������������������������������������������\\n���������������������������\\n���������������������������������������������������������\\n�\\n����������������������������������������������������������\\n�\\n���������������������� ����������\\n����������������������������������������������������������\\n�\\n�����������������������������������������������������\\n������\\n���������������������������������������������������\\n������������������������\\n�������������������������������������������������������\\n�\\n����������������������������������������� ��������� �\\n���������� �����\\n���������������������������������������������������� ������\\n�������������� ��\\n���������������������������������� �\\n����������������������������������������������������������\\n���������������������������������������������������������\\n�\\n������������������������������������� ����������������� �\\n�����������������������\\n������������������������������������ �\\n�\\n��������������������������������������������������������\\n�\\n���������������������������������������������������\\n�\\n��������������������������\\n��������������\\n��������������������� �\\n������������������������������ �\\n�������������������� �\\n����������������������������������������������������������\\n�\\n��������������������������������������\\n�\\n������������������������ �\\n����������������������������������������������������\\n�\\n������������������������� �\\n������������������������������������������� �\\n����������������������� �\\n������������������������������������������� �\\n����������������������� �\\n�������������������������\\n�\\n�������������������������������������������������������\\n�\\n����������������������������������������������������������\\n�\\n���������������������������������������������������\\n�\\n����������������������������������������������������\\n������������\\n��������������\\nFigure 1: (1) Comparison of 4 prompting methods, (a) Standard, (b) Chain-of-thought (CoT,\\nReason Only), (c) Act-only, and (d) ReAct (Reason+Act), solving a HotpotQA (Yang et al., 2018)\\nquestion. (2) Comparison of (a) Act-only and (b) ReAct prompting to solve an AlfWorld (Shridhar\\net al., 2020b) game. In both domains, we omit in-context examples in the prompt, and only show task\\nsolving trajectories generated by the model (Act, Thought) and the environment (Obs).\\nanswers from questions in arithmetic, commonsense, and symbolic reasoning tasks (Wei et al.,\\n2022). However, this “chain-of-thought” reasoning is a static black box, in that the model uses\\nits own internal representations to generate thoughts and is not grounded in the external world,\\nwhich limits its ability to reason reactively or update its knowledge. This can lead to issues like fact\\nhallucination and error propagation over the reasoning process (Figure 1 (1b)). On the other hand,\\nrecent work has explored the use of pre-trained language models for planning and acting in interactive\\nenvironments (Ahn et al., 2022; Nakano et al., 2021; Yao et al., 2020; Huang et al., 2022a), with\\na focus on predicting actions via language priors. These approaches usually convert multi-modal\\nobservations into text, use a language model to generate domain-speciﬁc actions or plans, and then\\nuse a controller to choose or execute them. However, they do not employ language models to reason\\nabstractly about high-level goals or maintain a working memory to support acting, barring Huang\\net al. (2022b) who perform a limited form of verbal reasoning to reiterate spatial facts about the\\ncurrent state. Beyond such simple embodied tasks to interact with a few blocks, there have not been\\nstudies on how reasoning and acting can be combined in a synergistic manner for general task solving,\\nand if such a combination can bring systematic beneﬁts compared to reasoning or acting alone.\\nIn this work, we present ReAct, a general paradigm to combine reasoning and acting with language\\nmodels for solving diverse language reasoning and decision making tasks (Figure 1). ReAct\\nprompts LLMs to generate both verbal reasoning traces and actions pertaining to a task in an\\ninterleaved manner, which allows the model to perform dynamic reasoning to create, maintain, and\\nadjust high-level plans for acting (reason to act), while also interact with the external environments\\n(e.g. Wikipedia) to incorporate additional information into reasoning (act to reason).\\n2\\nPublished as a conference paper at ICLR 2023\\nWe conduct empirical evaluations of ReAct and state-of-the-art baselines on four diverse benchmarks:\\nquestion answering (HotPotQA, Yang et al., 2018), fact veriﬁcation (Fever, Thorne et al., 2018),\\ntext-based game (ALFWorld, Shridhar et al., 2020b), and webpage navigation (WebShop, Yao\\net al., 2022). For HotPotQA and Fever, with access to a Wikipedia API that the model can interact\\nwith, ReAct outperforms vanilla action generation models while being competitive with chain-of-\\nthought reasoning (CoT) (Wei et al., 2022). The best approach overall is a combination of ReAct\\nand CoT that allows for the use of both internal knowledge and externally obtained information\\nduring reasoning. On ALFWorld and WebShop, two or even one-shot ReAct prompting is able\\nto outperform imitation or reinforcement learning methods trained with 103 ∼ 105 task instances,\\nwith an absolute improvement of 34% and 10% in success rates respectively. We also demonstrate\\nthe importance of sparse, versatile reasoning in decision making by showing consistent advantages\\nover controlled baselines with actions only. Besides general applicability and performance boost,\\nthe combination of reasoning and acting also contributes to model interpretability, trustworthiness,\\nand diagnosability across all domains, as humans can readily distinguish information from model’s\\ninternal knowledge versus external environments, as well as inspect reasoning traces to understand\\nthe decision basis of model actions.\\nTo summarize, our key contributions are the following: (1) we introduce ReAct, a novel prompt-\\nbased paradigm to synergize reasoning and acting in language models for general task solving; (2) we\\nperform extensive experiments across diverse benchmarks to showcase the advantage of ReAct in a\\nfew-shot learning setup over prior approaches that perform either reasoning or action generation in\\nisolation; (3) we present systematic ablations and analysis to understand the importance of acting in\\nreasoning tasks, and reasoning in interactive tasks; (4) we analyze the limitations of ReAct under the\\nprompting setup (i.e. limited support of reasoning and acting behaviors), and perform initial ﬁnetuning\\nexperiments showing the potential of ReAct to improve with additional training data. Scaling up\\nReAct to train and operate on more tasks and combining it with complementary paradigms like\\nreinforcement learning could further unlock the potential of large language models.\\n2\\nREAC T: SYNERGIZING REASONING + ACTING\\nConsider a general setup of an agent interacting with an environment for task solving. At time\\nstep t, an agent receives an observation ot ∈ O from the environment and takes an action at ∈ A\\nfollowing some policy π(at|ct), where ct = (o1, a1, · · · , ot−1, at−1, ot) is the context to the agent.\\nLearning a policy is challenging when the mapping ct �→ at is highly implicit and requires extensive\\ncomputation. For example, the agent shown in Figure 1(1c) is unable to generate the correct ﬁnal\\naction (Act 4) to ﬁnish the QA task as it requires complex reasoning over the trajectory context\\n(Question, Act 1-3, Obs 1-3). Similarly, the agent shown in Figure 1(2a) fails to comprehend from the\\ncontext that sinkbasin 1 does not contain peppershaker 1, thus keep producing hallucinating actions.\\nThe idea of ReAct is simple: we augment the agent’s action space to ˆ\\nA = A ∪ L, where L is the\\nspace of language. An action ˆat ∈ L in the language space, which we will refer to as a thought or a\\nreasoning trace, does not affect the external environment, thus leading to no observation feedback.\\nInstead, a thought ˆat aims to compose useful information by reasoning over the current context ct,\\nand update the context ct+1 = (ct, ˆat) to support future reasoning or acting. As shown in Figure 1,\\nthere could be various types of useful thoughts, e.g. decomposing task goals and create action plans\\n(2b, Act 1; 1d, Thought 1), injecting commonsense knowledge relevant to task solving (2b, Act 1),\\nextracting important parts from observations (1d, Thought2, 4), track progress and transit action plans\\n(2b, Act 8), handle exceptions and adjust action plans (1d, Thought 3), and so on.\\nHowever, as the language space L is unlimited, learning in this augmented action space is difﬁcult\\nand requires strong language priors. In this paper, we mainly focus on the setup where a frozen\\nlarge language model, PaLM-540B (Chowdhery et al., 2022)1, is prompted with few-shot in-context\\nexamples to generate both domain-speciﬁc actions and free-form language thoughts for task solving\\n(Figure 1 (1d), (2b)). Each in-context example is a human trajectory of actions, thoughts, and\\nenvironment observations to solve a task instance (see Appendix C). For the tasks where reasoning is\\nof primary importance (Figure 1(1)), we alternate the generation of thoughts and actions so that the\\ntask-solving trajectory consists of multiple thought-action-observation steps. In contrast, for decision\\nmaking tasks that potentially involve a large number of actions (Figure 1(2)), thoughts only need to\\n1We show some GPT-3 (Brown et al., 2020) results in Appendix A.1, which outperforms PaLM-540B.\\n3\\nPublished as a conference paper at ICLR 2023\\nappear sparsely in the most relevant positions of a trajectory, so we let the language model decide the\\nasynchronous occurrence of thoughts and actions for itself.\\nSince decision making and reasoning capabilities are integrated into a large language model, ReAct\\nenjoys several unique features: A) Intuitive and easy to design: Designing ReAct prompts is\\nstraightforward as human annotators just type down their thoughts in language on top of their actions\\ntaken. No ad-hoc format choice, thought design, or example selection is used in this paper. We detail\\nprompt design for each task in Sections 3 and 4. B) General and ﬂexible: Due to the ﬂexible thought\\nspace and thought-action occurrence format, ReAct works for diverse tasks with distinct action\\nspaces and reasoning needs, including but not limited to QA, fact veriﬁcation, text game, and web\\nnavigation. C) Performant and robust: ReAct shows strong generalization to new task instances\\nwhile learning solely from one to six in-context examples, consistently outperforming baselines with\\nonly reasoning or acting across different domains. We also show in Section 3 additional beneﬁts\\nwhen ﬁnetuning is enabled, and in Section 4 how ReAct performance is robust to prompt selections.\\nD) Human aligned and controllable: ReAct promises an interpretable sequential decision making\\nand reasoning process where humans can easily inspect reasoning and factual correctness. Moreover,\\nhumans can also control or correct the agent behavior on the go by thought editing, as shown in\\nFigure 5 in Section 4.\\n3\\nKNOWLEDGE-INTENSIVE REASONING TASKS\\nWe begin with knowledge-intensive reasoning tasks like multi-hop question answering and fact\\nveriﬁcation. As shown in Figure 1(1d), by interacting with a Wikipedia API, ReAct is able to\\nretrieve information to support reasoning, while also use reasoning to target what to retrieve next,\\ndemonstrating a synergy of reasoning and acting.\\n3.1\\nSETUP\\nDomains\\nWe consider two datasets challenging knowledge retrieval and reasoning: (1) Hot-\\nPotQA (Yang et al., 2018), a multi-hop question answering benchmark that requires reasoning\\nover two or more Wikipedia passages, and (2) FEVER (Thorne et al., 2018), a fact veriﬁcation\\nbenchmark where each claim is annotated SUPPORTS, REFUTES, or NOT ENOUGH INFO, based\\non if there exists a Wikipedia passage to verify the claim. In this work, we operate in a question-only\\nsetup for both tasks, where models only receive the question/claim as input without access to support\\nparagraphs, and have to rely on their internal knowledge or retrieve knowledge via interacting with\\nan external environment to support reasoning.\\nAction Space\\nWe design a simple Wikipedia web API with three types of actions to support\\ninteractive information retrieval: (1) search[entity], which returns the ﬁrst 5 sentences from\\nthe corresponding entity wiki page if it exists, or else suggests top-5 similar entities from the\\nWikipedia search engine, (2) lookup[string], which would return the next sentence in the page\\ncontaining string, simulating Ctrl+F functionality on the browser. (3) finish[answer], which\\nwould ﬁnish the current task with answer. We note that this action space mostly can only retrieve a\\nsmall part of a passage based on exact passage name, which is signiﬁcantly weaker than state-of-the-\\nart lexical or neural retrievers. The purpose is to simulate how humans would interact with Wikipedia,\\nand force models to retrieve via explicit reasoning in language.\\n3.2\\nMETHODS\\nReAct Prompting\\nFor HotpotQA and Fever, we randomly select 6 and 3 cases2 from the training\\nset and manually compose ReAct-format trajectories to use as few-shot exemplars in the prompts.\\nSimilar to Figure 1(d), each trajectory consists of multiple thought-action-observation steps (i.e. dense\\nthought), where free-form thoughts are used for various purposes. Speciﬁcally, we use a combination\\nof thoughts that decompose questions (“I need to search x, ﬁnd y, then ﬁnd z”), extract information\\nfrom Wikipedia observations (“x was started in 1844”, “The paragraph does not tell x”), perform\\ncommonsense (“x is not y, so z must instead be...”) or arithmetic reasoning (“1844 < 1989”), guide\\n2We ﬁnd more examples do not improve performance.\\n4\\nPublished as a conference paper at ICLR 2023\\nPrompt Methoda\\nHotpotQA\\nFever\\n(EM)\\n(Acc)\\nStandard\\n28.7\\n57.1\\nCoT (Wei et al., 2022)\\n29.4\\n56.3\\nCoT-SC (Wang et al., 2022a)\\n33.4\\n60.4\\nAct\\n25.7\\n58.9\\nReAct\\n27.4\\n60.9\\nCoT-SC → ReAct\\n34.2\\n64.6\\nReAct→ CoT-SC\\n35.1\\n62.0\\nSupervised SoTAb\\n67.5\\n89.5\\nTable 1: PaLM-540B prompting results on\\nHotpotQA and Fever.\\naHotpotQA EM is 27.1, 28.9, 33.8 for Standard, CoT,\\nCoT-SC in Wang et al. (2022b).\\nb(Zhu et al., 2021; Lewis et al., 2020)\\n0\\n5\\n10\\n15\\n20\\n#CoT-SC trials\\n26\\n28\\n30\\n32\\n34\\nHotpotQA EM\\n0\\n5\\n10\\n15\\n20\\n#CoT-SC trials\\n47.5\\n50.0\\n52.5\\n55.0\\n57.5\\n60.0\\n62.5\\n65.0\\nFever Acc\\nMethod\\nCoT-SC -> ReAct\\nReAct -> CoT-SC\\nCoT-SC\\nReAct\\nCoT\\nFigure 2: PaLM-540B prompting results with respect to\\nnumber of CoT-SC samples used.\\nsearch reformulation (“maybe I can search/look up x instead”), and synthesize the ﬁnal answer (“...so\\nthe answer is x”). See Appendix C for more details.\\nBaselines\\nWe systematically ablate ReAct trajectories to build prompts for multiple baselines (with\\nformats as Figure 1(1a-1c)): (a) Standard prompting (Standard), which removes all thoughts,\\nactions, observations in ReAct trajectories. (b) Chain-of-thought prompting (CoT) (Wei et al.,\\n2022), which removes actions and observations and serve as a reasoning-only baseline. We also\\nbuild a self-consistency baseline (CoT-SC) (Wang et al., 2022a;b) by sampling 21 CoT trajectories\\nwith decoding temperature 0.7 during inference and adopting the majority answer, which is found to\\nconsistently boost performance over CoT. (c) Acting-only prompt (Act), which removes thoughts\\nin ReAct trajectories, loosely resembling how WebGPT (Nakano et al., 2021) interacts with the\\nInternet to answer questions, though it operates on a different task and action space, and uses imitation\\nand reinforcement learning instead of prompting.\\nCombining Internal and External Knowledge\\nAs will be detail in Section 3.3, we observe that\\nthe problem solving process demonstrated by ReAct is more factual and grounded, whereas CoT\\nis more accurate in formulating reasoning structure but can easily suffer from hallucinated facts\\nor thoughts. We therefore propose to incorporate ReAct and CoT-SC, and let the model decide\\nwhen to switch to the other method based on the following heuristics: A) ReAct → CoT-SC: when\\nReAct fails to return an answer within given steps, back off to CoT-SC. We set 7 and 5 steps for\\nHotpotQA and FEVER respectively as we ﬁnd more steps will not improve ReAct performance3.\\nB) CoT-SC → ReAct: when the majority answer among n CoT-SC samples occurs less than n/2\\ntimes (i.e. internal knowledge might not support the task conﬁdently), back off to ReAct.\\nFinetuning\\nDue to the challenge of manually annotating reasoning traces and actions at scale,\\nwe consider a bootstraping approach similar to Zelikman et al. (2022), using 3,000 trajectories\\nwith correct answers generated by ReAct (also for other baselines) to ﬁnetune smaller language\\nmodels (PaLM-8/62B) to decode trajectories (all thoughts, actions, observations) conditioned on\\ninput questions/claims. More details are in Appendix B.1.\\n3.3\\nRESULTS AND OBSERVATIONS\\nReAct outperforms Act consistently\\nTable 1 shows HotpotQA and Fever results using PaLM-\\n540B as the base model with different prompting methods. We note that ReAct is better than Act\\non both tasks, demonstrating the value of reasoning to guide acting, especially for synthesizing the\\nﬁnal answer, as shown in Figure 1 (1c-d). Fine-tuning results 3 also conﬁrm the beneﬁt of reasoning\\ntraces for more informed acting.\\n3Of all trajectories with correct ﬁnal answers, those with 7 steps on HotpotQA and 5 steps on FEVER only\\ntake up 0.84% and 1.33% respectively.\\n5\\nPublished as a conference paper at ICLR 2023\\nType\\nDeﬁnition\\nReAct\\nCoT\\nSuccess\\nTrue positive\\nCorrect reasoning trace and facts\\n94%\\n86%\\nFalse positive\\nHallucinated reasoning trace or facts\\n6%\\n14%\\nFailure\\nReasoning error\\nWrong reasoning trace (including failing to recover from repetitive steps)\\n47%\\n16%\\nSearch result error\\nSearch return empty or does not contain useful information\\n23%\\n-\\nHallucination\\nHallucinated reasoning trace or facts\\n0%\\n56%\\nLabel ambiguity\\nRight prediction but did not match the label precisely\\n29%\\n28%\\nTable 2: Types of success and failure modes of ReAct and CoT on HotpotQA, as well as their\\npercentages in randomly selected examples studied by human.\\nReAct vs. CoT\\nOn the other hand, ReAct outperforms CoT on Fever (60.9 vs. 56.3) and slightly\\nlags behind CoT on HotpotQA (27.4 vs. 29.4). Fever claims for SUPPORTS/REFUTES might only\\ndiffer by a slight amount (see Appendix D.1), so acting to retrieve accurate and up-to-date knowledge\\nis vital. To better understand the behavioral difference between ReAct and CoT on HotpotQA, we\\nrandomly sampled 50 trajectories with correct and incorrect answers (judged by EM) from ReAct\\nand CoT respectively (thus 200 examples in total), and manually labeled their success and failure\\nmodes in Table 2. Some key observations are as follows:\\nA) Hallucination is a serious problem for CoT, resulting in much higher false positive rate than\\nReAct (14% vs. 6%) in success mode, and make up its major failure mode (56%). In contrast, the\\nproblem solving trajectory of ReActis more grounded, fact-driven, and trustworthy, thanks to the\\naccess of an external knowledge base.\\nB) While interleaving reasoning, action and observation steps improves ReAct’s grounded-\\nness and trustworthiness, such a structural constraint also reduces its ﬂexibility in formulating\\nreasoning steps, leading to more reasoning error rate than CoT. we note that there is one frequent\\nerror pattern speciﬁc to ReAct, in which the model repetitively generates the previous thoughts and\\nactions, and we categorize it as part of “reasoning error” as the model fails to reason about what the\\nproper next action to take and jump out of the loop4.\\nC) For ReAct, successfully retrieving informative knowledge via search is critical. Non-\\ninformative search, which counts for 23% of the error cases, derails the model reasoning and gives\\nit a hard time to recover and reformulate thoughts. This is perhaps an expected trade-off between\\nfactuality and ﬂexibility, which motivates our proposed strategies of combining two methods.\\nWe provide examples for each success and failure modes in Appendix E.1. We also ﬁnd some\\nHotpotQA questions may contain outdated answer labels, see Figure 4 for example.\\nReAct + CoT-SC perform best for prompting LLMs\\nAlso shown in Table 1, the best prompting\\nmethod on HotpotQA and Fever are ReAct → CoT-SC and CoT-SC → ReAct respectively.\\nFurthermore, Figure 2 shows how different methods perform with respect to the number of CoT-SC\\nsamples used. While two ReAct + CoT-SC methods are advantageous at one task each, they both\\nsigniﬁcantly and consistently outperform CoT-SC across different number of samples, reaching\\nCoT-SC performance with 21 samples using merely 3-5 samples. These results indicate the value of\\nproperly combining model internal knowledge and external knowledge for reasoning tasks.\\nReAct performs best for ﬁne-tuning\\nFigure 3 shows the scaling effect of prompting/ﬁnetuning\\nfour methods (Standard, CoT, Act, ReAct) on HotpotQA. With PaLM-8/62B, prompting ReAct\\nperforms worst among four methods due to the difﬁculty to learn both reasoning and acting from\\nin-context examples. However, when ﬁnetuned with just 3,000 examples, ReAct becomes the best\\nmethod among the four, with PaLM-8B ﬁnetuned ReAct outperforming all PaLM-62B prompting\\nmethods, and PaLM-62B ﬁnetuned ReAct outperforming all 540B prompting methods. In contrast,\\nﬁnetuning Standard or CoT is signiﬁcantly worse than ﬁnetuning ReAct or Act for both PaLM-\\n8/62B, as the former essentially teaches models to memorize (potentially halluincated) knowledge\\nfacts, and the latter teaches models how to (reason and) act to access information from Wikipedia, a\\nmore generalizable skill for knowledge reasoning. As all prompting methods are still signiﬁcantly\\nfar from domain-speciﬁc state-of-the-art approaches (Table 1), we believe ﬁnetuning with more\\nhuman-written data might be a better way to unleash the power of ReAct.\\n4We suspect that this could be due to the sub-optimal greedy decoding procedure, and future work using\\nbetter decoding (e.g. beam search) might help address this issue.\\n6\\nPublished as a conference paper at ICLR 2023\\n8b\\n62b\\n540b\\nsize\\n0\\n5\\n10\\n15\\n20\\n25\\n30\\nHotpotQA EM\\nlearning = prompt\\n8b\\n62b\\n540b\\nsize\\nlearning = finetune\\nMethod\\nStandard\\nCoT\\nAct\\nReAct\\nFigure 3: Scaling results for prompting and ﬁnetuning on HotPotQA with ReAct (ours) and baselines.\\n4\\nDECISION MAKING TASKS\\nWe also test ReAct on two language-based interactive decision-making tasks, ALFWorld and\\nWebShop, both of which feature complex environments that require agents to act over long horizons\\nwith sparse rewards, warranting the need for reasoning to act and explore effectively.\\nALFWorld\\nALFWorld (Shridhar et al., 2020b) (Figure 1(2)) is a synthetic text-based game designed\\nto align with the embodied ALFRED benchmark (Shridhar et al., 2020a). It includes 6 types of\\ntasks in which an agent needs to achieve a high-level goal (e.g. examine paper under desklamp) by\\nnavigating and interacting with a simulated household via text actions (e.g. go to coffeetable 1, take\\npaper 2, use desklamp 1). A task instance can have more than 50 locations and take an expert policy\\nmore than 50 steps to solve, thus challenging an agent to plan and track subgoals, as well as explore\\nsystematically (e.g. check all desks one by one for desklamp). In particular, one challenge built into\\nALFWorld is the need to determine likely locations for common household items (e.g. desklamps will\\nlikely be on desks, shelfs, or dressers), making this environment a good ﬁt for LLMs to exploit their\\npretrained commonsense knowledge. To prompt ReAct, we randomly annotate three trajectories\\nfrom the training set for each task type, where each trajectory includes sparse thoughts that (1)\\ndecompose the goal, (2) track subgoal completion, (3) determine the next subgoal, and (4) reason via\\ncommonsense where to ﬁnd an object and what to do with it. We show prompts used for ALFWorld\\nin Appendix C.4. Following Shridhar et al. (2020b), we evaluate on 134 unseen evaluation games\\nin a task-speciﬁc setup. For robustness, we construct 6 prompts for each task type through each\\npermutation of 2 annotated trajectories from the 3 we annotate. Act prompts are constructed using\\nthe same trajectories, but without thoughts — since task instances are randomly chosen from the\\ntraining set, it favors neither ReAct nor Act and provides a fair and controlled comparison to test the\\nimportance of sparse thoughts. For baselines, we use BUTLER (Shridhar et al., 2020b), an imitation\\nlearning agent trained on 105 expert trajectories for each task type5.\\nWebShop\\nCan ReAct also interact with noisy real-world language environments for practical\\napplications? We investigate WebShop (Yao et al., 2022), a recently proposed online shopping\\nwebsite environment with 1.18M real-world products and 12k human instructions. Unlike ALFWorld,\\nWebshop contains a high variety of structured and unstructured texts (e.g. product titles, descriptions,\\nand options crawled from Amazon), and requires an agent to purchase a product based on a user\\ninstruction (e.g. “I am looking for a nightstand with drawers. It should have a nickel ﬁnish, and\\npriced lower than $140”) through web interactions (e.g. search “nightstand drawers”, choose buttons\\nsuch as “color: modern-nickel-white” or “back to search”). This task is evaluated by average score\\n(percentage of desired attributes covered by the chosen product averaged across all episodes) and\\nsuccess rate (percentage of episodes where the chosen product satisﬁes all requirements) on 500 test\\ninstructions. We formulate Act prompts with actions to search, choose product, choose options,\\nand buy, with ReAct prompts additionally reasoning to determine what to explore, when to buy,\\nand what products options are relevant to the instruction. See Table 6 for an example prompt, and\\nTable 10 for model predictions in the Appendix. We compare to an imitation learning (IL) method\\n5Micheli & Fleuret (2021) ﬁnetuned a GPT-2 model on 3553 task instances and achieved a much improved\\nperformance than BUTLER, but it is trained on all task types, thus not included as a baseline.\\n7\\nPublished as a conference paper at ICLR 2023\\nMethod\\nPick\\nClean\\nHeat\\nCool\\nLook\\nPick 2\\nAll\\nAct (best of 6)\\n88\\n42\\n74\\n67\\n72\\n41\\n45\\nReAct (avg)\\n65\\n39\\n83\\n76\\n55\\n24\\n57\\nReAct (best of 6)\\n92\\n58\\n96\\n86\\n78\\n41\\n71\\nReAct-IM (avg)\\n55\\n59\\n60\\n55\\n23\\n24\\n48\\nReAct-IM (best of 6)\\n62\\n68\\n87\\n57\\n39\\n33\\n53\\nBUTLERg (best of 8)\\n33\\n26\\n70\\n76\\n17\\n12\\n22\\nBUTLER (best of 8)\\n46\\n39\\n74\\n100\\n22\\n24\\n37\\nTable 3: AlfWorld task-speciﬁc success rates (%). BUTLER and\\nBUTLERg results are from Table 4 of Shridhar et al. (2020b). All\\nmethods use greedy decoding, except that BUTLER uses beam search.\\nMethod\\nScore\\nSR\\nAct\\n62.3\\n30.1\\nReAct\\n66.6\\n40.0\\nIL\\n59.9\\n29.1\\nIL+RL\\n62.4\\n28.7\\nHuman\\n82.1\\n59.6\\nExpert\\nTable 4: Score and suc-\\ncess rate (SR) on Web-\\nshop. IL/IL+RL taken\\nfrom Yao et al. (2022).\\ntrained with 1,012 human annotated trajectories, and a imitation + reinforcement learning (IL + RL)\\nmethod additionally trained with 10,587 training instructions.\\nResults\\nReAct outperforms Act on both ALFWorld (Table 3) and Webshop (Table 4). On\\nALFWorld, the best ReAct trial achieves an average success rate of 71%, signiﬁcantly outperforming\\nthe best Act (45%) and BUTLER (37%) trials. In fact, even the worse ReAct trial (48%) beats\\nthe best trial of both methods. Moreover, the advantage of ReAct over Act is consistent across\\nsix controlled trials, with relative performance gain ranging from 33% to 90% and averaging 62%.\\nQualitatively, we saw that, without any thoughts at all, Act fails to correctly decompose goals\\ninto smaller subgoals, or loses track of the current state of the environment. Example trajectories\\ncomparing ReAct and Act can be found in Appendix D.2.1 and Appendix D.2.2.\\nOn Webshop, one-shot Act prompting already performs on par with IL and IL+RL methods. With\\nadditional sparse reasoning, ReAct achieves signiﬁcantly better performance, with an absolute 10%\\nimprovement over the previous best success rate. By checking examples, we ﬁnd that ReAct is more\\nlikely to identify instruction-relevant products and options by reasoning to bridge the gap between\\nnoisy observations and actions (e.g. “For ‘space-saving ottoman bench for living room’, the item\\nhas options ‘39x18x18inch’ and ‘blue’ and seems good to buy.”). However, existing methods are\\nstill far from the performance of expert humans (Table 4), who perform signiﬁcantly more product\\nexplorations and query re-formulations that are still challenging for prompting-based methods.\\nOn the value of internal reasoning vs. external feedback\\nTo our knowledge, ReAct is the ﬁrst\\ndemonstration of combined reasoning and action using an LLM applied to an interactive environment\\nwithin a closed-loop system. Perhaps the closest prior work is Inner Monologue (IM), from Huang\\net al. (2022b), in which actions from an embodied agent are motivated by an eponymous “inner\\nmonologue”. However, IM’s “inner monologue” is limited to observations of the environment\\nstate and what needs to be completed by the agent for the goal to be satisﬁed. In contrast, the\\nreasoning traces in ReAct for decision making is ﬂexible and sparse, allowing diverse reasoning\\ntypes (see Section 2) to be induced for different tasks.\\nTo demonstrate the differences between ReAct and IM, and to highlight the importance of internal\\nreasoning vs. simple reactions to external feedback, we ran an ablation experiment using a thought\\npattern composed of IM-like dense external feedback. As can be seen in Table 3, ReAct substantially\\noutperforms IM-style prompting (ReAct-IM) (71 vs. 53 overall success rate), with consistent\\nadvantages on ﬁve out of six tasks. Qualitatively, we observed that ReAct-IM often made mistakes\\nin identifying when subgoals were ﬁnished, or what the next subgoal should be, due to a lack of high-\\nlevel goal decomposition. Additionally, many ReAct-IM trajectories struggled to determine where\\nan item would likely be within the ALFWorld environment, due to a lack of commonsense reasoning.\\nBoth shortcomings can be addressed in the ReAct paradigm. More details about ReAct-IM is in\\nAppendix B.2. An example prompt for ReAct-IM can be found in Appendix C.4, and an example\\ntrajectory in Appendix D.2.3.\\n8\\nPublished as a conference paper at ICLR 2023\\n5\\nRELATED WORK\\nLanguage model for reasoning\\nPerhaps the most well-known work of using LLMs for reasoning\\nis Chain-of-Thought (CoT) (Wei et al., 2022), which reveals the ability of LLMs to formulate their\\nown “thinking procedure” for problem solving. Several follow-up works have since been performed,\\nincluding least-to-most prompting for solving complicated tasks (Zhou et al., 2022), zero-shot-\\nCoT (Kojima et al., 2022), and reasoning with self-consistency (Wang et al., 2022a). Recently,\\n(Madaan & Yazdanbakhsh, 2022) systematically studied the formulation and structure of CoT, and\\nobserved that the presence of symbols, patterns and texts is crucial to the effectiveness of CoT. Other\\nwork has also been extended to more sophisticated reasoning architecture beyond simple prompting.\\nFor example Selection-Inference (Creswell et al., 2022) divides the reasoning process into two steps\\nof “selection” and “inference”. STaR (Zelikman et al., 2022) bootstraps the reasoning process by\\nﬁnetuning the model on correct rationales generated by the model itself. Faithful reasoning (Creswell\\n& Shanahan, 2022) decomposes multi-step reasoning into three steps, each performed by a dedicated\\nLM respectively. Similar approaches like Scratchpad (Nye et al., 2021), which ﬁnetunes a LM on\\nintermediate computation steps, also demonstrate improvement on multi-step computation problems.\\nIn contrast to these methods, ReAct performs more than just isolated, ﬁxed reasoning, and integrates\\nmodel actions and their corresponding observations into a coherent stream of inputs for the model to\\nreason more accurately and tackle tasks beyond reasoning (e.g. interactive decision making).\\nLanguage model for decision making\\nThe strong capability of LLMs has enabled them to perform\\ntasks beyond language generation, and it is becoming more popular to take advantage of LLMs as a\\npolicy model for decision making, especially in interactive environments. WebGPT (Nakano et al.,\\n2021) uses an LM to interact with web browsers, navigate through web pages, and infer answers to\\ncomplicated questions from ELI5 (Fan et al., 2019). In comparison to ReAct, WebGPT does not\\nexplicitly model the thinking and reasoning procedure, instead rely on expensive human feedback for\\nreinforcement learning. In conversation modeling, chatbots like BlenderBot (Shuster et al., 2022b)\\nand Sparrow (Glaese et al., 2022) and task-oriented dialogue systems like SimpleTOD (Hosseini-Asl\\net al., 2020) also train LMs to make decision about API calls. Unlike ReAct, they do not explicitly\\nconsider the reasoning procedure either, and also relies on expensive datasets and human feedback\\ncollections for policy learning. In contrast, ReAct learns a policy in a much cheaper way, since the\\ndecision making process only requires language description of the reasoning procedure.6\\nLLMS have also been increasingly employed in interactive and embodied environments for planning\\nand decision making. Perhaps most relevant to ReAct in this respect are SayCan (Ahn et al., 2022)\\nand Inner Monologue (Huang et al., 2022b), which use LLMs for robotic action planning and decision\\nmaking. In SayCan, LLMs were prompted to directly predict possible actions a robot can take, which\\nis then reranked by an affordance model grounded on the visual environments for ﬁnal prediction.\\nInner Monologue made further improvements by adding the eponymous “inner monologue\", which is\\nimplemented as injected feedback from the environment. To our knowledge, Inner Monologue is the\\nﬁrst work that demonstrates such a closed-loop system, which ReAct builds on. However, we argue\\nthat Inner Monologue does not truly comprise of inner thoughts — this is elaborated in Section 4. We\\nalso note that leveraging language as semantically-rich inputs in the process of interactive decision\\nmaking has been shown to be successful under other settings (Abramson et al., 2020; Karamcheti\\net al., 2021; Huang et al., 2022a; Li et al., 2022). It is becoming more evident that with the help of\\nLLMs, language as a fundamental cognitive mechanism will play a critical role in interaction and\\ndecision making. What is more, progress in LLMs has also inspired the development of versatile and\\ngeneralist agents like Reed et al. (2022).\\n6\\nCONCLUSION\\nWe have proposed ReAct – a simple yet effective method for synergizing reasoning and acting in\\nlarge language models. Through a diverse set of experiments on multi-hop question-answering, fact\\nchecking, and interactive decision-making tasks, we show that ReAct leads to superior performance\\nwith interpretable decision traces. Despite the simplicity of our method, complex tasks with large\\naction spaces require more demonstrations to learn well, which unfortunately can easily go beyond\\nthe input length limit of in-context learning. We explore the ﬁne-tuning approach on HotpotQA\\n6Human feedback can also be incorporated in a complementary manner but we leave it for future work.\\n9\\nPublished as a conference paper at ICLR 2023\\nwith initial promising results, but learning from more high-quality human annotations will be the\\ndesiderata to further improve the performance. Scaling up ReAct with multi-task training and\\ncombining it with complementary paradigms like reinforcement learning could result in stronger\\nagents that further unlock the potential of LLMs for more applications.\\nACKNOWLEDGMENTS\\nWe thank the support and feedback of many people from Google Brain team and Princeton NLP\\nGroup. This work was supported in part by the National Science Foundation under Grant No.\\n2107048. Any opinions, ﬁndings, and conclusions or recommendations expressed in this material are\\nthose of the author(s) and do not necessarily reﬂect the views of the National Science Foundation.\\nREPRODUCIBILITY STATEMENT\\nOur main experiments are done on PaLM (Chowdhery et al., 2022), which is not an openly accessible\\nmodel yet. To increase reproducibility, we have included all used prompts in Appendix C, additional\\nexperiments using GPT-3 (Brown et al., 2020) in Appendix A.1, and associated GPT-3 ReAct\\nprompting code at https://anonymous.4open.science/r/ReAct-2268/.\\nETHICS STATEMENT\\nReAct prompts large language models to generate more human interpretable, diagnosable, and\\ncontrollable task-solving trajectories than previous methods. However, hooking up a large language\\nmodel with an action space to interact with external environments (e.g. the web, physical environ-\\nments) has potential dangers, e.g. looking up inappropriate or private information, or taking harmful\\nactions in an environment. Our experiments minimize such risks by limiting the interactions to\\nspeciﬁc websites (Wikipedia or WebShop) that are free of private information, without any dangerous\\nactions in the action space design (i.e. models cannot really buy products on WebShop the research\\nbenchmark, or edit Wikipedia). We believe researchers should be aware of such risks before designing\\nmore extensive experiments in the future.\\nREFERENCES\\nJosh Abramson, Arun Ahuja, Iain Barr, Arthur Brussee, Federico Carnevale, Mary Cassin, Rachita\\nChhaparia, Stephen Clark, Bogdan Damoc, Andrew Dudzik, Petko Georgiev, Aurelia Guy, Tim\\nHarley, Felix Hill, Alden Hung, Zachary Kenton, Jessica Landon, Timothy Lillicrap, Kory Mathew-\\nson, Soˇna Mokrá, Alistair Muldal, Adam Santoro, Nikolay Savinov, Vikrant Varma, Greg Wayne,\\nDuncan Williams, Nathaniel Wong, Chen Yan, and Rui Zhu. Imitating interactive intelligence,\\n2020. URL https://arxiv.org/abs/2012.05672.\\nMichael Ahn, Anthony Brohan, Noah Brown, Yevgen Chebotar, Omar Cortes, Byron David, Chelsea\\nFinn, Chuyuan Fu, Keerthana Gopalakrishnan, Karol Hausman, Alex Herzog, Daniel Ho, Jasmine\\nHsu, Julian Ibarz, Brian Ichter, Alex Irpan, Eric Jang, Rosario Jauregui Ruano, Kyle Jeffrey, Sally\\nJesmonth, Nikhil J Joshi, Ryan Julian, Dmitry Kalashnikov, Yuheng Kuang, Kuang-Huei Lee,\\nSergey Levine, Yao Lu, Linda Luu, Carolina Parada, Peter Pastor, Jornell Quiambao, Kanishka\\nRao, Jarek Rettinghouse, Diego Reyes, Pierre Sermanet, Nicolas Sievers, Clayton Tan, Alexander\\nToshev, Vincent Vanhoucke, Fei Xia, Ted Xiao, Peng Xu, Sichun Xu, Mengyuan Yan, and\\nAndy Zeng. Do as i can, not as i say: Grounding language in robotic affordances, 2022. URL\\nhttps://arxiv.org/abs/2204.01691.\\nBen Alderson-Day and Charles Fernyhough.\\nInner speech: development, cognitive functions,\\nphenomenology, and neurobiology. Psychological bulletin, 141(5):931, 2015.\\nAlan Baddeley. Working memory. Science, 255(5044):556–559, 1992.\\nTom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal,\\nArvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. Language models are\\nfew-shot learners. Advances in neural information processing systems, 33:1877–1901, 2020.\\n10\\nPublished as a conference paper at ICLR 2023\\nAakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam\\nRoberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, et al. Palm:\\nScaling language modeling with pathways. arXiv preprint arXiv:2204.02311, 2022.\\nAntonia Creswell and Murray Shanahan. Faithful reasoning using large language models, 2022. URL\\nhttps://arxiv.org/abs/2208.14271.\\nAntonia Creswell, Murray Shanahan, and Irina Higgins. Selection-inference: Exploiting large\\nlanguage models for interpretable logical reasoning, 2022. URL https://arxiv.org/abs/\\n2205.09712.\\nAngela Fan, Yacine Jernite, Ethan Perez, David Grangier, Jason Weston, and Michael Auli. ELI5:\\nLong form question answering. In Proceedings of the 57th Annual Meeting of the Association\\nfor Computational Linguistics, pp. 3558–3567, Florence, Italy, July 2019. Association for Com-\\nputational Linguistics. doi: 10.18653/v1/P19-1346. URL https://aclanthology.org/\\nP19-1346.\\nCharles Fernyhough. Vygotsky, luria, and the social brain. Self and social regulation: Social\\ninteraction and the development of social understanding and executive functions, pp. 56–79, 2010.\\nAmelia Glaese, Nat McAleese, Maja Trebacz, John Aslanides, Vlad Firoiu, Timo Ewalds, Mari-\\nbeth Rauh, Laura Weidinger, Martin Chadwick, Phoebe Thacker, Lucy Campbell-Gillingham,\\nJonathan Uesato, Po-Sen Huang, Ramona Comanescu, Fan Yang, Abigail See, Sumanth\\nDathathri, Rory Greig, Charlie Chen, Doug Fritz, Jaume Sanchez Elias, Richard Green,\\nSoˇna Mokrá, Nicholas Fernando, Boxi Wu, Rachel Foley, Susannah Young, Iason Gabriel,\\nWilliam Isaac, John Mellor, Demis Hassabis, Koray Kavukcuoglu, Lisa Anne Hendricks, and\\nGeoffrey Irving.\\nImproving alignment of dialogue agents via targeted human judgements,\\n2022.\\nURL https://storage.googleapis.com/deepmind-media/DeepMind.\\ncom/Authors-Notes/sparrow/sparrow-final.pdf.\\nEhsan Hosseini-Asl, Bryan McCann, Chien-Sheng Wu, Semih Yavuz, and Richard Socher. A simple\\nlanguage model for task-oriented dialogue. Advances in Neural Information Processing Systems,\\n33:20179–20191, 2020.\\nWenlong Huang, Pieter Abbeel, Deepak Pathak, and Igor Mordatch. Language models as zero-shot\\nplanners: Extracting actionable knowledge for embodied agents. arXiv preprint arXiv:2201.07207,\\n2022a.\\nWenlong Huang, Fei Xia, Ted Xiao, Harris Chan, Jacky Liang, Pete Florence, Andy Zeng, Jonathan\\nTompson, Igor Mordatch, Yevgen Chebotar, et al. Inner monologue: Embodied reasoning through\\nplanning with language models. arXiv preprint arXiv:2207.05608, 2022b.\\nSiddharth Karamcheti, Megha Srivastava, Percy Liang, and Dorsa Sadigh. Lila: Language-informed\\nlatent actions. In CoRL, pp. 1379–1390, 2021. URL https://proceedings.mlr.press/\\nv164/karamcheti22a.html.\\nTakeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa. Large\\nlanguage models are zero-shot reasoners. arXiv preprint arXiv:2205.11916, 2022.\\nAngeliki Lazaridou, Elena Gribovskaya, Wojciech Stokowiec, and Nikolai Grigorev. Internet-\\naugmented language models through few-shot prompting for open-domain question answering.\\narXiv preprint arXiv:2203.05115, 2022.\\nPatrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal,\\nHeinrich Küttler, Mike Lewis, Wen-tau Yih, Tim Rocktäschel, et al. Retrieval-augmented genera-\\ntion for knowledge-intensive nlp tasks. Advances in Neural Information Processing Systems, 33:\\n9459–9474, 2020.\\nShuang Li, Xavier Puig, Chris Paxton, Yilun Du, Clinton Wang, Linxi Fan, Tao Chen, De-An\\nHuang, Ekin Akyürek, Anima Anandkumar, Jacob Andreas, Igor Mordatch, Antonio Torralba,\\nand Yuke Zhu. Pre-trained language models for interactive decision-making, 2022. URL https:\\n//arxiv.org/abs/2202.01771.\\n11\\nPublished as a conference paper at ICLR 2023\\nAleksandr Romanovich Luria. Ls vygotsky and the problem of localization of functions. Neuropsy-\\nchologia, 3(4):387–392, 1965.\\nAman Madaan and Amir Yazdanbakhsh. Text and patterns: For effective chain of thought, it takes\\ntwo to tango, 2022. URL https://arxiv.org/abs/2209.07686.\\nVincent Micheli and François Fleuret. Language models are few-shot butlers. arXiv preprint\\narXiv:2104.07972, 2021.\\nReiichiro Nakano, Jacob Hilton, Suchir Balaji, Jeff Wu, Long Ouyang, Christina Kim, Christopher\\nHesse, Shantanu Jain, Vineet Kosaraju, William Saunders, Xu Jiang, Karl Cobbe, Tyna Eloundou,\\nGretchen Krueger, Kevin Button, Matthew Knight, Benjamin Chess, and John Schulman. Webgpt:\\nBrowser-assisted question-answering with human feedback, 2021. URL https://arxiv.\\norg/abs/2112.09332.\\nMaxwell Nye, Anders Johan Andreassen, Guy Gur-Ari, Henryk Michalewski, Jacob Austin, David\\nBieber, David Dohan, Aitor Lewkowycz, Maarten Bosma, David Luan, Charles Sutton, and\\nAugustus Odena. Show your work: Scratchpads for intermediate computation with language\\nmodels, 2021. URL https://arxiv.org/abs/2112.00114.\\nScott Reed, Konrad Zolna, Emilio Parisotto, Sergio Gomez Colmenarejo, Alexander Novikov,\\nGabriel Barth-Maron, Mai Gimenez, Yury Sulsky, Jackie Kay, Jost Tobias Springenberg, Tom\\nEccles, Jake Bruce, Ali Razavi, Ashley Edwards, Nicolas Heess, Yutian Chen, Raia Hadsell,\\nOriol Vinyals, Mahyar Bordbar, and Nando de Freitas. A generalist agent, 2022. URL https:\\n//arxiv.org/abs/2205.06175.\\nMohit Shridhar, Jesse Thomason, Daniel Gordon, Yonatan Bisk, Winson Han, Roozbeh Mottaghi,\\nLuke Zettlemoyer, and Dieter Fox. Alfred: A benchmark for interpreting grounded instructions\\nfor everyday tasks. In Proceedings of the IEEE/CVF conference on computer vision and pattern\\nrecognition, pp. 10740–10749, 2020a.\\nMohit Shridhar, Xingdi Yuan, Marc-Alexandre Côté, Yonatan Bisk, Adam Trischler, and Matthew\\nHausknecht. Alfworld: Aligning text and embodied environments for interactive learning. arXiv\\npreprint arXiv:2010.03768, 2020b.\\nKurt Shuster, Mojtaba Komeili, Leonard Adolphs, Stephen Roller, Arthur Szlam, and Jason Weston.\\nLanguage models that seek for knowledge: Modular search & generation for dialogue and prompt\\ncompletion. arXiv preprint arXiv:2203.13224, 2022a.\\nKurt Shuster, Jing Xu, Mojtaba Komeili, Da Ju, Eric Michael Smith, Stephen Roller, Megan Ung,\\nMoya Chen, Kushal Arora, Joshua Lane, Morteza Behrooz, William Ngan, Spencer Poff, Naman\\nGoyal, Arthur Szlam, Y-Lan Boureau, Melanie Kambadur, and Jason Weston. Blenderbot 3:\\na deployed conversational agent that continually learns to responsibly engage, 2022b. URL\\nhttps://arxiv.org/abs/2208.03188.\\nJames Thorne, Andreas Vlachos, Christos Christodoulopoulos, and Arpit Mittal. Fever: a large-scale\\ndataset for fact extraction and veriﬁcation. arXiv preprint arXiv:1803.05355, 2018.\\nLev S Vygotsky. Thinking and speech. The collected works of LS Vygotsky, 1:39–285, 1987.\\nXuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, Sharan Narang, Aakanksha Chowdh-\\nery, and Denny Zhou. Self-consistency improves chain of thought reasoning in language models,\\n2022a. URL https://arxiv.org/abs/2203.11171.\\nXuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, and Denny Zhou. Rationale-augmented\\nensembles in language models. arXiv preprint arXiv:2207.00747, 2022b.\\nJason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Ed Chi, Quoc Le, and Denny\\nZhou. Chain of thought prompting elicits reasoning in large language models. arXiv preprint\\narXiv:2201.11903, 2022.\\nZhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Bengio, William W Cohen, Ruslan Salakhutdinov,\\nand Christopher D Manning. Hotpotqa: A dataset for diverse, explainable multi-hop question\\nanswering. arXiv preprint arXiv:1809.09600, 2018.\\n12\\nPublished as a conference paper at ICLR 2023\\nShunyu Yao, Rohan Rao, Matthew Hausknecht, and Karthik Narasimhan. Keep CALM and explore:\\nLanguage models for action generation in text-based games. In Proceedings of the 2020 Conference\\non Empirical Methods in Natural Language Processing (EMNLP), pp. 8736–8754, Online, Novem-\\nber 2020. Association for Computational Linguistics. doi: 10.18653/v1/2020.emnlp-main.704.\\nURL https://aclanthology.org/2020.emnlp-main.704.\\nShunyu Yao, Howard Chen, John Yang, and Karthik Narasimhan. Webshop: Towards scalable\\nreal-world web interaction with grounded language agents. arXiv preprint arXiv:2207.01206,\\n2022.\\nEric Zelikman, Yuhuai Wu, Jesse Mu, and Noah D. Goodman. Star: Bootstrapping reasoning with\\nreasoning, 2022. URL https://arxiv.org/abs/2203.14465.\\nDenny Zhou, Nathanael Schärli, Le Hou, Jason Wei, Nathan Scales, Xuezhi Wang, Dale Schuurmans,\\nOlivier Bousquet, Quoc Le, and Ed Chi. Least-to-most prompting enables complex reasoning in\\nlarge language models, 2022. URL https://arxiv.org/abs/2205.10625.\\nYunchang Zhu, Liang Pang, Yanyan Lan, Huawei Shen, and Xueqi Cheng. Adaptive information\\nseeking for open-domain question answering. arXiv preprint arXiv:2109.06747, 2021.\\n13\\nPublished as a conference paper at ICLR 2023\\nA\\nADDITIONAL RESULTS\\nA.1\\nGPT-3 EXPERIMENTS\\nPaLM-540B\\nGPT-3\\nHotpotQA (exact match)\\n29.4\\n30.8\\nALFWorld (success rate %)\\n70.9\\n78.4\\nTable 5: ReAct prompting results using PaLM-540B vs. GPT-3 (text-davinci-002, greedy decoding).\\nOn HotpotQA, we randomly sample a subset of 500 validation questions. On ALFWorld, we use all\\n134 unseen validation task instances, and use the best prompt set according to PaLM-540B.\\nWe run additional GPT-3 (Brown et al., 2020) experiments to conﬁrm ReAct prompting performance\\nis general across different large language models. As shown in Table 5, GPT-3 (text-davinci-002,\\ngreedy decoding) consistently outperforms PaLM-540B on HotpotQA and ALFWorld, possibly\\nbecause it is ﬁnetuned with human instruction following. This indicates ReAct prompting is effective\\nacross different large language models on different tasks. The code for these experiments are at\\nhttps://react-lm.github.io/.\\nA.2\\nREACT OBTAINS UP-TO-DATE KNOWLEDGE ON HOTPOTQA\\n�������������\\n�������������\\n����������������������\\n������������������������� �\\n�������������������������� �\\n��������������������� �\\n���������������������� �\\n����������������� �������� �\\n�������������������������� �\\n��������������������\\n�������������\\n��������������\\n������������������������������ ��\\n���������������������������� �\\n�������������������������������\\n�����������������������\\n����������������������\\n����������������������� ��������� �\\n������������ ��\\n����������������������\\n�������������������������������� �\\n���������\\n����������������������������� �\\n�����������\\n����������������������������� �\\n����������������� �\\n����������������������\\n�������������������������\\n����������������������������������������������������������\\n�\\n���������������������������������������������������������\\n�\\n����������\\n������������������������������������������� �\\n����������������������������������������������������\\n�\\n������������������������������\\n����������������������������������������������������������\\n�\\n���������� �\\n���������������������������������������� �\\n�������������������������������� ������������������������� ���\\n��������������������������������������\\n����������������������������������������������������� �\\n�����������������������������������������������������\\n�\\n���������������������������������������������������������\\n�\\n����������������������\\n���������������������������������������������� �\\n���������������� �������������������������� ���������������� �\\n����������������\\n�����������������������������������������������������������\\n�\\n���������������������������������������\\n��������������������\\n�\\n���������������������������������������������������������\\n�\\n����������������������������������\\n���������������������\\n��������������\\n���������\\n�����������\\nFigure 4: Another example HotpotQA question, where the original label is outdated. Only ReAct is\\nable to obtain the up-to-date answer thanks to real-world web interaction plus reasoning.\\nDuring trajectory inspection, we also ﬁnd that sometimes ReAct does not agree with dataset labels as\\nthe labels themselves could be outdated. For example, as shown in Figure 4, the question asks about\\nthe size of a hotel, which increased from the HotpotQA construction time. While Standard and CoT\\ngive wrong answers due to hallucination, Act fails despite the access of real-world web interaction,\\ndue to a lack of reasoning to guide how to interact with the Internet for QA. Only ReAct is able to\\nretrieve up-to-date information from the Internet and provide a reasonable answer. Therefore, better\\nincorporation of reasoning abilities might beneﬁt recent Internet-augmented language models (Nakano\\net al., 2021; Lazaridou et al., 2022; Shuster et al., 2022a) for up-to-date task solving.\\nA.3\\nHUMAN-IN-THE-LOOP BEHAVIOR CORRECTION ON ALFWORLD\\nWe also explore human-in-the-loop interaction with ReAct, to allow a human to inspect and edit\\nReAct’s reasoning traces. Figure 5 shows that by simply removing a hallucinating sentence in Act\\n17 and adding some hints in Act 23, ReAct can be made to change its behavior drastically to align\\nwith these human thought edits and succeed in the task. From a human perspective, solving such a\\ntask becomes signiﬁcantly easier, from typing tens of actions to only editing a couple of thoughts,\\nwhich enables new forms of human-machine collaboration. We note that such a policy edit on-the-go\\n14\\nPublished as a conference paper at ICLR 2023\\n����������\\n������\\n���������������������������������������������������������������\\n�\\n�������������������������������� �\\n�����������������������������������������������������������������\\n�\\n��������������������������������������������������������������\\n��\\n������������������������������������� �\\n�����������������������������������������������������\\n�\\n������\\n����������������������������������� �\\n������������������������������������������������ �\\n�����������������������������������������������������������������\\n�\\n�����������������������������������������������������������\\n��\\n���������������������� �\\n�������������������������������������������������������\\n�\\n���������������������������������������������������������������\\n�\\n����������� �\\n������������������������������������� �\\n������������������������\\n������������������������������\\n������\\n���������������������������������������������������������������������\\n�\\n�������������������������� �\\n���������������������������������������������������������������������������\\n��\\n���������������������������������������������������\\n�\\n������������������������������������� �\\n�����������������������������������������������������\\n�\\n������\\n����������������������������������� �\\n������������������������������������������������ �\\n�������������������������������������������������������������������������\\n�\\n������������������� ������������������������������������������������\\n�\\n���������������������������������������������������������������\\n��\\n����������������������� �\\n��������������������������������������������������������������������������\\n�\\n�������������������������\\n������������������������������������������������������������������������\\n����\\n�������������������������������������� �\\n������������������������������������������������������\\n�\\n��������������������������������������������������������������������������\\n������������� �\\n��������������������\\n��������������������������������������������������������������������������\\n�\\n��������\\n�����������������������������������\\n������������������������������������������������\\n�\\n������������������������������������������������������������\\n�\\n�������������������������������������������������������������\\n�\\n�������������������������������������������������������������\\n�\\n����������������������������������������������\\n�\\n������������������������������������������\\n��������\\nFigure 5: A human-in-the-loop behavior correction example with ReAct in AlfWorld. (a) ReAct\\ntrajectory fails due to a hallucinating thought (Act 17). (b) By a human simply editing two thoughts\\n(Act 17, 23), the ReAct trajectory produces desirable reasoning traces and actions and succeeds.\\nis difﬁcult for Act and previous RL methods, as a human cannot change the model parameters, and\\nchanging a few actions might not edit the rest of the model behavior. This paradigm is also more than\\nhuman dialogue to update the goal or subgoal as in Huang et al. (2022b) — while editing ReAct\\nthoughts can do these, it can also modify the model’s internal belief, reasoning styles, or anything the\\nﬂexible thought space supports, for better task solving. We believe this is an exciting direction for\\nhuman alignment and leave more systematic study as future work.\\nB\\nEXPERIMENT DETAILS\\nB.1\\nHOTPOTQA FINETUNING DETAILS\\nFor all ﬁnetuning we use a batch size of 64. On PaLM-8B, we ﬁnetune ReAct and Act methods\\nfor 4, 000 steps and Standard and CoT methods for 2, 000 steps. On PaLM-62B, we ﬁnetune\\nReAct and Act methods for 4, 000 steps and Standard and CoT methods for 1, 000 steps. We\\nﬁnd ReAct and Act methods generally beneﬁt from more training steps (and more training data),\\nwhile Standard and CoT methods degrade soon after ﬁnetuning.\\nB.2\\nALFWORLD IM-STYLE DETAILS\\nFor the IM-style ablation, the same expert trajectories used in ReAct are reannotated with dense\\nexternal feedback thoughts within these trajectories, that limit ReAct-IM to only think about (1)\\ndecomposing the current goal and (2) the current subgoal that needs to be completed. In particular,\\nReAct-IM lacks thoughts that (1) determine when a subgoal is completed (2) determine what the\\nnext subgoal should be (3) inducing the LLM to refer to its internal pretraining knowledge to identify\\nwhere items can be within the environment.\\n15\\nPublished as a conference paper at ICLR 2023\\nC\\nPROMPTS\\nC.1\\nHOTPOTQA\\nHotpot QA Prompts\\nOriginal\\nQuestion\\nWhat is the elevation range for the area that the eastern sector of the\\nColorado orogeny extends into?\\nAnswer\\n1,800 to 7,000 ft\\nQuestion\\nMusician and satirist Allie Goertz wrote a song about the \"The Simpsons\"\\ncharacter Milhouse, who Matt Groening named after who?\\nAnswer\\nRichard Nixon\\nQuestion\\nWhich documentary is about Finnish rock groups, Adam Clayton Powell or The\\nSaimaa Gesture?\\nAnswer\\nThe Saimaa Gesture\\nQuestion\\nWhat profession does Nicholas Ray and Elia Kazan have in common?\\nAnswer\\ndirector, screenwriter, actor\\nQuestion\\nWhich magazine was started first Arthur’s Magazine or First for Women?\\nAnswer\\nArthur’s Magazine\\nQuestion\\nWere Pavel Urysohn and Leonid Levin known for the same type of work?\\nAnswer\\nYes\\nAct\\nQuestion\\nWhat is the elevation range for the area that the eastern sector of the\\nColorado orogeny extends into?\\nAction 1\\nSearch[Colorado orogeny]\\nObservation 1\\nThe Colorado orogeny was an episode of mountain building (an orogeny) in\\nColorado and surrounding areas.\\nAction 2\\nLookup[eastern sector]\\nObservation 2\\n(Result 1 / 1) The eastern sector extends into the High Plains and is called\\nthe Central Plains orogeny.\\nAction 3\\nSearch[High Plains]\\nObservation 3\\nHigh Plains refers to one of two distinct land regions:\\nAction 4\\nSearch[High Plains (United States)]\\nObservation 4\\nThe High Plains are a subregion of the Great Plains.\\nFrom east to west, the\\nHigh Plains rise in elevation from around 1,800 to 7,000 ft (550 to 2,130\\nm).[3]\\nAction 5\\nFinish[1,800 to 7,000 ft]\\nQuestion\\nMusician and satirist Allie Goertz wrote a song about the \"The Simpsons\"\\ncharacter Milhouse, who Matt Groening named after who?\\nAction 1\\nSearch[Milhouse]\\nObservation 1\\nMilhouse Mussolini Van Houten is a recurring character in the Fox animated\\ntelevision series The Simpsons voiced by Pamela Hayden and created by Matt\\nGroening.\\nAction 2\\nLookup[named after]\\nObservation 2\\n(Result 1 / 1) Milhouse was named after U.S. president Richard Nixon, whose\\nmiddle name was Milhous.\\nAction 3\\nFinish[Richard Nixon]\\nQuestion\\nWhich documentary is about Finnish rock groups, Adam Clayton Powell or The\\nSaimaa Gesture?\\nAction 1\\nSearch[Adam Clayton Powell]\\nObservation 1\\nCould not find [Adam Clayton Powell].\\nSimilar:\\n[’Adam Clayton Powell\\nIII’, ’Seventh Avenue (Manhattan)’, ’Adam Clayton Powell Jr.\\nState Office\\nBuilding’, ’Isabel Washington Powell’, ’Adam Powell’, ’Adam Clayton Powell\\n(film)’, ’Giancarlo Esposito’].\\nAction 2\\nSearch[Adam Clayton Powell (film)]\\nObservation 2\\nAdam Clayton Powell is a 1989 American documentary film directed by\\nRichard Kilberg.\\nThe film is about the rise and fall of influential\\nAfrican-American politician Adam Clayton Powell Jr.[3][4] It was later aired\\nas part of the PBS series The American Experience.\\nAction 3\\nFinish[The Saimaa Gesture]\\nQuestion\\nWhat profession does Nicholas Ray and Elia Kazan have in common?\\nAction 1\\nSearch[Nicholas Ray]\\nObservation 1\\nNicholas Ray (born Raymond Nicholas Kienzle Jr., August 7, 1911 - June 16,\\n1979) was an American film director, screenwriter, and actor best known for\\nthe 1955 film Rebel Without a Cause.\\nAction 2\\nSearch[Elia Kazan]\\nObservation 2\\nElia Kazan was an American film and theatre director, producer, screenwriter\\nand actor.\\nContinued on next page\\n16\\nPublished as a conference paper at ICLR 2023\\nHotpot QA Prompts – Continued from previous page\\nAction 3\\nFinish[director, screenwriter, actor]\\nQuestion\\nWhich magazine was started first Arthur’s Magazine or First for Women?\\nAction 1\\nSearch[Arthur’s Magazine]\\nObservation 1\\nArthur’s Magazine (1844-1846) was an American literary periodical published\\nin Philadelphia in the 19th century.\\nAction 2\\nSearch[First for Women]\\nObservation 2\\nFirst for Women is a woman’s magazine published by Bauer Media Group in the\\nUSA.[1] The magazine was started in 1989.\\nAction 3\\nFinish[Arthur’s Magazine]\\nQuestion\\nWere Pavel Urysohn and Leonid Levin known for the same type of work?\\nAction 1\\nSearch[Pavel Urysohn]\\nObservation 1\\nPavel Samuilovich Urysohn (February 3, 1898 - August 17, 1924) was a Soviet\\nmathematician who is best known for his contributions in dimension theory.\\nAction 2\\nSearch[Leonid Levin]\\nObservation 2\\nLeonid Anatolievich Levin is a Soviet-American mathematician and computer\\nscientist.\\nAction 3\\nFinish[yes]\\nCoT\\nQuestion\\nWhat is the elevation range for the area that the eastern sector of the\\nColorado orogeny extends into?\\nThought\\nLet’s think step by step.\\nThe eastern sector of Colorado orogeny extends\\ninto the High Plains.\\nHigh Plains rise in elevation from around 1,800 to\\n7,000 ft, so the answer is 1,800 to 7,000 ft.\\nAnswer\\n1,800 to 7,000 ft\\nQuestion\\nMusician and satirist Allie Goertz wrote a song about the \"The Simpsons\"\\ncharacter Milhouse, who Matt Groening named after who?\\nThought\\nLet’s think step by step.\\nMilhouse was named after U.S. president Richard\\nNixon, so the answer is Richard Nixon.\\nAnswer\\nRichard Nixon\\nQuestion\\nWhich documentary is about Finnish rock groups, Adam Clayton Powell or The\\nSaimaa Gesture?\\nThought\\nLet’s think step by step.\\nAdam Clayton Powell (film) is a documentary about\\nan African-American politician, not Finnish rock groups.\\nSo the documentary\\nabout Finnish rock groups must instead be The Saimaa Gesture.\\nAnswer\\nThe Saimaa Gesture\\nQuestion\\nWhat profession does Nicholas Ray and Elia Kazan have in common?\\nThought\\nLet’s think step by step.\\nProfessions of Nicholas Ray are director,\\nscreenwriter, and actor.\\nProfessions of Elia Kazan are director, producer,\\nscreenwriter, and actor.\\nSo profession Nicholas Ray and Elia Kazan have in\\ncommon is director, screenwriter, and actor.\\nAnswer\\ndirector, screenwriter, actor\\nQuestion\\nWhich magazine was started first Arthur’s Magazine or First for Women?\\nThought\\nLet’s think step by step.\\nArthur’s Magazine was started in 1844.\\nFirst\\nfor Women was started in 1989.\\n1844 (Arthur’s Magazine) < 1989 (First for\\nWomen), so Arthur’s Magazine was started first.\\nAnswer\\nArthur’s Magazine\\nQuestion\\nWere Pavel Urysohn and Leonid Levin known for the same type of work?\\nThought\\nLet’s think step by step.\\nPavel Urysohn is a mathematician.\\nLeonid Levin\\nis a mathematician and computer scientist.\\nSo Pavel Urysohn and Leonid\\nLevin have the same type of work.\\nAnswer\\nYes\\nReAct\\nQuestion\\nWhat is the elevation range for the area that the eastern sector of the\\nColorado orogeny extends into?\\nThought 1\\nI need to search Colorado orogeny, find the area that the eastern sector\\nof the Colorado orogeny extends into, then find the elevation range of the\\narea.\\nAction 1\\nSearch[Colorado orogeny]\\nObservation 1\\nThe Colorado orogeny was an episode of mountain building (an orogeny) in\\nColorado and surrounding areas.\\nThought 2\\nIt does not mention the eastern sector.\\nSo I need to look up eastern\\nsector.\\nAction 2\\nLookup[eastern sector]\\nObservation 2\\n(Result 1 / 1) The eastern sector extends into the High Plains and is called\\nthe Central Plains orogeny.\\nThought 3\\nThe eastern sector of Colorado orogeny extends into the High Plains.\\nSo I\\nneed to search High Plains and find its elevation range.\\nAction 3\\nSearch[High Plains]\\nObservation 3\\nHigh Plains refers to one of two distinct land regions\\nThought 4\\nI need to instead search High Plains (United States).\\nAction 4\\nSearch[High Plains (United States)]\\nContinued on next page\\n17\\nPublished as a conference paper at ICLR 2023\\nHotpot QA Prompts – Continued from previous page\\nObservation 4\\nThe High Plains are a subregion of the Great Plains.\\nFrom east to west, the\\nHigh Plains rise in elevation from around 1,800 to 7,000 ft (550 to 2,130\\nm).[3]\\nThought 5\\nHigh Plains rise in elevation from around 1,800 to 7,000 ft, so the answer\\nis 1,800 to 7,000 ft.\\nAction 5\\nFinish[1,800 to 7,000 ft]\\nQuestion\\nMusician and satirist Allie Goertz wrote a song about the \"The Simpsons\"\\ncharacter Milhouse, who Matt Groening named after who?\\nThought 1\\nThe question simplifies to \"The Simpsons\" character Milhouse is named after\\nwho.\\nI only need to search Milhouse and find who it is named after.\\nAction 1\\nSearch[Milhouse]\\nObservation 1\\nMilhouse Mussolini Van Houten is a recurring character in the Fox animated\\ntelevision series The Simpsons voiced by Pamela Hayden and created by Matt\\nGroening.\\nThought 2\\nThe paragraph does not tell who Milhouse is named after, maybe I can look up\\n\"named after\".\\nAction 2\\nLookup[named after]\\nObservation 2\\n(Result 1 / 1) Milhouse was named after U.S. president Richard Nixon, whose\\nmiddle name was Milhous.\\nThought 3\\nMilhouse was named after U.S. president Richard Nixon, so the answer is\\nRichard Nixon.\\nAction 3\\nFinish[Richard Nixon]\\nQuestion\\nWhich documentary is about Finnish rock groups, Adam Clayton Powell or The\\nSaimaa Gesture?\\nThought 1\\nI need to search Adam Clayton Powell and The Saimaa Gesture, and find which\\ndocumentary is about Finnish rock groups.\\nAction 1\\nSearch[Adam Clayton Powell]\\nObservation 1\\nCould not find [Adam Clayton Powell].\\nSimilar:\\n[’Adam Clayton Powell\\nIII’, ’Seventh Avenue (Manhattan)’, ’Adam Clayton Powell Jr.\\nState Office\\nBuilding’, ’Isabel Washington Powell’, ’Adam Powell’, ’Adam Clayton Powell\\n(film)’, ’Giancarlo Esposito’].\\nThought 2\\nTo find the documentary, I can search Adam Clayton Powell (film).\\nAction 2\\nSearch[Adam Clayton Powell (film)]\\nObservation 2\\nAdam Clayton Powell is a 1989 American documentary film directed by\\nRichard Kilberg.\\nThe film is about the rise and fall of influential\\nAfrican-American politician Adam Clayton Powell Jr.[3][4] It was later aired\\nas part of the PBS series The American Experience.\\nThought 3\\nAdam Clayton Powell (film) is a documentary about an African-American\\npolitician, not Finnish rock groups.\\nSo the documentary about Finnish rock\\ngroups must instead be The Saimaa Gesture.\\nAction 3\\nFinish[The Saimaa Gesture]\\nQuestion\\nWhat profession does Nicholas Ray and Elia Kazan have in common?\\nThought 1\\nI need to search Nicholas Ray and Elia Kazan, find their professions, then\\nfind the profession they have in common.\\nAction 1\\nSearch[Nicholas Ray]\\nObservation 1\\nNicholas Ray (born Raymond Nicholas Kienzle Jr., August 7, 1911 - June 16,\\n1979) was an American film director, screenwriter, and actor best known for\\nthe 1955 film Rebel Without a Cause.\\nThought 2\\nProfessions of Nicholas Ray are director, screenwriter, and actor.\\nI need\\nto search Elia Kazan next and find his professions.\\nAction 2\\nSearch[Elia Kazan]\\nObservation 2\\nElia Kazan was an American film and theatre director, producer, screenwriter\\nand actor.\\nThought 3\\nProfessions of Elia Kazan are director, producer, screenwriter, and actor.\\nSo profession Nicholas Ray and Elia Kazan have in common is director,\\nscreenwriter, and actor.\\nAction 3\\nFinish[director, screenwriter, actor]\\nQuestion\\nWhich magazine was started first Arthur’s Magazine or First for Women?\\nThought 1\\nI need to search Arthur’s Magazine and First for Women, and find which was\\nstarted first.\\nAction 1\\nSearch[Arthur’s Magazine]\\nObservation 1\\nArthur’s Magazine (1844-1846) was an American literary periodical published\\nin Philadelphia in the 19th century.\\nThought 2\\nArthur’s Magazine was started in 1844.\\nI need to search First for Women\\nnext.\\nAction 2\\nSearch[First for Women]\\nObservation 2\\nFirst for Women is a woman’s magazine published by Bauer Media Group in the\\nUSA.[1] The magazine was started in 1989.\\nThought 3\\nFirst for Women was started in 1989.\\n1844 (Arthur’s Magazine) < 1989 (First\\nfor Women), so Arthur’s Magazine was started first.\\nAction 3\\nFinish[Arthur’s Magazine]\\nQuestion\\nWere Pavel Urysohn and Leonid Levin known for the same type of work?\\nThought 1\\nI need to search Pavel Urysohn and Leonid Levin, find their types of work,\\nthen find if they are the same.\\nAction 1\\nSearch[Pavel Urysohn]\\nContinued on next page\\n18\\nPublished as a conference paper at ICLR 2023\\nHotpot QA Prompts – Continued from previous page\\nObservation 1\\nPavel Samuilovich Urysohn (February 3, 1898 - August 17, 1924) was a Soviet\\nmathematician who is best known for his contributions in dimension theory.\\nThought 2\\nPavel Urysohn is a mathematician.\\nI need to search Leonid Levin next and\\nfind its type of work.\\nAction 2\\nSearch[Leonid Levin]\\nObservation 2\\nLeonid Anatolievich Levin is a Soviet-American mathematician and computer\\nscientist.\\nThought 3\\nLeonid Levin is a mathematician and computer scientist.\\nSo Pavel Urysohn\\nand Leonid Levin have the same type of work.\\nAction 3\\nFinish[yes]\\n19\\nPublished as a conference paper at ICLR 2023\\nC.2\\nFEVER\\nFEVER Prompts\\nOriginal\\nDetermine if there is Observation that SUPPORTS or REFUTES a Claim, or if\\nthere is NOT ENOUGH INFORMATION.\\nClaim\\nNikolaj Coster-Waldau worked with the Fox Broadcasting Company.\\nAnswer\\nSUPPORTS\\nClaim\\nStranger Things is set in Bloomington, Indiana.\\nAnswer\\nREFUTES\\nClaim\\nBeautiful reached number two on the Billboard Hot 100 in 2003.\\nAnswer\\nNOT ENOUGH INFO\\nAct\\nDetermine if there is Observation that SUPPORTS or REFUTES a Claim, or if\\nthere is NOT ENOUGH INFORMATION.\\nClaim\\nNikolaj Coster-Waldau worked with the Fox Broadcasting Company.\\nAction2\\nSearch[Nikolaj Coster-Waldau]\\nObservation 1\\nNikolaj William Coster-Waldau (born 27 July 1970) is a Danish actor and\\nproducer.\\nHe graduated from the Danish National School of Performing Arts\\nin Copenhagen in 1993,[1] and had his breakthrough role in Denmark with\\nthe film Nightwatch (1994).\\nHe played Jaime Lannister in the HBO fantasy\\ndrama series Game of Thrones, for which he received two Primetime Emmy\\nAward nominations for Outstanding Supporting Actor in a Drama Series..\\nCoster-Waldau has appeared in numerous films in his native Denmark and\\nScandinavia, including Headhunters (2011) and A Thousand Times Good Night\\n(2013).\\nIn the U.S, his debut film role was in the war film Black Hawk Down\\n(2001), playing Medal of Honor recipient Gary Gordon.[2] He then played a\\ndetective in the short-lived Fox television series New Amsterdam (2008), and\\nappeared in the 2009 Fox television film Virtuality, originally intended as\\na pilot.\\nAction 2\\nFinish[SUPPORTS]\\nClaim\\nStranger Things is set in Bloomington, Indiana.\\nAction 1\\nSearch[Stranger Things]\\nObservation 1\\nStranger Things is an American science fiction horror drama television\\nseries created by the Duffer Brothers.\\nSet in the 1980s, primarily in\\nthe fictional town of Hawkins, Indiana, the series centers on a number of\\nmysteries and supernatural events occurring around the town and their impact\\non an ensemble of child and adult characters.\\nAction 2\\nFinish[REFUTES]\\nClaim\\nBeautiful reached number two on the Billboard Hot 100 in 2003.\\nAction 1\\nSearch[Beautiful]\\nObservation 1\\nCould not find [Beautiful].\\nSimilar:\\n[’Beautiful’, ’Beautiful, Beautiful’,\\n’A Beautiful Mind (film)’, ’Beautiful (Christina Aguilera song)’, ’Life Is\\nBeautiful’].\\nAction 2\\nSearch[Beautiful (Christina Aguilera song)\\nObservation 2\\n\"Beautiful\" is a song recorded by American singer Christina Aguilera for her\\nfourth studio album, Stripped (2002).\\nAction 3\\nLookup[Billboard Hot 100]\\nObservation 3\\n(Result 1 / 3) The song peaked at number two on the Billboard Hot 100 in the\\nUnited States, where it was certified Gold for 500,000 units shipped.\\nAction 4\\nFinish[NOT ENOUGH INFO]\\nCoT\\nDetermine if there is Observation that SUPPORTS or REFUTES a Claim, or if\\nthere is NOT ENOUGH INFORMATION.\\nClaim\\nNikolaj Coster-Waldau worked with the Fox Broadcasting Company.\\nThought\\nNikolaj William Coster-Waldau appeared in the 2009 Fox television film\\nVirtuality, so he has worked with the Fox Broadcasting Company.\\nAnswer\\nSUPPORTS\\nClaim\\nStranger Things is set in Bloomington, Indiana.\\nThought\\nStranger Things is in the fictional town of Hawkins, Indiana, not in\\nBloomington, Indiana.\\nAnswer\\nREFUTES\\nContinued on next page\\n20\\nPublished as a conference paper at ICLR 2023\\nFever Prompts – Continued from previous page\\nClaim\\nBeautiful reached number two on the Billboard Hot 100 in 2003.\\nThought\\nThe song peaked at number two on the Billboard Hot 100 in the United States,\\nbut not sure if it was in 2003.\\nAnswer\\nNOT ENOUGH INFO\\nReAct\\nDetermine if there is Observation that SUPPORTS or REFUTES a Claim, or if\\nthere is NOT ENOUGH INFORMATION.\\nClaim\\nNikolaj Coster-Waldau worked with the Fox Broadcasting Company.\\nThought 1\\nI need to search Nikolaj Coster-Waldau and find if he has worked with the\\nFox Broadcasting Company.\\nAction 1\\nSearch[Nikolaj Coster-Waldau]\\nObservation 1\\nNikolaj William Coster-Waldau (born 27 July 1970) is a Danish actor and\\nproducer.\\nHe graduated from the Danish National School of Performing Arts\\nin Copenhagen in 1993,[1] and had his breakthrough role in Denmark with\\nthe film Nightwatch (1994).\\nHe played Jaime Lannister in the HBO fantasy\\ndrama series Game of Thrones, for which he received two Primetime Emmy\\nAward nominations for Outstanding Supporting Actor in a Drama Series..\\nCoster-Waldau has appeared in numerous films in his native Denmark and\\nScandinavia, including Headhunters (2011) and A Thousand Times Good Night\\n(2013).\\nIn the U.S, his debut film role was in the war film Black Hawk Down\\n(2001), playing Medal of Honor recipient Gary Gordon.[2] He then played a\\ndetective in the short-lived Fox television series New Amsterdam (2008), and\\nappeared in the 2009 Fox television film Virtuality, originally intended as\\na pilot.\\nThought 2\\nBecause he \"appeared in the 2009 Fox television film Virtuality\", he should\\nhave worked with the Fox Broadcasting Company.\\nAction 2\\nFinish[SUPPORTS]\\nClaim\\nStranger Things is set in Bloomington, Indiana.\\nThought 1\\nI should search for Stranger Things, and see if it is set in Bloomington,\\nIndiana.\\nAction 1\\nSearch[Stranger Things]\\nObservation 1\\nStranger Things is an American science fiction horror drama television\\nseries created by the Duffer Brothers.\\nSet in the 1980s, primarily in\\nthe fictional town of Hawkins, Indiana, the series centers on a number of\\nmysteries and supernatural events occurring around the town and their impact\\non an ensemble of child and adult characters.\\nThought 2\\nThe observation says that it is set in a \"fictional town of Hawkins,\\nIndiana\", so it is not set in Bloomington.\\nAction 2\\nFinish[REFUTES]\\nClaim\\nBeautiful reached number two on the Billboard Hot 100 in 2003.\\nThought 1\\nI need to search the song Beautiful and find if it reached number two on the\\nBillboard Hot 100 in 2003.\\nAction 1\\nSearch[Beautiful]\\nObservation 1\\nCould not find [Beautiful].\\nSimilar:\\n[’Beautiful’, ’Beautiful, Beautiful’,\\n’A Beautiful Mind (film)’, ’Beautiful (Christina Aguilera song)’, ’Life Is\\nBeautiful’].\\nThought 2\\nFrom suggestions, I should search \"Beautiful (Christina Aguilera song)\" to\\nfind the song.\\nAction 2\\nSearch[Beautiful (Christina Aguilera song)]\\nObservation 2\\n\"Beautiful\" is a song recorded by American singer Christina Aguilera for her\\nfourth studio album, Stripped (2002).\\nThought 3\\nIt does not mention Billboard, so I need to look up \"Billboard Hot 100\" to\\nfind if it reached number two on it in 2003.\\nAction 3\\nLookup[Billboard Hot 100]\\nObservation 3\\n(Result 1 / 3) The song peaked at number two on the Billboard Hot 100 in the\\nUnited States, where it was certified Gold for 500,000 units shipped.\\nThought 4\\nIt only says the song peaked at number two on the Billboard Hot 100, but not\\nif it was in 2003.\\nI am not sure if this claim is true or not.\\nAction 4\\nFinish[NOT ENOUGH INFO]\\n21\\nPublished as a conference paper at ICLR 2023\\nC.3\\nWEBSHOP\\nTable 6: Prompts used for the Webshop experiments in Section 4. We use the prompt on the left for\\nAct, and use the prompt on the right (add reasoning) for ReAct.\\nInstruction: i would like a 3 ounce bottle of bright citrus deodorant for sensitive skin, and price lower than 50.00 dollars\\nAct\\nReAct\\nAction: search\\n�\\n3 ounce bright citrus deodorant sensitive skin\\n�\\nObservation:\\n�\\nBack to Search\\n�\\nPage 1 (Total results: 50)\\n�\\nNext\\n�\\n�\\nB078GWRC1J\\n�\\nBright Citrus Deodorant by Earth Mama | Natural and Safe for\\nSensitive Skin, Pregnancy and Breastfeeding, Contains Organic\\nCalendula 3-Ounce\\n$10.99\\n�\\nB078GTKVXY\\n�\\nGinger Fresh Deodorant by Earth Mama | Natural and Safe for\\nSensitive Skin, Pregnancy and Breastfeeding, Contains Organic\\nCalendula 3-Ounce\\n$10.99\\n�\\nB08KBVJ4XN\\n�\\nBarrel and Oak - Aluminum-Free Deodorant, Deodorant for Men\\n, Essential Oil-Based Scent, 24-Hour Odor Protection, Cedar\\n& Patchouli Blend, Gentle on Sensitive Skin (Mountain Sage,\\n2.7 oz, 2-Pack)\\n$15.95\\nAction: click\\n�\\nB078GWRC1J\\n�\\nObservation:\\n�\\nBack to Search\\n�\\n�\\nPrev\\n�\\nscent [assorted scents][bright citrus][calming lavender][ginger\\n[fresh] simply non-scents]\\nsize [travel set (4-pack)][3 ounce (pack of 1)][3-ounce (2\\n-pack)]\\nBright Citrus Deodorant by Earth Mama | Natural and Safe for\\nSensitive Skin, Pregnancy and Breastfeeding, Contains Organic\\nCalendula 3-Ounce\\nPrice: $10.99\\nRating: N.A.\\n[Description]\\n[Features]\\n[Reviews]\\n[Buy Now]\\nAction: click[bright citrus]\\nObservation: You have clicked bright citrus.\\nAction: click[3 ounce (pack of 1)]\\nObservation: You have clicked 3 ounce (pack of 1).\\nAction: click[Buy Now]\\nAction: search\\n�\\n3 ounce bright citrus deodorant sensitive skin\\nObservation:\\n�\\nBack to Search\\n�\\nPage 1 (Total results: 50)\\n�\\nNext\\n�\\n�\\nB078GWRC1J\\n�\\nBright Citrus Deodorant by Earth Mama | Natural and Safe for\\nSensitive Skin, Pregnancy and Breastfeeding, Contains Organic\\nCalendula 3-Ounce\\n$10.99\\n�\\nB078GTKVXY\\n�\\nGinger Fresh Deodorant by Earth Mama | Natural and Safe for\\nSensitive Skin, Pregnancy and Breastfeeding, Contains Organic\\nCalendula 3-Ounce\\n$10.99\\n�\\nB08KBVJ4XN\\n�\\nBarrel and Oak - Aluminum-Free Deodorant, Deodorant for Men\\n, Essential Oil-Based Scent, 24-Hour Odor Protection, Cedar\\n& Patchouli Blend, Gentle on Sensitive Skin (Mountain Sage,\\n2.7 oz, 2-Pack)\\n$15.95\\nAction: think[B078GWRC1J and B078GTKVXY are bright citrus\\ndeodorant less then 50 dollars. I can check B078GWRC1J ﬁrst.\\nObservation: OK.\\nAction: click\\n�\\nB078GWRC1J\\n�\\nObservation:\\n�\\nBack to Search\\n�\\n�\\nPrev\\n�\\nscent [assorted scents][bright citrus][calming lavender][ginger\\n[fresh] simply non-scents]\\nsize [travel set (4-pack)][3 ounce (pack of 1)][3-ounce (2\\n-pack)]\\nBright Citrus Deodorant by Earth Mama | Natural and Safe for\\nSensitive Skin, Pregnancy and Breastfeeding, Contains Organic\\nCalendula 3-Ounce\\nPrice: $10.99\\nRating: N.A.\\n[Description]\\n[Features]\\n[Reviews]\\n[Buy Now]\\nAction: think[For 3 ounce bottle of bright citrus deodorant\\nfor sensitive skin, the item has options ’bright citrus’\\nand ’3 ounce (pack of 1)’ and seems good to buy.]\\nObservation: OK.\\nAction: click[bright citrus]\\nObservation: You have clicked bright citrus.\\nAction: click[3 ounce (pack of 1)]\\nObservation: You have clicked 3 ounce (pack of 1).\\nAction: click[Buy Now]\\n22\\nPublished as a conference paper at ICLR 2023\\nC.4\\nALFWORLD\\nTable 7: An Act prompt on the ALFWorld clean task. No thoughts are provided.\\nYou are in the middle of a room.\\nLooking quickly around you, you see a cabinet\\n13, a cabinet 12, a cabinet 11, a cabinet 10, a cabinet 9, a cabinet 8, a cabinet\\n7, a cabinet 6, a cabinet 5, a cabinet 4, a cabinet 3, a cabinet 2, a cabinet\\n1, a coffeemachine 1, a countertop 1, a diningtable 1, a drawer 1, a fridge 1, a\\ngarbagecan 1, a microwave 1, a shelf 3, a shelf 2, a shelf 1, a sinkbasin 1, a\\nstoveburner 4, a stoveburner 3, a stoveburner 2, a stoveburner 1, and a toaster 1.\\nYour task is to:\\nput a clean lettuce in diningtable.\\n> go to fridge 1\\nThe fridge 1 is closed.\\n> open fridge 1\\nYou open the fridge 1.\\nThe fridge 1 is open.\\nIn it, you see a cup 3, a egg 2, a\\npotato 3, and a potato 2.\\n> go to diningtable 1\\nOn the diningtable 1, you see a apple 1, a bread 1, a butterknife 2, a cup 2, a\\nfork 2, a knife 2, a knife 1, a ladle 1, a lettuce 1, a mug 2, a mug 1, a pan 2, a\\npeppershaker 1, a spatula 3, a tomato 2, and a tomato 1.\\n> take lettuce 1 from diningtable 1\\nYou pick up the lettuce 1 from the diningtable 1.\\n> go to sinkbasin 1\\nOn the sinkbasin 1, you see a apple 2, a ladle 2, a spoon 1, and a tomato 3.\\n> clean lettuce 1 with sinkbasin 1\\nYou clean the lettuce 1 using the sinkbasin 1.\\n> think:\\nNow I clean a lettuce (1).\\nNext, I need to put it in/on diningtable 1.\\nOK.\\n> go to diningtable 1\\nOn the diningtable 1, you see a apple 1, a bread 1, a butterknife 2, a cup 2, a fork\\n2, a knife 2, a knife 1, a ladle 1, a mug 2, a mug 1, a pan 2, a peppershaker 1, a\\nspatula 3, a tomato 2, and a tomato 1.\\n> put lettuce 1 in/on diningtable 1\\nYou put the lettuce 1 in/on the diningtable 1.\\n23\\nPublished as a conference paper at ICLR 2023\\nTable 8: An ReAct prompt on the ALFWorld clean task.\\nYou are in the middle of a room.\\nLooking quickly around you, you see a cabinet\\n13, a cabinet 12, a cabinet 11, a cabinet 10, a cabinet 9, a cabinet 8, a cabinet\\n7, a cabinet 6, a cabinet 5, a cabinet 4, a cabinet 3, a cabinet 2, a cabinet\\n1, a coffeemachine 1, a countertop 1, a diningtable 1, a drawer 1, a fridge 1, a\\ngarbagecan 1, a microwave 1, a shelf 3, a shelf 2, a shelf 1, a sinkbasin 1, a\\nstoveburner 4, a stoveburner 3, a stoveburner 2, a stoveburner 1, and a toaster 1.\\nYour task is to:\\nput a clean lettuce in diningtable.\\n> think:\\nTo solve the task, I need to find and take a lettuce, then clean it with\\nsinkbasin, then put it in diningtable.\\nOK.\\n> think:\\nFirst I need to find a lettuce.\\nA lettuce is more likely to appear in\\nfridge (1), diningtable (1), sinkbasin (1), stoveburner (1-3), cabinet (1-13).\\nI\\ncan check one by one, starting with fridge 1.\\nOK.\\n> go to fridge 1\\nThe fridge 1 is closed.\\n> open fridge 1\\nYou open the fridge 1.\\nThe fridge 1 is open.\\nIn it, you see a cup 3, a egg 2, a\\npotato 3, and a potato 2.\\n> go to diningtable 1\\nOn the diningtable 1, you see a apple 1, a bread 1, a butterknife 2, a cup 2, a\\nfork 2, a knife 2, a knife 1, a ladle 1, a lettuce 1, a mug 2, a mug 1, a pan 2, a\\npeppershaker 1, a spatula 3, a tomato 2, and a tomato 1.\\n> think:\\nNow I find a lettuce (1).\\nNext, I need to take it.\\nOK.\\n> take lettuce 1 from diningtable 1\\nYou pick up the lettuce 1 from the diningtable 1.\\n> think:\\nNow I take a lettuce (1).\\nNext, I need to go to sinkbasin (1) and clean\\nit.\\nOK.\\n> go to sinkbasin 1\\nOn the sinkbasin 1, you see a apple 2, a ladle 2, a spoon 1, and a tomato 3.\\n> clean lettuce 1 with sinkbasin 1\\nYou clean the lettuce 1 using the sinkbasin 1.\\n> think:\\nNow I clean a lettuce (1).\\nNext, I need to put it in/on diningtable 1.\\nOK.\\n> go to diningtable 1\\nOn the diningtable 1, you see a apple 1, a bread 1, a butterknife 2, a cup 2, a fork\\n2, a knife 2, a knife 1, a ladle 1, a mug 2, a mug 1, a pan 2, a peppershaker 1, a\\nspatula 3, a tomato 2, and a tomato 1.\\n> put lettuce 1 in/on diningtable 1\\nYou put the lettuce 1 in/on the diningtable 1.\\n24\\nPublished as a conference paper at ICLR 2023\\nTable 9: An ReAct-IM prompt on the ALFWorld clean task.\\nYou are in the middle of a room.\\nLooking quickly around you, you see a cabinet\\n13, a cabinet 12, a cabinet 11, a cabinet 10, a cabinet 9, a cabinet 8, a cabinet\\n7, a cabinet 6, a cabinet 5, a cabinet 4, a cabinet 3, a cabinet 2, a cabinet\\n1, a coffeemachine 1, a countertop 1, a diningtable 1, a drawer 1, a fridge 1, a\\ngarbagecan 1, a microwave 1, a shelf 3, a shelf 2, a shelf 1, a sinkbasin 1, a\\nstoveburner 4, a stoveburner 3, a stoveburner 2, a stoveburner 1, and a toaster 1.\\nYour task is to:\\nput a clean lettuce in diningtable.\\n> think:\\nTo solve the task, I need to find and take a lettuce, then clean it with\\nsinkbasin, then put it in diningtable.\\nOK.\\n> think:\\nFirst I need to find a lettuce.\\nOK.\\n> go to fridge 1\\nThe fridge 1 is closed.\\n> think:\\nFirst I need to find a lettuce.\\nOK.\\n> open fridge 1\\nYou open the fridge 1.\\nThe fridge 1 is open.\\nIn it, you see a cup 3, a egg 2, a\\npotato 3, and a potato 2.\\n> think:\\nFirst I need to find a lettuce.\\nOK.\\n> go to diningtable 1\\nOn the diningtable 1, you see a apple 1, a bread 1, a butterknife 2, a cup 2, a\\nfork 2, a knife 2, a knife 1, a ladle 1, a lettuce 1, a mug 2, a mug 1, a pan 2, a\\npeppershaker 1, a spatula 3, a tomato 2, and a tomato 1.\\n> think:\\nFirst I need to find a lettuce.\\nOK.\\n> take lettuce 1 from diningtable 1\\nYou pick up the lettuce 1 from the diningtable 1.\\n> think:\\nI need to clean this lettuce (1) using sinkbasin 1.\\nOK.\\n> go to sinkbasin 1\\nOn the sinkbasin 1, you see a apple 2, a ladle 2, a spoon 1, and a tomato 3.\\n> think:\\nI need to clean this lettuce (1) using sinkbasin 1.\\nOK.\\n> clean lettuce 1 with sinkbasin 1\\nYou clean the lettuce 1 using the sinkbasin 1.\\n> think:\\nI need to put this cleaned lettuce (1) in/on diningtable 1.\\nOK.\\n> go to diningtable 1\\nOn the diningtable 1, you see a apple 1, a bread 1, a butterknife 2, a cup 2, a fork\\n2, a knife 2, a knife 1, a ladle 1, a mug 2, a mug 1, a pan 2, a peppershaker 1, a\\nspatula 3, a tomato 2, and a tomato 1.\\n> think:\\nI need to put this cleaned lettuce (1) in/on diningtable 1.\\nOK.\\n> put lettuce 1 in/on diningtable 1\\nYou put the lettuce 1 in/on the diningtable 1.\\nD\\nTRAJECTORIES\\nD.1\\nFEVER TRAJECTORIES\\nWe provide some trajectories produced by ReAct, CoTand Acton several randomly selected exam-\\nples from the FEVER dev set below. Search results are omitted to space.\\n25\\nPublished as a conference paper at ICLR 2023\\nExample 2491 (gt: REFUTES)\\nReAct\\nClaim:\\nBermuda Triangle is a loosely-defined region in the Pacific Ocean.\\nThought 1:\\nI need to search Bermuda Triangle and find if it is in the Pacific Ocean.\\nAction 1:\\nSearch[Bermuda Triangle]\\nObservation 1:\\nReportedly haunted locations...\\nThought 2:\\nThe observation says that it is in the western part of the North Atlantic\\nOcean, so it is not in the Pacific Ocean.\\nAction 2:\\nFinish[REFUTES]\\nObservation 2:\\nEpisode finished\\nAct\\nClaim:\\nBermuda Triangle is a loosely-defined region in the Pacific Ocean.\\nAction 1\\n:\\nSearch[Bermuda Triangle]\\nObservation 1\\n:\\nReportedly haunted locations:...\\nAction 2:\\nFinish[REFUTES]\\nObservation 2:\\nEpisode finished\\nCoT\\nClaim:\\nBermuda Triangle is a loosely-defined region in the Pacific Ocean.\\nThought:\\nLet’s think step by step.\\nThe Bermuda Triangle is a loosely-defined region\\nin the Atlantic Ocean.\\nThe Pacific Ocean is not the Atlantic Ocean.\\nAnswer:\\nREFUTES\\nExample 5908 (gt: SUPPORTS)\\nReAct\\nClaim:\\nPrincess Mononoke is a film.\\nThought 1:\\nI need to search Princess Mononoke and find if it is a film.\\nAction 1:\\nSearch[Princess Mononoke]\\nObservation 1:\\nPrincess Mononoke ...\\nThought 2:\\nFrom the observation, it says that Princess Mononoke is a film.\\nAction 2:\\nFinish[SUPPORTS]\\nObservation 2:\\nEpisode finished\\nAct\\nClaim:\\nPrincess Mononoke is a film.\\nAction 1:\\nSearch[Princess Mononoke]\\nObservation 1:\\nPrincess Mononoke ...\\nAction 2:\\nFinish[SUPPORTS]\\nObservation 2:\\nEpisode finished\\nCoT\\nClaim:\\nPrincess Mononoke is a film.\\nThought:\\nLet’s think step by step.\\nPrincess Mononoke is a movie, and movies are\\nfilms.\\nAnswer:\\nSUPPORTS\\nExample 1951 (gt: REFUTES)\\nReAct\\nClaim:\\nSoyuz was part of the American space program.\\nThought 1:\\nI need to search Soyuz and find if it was part of the American space\\nprogram.\\nAction 1:\\nSearch[Soyuz]\\nObservation 1:\\nSoyuz is a transliteration...\\nThought 2:\\nIt does not mention the American space program, so I need to search\\n\"American space program\" to find if it was part of it.\\nAction 2:\\nSearch[American space program]\\nObservation 2:\\nThe space policy...\\nThought 3:\\nIt does not mention Soyuz, so I am not sure if this claim is true or not.\\nAction 3:\\nFinish[NOT ENOUGH INFO]\\nObservation 3:\\nEpisode finished\\nAct\\nClaim:\\nSoyuz was part of the American space program.\\nAction 1:\\nSearch[Soyuz]\\nObservation 1:\\nSoyuz is a transliteration...\\nAction 2:\\nFinish[NOT ENOUGH INFO]\\nObservation 2:\\nEpisode finished\\nCoT\\nClaim:\\nSoyuz was part of the American space program.\\nThought:\\nLet’s think step by step.\\nSoyuz is a Russian spacecraft.\\nThe American\\nspace program is NASA. NASA and Russia have worked together on the\\nInternational Space Station.\\nAnswer:\\nSUPPORTS\\n26\\nPublished as a conference paper at ICLR 2023\\nExample 3208 (gt: REFUTES)\\nReAct\\nClaim:\\nReign Over Me is an American film made in 2010.\\nThought 1:\\nI need to search for Reign Over Me and find if it is an American film made\\nin 2010.\\nAction 1:\\nSearch[Reign Over Me]\\nObservation 1:\\nReign Over Me ...\\nThought 2:\\nThe observation says that it is an American film made in 2007, so it is not\\nmade in 2010.\\nAction 2:\\nFinish[REFUTES]\\nObservation 2:\\nEpisode finished\\nAct\\nClaim:\\nReign Over Me is an American film made in 2010.\\nAction 1:\\nSearch[Reign Over Me]\\nAction 2:\\nFinish[SUPPORTS]\\nObservation 2:\\nEpisode finished\\nCoT\\nClaim:\\nReign Over Me is an American film made in 2010.\\nThought:\\nLet’s think step by step.\\nFirst, is Reign Over Me an American film?\\nYes,\\nit is.\\nSecond, was it made in 2010?\\nYes, it was.\\nAnswer:\\nSUPPORTS\\nD.2\\nALFWORLD TRAJECTORIES\\nWe provide an example trajectory of ReAct, Act, and ReAct-IM on the same ALFWorld game,\\npick_clean_then_place_in_recep-Knife-None-CounterTop-10/\\ntrial_T20190909_110445_675754.\\nD.2.1\\nREACT TRAJECTORY\\nReAct is able to correctly ﬁnd the knife, clean it, and then place it on a countertop.\\n27\\nPublished as a conference paper at ICLR 2023\\nReAct ALFWorld trajectory\\nYou are in the middle of a room.\\nLooking quickly around you, you see a cabinet 6, a\\ncabinet 5, a cabinet 4, a cabinet 3, a cabinet 2, a cabinet 1, a coffeemachine 1, a\\ncountertop 3, a countertop 2, a countertop 1, a drawer 3, a drawer 2, a drawer 1, a\\nfridge 1, a garbagecan 1, a microwave 1, a shelf 3, a shelf 2, a shelf 1, a sinkbasin\\n1, a stoveburner 4, a stoveburner 3, a stoveburner 2, a stoveburner 1, and a toaster\\n1.\\nYour task is to:\\nput a clean knife in countertop.\\n> think:\\nTo solve the task, I need to find and take a knife, then clean it with\\nsinkbasin, then put it in countertop.\\nOK.\\n> think:\\nFirst I need to find a knife.\\nA knife is more likely to appear in cabinet\\n(1-6), drawer (1-3), countertop (1-3), fridge (1), garbagecan (1), shelf (1-3),\\nsinkbasin (1), stoveburner (1-4), toaster (1).\\nI can check one by one, starting with\\ncabinet 1.\\nOK.\\n> go to cabinet 1\\nOn the cabinet 1, you see a bowl 1.\\n> go to cabinet 2\\nThe cabinet 2 is closed.\\n> go to cabinet 3\\nOn the cabinet 3, you see a glassbottle 1.\\n> go to cabinet 4\\nOn the cabinet 4, you see a mug 1.\\n> go to cabinet 5\\nThe cabinet 5 is closed.\\n> go to cabinet 6\\nThe cabinet 6 is closed.\\n> go to drawer 1\\nThe drawer 1 is closed.\\n> go to drawer 2\\nThe drawer 2 is closed.\\n> go to drawer 3\\nThe drawer 3 is closed.\\n> go to countertop 1\\nOn the countertop 1, you see a lettuce 2, a mug 2, a peppershaker 1, and a spoon 2.\\n> go to countertop 2\\nOn the countertop 2, you see a cup 1, a dishsponge 1, a glassbottle 3, a knife 1, a\\nplate 2, a potato 3, and a statue 1.\\n> think:\\nNow I find a knife (1).\\nNext, I need to take it.\\nOK.\\n> take knife 1 from countertop 2\\nYou pick up the knife 1 from the countertop 2.\\n> think:\\nNow I take a knife (1).\\nNext, I need to go to sinkbasin (1) and clean it.\\nOK.\\n> go to sinkbasin 1\\nOn the sinkbasin 1, you see a fork 3, a lettuce 3, and a spatula 2.\\n> clean knife 1 with sinkbasin 1\\nYou clean the knife 1 using the sinkbasin 1.\\n> think:\\nNow I clean a knife (1).\\nNext, I need to put it in/on countertop 1.\\nOK.\\n> go to countertop 1\\nOn the countertop 1, you see a lettuce 2, a mug 2, a peppershaker 1, and a spoon 2.\\n> put knife 1 in/on countertop 1\\nYou put the knife 1 in/on the countertop 1.\\nD.2.2\\nACT TRAJECTORY\\nAct is able to correctly ﬁnd the knife, but tries to clean it using a sinkbasin before actually going\\nto the sinkbasin. From there on, the model is unable to recover, and is stuck repeating the same\\nsequence of commands. With ReAct, an existing thought would have concretely identiﬁed that the\\nknife had been taken, and that the next subgoal was to go to a sinkbasin to clean it.\\n28\\nPublished as a conference paper at ICLR 2023\\nAct ALFWorld trajectory\\nYou are in the middle of a room.\\nLooking quickly around you, you see a cabinet 6, a\\ncabinet 5, a cabinet 4, a cabinet 3, a cabinet 2, a cabinet 1, a coffeemachine 1, a\\ncountertop 3, a countertop 2, a countertop 1, a drawer 3, a drawer 2, a drawer 1, a\\nfridge 1, a garbagecan 1, a microwave 1, a shelf 3, a shelf 2, a shelf 1, a sinkbasin\\n1, a stoveburner 4, a stoveburner 3, a stoveburner 2, a stoveburner 1, and a toaster\\n1.\\nYour task is to:\\nput a clean knife in countertop.\\n> go to countertop 1\\nOn the countertop 1, you see a lettuce 2, a mug 2, a peppershaker 1, and a spoon 2.\\n> go to countertop 2\\nOn the countertop 2, you see a cup 1, a dishsponge 1, a glassbottle 3, a knife 1, a\\nplate 2, a potato 3, and a statue 1.\\n> take knife 1 from countertop 2\\nYou pick up the knife 1 from the countertop 2.\\n> go to countertop 1\\nOn the countertop 1, you see a lettuce 2, a mug 2, a peppershaker 1, and a spoon 2.\\n> clean knife 1 with sinkbasin 1\\nNothing happens.\\n> go to countertop 3\\nOn the countertop 3, you see a bread 3, a butterknife 2, a cellphone 1, a creditcard\\n1, a fork 2, a houseplant 1, a knife 2, a spatula 1, a statue 3, a tomato 3, a tomato\\n2, a tomato 1, and a vase 2.\\n> take knife 2 from countertop 3\\nNothing happens.\\n> go to countertop 2\\nOn the countertop 2, you see a cup 1, a dishsponge 1, a glassbottle 3, a plate 2, a\\npotato 3, and a statue 1.\\n> take knife 1 from countertop 2\\nNothing happens.\\n> go to countertop 1\\nOn the countertop 1, you see a lettuce 2, a mug 2, a peppershaker 1, and a spoon 2.\\n> clean knife 1 with sinkbasin 1\\nNothing happens.\\n> go to countertop 3\\nOn the countertop 3, you see a bread 3, a butterknife 2, a cellphone 1, a creditcard\\n1, a fork 2, a houseplant 1, a knife 2, a spatula 1, a statue 3, a tomato 3, a tomato\\n2, a tomato 1, and a vase 2.\\n> take knife 2 from countertop 3\\nNothing happens.\\n> go to countertop 2\\nOn the countertop 2, you see a cup 1, a dishsponge 1, a glassbottle 3, a plate 2, a\\npotato 3, and a statue 1.\\n> take knife 1 from countertop 2\\nNothing happens.\\n> go to countertop 1\\nOn the countertop 1, you see a lettuce 2, a mug 2, a peppershaker 1, and a spoon 2.\\n> clean knife 1 with sinkbasin 1\\nNothing happens.\\n> go to countertop 3\\nOn the countertop 3, you see a bread 3, a butterknife 2, a cellphone 1, a creditcard\\n1, a fork 2, a houseplant 1, a knife 2, a spatula 1, a statue 3, a tomato 3, a tomato\\n2, a tomato 1, and a vase 2.\\n> take knife 2 from countertop 3\\nNothing happens.\\n> go to countertop 2\\nOn the countertop 2, you see a cup 1, a dishsponge 1, a glassbottle 3, a plate 2, a\\npotato 3, and a statue 1.\\n> take knife 1 from countertop 2\\nNothing happens.\\n> go to countertop 1\\nOn the countertop 1, you see a lettuce 2, a mug 2, a peppershaker 1, and a spoon 2.\\n> clean knife 1 with sinkbasin 1\\nNothing happens.\\nD.2.3\\nREACT-IM TRAJECTORY\\nReAct-IM is able to correctly ﬁnd the knife, but is unable to clean it as well. The LLM then\\ngets stuck trying to place this knife on a countertop. One possible issue is the incorrect thought\\nthink:\\nI need to find a clean knife., which seems to trick the LLM in believing\\nthat the knife is already cleaned. In ReAct, this sequence of subgoals would be concretely captured\\nby each thought.\\n29\\nPublished as a conference paper at ICLR 2023\\nReAct-IM ALFWorld trajectory\\nYou are in the middle of a room.\\nLooking quickly around you, you see a cabinet 6, a\\ncabinet 5, a cabinet 4, a cabinet 3, a cabinet 2, a cabinet 1, a coffeemachine 1, a\\ncountertop 3, a countertop 2, a countertop 1, a drawer 3, a drawer 2, a drawer 1, a\\nfridge 1, a garbagecan 1, a microwave 1, a shelf 3, a shelf 2, a shelf 1, a sinkbasin\\n1, a stoveburner 4, a stoveburner 3, a stoveburner 2, a stoveburner 1, and a toaster\\n1.\\nYour task is to:\\nput a clean knife in countertop.\\n> think:\\nTo solve the task, I need to find and take a clean knife, then put it in\\ncountertop.\\nOK.\\n> think:\\nI need to find a clean knife.\\nOK.\\n> go to countertop 1\\nOn the countertop 1, you see a lettuce 2, a mug 2, a peppershaker 1, and a spoon 2.\\n> think:\\nI need to find a clean knife.\\nOK.\\n> go to countertop 2\\nOn the countertop 2, you see a cup 1, a dishsponge 1, a glassbottle 3, a knife 1, a\\nplate 2, a potato 3, and a statue 1.\\n> think:\\nI need to find a clean knife.\\nOK.\\n> take knife 1 from countertop 2\\nYou pick up the knife 1 from the countertop 2.\\n> think:\\nI need to put this knife (1) in/on countertop 1.\\nOK.\\n> go to countertop 1\\nOn the countertop 1, you see a lettuce 2, a mug 2, a peppershaker 1, and a spoon 2.\\n> think:\\nI need to put this knife (1) in/on countertop 1.\\nOK.\\n> put knife 1 in/on countertop 1\\nYou put the knife 1 in/on the countertop 1.\\n> think:\\nI need to put this knife (1) in/on countertop 1.\\nOK.\\n> put knife 1 in/on countertop 1\\nNothing happens.\\n> think:\\nI need to put this knife (1) in/on countertop 1.\\nOK.\\n> put knife 1 in/on countertop 1\\nNothing happens.\\n> think:\\nI need to put this knife (1) in/on countertop 1.\\nOK.\\n> put knife 1 in/on countertop 1\\nNothing happens.\\n> think:\\nI need to put this knife (1) in/on countertop 1.\\nOK.\\n> put knife 1 in/on countertop 1\\nNothing happens.\\n> think:\\nI need to put this knife (1) in/on countertop 1.\\nOK.\\n> put knife 1 in/on countertop 1\\nNothing happens.\\n> think:\\nI need to put this knife (1) in/on countertop 1.\\nOK.\\n30\\nPublished as a conference paper at ICLR 2023\\nD.3\\nWEBSHOP TRAJECTORIES\\nTable 10: Example trajectories for Webshop predicted by Act and ReAct. Compared to Act,\\nReAct uses reasoning to ﬁnd products that satisfy all target attributes.\\nInstruction: get me a sixteen pack of apple cinnamon freeze dried banana chips, and price lower than 50.00 dollars\\nAct\\nReAct\\nAction: search\\n�\\nsixteen pack apple cinnamon freeze dried banana\\nchips\\n�\\nObservation:\\n�\\nBack to Search\\n�\\nPage 1 (Total results: 50)\\n�\\nNext\\n�\\n�\\nB0061IVFZE\\n�\\nBrothers-ALL-Natural Fruit Crisps, Strawberry Banana, 0.42 -\\nOunce (Pack of 100)\\n$85.0\\n�\\nB096H2P6G2\\n�\\nMoon Fruit Freeze Dried Fruit Snacks. Fruit Snacks for Kids -\\n(Variety Pack)\\n$18.99\\n�\\nB092JLLYK6\\n�\\nNature’s Turn Freeze-Dried Fruit Snacks - Banana Crisps - Perfect\\nFor School Lunches or an On-The-Go Snack - No Sugar Added,\\nNon GMO, Gluten Free, Nothing Artiﬁcial (0.53oz) 6-Pack\\n$12.99\\nAction: click\\n�\\nB0061IVFZE\\n�\\nObservation:\\n�\\nBack to Search\\n�\\n�\\nPrev\\n�\\nﬂavor name [asian pear][banana][fuji apple & cinnamon][strawberry\\nbanana] Brothers-ALL-Natural Fruit Crisps, Strawberry Banana,\\n0.42 Ounce (Pack of 100)\\nPrice: $85.0\\nRating: N.A.\\n[Description]\\n[Features]\\n[Reviews]\\n[Buy Now]\\nAction: click[Buy Now]\\nAction: search\\n�\\nsixteen pack apple cinnamon freeze dried banana\\nchips\\n�\\nObservation:\\n�\\nBack to Search\\n�\\nPage 1 (Total results: 50)\\n�\\nNext\\n�\\n�\\nB0061IVFZE\\n�\\nBrothers-ALL-Natural Fruit Crisps, Strawberry Banana, 0.42 -\\nOunce (Pack of 100)\\n$85.0\\n�\\nB096H2P6G2\\n�\\nMoon Fruit Freeze Dried Fruit Snacks. Fruit Snacks for Kids -\\n(Variety Pack)\\n$18.99\\n�\\nB092JLLYK6\\n�\\nNature’s Turn Freeze-Dried Fruit Snacks - Banana Crisps - Perfect\\nFor School Lunches or an On-The-Go Snack - No Sugar Added,\\nNon GMO, Gluten Free, Nothing Artiﬁcial (0.53oz) 6-Pack\\n$12.99\\nAction: think[B0061IVFZE is strawberry banana, not apple cinnamon.\\nB096H2P6G2 is fruit snacks, not freeze dried banana chips.\\nB092JLLYK6 is banana crisps, not apple cinnamon. I can check\\nB092JLLYK6 ﬁrst.\\nObservation: OK.\\nAction: click\\n�\\nB092JLLYK6\\n�\\nObservation:\\n�\\nBack to Search\\n�\\n�\\nPrev\\n�\\nﬂavor name [apple][apple cinnamon][banana][cantaloupe][peach][pear]\\n[strawberry][strawberry banana][sampler variety pack][mega variety\\npack][orchard variety pack]\\nsize [0.53 ounce (pack of 6)][0.53 ounce (pack of 8)][0.53 ounce (pack\\nof 16)]\\nNature’s Turn Freeze-Dried Fruit Snacks - Banana Crisps - Perfect\\nFor School Lunches or an On-The-Go Snack - No Sugar Added, Non\\nGMO, Gluten Free, Nothing Artiﬁcial (0.53oz) 6-Pack\\nPrice: $12.99\\nRating: N.A.\\n[Description]\\n[Features]\\n[Reviews]\\n[Buy Now]\\nAction: think[For sixteen pack of apple cinnamon freeze dried banana\\nchips, the item has options ’apple cinnamon’ and ’0.53 ounce (pack of\\n16)’ and seems good to buy.]\\nObservation: OK.\\nAction: click[apple cinnamon]\\nObservation: You have clicked apple cinnamon.\\nAction: click[0.53 ounce (pack of 16)]\\nObservation: You have clicked 0.53 ounce (pack of 16).\\nAction: click[Buy Now]\\nScore: 0.125\\nScore: 1.0\\n31\\nPublished as a conference paper at ICLR 2023\\nE\\nMORE ANALYSIS\\nE.1\\nSUCCESS AND FAILURE MODES ANALYSIS\\nWe provide some examples corresponding to the success and error mode analysis given in Sec. 3.3.\\nSearch results and non-representative steps are omitted to reduce space.\\nSuccess: True positive\\nReAct\\nQuestion:\\nAuthor David Chanoff has collaborated with a U.S. Navy admiral who served as\\nthe ambassador to the United Kingdom under which President?\\nThought 1:\\nI need to search David Chanoff and find the U.S. Navy admiral he\\ncollaborated with.\\nAction 1:\\nSearch[David Chanoff]\\nObservation 1:\\nDavid Chanoff is a noted author...\\nAction 2:\\nSearch[William J. Crowe]\\nObservation 2:\\nWilliam J. Crowe is...\\nThought 3:\\nWilliam J. Crowe served as the ambassador to the United Kingdom under\\nPresident Bill Clinton.\\nSo the answer is Bill Clinton.\\nAction 3:\\nFinish[Bill Clinton]\\nObservation 3:\\nEpisode finished\\nCoT\\nQuestion:\\nWhat was the name of the team that represented an Arizona university in\\nthe conference that covers a broad expanse of the western United States,\\nincluding Arizona, California, and New Mexico?\\nThought:\\nLet’s think step by step.\\nThe name of the team that represented an Arizona\\nuniversity in the conference that covers a broad expanse of the western\\nUnited States, including Arizona, California, and New Mexico is Arizona\\nState Sun Devils.\\nAnswer:\\nArizona State Sun Devils\\nSuccess: False positive\\nReAct\\nQuestion:\\nDid the board game San Marco or About Time come out first?\\nThought 1:\\nI need to search San Marco and About Time, and find which came out first.\\nAction 1:\\nSearch[San Marco]\\nObservation 1:\\nSan Marco is one of the ...\\nThe was built in venice.\\nThought 2:\\nSan Marco is a sestiere of Venice.\\nI need to search About Time next.\\nAction 2:\\nSearch[About Time]\\nObservation 2:\\nCould not find [About Time].\\nSimilar:\\n[...].\\nThought 3:\\nAbout Time is a 2013 film.\\nSo San Marco came out first.\\nAction 3:\\nFinish[San Marco]\\nObservation 3:\\nEpisode finished\\nCoT\\nQuestion:\\nWas Vanderbilt University or Emory University founded first?\\nThought:\\nLet’s think step by step.\\nVanderbilt University was founded in 1873.\\nEmory\\nUniversity was founded in 1836.\\n1873 (Vanderbilt University) > 1836 (Emory\\nUniversity), so Vanderbilt University was founded first.\\nAnswer:\\nEmory University\\nFailure: Reasoning error\\nReAct\\nQuestion:\\nWhat was the middle name of the actress who was cast alongside Harvey\\nFierstein, Linda Hart, Dick Latessa, Clarke Thorell, Mary Bond Davis, Laura\\nBell Bundy, Matthew Morrison, Corey Reynolds, and Marissa Jaret Winokur in\\nHairspray?\\nThought 1:\\nI need to search Harvey Fierstein, Linda Hart, Dick Latessa, Clarke Thorell,\\nMary Bond Davis, Laura Bell Bundy, Matthew Morrison, Corey Reynolds, and\\nMarissa Jaret Winokur, find the actress that was cast alongside them in\\nHairspray, then find its middle name.\\nAction 1:\\nSearch[Harvey Fierstein]\\nObservation 1:\\nHarvey Forbes Fierstein ...\\nThought 2:\\nHarvey Fierstein is an actor, playwright, and screenwriter.\\nI need to\\nsearch Linda Hart next...\\nAction 2:\\nSearch[Linda Hart]...\\nCoT\\nQuestion:\\nWho is older Danny Green or James Worthy?\\nThought:\\nLet’s think step by step.\\nDanny Green was born in 1987.\\nJames Worthy was\\nborn in 1961.\\n1987 (Danny Green) > 1961 (James Worthy), so Danny Green is\\nolder.\\nAnswer:\\nDanny Green\\n32\\nPublished as a conference paper at ICLR 2023\\nFailure: Search error\\nReAct\\nQuestion:\\nWhat does the goddess associated with the goddess frigg consists of what\\ntales?\\nThought 1:\\nI need to search goddess frigg and find its associated goddess.\\nAction 1:\\nSearch[goddess frigg]\\nObservation 1:\\nCould not find goddess frigg.\\nSimilar:\\n[’Frigg’, ’Frigg and Freyja common\\norigin hypothesis’, ’Freyja (section Relation to Frigg and other goddesses\\nand figures)’, ’Eir (redirect from Eir (goddess))’, ’Baldr’].\\nThought 2:\\nI need to search Frigg instead...\\nFailure: Hallucination\\nCoT\\nQuestion:\\nWhat was the first year a scientific journal published by an organization\\nlocated in the Bronx was published?\\nThought:\\nLet’s think step by step.\\nThe first year a scientific journal published by\\nan organization located in the Bronx was published was 1916.\\nAnswer:\\n1916 (Label:\\n1909)\\nFailure: Label ambiguity\\nReAct\\nQuestion:\\nWhat nationality is the man who developed the dictator game?\\nThought 1:\\nI need to search dictator game, find the man who developed it, then find his\\nnationality.\\nAction 1:\\nSearch[dictator game]\\nObservation 1:\\nThe dictator game is a popular experimental instrument in social psychology\\nand economics...\\nAction 3:\\nSearch[Amos Tversky]\\nObservation 3:\\nAmos Nathan Tversky...\\nThought 4:\\nAmos Tversky is an Israeli cognitive and mathematical psychologist.\\nSo the\\nman who developed the dictator game is Israeli.\\nAction 4:\\nFinish[Israeli] (label:\\nIsrael-American)\\nCoT\\nQuestion:\\nKurt Fuller from Stockton, CA appeared in which American Detective Comedy\\nDrama television series created by Steve Franks?\\nThought:\\nLet’s think step by step.\\nKurt Fuller from Stockton, CA appeared in Psych.\\nPsych is an American Detective Comedy Drama television series created by\\nSteve Franks.\\nAnswer:\\nPsych (label:\\nPsych is an American detective comedy-drama)\\n33\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arxiv_by_arxiv_loader[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f5b5a4ba-f76b-467f-b96f-3206ab20b9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import WikipediaLoader\n",
    "\n",
    "wiki = WikipediaLoader(query=\"ドラゴンボール\", lang=\"ja\", load_max_docs=2).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "04b76005-7aea-4e76-9878-789070f29bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import WebBaseLoader\n",
    "\n",
    "web = WebBaseLoader(\"https://ja.wikipedia.org/wiki/%E3%83%89%E3%83%A9%E3%82%B4%E3%83%B3%E3%83%9C%E3%83%BC%E3%83%AB\").load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a06e3692-57a0-4402-809e-f896b53f82d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n\\n\\nドラゴンボール - Wikipedia\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nコンテンツにスキップ\\n\\n\\n\\n\\n\\n\\n\\nメインメニュー\\n\\n\\n\\n\\n\\nメインメニュー\\nサイドバーに移動\\n非表示\\n\\n\\n\\n\\t\\t案内\\n\\t\\n\\n\\nメインページコミュニティ・ポータル最近の出来事新しいページ最近の更新おまかせ表示練習用ページアップロード (ウィキメディア・コモンズ)\\n\\n\\n\\n\\n\\n\\t\\tヘルプ\\n\\t\\n\\n\\nヘルプ井戸端お知らせバグの報告寄付ウィキペディアに関するお問い合わせ\\n\\n\\n\\n\\n\\n言語\\n\\n言語間リンクはページの先頭にあるページ名の向かい側に設置されています。\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n検索\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n検索\\n\\n\\n\\n\\n\\n\\n\\n\\nアカウント作成ログイン\\n\\n\\n\\n\\n\\n\\n個人用ツール\\n\\n\\n\\n\\n\\n アカウント作成 ログイン\\n\\n\\n\\n\\n\\n\\t\\tログアウトした編集者のページ もっと詳しく\\n\\n\\n\\n投稿記録トーク\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n目次\\nサイドバーに移動\\n非表示\\n\\n\\n\\n\\nページ先頭\\n\\n\\n\\n\\n\\n1概要\\n\\n\\n\\n\\n\\n\\n\\n2あらすじ\\n\\n\\n\\nあらすじサブセクションを切り替えます\\n\\n\\n\\n\\n\\n2.1孫悟空少年編\\n\\n\\n\\n\\n\\n\\n\\n2.2ピッコロ大魔王編\\n\\n\\n\\n\\n\\n\\n\\n2.3サイヤ人編\\n\\n\\n\\n\\n\\n\\n\\n2.4フリーザ編\\n\\n\\n\\n\\n\\n\\n\\n2.5人造人間・セル編\\n\\n\\n\\n\\n\\n\\n\\n2.6魔人ブウ編\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n3登場人物\\n\\n\\n\\n\\n\\n\\n\\n4歴史\\n\\n\\n\\n歴史サブセクションを切り替えます\\n\\n\\n\\n\\n\\n4.1連載開始までの経緯\\n\\n\\n\\n\\n\\n\\n\\n4.2連載開始から連載終了までの経緯\\n\\n\\n\\n\\n\\n\\n\\n4.3連載終了後の展開\\n\\n\\n\\n\\n\\n\\n\\n4.4リバイバルブーム到来\\n\\n\\n\\n\\n\\n\\n\\n4.5新展開へ\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n5設定\\n\\n\\n\\n\\n\\n\\n\\n6用語\\n\\n\\n\\n\\n\\n\\n\\n7制作背景\\n\\n\\n\\n\\n\\n\\n\\n8歴代担当編集者\\n\\n\\n\\n\\n\\n\\n\\n9社会的評価\\n\\n\\n\\n社会的評価サブセクションを切り替えます\\n\\n\\n\\n\\n\\n9.1日本\\n\\n\\n\\n\\n\\n\\n\\n9.2売上\\n\\n\\n\\n\\n\\n9.2.1漫画\\n\\n\\n\\n\\n\\n\\n\\n9.2.2ゲーム\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n9.3アンケートランキング\\n\\n\\n\\n\\n\\n\\n\\n9.4受賞歴\\n\\n\\n\\n\\n\\n\\n\\n9.5その他\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n10日本国外での展開\\n\\n\\n\\n日本国外での展開サブセクションを切り替えます\\n\\n\\n\\n\\n\\n10.1北米\\n\\n\\n\\n\\n\\n\\n\\n10.2中南米\\n\\n\\n\\n\\n\\n\\n\\n10.3ヨーロッパ\\n\\n\\n\\n\\n\\n\\n\\n10.4中東・アフリカ\\n\\n\\n\\n\\n\\n\\n\\n10.5アジア\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n11書誌情報\\n\\n\\n\\n書誌情報サブセクションを切り替えます\\n\\n\\n\\n\\n\\n11.1単行本\\n\\n\\n\\n\\n\\n\\n\\n11.2完全版\\n\\n\\n\\n\\n\\n\\n\\n11.3外国語版\\n\\n\\n\\n\\n\\n\\n\\n11.4フルカラーコミックス\\n\\n\\n\\n\\n\\n\\n\\n11.5コミックスのコーナー\\n\\n\\n\\n\\n\\n\\n\\n11.6ドラゴンボール大全集\\n\\n\\n\\n\\n\\n\\n\\n11.7ドラゴンボール超全集\\n\\n\\n\\n\\n\\n\\n\\n11.8DRAGON BALL総集編\\n\\n\\n\\n\\n\\n\\n\\n11.9その他の関連書籍\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n12関連漫画\\n\\n\\n\\n関連漫画サブセクションを切り替えます\\n\\n\\n\\n\\n\\n12.1ドラゴンボールSD\\n\\n\\n\\n\\n\\n\\n\\n12.2ドラゴンボール超\\n\\n\\n\\n\\n\\n\\n\\n12.3番外編\\n\\n\\n\\n\\n\\n\\n\\n12.4スピンオフ\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n13アニメ\\n\\n\\n\\nアニメサブセクションを切り替えます\\n\\n\\n\\n\\n\\n13.1アニメシリーズ一覧\\n\\n\\n\\n\\n\\n\\n\\n13.2特別編\\n\\n\\n\\n\\n\\n\\n\\n13.3OVA\\n\\n\\n\\n\\n\\n\\n\\n13.4アニメ映画\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n14メディア\\n\\n\\n\\nメディアサブセクションを切り替えます\\n\\n\\n\\n\\n\\n14.1テレビ番組\\n\\n\\n\\n\\n\\n\\n\\n14.2CM\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n15実写映画\\n\\n\\n\\n\\n\\n\\n\\n16ゲームシリーズ一覧\\n\\n\\n\\nゲームシリーズ一覧サブセクションを切り替えます\\n\\n\\n\\n\\n\\n16.1家庭用ゲーム機向けソフト\\n\\n\\n\\n\\n\\n\\n\\n16.2携帯ゲーム機向けソフト\\n\\n\\n\\n\\n\\n\\n\\n16.3日本国外向けゲームソフト\\n\\n\\n\\n\\n\\n\\n\\n16.4アーケードゲーム\\n\\n\\n\\n\\n\\n\\n\\n16.5スマートフォン向けゲーム\\n\\n\\n\\n\\n\\n\\n\\n16.6電子ゲーム\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n17イベント・企画\\n\\n\\n\\nイベント・企画サブセクションを切り替えます\\n\\n\\n\\n\\n\\n17.1日本国外でのイベント\\n\\n\\n\\n\\n\\n\\n\\n17.2展覧会\\n\\n\\n\\n\\n\\n\\n\\n17.3カフェ・レストラン\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n18関連商品\\n\\n\\n\\n関連商品サブセクションを切り替えます\\n\\n\\n\\n\\n\\n18.1玩具\\n\\n\\n\\n\\n\\n\\n\\n18.2タイアップ\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n19脚注\\n\\n\\n\\n脚注サブセクションを切り替えます\\n\\n\\n\\n\\n\\n19.1注釈\\n\\n\\n\\n\\n\\n\\n\\n19.2出典\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n20外部リンク\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n目次の表示・非表示を切り替え\\n\\n\\n\\n\\n\\n目次の表示・非表示を切り替え\\n\\n\\n\\n\\n\\n\\n\\nドラゴンボール\\n\\n\\n\\n102の言語版\\n\\n\\n\\n\\nAfrikaansAlemannischአማርኛAragonésالعربيةالدارجةمصرىAsturianuAzərbaycancaBoarischБеларускаяБългарскиবাংলাBrezhonegBosanskiCatalàCebuanoکوردیČeštinaCymraegDanskDeutschދިވެހިބަސްΕλληνικάEnglishEsperantoEspañolEestiEuskaraفارسیSuomiFrançaisArpetanGalegoעבריתहिन्दीHrvatskiKreyòl ayisyenMagyarՀայերենInterlinguaBahasa IndonesiaÍslenskaItalianoJawaಕನ್ನಡ한국어KurdîLatinaLadinoLëtzebuergeschLadinLietuviųLatviešuМакедонскиമലയാളംМонголमराठीBahasa Melayuမြန်မာဘာသာNāhuatlNapulitanoPlattdüütschNederlandsNorsk nynorskNorsk bokmålOccitanOromooਪੰਜਾਬੀPapiamentuPicardPolskiPortuguêsRomânăРусскийСаха тылаSarduSrpskohrvatski / српскохрватскиSimple EnglishSlovenčinaSlovenščinaSoomaaligaShqipСрпски / srpskiSundaSvenskaతెలుగుไทยTagalogTürkçeУкраїнськаاردوVènetoTiếng ViệtWinaray吴语ייִדישYorùbá中文文言Bân-lâm-gú粵語\\n\\nリンクを編集\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nページノート\\n\\n\\n\\n\\n\\n日本語\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n閲覧編集履歴表示\\n\\n\\n\\n\\n\\n\\n\\nツール\\n\\n\\n\\n\\n\\nツール\\nサイドバーに移動\\n非表示\\n\\n\\n\\n\\t\\t操作\\n\\t\\n\\n\\n閲覧編集履歴表示\\n\\n\\n\\n\\n\\n\\t\\t全般\\n\\t\\n\\n\\nリンク元関連ページの更新状況ファイルをアップロード特別ページこの版への固定リンクページ情報このページを引用短縮URLを取得するウィキデータ項目\\n\\n\\n\\n\\n\\n\\t\\t印刷/書き出し\\n\\t\\n\\n\\nブックの新規作成PDF 形式でダウンロード印刷用バージョン\\n\\n\\n\\n\\n\\n\\t\\t他のプロジェクト\\n\\t\\n\\n\\nコモンズ\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n出典: フリー百科事典『ウィキペディア（Wikipedia）』\\n\\n\\n\\n\\n\\n\\n\\nこの項目では、鳥山明の漫画について説明しています。その他の用法については「ドラゴンボール (曖昧さ回避)」をご覧ください。\\n\\n\\n\\n\\nドラゴンボールDRAGON BALL\\n旧コミックス版ロゴマーク\\n\\nジャンル\\n\\n少年漫画・冒険・バトルSF漫画・ファンタジー\\n\\n\\n漫画\\n\\n\\n作者\\n\\n鳥山明\\n\\n\\n出版社\\n\\n集英社\\n\\n\\n\\n\\n\\nその他の出版社\\n\\n\\n      Viz Media\\n    Glénat\\n  Planeta DeAgostini\\n   Carlsen\\n Sangatsu Manga\\n Schibsted Forlagene\\n Outland（2016年 - ）\\n Japonica Polonica Fantastica\\n Gollancz Manga（2005年 - 2007年）\\n Semic Interprint\\n Star Comics\\n Grupo Editorial Vid\\n Panini Comics México（2015年 - ）\\n Panini Comics Colombia\\n Panini Comics Venezuela\\n Editorial Ivrea\\n Conrad Editora（2000年 - 2011年）\\n Panini Comics Brazil（2012年 - ）\\n 中国少年児童出版社\\n 文化伝信\\n 東立出版社\\n ソウル文化社\\n NED Comics\\n Comics House（1995年 - 2016年）\\n Comic Paradise（2017年 - ）\\n Elex Media Komputindo\\n Kim Dong Publishing House\\n   Chuang Yi（ - 2014年）\\n Eksmo / Comix-ART\\n\\n\\n\\n\\n掲載誌\\n\\n週刊少年ジャンプ\\n\\n\\nレーベル\\n\\nジャンプ・コミックス\\n\\n\\n発表号\\n\\n1984年51号 - 1995年25号\\n\\n\\n発表期間\\n\\n1984年11月20日 - 1995年6月5日\\n\\n\\n巻数\\n\\n全42巻（JC）全34巻（完全版）\\n\\n\\n話数\\n\\n全519話\\n\\n\\nアニメ\\n\\n\\n\\nシリーズ作品\\nドラゴンボール\\nドラゴンボールZ\\nドラゴンボールGT\\nドラゴンボール改\\nドラゴンボール超\\nドラゴンボールDAIMA\\n\\n\\n映画\\n\\n\\n\\n下記参照\\n\\n\\nゲーム\\n\\n\\n\\n下記参照\\n\\n\\nテンプレート - ノート\\n\\n\\nプロジェクト\\n\\n漫画・アニメ・コンピュータゲーム\\n\\n\\nポータル\\n\\n漫画・アニメ・コンピュータゲーム\\n\\n『ドラゴンボール』（DRAGON BALL）は、鳥山明による日本の漫画作品。『週刊少年ジャンプ』（集英社）にて1984年51号から1995年25号まで連載された。略称は「DB」[1]。\\n\\n\\n概要[編集]\\n世界中に散らばった七つの球をすべて集めると、どんな願いも一つだけ叶えられるという秘宝・ドラゴンボールと主人公・孫悟空（そん・ごくう）を中心に展開する「冒険」「夢」「バトル」「友情」などを描いた長編漫画作品。\\n1986年から1996年までフジテレビ系列で『ドラゴンボール』、『ドラゴンボールZ』が放送され、11年間のシリーズ放送期間中、平均視聴率20%以上を記録した[2]。また全世界80か国以上で放送されるなど[3]、世界中で絶大な人気を誇る日本の漫画・アニメを代表する作品である[4][5]。\\n連載終了後もテレビアニメ・映画・ゲームなどが展開しており、映画『ドラゴンボール超 ブロリー』が全世界興行収入135億円を記録し[6]、各国で大ヒットした[7]。\\n1991年に『週刊少年ジャンプ21・22合併号』で行われた読者アンケートで同誌のアンケート史上最大得票となる1000通中815票を獲得し[8]、1995年3・4合併号で同誌の発行部数は653万部を記録。本作の連載終了後は同誌の部数が急速に減少していくなど[9]、連載作品の中でも特に影響は大きかった。\\n単行本の発行部数は完全版（2000万部）を含み国内で1億6000万部以上[2][10]、全世界累計で2億6000万部を記録[11]。\\nゲームソフトは現在までにミリオンセラーを10本以上輩出し、シリーズ累計販売本数は全世界5000万本に達する[12]。\\n『ドラゴンボールZ ドッカンバトル』は2023年2月時点で、5000億円の収益を記録し、バンダイナムコエンターテインメントの収益を牽引する存在となっている[13]。『スーパードラゴンボールヒーローズ』はカード累計出荷枚数10億枚、登録ユーザー数は400万人を突破し[14]、デジタルキッズカードゲーム市場でNo.1の人気タイトルである[15]。\\n2019年時点で、漫画・アニメシリーズ・ゲーム作品などを含めた総売上は230億ドル（約2兆5000億円）に達する[16]。\\n\\nあらすじ[編集]\\n「ドラゴンボールの世界における年表」も参照\\n孫悟空少年編[編集]\\n地球の人里離れた山奥に住む尻尾の生えた少年・孫悟空はある日、西の都からやって来た少女・ブルマと出会う。そこで7つ集めると神龍（シェンロン）が現れ、どんな願いでも一つだけ叶えてくれるというドラゴンボールの存在を、さらに育ての親である孫悟飯の形見として大切に持っていた球がその1つ「四星球（スーシンチュウ）」であることを知り、ブルマと共に残りのドラゴンボールを探す旅に出る。人さらいのウーロンや盗賊のヤムチャらを巻き込んだドラゴンボール探しの末、世界征服を企むピラフ一味にボールを奪われ神龍を呼び出されるが、ウーロンがとっさに言い放った下らない願いを叶えてもらうことで一味の野望を阻止する。\\nその後、悟空は旅の途中に知り合った武術の達人・亀仙人の下で、後に親友となるクリリンと共に8か月間にわたる修行を積み、その成果を確かめるために世界一の武術の達人を決める天下一武道会に出場し、変装して出場していた亀仙人に敗れるも準優勝を果たす。悟空は再び修行の旅へと出発し、ドラゴンボールの悪用を企むレッドリボン軍との闘いや、仙猫カリンの修行、孫悟飯との再会などを経てさらに強さを増していく。さらに3年後の天下一武道会では、亀仙流のライバルである鶴仙流の天津飯（テンシンハン）と闘うが、あと一歩のところで敗れ、前回と同じく準優勝に終わる。\\n\\nピッコロ大魔王編[編集]\\n天下一武道会終了後、ピラフ一味によって復活したピッコロ大魔王によって、クリリンや亀仙人など悟空の仲間たちや多くの武道家たちが殺される。悟空は仇を討つため、道中に出会ったヤジロベーやカリンの協力を得て命を賭して潜在する力を引き出し、ピッコロ大魔王に闘いを挑み勝利する。闘いの後、悟空はピッコロ大魔王に殺された神龍や仲間たちの復活のため天界へ向かい、ドラゴンボールの創造者である神様に会う。そこで神龍復活の条件として、神の下、天界で修行することとなった。\\nその約3年後、少年から青年へと成長した悟空は、天下一武道会の会場で仲間たちと再会。試合では、少年時代に出会った際に「嫁にもらう」と約束していた牛魔王の娘・チチと再会しその場で結婚。そして武道会に出場していたピッコロ大魔王の生まれ変わりであるマジュニアと決勝戦で激突、悟空はこれに勝利し初の天下一武道会優勝を飾る。\\n\\nサイヤ人編[編集]\\nピッコロ（マジュニア）との闘いから約5年後、息子の孫悟飯を儲けて平和な日々を過ごしていた悟空のもとに、実兄・ラディッツが宇宙より来襲し、自分が惑星ベジータの戦闘民族・サイヤ人であることを知らされる。さらわれた孫悟飯を助けるため悟空は宿敵ピッコロと手を組み、自らの命と引き換えにラディッツを倒すが、約1年後にはさらに強力なサイヤ人たちがドラゴンボールを求めて地球に来襲することを知る。\\n悟空はドラゴンボールによって生き返るまでの間、あの世の界王の下で修業し、仲間と共に地球に強襲したサイヤ人の戦士・ナッパとベジータを迎え撃つ。悟空は修行により増した力でナッパを一蹴し、ベジータと決闘。仲間の協力もあり、何とか辛勝し撤退させるが、多くの仲間を失うとともに、ピッコロの戦死により彼と一心同体であった神も死亡し、地球のドラゴンボールも消滅する。\\n\\nフリーザ編[編集]\\n地球の神と殺された仲間たちを甦らせるため、重傷で入院中の悟空に代わり、悟飯、クリリン、ブルマの3人が神とピッコロの故郷であるナメック星へ向かう。だが、そこには地球で闘ったベジータや、界王すら畏怖する宇宙の帝王・フリーザとその一味が不老不死を求めて来襲し、ナメック星人を虐殺しながらドラゴンボールを略奪していた。悟飯たちはベジータ、フリーザ一味とのドラゴンボールをめぐる三つ巴の攻防の末、後から到着した悟空とナメック星人たちの協力を得てナメック星の神龍・ポルンガを呼び出し、ピッコロと地球のドラゴンボールを復活させる。\\n出し抜かれて願いが叶えられなかったフリーザは激怒し、一行は対決を強いられる。フリーザの持つ圧倒的な力の前にはベジータやピッコロ、悟空すら歯が立たず仲間たちが次々と命を落としていった。怒りを爆発させた悟空は伝説の戦士・超（スーパー）サイヤ人へと覚醒。フルパワーを解放したフリーザに勝利する。ポルンガによって地球に帰還した悟飯たちは復活したドラゴンボールによりサイヤ人やフリーザ一味に殺された人々を蘇生させた。一方の悟空も爆発するナメック星を辛くも脱出、ヤードラット星に漂着し一命を取り留めた。\\n\\n人造人間・セル編[編集]\\nナメック星での闘いから約1年後、密かに生き延びていたフリーザとその一味が地球を襲撃するが、謎の超サイヤ人によって撃退される。トランクスと名乗るその青年は、自分は未来からやってきたブルマとベジータの息子であることを悟空にだけ明かすと同時に、悟空は心臓病によって命を落とすこと、3年後に現れる2体の人造人間が絶望の未来をもたらすことを告げる。その後本当に心臓病によって危篤状態になるも、トランクスから渡された特効薬によって生還、来るべき日に備えて3年間各々に修行してその日を迎える悟空たちであったが、事態はトランクスが知っている歴史とは大きく違うものとなり、彼さえ知らなかった人造人間たちまで現れ、さらに究極の人造人間・セルが未来から出現。悟空らの想定を遥かに超えた戦士が続々と現れた。\\n人造人間17号と人造人間18号を吸収することで完全体となったセルは地球の命運を賭けた武道会「セルゲーム」の開催を全世界に宣言する。悟空らは天界にある1日で1年の修行が行えるも過酷な環境に晒される「精神と時の部屋」で修行し、強さを増してセルゲームに臨むが、悟空はセルとの激闘の末降参する。その意思を継いだ悟飯が怒りをきっかけに超サイヤ人2へと覚醒、勝つことを断念したセルは地球ごと爆破させる自爆を図るが、悟空の命と引き換えの咄嗟の機転により地球の爆破は免れる。しかしセルは生きており悟飯と再び闘うことになる。セルもパワーアップしているため闘いは苦戦を強いられたが悟空の幻影と共にかめはめ波を放ちセルを撃破。セルゲームを制した悟飯たちは、ドラゴンボールによりセルに殺された人々を蘇生させるが、悟空は自分が悪人を引き寄せているという理由で生き返りを拒否し、あの世に残ることを選ぶ。\\n\\n魔人ブウ編[編集]\\nセルゲームより約7年後、高校生に成長した悟飯が天下一武道会に出場することを知った悟空は、自らも出場するために占いババの力によって1日だけこの世に戻る。天下一武道会の最中、悟空たちは界王よりもさらに高位の存在である界王神から恐ろしい力を持つ魔人ブウの封印が解かれようとしていることを知らされる。復活した魔人ブウにより悟飯やベジータが倒され、悟空はあの世に帰ったため、地球の命運は悟空の次男・孫悟天と少年トランクスの幼い2人に託される。\\n一方、魔人ブウは様々な人間との出会いからより邪悪で強力な魔人（魔人ブウ〈悪〉）へと変貌。悟天とトランクスが「フュージョン（融合）」して誕生した戦士・ゴテンクスや、潜在能力を解放し、パワーアップを遂げて帰ってきた悟飯らが応戦するが、戦士たちを次々と吸収し姿を変えていく魔人ブウに苦戦を強いられる。危機に陥った悟飯らを救うため現世に舞い戻った悟空とベジータは、界王神界で真の姿となった魔人ブウとの最終決戦に臨む。ドラゴンボールの協力もあり、地球・ナメック星・あの世の人々のエネルギーによって作り上げられた超特大の元気玉によって魔人ブウは完全に消滅する。\\nそれから10年後、悟空は孫のパンと共に天下一武道会に久しぶりに出場し、魔人ブウの生まれ変わりである少年・ウーブと出会う。悟空はウーブと共に見果てぬ強さを追い求めて修行に旅立ち、物語は幕を閉じる。\\n\\n登場人物[編集]\\n詳細は「ドラゴンボールの登場人物」を参照\\n以下は、主人公と主要キャラクターである。\\n\\n孫悟空\\n声 - 野沢雅子\\n本作の主人公。純粋で心優しい性格の地球育ちのサイヤ人。サイヤ人としての名は「カカロット」。様々な師の下での修行と強敵やライバルとの死闘を経て、最強の戦士へと成長していく。\\n孫悟飯\\n声 - 野沢雅子\\n孫悟空とチチの息子で、悟天の兄。幼少時にピッコロの弟子となり、悟空たちと共に数々の強敵と闘う。後にビーデルと結婚し、2人の間に娘のパンが生まれる。\\n孫悟天\\n声 - 野沢雅子\\n孫悟空とチチの息子で、悟飯の弟。トランクスとは幼馴染みであり、魔人ブウ編で共に魔人ブウと戦う。\\nベジータ\\n声 - 堀川亮（現：堀川りょう）\\n惑星ベジータの王子。初期の頃は残忍で冷酷な性格だったが、悟空やブルマたちに感化され、次第に残忍さは薄れていく。後にブルマと結ばれトランクスとブラの父親となる。\\nブルマ\\n声 - 鶴ひろみ→久川綾\\nカプセルコーポレーションの令嬢。天才的な頭脳の持ち主であり、様々なメカの発明・改造によって仲間たちをサポートする。後にベジータと結ばれ、トランクスとブラを授かる。\\nトランクス\\n声 - 草尾毅\\nブルマとベジータの息子で、サイヤ人と地球人の混血。人造人間編では未来から来た青年として戦い、魔人ブウ編では、孫悟天とフュージョンをして魔人ブウと闘う。\\nピッコロ（マジュニア）\\n声 - 古川登志夫\\nピッコロ大魔王の息子かつ分身にして生まれ変わり。当初は悟空たちと敵対するが、後に悟空たちと共に地球の平和を守るため数々の強敵と闘う。\\nクリリン\\n声 - 田中真弓\\n悟空の兄弟弟子であり一番の親友。後に人造人間18号と結婚し、娘のマーロンが生まれる。\\nミスター・サタン\\n声 - 郷里大輔(Z、GT)→石塚運昇（改、超）→江原正士\\n悟空たちが表舞台を去った後の格闘技世界チャンピオン。調子のいい性格だが強い正義感の持ち主で、セルと魔人ブウの戦いではその勝利に舞台裏で大きく貢献し、魔人ブウとの戦いの後は悟空たちの仲間になり親睦を深める。\\nフリーザ\\n声 - 中尾隆聖\\n宇宙の帝王。ドラゴンボールの願いで不老不死を叶えるためナメック星に降り立ち、そこで悟空たちと激戦を繰り広げる。\\nセル\\n声 - 若本規夫\\nドクター・ゲロが開発したコンピュータにより、悟空たちの細胞を組み合わせて誕生した。後に完全体となり、セルゲームで悟空や悟飯と激闘を繰り広げる。\\n魔人ブウ\\n声 - 塩屋浩三\\n魔導師ビビディによって作られた、遥か太古に全宇宙を破壊の恐怖に落とし入れた魔人。地球に封印されていたがバビディによって解放され、悟空たちと激戦を繰り広げる。\\n歴史[編集]\\n連載開始までの経緯[編集]\\n『ドラゴンボール』の主な年表198411月 『週刊少年ジャンプ』51号より連載開始19859月 コミックス第1巻発売19862月 アニメ『ドラゴンボール』放送開始11月 ファミリーコンピュータゲーム『ドラゴンボール 神龍の謎』発売12月 初の劇場版アニメ『ドラゴンボール 神龍の伝説』公開1987アニメ『ドラゴンボール』第47話で最高視聴率29.5%を記録198811月 カードダス ドラゴンボールシリーズ発売開始19894月 アニメ『ドラゴンボールZ』放送開始199010月 TVスペシャル『たったひとりの最終決戦』放送1991『週刊少年ジャンプ』の読者アンケート史上最大得票となる815票を獲得1992劇場版『ドラゴンボールZ 極限バトル!!三大超サイヤ人』が400万人の動員を記録19932月 TVスペシャル『絶望への反抗!!』放送1994アニメ『ドラゴンボールZ』第218話で最高視聴率27.5%を記録19955月 『週刊少年ジャンプ』25号に最終回「バイバイドラゴンワールド」掲載8月 コミックス最終巻となる42巻発売19962月 アニメ『ドラゴンボールGT』放送開始1997199819999月 米国カートゥーン ネットワークの局の視聴率記録を樹立20002001200212月 完全版コミックス発売20032月 PlayStation 2ソフト『ドラゴンボールZ』が300万本以上の出荷を記録20047月 アニメ『ドラゴンボール』のDVD-BOX「DRAGON BOX」が発売20053月 『データカードダス ドラゴンボールZ』稼働開始20069月 『超こち亀』に秋本治との共作『こちらナメック星ドラゴン公園前派出所』を掲載2007『週刊少年ジャンプ』4・5合併号で尾田栄一郎との共作『CROSS EPOCH』を掲載200820094月 アニメ『ドラゴンボール改』放送開始201011月 アーケードゲーム『ドラゴンボールヒーローズ』稼働開始12月 オオイシナホによるスピンオフ漫画『ドラゴンボールSD』連載開始2011201220133月 17年ぶりとなる劇場版『ドラゴンボールZ 神と神』が公開20144月 アニメ『ドラゴンボール改』第二期放送開始20154月 劇場版『ドラゴンボールZ 復活の「F」』が公開7月 アニメ『ドラゴンボール超』放送開始8月 とよたろうによる漫画『ドラゴンボール超』が連載開始20166月 集英社に「ドラゴンボール室」新設11月 アーケードゲーム『スーパードラゴンボールヒーローズ』稼働開始20175月 バンナムの売上で『機動戦士ガンダム』を抜き1位となる20184月 東映に「ドラゴンボール部署」新設12月 劇場版『ドラゴンボール超 ブロリー』公開20192020202120226月 劇場版『ドラゴンボール超 スーパーヒーロー』公開20232024秋 アニメ『ドラゴンボールDAIMA』放送開始（予定）\\n本作は、連載が始まるまでにさまざまな紆余曲折があった。鳥山と担当編集者の鳥嶋和彦は、当時連載中であった『Dr.スランプ』のアイデアが尽きかけていたため連載を終了させたがっていたが、そう簡単に人気作品を終わらせるわけにもいかず、連載終了3か月後に新連載を始めるなら辞めてもいいという条件を受け、『Dr.スランプ』の連載と平行して描いた読み切り作品『騎竜少年（ドラゴンボーイ）』、『トンプー大冒険』（両作品とも『鳥山明○作劇場VOL.2』に収録）を基に[17][18]、『ドラゴンボール』のネタを固めていった[17]。\\nプロット段階においては『西遊記』の要素も取り入れると共に[19]、「ボールを集める」というアイデアは『南総里見八犬伝』から取られたが[20]、「『八犬伝』が8つの球なので、同じじゃ悔しいから」とボールの数は7個にされ[21]、タイトルは映画『燃えよドラゴン』から取られた[22]。こうして本作の初期の構想がまとまった。\\n当初は鳥山版『西遊記』を目指しストーリーを進めようとしていたが、担当の鳥嶋の反応は「西遊記そのものではないか」と冷たかった[19]。そのため、第二稿（SF要素が取り入れられ、服装が現代風）、第三稿（現行の『ドラゴンボール』にかなり近い設定）と変更が加えられ、最終的には『西遊記』の要素は主人公の名前やキャラクターデザインのほか、初期のいくつかのエピソードやアイテムなどにその名残を留めるのみとなった[17]。\\n\\n連載開始から連載終了までの経緯[編集]\\n5週連続カラーという大々的な扱いで連載開始されるも当初はあまり人気がなく[23]、開始当初は前作『Dr.スランプ』の影響による期待票や編集部のバックアップもあり良かったものの、徐々に人気は下降し、アンケート結果における順位が15位になることもあった[17][24]。担当の鳥嶋に「主人公が地味だ。だから人気がないんだ」と指摘された鳥山は、以後「強さを追い求める主人公」というテーマを作品に持たせることになる[23]。その発想から一旦サブキャラクターを下げて修行編を作り、武術の師匠としての亀仙人、最初のライバルとしてクリリンを登場させ、悟空と違ってズル賢い性格のクリリンを描くことで、悟空の愚直なキャラクターが際立つようになる[25]。修行の成果を見せるために天下一武道会の本編が始まり、主人公である孫悟空のキャラクターも確立され、人気も急激に上昇する。同じ頃にフジテレビから集英社に話があり、アニメ化に繋がった[18]。\\n1990年発売の『週刊少年ジャンプ45号』にて本作と『こちら葛飾区亀有公園前派出所』が共に5000万部突破(ドラゴンボール50977000部、こちら葛飾区亀有公園前派出所50122000部)した事が発表され、本誌に各方面から祝電がよせられた[26]。\\nフリーザ編が佳境に入る頃にはその人気はピークに達し、1991年に行われた『週刊少年ジャンプ』の1000票アンケートで815票を獲得。ジャンプにおける地位を不動のものとする[27][注釈 1]。\\n天下一武道会編で読者アンケート1位を獲得し、その後、連載終了まで不動の1位となる。その人気は漫画の枠を越え、アニメ『ドラゴンボール』第47話で最高視聴率29.5%を記録。ファミコンソフト『ドラゴンボール 神龍の謎』は120万本の出荷を記録した[29]。\\n担当を近藤から武田に変更。武田にはそれまでの担当と異なり鳥山のネームに口を出さずにそのまま掲載させるよう指示を出す。このため、ブウ編開始後は人気が急落し、本誌においてトップの座を『SLAM DUNK』に譲り渡すこととなった[30]。\\n1995年の連載終了については、鳥山の強い要望によるものであったとはいえ、最終的には関係各社のトップ級会議などの調整や各社の上層部による経営判断を必要とし、関連企業の株価・業績への影響を最小限に抑えるべく様々な配慮や下準備を行った上でようやく実現できたという、前代未聞の事態となった[31]。後に鳥山はブウ編について「漫画を描いている自分でさえイヤになるほど激しくくどい闘いの連続。血圧高めで薄味好きのオジサンになってしまった今では、もうこんな闘いは描けない。というか、これ以降、闘いの漫画を描く気がなくなってしまった」と告白している[32]。前述のように、ブウ編開始前において鳥山は鳥嶋と連載終了の約束を取り付けていたが、当時の編集長であった堀江信彦はその事実を途中まで知らされていなかったという[33]。\\nこうした背景もあって、本作は延べ10年半に及ぶ長期連載となった。最終話は巻頭カラーであり、これはジャンプにおいては『リングにかけろ』に続いて2度目であった[34]。最終話もまだ悟空の冒険が続くようなシーンで終了している。\\nかつての週刊少年ジャンプ編集長であった西村繁男によると、それまで守っていた600万部の発行部数が、ドラゴンボール終了直後に割れこみ、あっという間に部数が急落したことである[35]。\\n\\n連載終了後の展開[編集]\\n連載終了後の『週刊少年ジャンプ』1995年26号から35号にかけて、10週連続特別企画として原作や各メディアでの展開を振り返る「HISTORY OF DRAGON BALL」が掲載された。\\n鳥山は連載終了直後のメッセージで「やりたいっすよ、次（の新しい作品）を。そのために（ドラゴンボールの連載を）やめたいと思ったってのもあるし。不器用だから他をやりながらってのがダメなんです。この作品をやって純粋にストーリー漫画の面白さってのもわかりましたし、自分では動きのある絵もやっと描けるようになってきたなあと思い始めた[36]」とコメントした。\\n連載が終了した翌年の1996年2月、アニメ『ドラゴンボールGT』の放送が開始された。完全オリジナルストーリーで描かれたこの作品に、鳥山はキャラクターデザインや設定画を書き下ろす形で参加した。全64話と番外編1話が放送され、第2話で視聴率19.7%を記録する人気アニメとなった[37][38]。この当時を鳥山は2013年のインタビューで「その頃、連載はもう終わっていたので、僕の頭は次の仕事に向いていました。だから…正直に言うと、そこでまた『DB(GT)』のデザインというのは、ちょっとだけ抵抗がありました（笑）。続けていただけるのは、本当にありがたいと思いましたが[39]」と語っている。\\n\\nリバイバルブーム到来[編集]\\n2002年12月4日から完全版コミックスが発売され、累計発行部数2000万部を超えるベストセラーとなった[2]。また、完全版の発売を皮切りに2003年3月には『ドラゴンボールZ』を収録したDVDBOX『DRAGON BOX VOL.1』が発売。10万円を超える高額商品にもかかわらず驚異的な売上を記録し、その後もアニメ『ドラゴンボール』シリーズのDVDが立て続けにリリースされた。同じく2003年には家庭用ゲームソフト『ドラゴンボールZ』がリリースされ、人気キャラクターが総登場するこの作品から、現在に続くDBゲームの流れが出来上がった[38]。\\nコミックス完全版の描き下ろしカバーイラストを描く仕事のため鳥山は初めて本作をまともに読み[39]、完全版では最終話の最後も修正されたが[40]、鳥山は「何年もたって完全版が出ましたが、その時最後を少し描き足しました。何だか最後がシャキッとしない気がしたんだと思います。悟空の闘いは終わって、世代交代というか、そういう意図を明確にしたかったんです[40]」と語っている。\\nシリーズ累計1億5000万部突破したことを記念して、2005年7月16日の読売新聞朝刊に特別広告が掲載された[41]。\\n\\n新展開へ[編集]\\n2009年からは『ドラゴンボールZ』のデジタルリマスター再編集版である『ドラゴンボール改』第一期が放送スタート。2014年には第2期「魔人ブウ編」が放送され、どちらも高視聴率を獲得。こうしてアニメ『ドラゴンボール』シリーズは世代を超えて愛される国民的人気作品へと発展を遂げた[42]。\\n2013年3月30日には、劇場版アニメとしては17年ぶりとなる新作『ドラゴンボールZ 神と神』が公開された。鳥山は破壊神ビルスなどの新キャラクターのデザインを手がけ、初めて劇場版のストーリー制作にも参加した。続いて、2015年4月18日に公開された劇場版『ドラゴンボールZ 復活の「F」』では、脚本を書き下ろしている。2つの劇場版の物語はその後、2015年7月5日から放送開始した『ドラゴンボール超』で再構成され、鳥山はテレビアニメ初となる原案に携わっている[42]。また、とよたろうによる漫画版が『Vジャンプ』2015年8月号から連載が開始されている。\\n『週刊少年ジャンプ』創刊45周年記念として2013年33号 - 44号まで、『銀河パトロール ジャコ』が短期連載された。その内容はDBの前日譚として、悟空が地球に送り込まれる前の話が描かれており、主人公のジャコは劇場版やテレビアニメにも登場し、『ドラゴンボール』においても主要キャラクターの1人となっている[42]。また、単行本には『DRAGON BALL－ 放たれた運命の子供』が収録されている。\\n2015年5月9日、日本記念日協会は5月9日を「悟空の日」に認定した[43]。\\n2016年10月12日、集英社は都内で行われた新刊企画発表会で、同年6月21日付で社内に単独作品の部署としては初の試みとなる「ドラゴンボール室」を新設したことを発表した。担当者は「単独作品の部署は新しい試み。ライツ（権利）と漫画の両方を備え、世界的な人気を誇るビッグコンテンツをさらに大きく展開することを目指していく」と説明。鳥山も「ずいぶん昔の作品を、集英社さんの優秀なスタッフの力を借りて、現代でも盛り上げていただこう、なんていうボクにとっては実にありがたくも頼もしいチームです。これでボクは何もしなくてもいいということになればホントに最高です」とコメントを寄せた[44]。\\n2018年3月23日、東映アニメーションは同年4月1日付で、従来のテレビ企画部を第一映像企画部、映像企画部を第二映像企画部とそれぞれ改称し、そして新たに『ドラゴンボール』を主に担当する第三映像企画部を新設することを発表した。『ドラゴンボール』は東映アニメーションのなかでも最もビジネスが大きな作品であり、独立させることで、さらに積極的にビジネス開発を進めることになる模様である[45][46]。\\n2018年3月にテレビアニメ『ドラゴンボール超』が終了したあとも2018年12月14日に劇場版『ドラゴンボール超 ブロリー』、2022年6月11日には劇場版『ドラゴンボール超 スーパーヒーロー』が公開された。\\n\\n設定[編集]\\n「ドラゴンボールの地理」および「地球 (ドラゴンボール)」も参照\\n各話数の通し番号は「其之○○」となっており、数字は漢数字で表される。\\n本作の主な舞台は太陽系の惑星「地球」である。文明については、一瞬で物体を実体化させる「ホイポイカプセル」やドラゴンボールを探知する「ドラゴンレーダー」など、現実の地球よりも高度なメカが登場する。ただし今日の現実世界に見られる携帯電話やインターネットの類は、連載当時にはまだ普及していなかったこともあり、登場していない[注釈 2]。交通手段には自動車やバイクのほかエアカーや飛行機などがあり、前述のホイポイカプセルで持ち運んで使用される。鉄道は作中では登場しないが、ランチは「列車強盗」というセリフを述べている[47]。鳥山明は「ドラゴンボールはいつの時代のどんな場所でのお話なのか、というような設定は決めてはいません。自由に何を描いてもいいわけですから」と語っている[48]。\\n宇宙には地球以外にも人型の知的生命体の住む惑星が多く存在している（ナメック星、ヤードラットなど）。これらの惑星には地球よりもさらに高度な文明を持つ星も存在する。宇宙では無数の星が集まり星雲を作り、星雲が無数に集まり銀河系を形成しており、宇宙空間に無限と言えるほどに存在している銀河系を統括するための行政単位として宇宙は東西南北4エリアの銀河に区分けされている[49]。地球はそのうちの「北銀河」に存在しており、宇宙全体は不思議な文様の刻まれた壁により密閉されている。また、生前の人類が暮らす「この世」に対し、死後の世界「あの世」が存在し、宇宙人を含め死んだ者は原則として魂があの世へと移る。人造人間・セル編では歴史の分岐により枝分かれした時間軸の世界、「並行世界」が存在することが明らかにされている。\\nアニメ版の詳細な設定は以下の個別記事を参照。\\n\\n『ドラゴンボールGT』\\nアニメ版『ドラゴンボールZ』の最終話（第291話）から5年後の世界が舞台のオリジナルアニメ。\\n『ドラゴンボール超』\\n鳥山明原案による漫画版およびテレビアニメ版。\\n2015年7月に放送が始まったアニメ『ドラゴンボール超』では新たな世界観などが追加された。本作の世界では全12の宇宙が存在し、それぞれの宇宙にはこの宇宙とそこに住む生命を生み出す創造神である界王神と対をなす破壊の神にして、宇宙全体のバランスを保つための存在である破壊神と付き人の天使が存在している。さらに全12の宇宙の神々の頂点に立つ存在である「全王」が存在する。\\n用語[編集]\\n「ドラゴンボールの技一覧」および「ドラゴンボールの道具」も参照\\n気\\n体の中を流れるエネルギーの比喩。これを操作して飛行することや、凝縮、放出して気功波として放つことができる。体の一部分に込めることで、攻撃力や防御力を上げたりと用法は様々であり、訓練すれば相手の気の強さや位置を感じたり遠く離れた相手も分かり個人の特定も可能で気を完全に消すことで気配を隠すこともできる。\\n気の容量はそのまま実力と結びついているが、技術や技量など他の要素も関係してくるので、力量を測る指針にはなるが絶対的な基準ではない[50]。\\n詳細は「気 (ドラゴンボール)」を参照\\nゼニー\\n地球での主な通貨単位で、世界共通の「ゼニー」。ゼニーは円と同じイメージであり、「1ゼニー ≒ 1円」とされる[51]。『ドラゴンボール』の前日談に当たる『銀河パトロール ジャコ』最終話では、登場人物の大盛が住む所のレートでは「1000億ゼニー ＝ 1500億円」（1ゼニー ＝ 1.5円）となっている。\\nエイジ\\n作品世界における紀年法。年号には「エイジ」が用いられている。連載開始時（悟空とブルマの出会い）が「エイジ749」、原作終了時（ウーブとの旅立ち）が「エイジ784」となる。ただし、作中で直接的に「エイジ」の文言が用いられているのは、人造人間・セル編でのトランクスの台詞のみで、作中の歴史と時期を知るにはそこから逆算するしかない。また、日付の表記方法は統一されておらず、ピッコロ大魔王の記念日は「5月9日」、人造人間19号・20号の出現日は「5月12日」と現実世界と同様の暦が用いられている一方、セルゲームの開催日は「Mの17日」と月名が英字になっている[注釈 3][注釈 4]。\\n戦闘力\\n強さを表す一つの指標で、サイヤ人編から取り入れられた概念。原作では片眼鏡型の装置「スカウター」によって気の強さを数値化したものとして表現された。直接気を感じる技術よりは具体的に力量を表しているが、ごく一部の気のコントロールができる戦士たちは、戦闘時に気を爆発的に高めることで戦闘力を上げたり、または気を消すことで戦闘力をゼロにまで下げることができるため、その数値は強さの指標として絶対ではない。\\nスカウターは気を感じることのできなかったフリーザ一味をはじめ、サイヤ人などが使用していた。劇中で、初めて計測した農夫の戦闘力は5、宇宙最強の存在であるフリーザの変身前の戦闘力は53万。これは敵味方とも数千から数万前後であった当時としては、フリーザがいかに強いかを読者に示すこととなった。なお、フリーザの変身後はスカウターによって戦闘力を計ることができず、トランクスの戦闘力を計測したのを最後に、作中に数値は出てきてはいない。連載終了後に発行された『ドラゴンボール 大全集7巻』によると、フリーザの最終形態の戦闘力は1億2000万、超サイヤ人となった悟空の戦闘力は通常の50倍の1億5000万にまで達しているとされる[52]が、後に鳥山は「50倍の強さとされていたがちょっと大袈裟で、作者の気持ちとしては今までの10倍ぐらいの変化という感じで描いていたと思う」と語っている[53]。以降の戦闘力は、物語中では特別な単位は語られていないが、魔人ブウ編において魔導士バビディは、エネルギーの量を「キリ」という単位を用いて測定しており、それによると超サイヤ人1の悟空は3000キリ以上。ただし、この単位は物語上ではほとんど使われていない。\\n戦闘力やスカウターの設定は、悟空たちがあまりにも強くなりすぎたため、2代目編集担当の近藤裕が「強い者同士、どっちが強いかもうわからない」と言ったことに対し、鳥山が数値化した方がいいのではないかとアイデアを出したのがきっかけとなっている[54]。\\n魔族\\nナメック星人の一人であったピッコロ大魔王の一派[55]。神が持っていた悪の部分が分離して生まれたピッコロ大魔王は自らを「魔族」と呼ぶ[55]。また、ピッコロ大魔王が自らの生命力を費やして産み出した、悪の心を持つ戦士たちのことでもある[56]。悟空たちが使う格闘技ではなく、相手を殺すための恐ろしい技を使いこなし[56]、彼らの使う技の流儀を地球人は「魔族流」と呼んだ[55]。ピッコロは、魔族の特性で体の容積を変化させ腕を伸ばしたり巨大化する能力を発揮している。この種族に殺された者の魂は、成仏できずに永久に空中をさまようことになる。ただし、生まれ変わったピッコロは以前とは様子が異なっており、彼に殺されたラディッツの魂は閻魔のもとを訪れ地獄行きにされている。また、魔族の攻撃は筋斗雲を消滅させる働きも持つ。ピッコロ大魔王の部下の魔族は、呪文を唱え体力を消費して口から産み出された卵から誕生する。若返ったピッコロ大魔王は呪文なしで卵を産んでいる。ピッコロ大魔王のイメージで好きなタイプを産むことができ、卵から誕生した魔族はドラゴンタイプや側近をつとめる知的なタイプなど様々な姿をしている[56]。魔族の戦士たちはピッコロ大魔王とテレパシーで会話が可能で、誰かが倒された時は大魔王が察知できる[56]。\\n制作背景[編集]\\nストーリー作り\\nストーリーや設定を考えた後にキャラクターの性格を考え、最後に絵を描くスタンスをとっており、連載の後半では絵を描くよりもストーリーを考える方に重きを置いていた[57]。ストーリーについて鳥山は「元々僕は、先の展開までジックリとかんがえるタイプではない。始まった時点では悟空が大猿に変身したりサイヤ人という宇宙人だったというようなことは全然考えていなかった。強引なまでの、うまい辻褄合わせに自分でも感心してしまう。先の話を考えずに行き当たりばったりで描くというのはけっこうスリルがあって悪くない。そのときそのときに応じて自由に話を変えていくことができ、自分でもどうなっていくかわからずドキドキワクワクして描ける」[48]「鉛筆で実際にコマを割って絵や台詞を書いたりして話を進めていくと、頭で考えていた漫画と、ちょっと違ってきてしまうことが僕はよくある」[58] と発言している。魔人ブウ編のことも鳥山は、「冒頭で悟飯がオレンジスターハイスクールに通っている辺りが好きだったけど、あの辺りを描いている時には、楽しくやりながら『さあ、そろそろ敵を考えなきゃいけないなあ…このまま日常がつづけばいいのにな』って、魔人ブウが出てくるのもわかんないまま描いていたんだと思います」と証言している[59]。\\n鳥山は「かなり多くの裏設定が頭の中にあったが説明っぽくなるから、ほとんど漫画にしなかった」[22]、「サイヤ人の特徴とかバックボーンみたいな裏設定をつくるのも、わりと好き。僕の頭の中にしかないし話の展開の中で出す機会がなく作品に反映される率はそんなに高くなく、されないほうが多い。考えるときは、人造人間編のレッドリボン軍とか過去の何でもないようなものをほじくり返してつくるのが好き。最初にちょっと緩めに考えているから後で応用を利かせやすい。最初にきっちり展開を作り込んでしまうと横道に入ったときに修正が効かなくなってしまう。如意棒の使い方もいいかげんにやってたのに、みんな「そうだったのか!」と思ってくれた」[60]、「18号とクリリン、ブルマとベジータなどの恋愛劇なども頭の中には出来上がっているが恥ずかしいという理由で作品にはしなかった」[61]、と多くの設定を頭の中に描いていたことを明らかにしている。また鳥山がアニメオリジナルエピソード用に描いたサイヤ人とツフル人の歴史や、あの世の設定、漫画で描かれなかったサイヤ人襲来までの1年間のキャラクターの生活などのメモや資料が存在する[62]。\\n鳥山は2015年に「ボクはいつもそうなんですが、人と話す時、特に収録などされていると余計に面倒だからとか、なんとなくとか、ちょっと格好つけて苦労を悟られないように話してしまうという、つまらないクセがあります。もちろん、そんなに面倒くさがりだったら漫画など描けないし、なんとなく描けるほど漫画家という職業は甘いものではありません。なんてことないようなフリをしていますが、陰ではけっこう頑張っているんです」「ジジイになった今だって、漫画の仕事こそあまりしませんが、わずかな睡眠時間であれこれ頑張っています。それでもなかなか満足できるような仕事はできません。自信のあるような態度も、じつは自分を追い込んでいるだけです。よく言われることではありますが、本当に永遠に勉強だと思っています」と語っている[63]。また、当時のストーリーや設定などについて鳥山は「仕事嫌いの僕は進んで描くというわけではなく、たくさん描かされたというべきで、僕は過去にはほとんど興味がなく、先しか見ないという性格なので、ドラゴンボールでも思い出せないことがいっぱいある[64]」という趣旨の発言をしている。\\nアニメへの関与\\n鳥山は「原作とアニメは別の物という意識はあったのか」という質問に「そんな感じはあった」と答えており、「毎週のアニメ版まで細かくチェックしていられないというのもあり、アニメはプロに任せたほうがいいだろうと思っていた」[22]、「僕は基本的にアニメの方はほとんどなにもしていない。おまかせしている」[48]、「アニメ化の際、スタッフに全てお任せするつもりだったので、特に要望は無かった。ただ、しばらくして健全な方向に行き過ぎていると感じて、その時だけは注意させていただきました」[65] と発言している。2016年の書籍では、最終回の直前に原作のラストを考えた時のことを「『本当にこれでおしまい』っていう話が必要だと思って、時間を10年後まで進めたんですけど…。まさかアニメで復活するとは思っていなかったから、アニメ会社さんは大変だったんじゃないかな（笑）[66]」と語った。一方で、悟空の父・バーダックやパイクーハンなどアニメオリジナルの人気キャラクターも生まれ、バーダックはアニメの設定を反映する形でフリーザの回想シーンにて原作にも登場した。\\n『ドラゴンボールZ』においては鳥山が書いた裏設定などアイデアメモを基にしたアニメ独自のシーンやエピソードは制作されているが[67]、『元祖』と『Z』どちらも原作者の鳥山は基本的にストーリーには関わっておらず[48]、鳥山は「ノータッチ」と発言している[68][69]。また『ドラゴンボールGT』についても鳥山は、東映アニメーションから挙がってきた当初の大まかな脚本やストーリーをチェックして、少しアドバイスを行ったが[70][71] 物語自体には「ノータッチ」と発言している[72]。\\n映画への関与\\n鳥山は『神龍の伝説』から『最強への道』までの劇場版について、「僕の中で劇場版は漫画の本編とは別次元の話[73][74]」、「東映動画から上がってきたプロットや脚本のチェック、キャラクターのデザインや手直し、名前の変更を手がけた[73]」「多少はデザインの手直しなどに関わったが、ほとんどは一鑑賞者として楽しんでいた[74]」とコメントしており、劇場版への関わりは少ない。2013年公開の『ドラゴンボールZ 神と神』では、初めて脚本の段階から深く関っており、「連載がもし続いていたら?」と想定して鳥山が書いたプロットの中から90%以上のストーリーと台詞が採用されている[75]。また、2015年公開の『ドラゴンボールZ 復活の「F」』では初めて鳥山が単独で脚本を務めている[76]。\\nゲームへの関与\\n『ドラゴンボール3 悟空伝』（1989年）から『ドラゴンボールZ 超サイヤ伝説』（1992年）までを手がけたドラゴンボール カードRPGシリーズプロデューサーの田中庸介によると、当時原作で名前がなかった技については鳥山明に決めてもらったり、開発側から提案したものに鳥山が返答したものなどがあったという。鳥山は『ドラゴンボール』の連載の合間にこれらを考え週刊少年ジャンプ編集部に原稿と共に技の絵と名前を描いたFAXを送り、それを受け取った開発陣がさらに東映アニメーションに送り色指定をしてもらっていた[77]。\\n作風\\n中国の伝奇小説『西遊記』をモチーフにしており、主人公の名前も同作品の主要登場人物である神仙・孫悟空から名付けられている。鳥山は当初『西遊記』を現代風かつ少年誌風に描こうと思っていたが、かえってやりにくいので無視して始めることにしたと言い、同じ孫悟空という名前でもサルの孫悟空とは別に考えてほしいと語っている[78]。\\n歴代担当編集者[編集]\\n初代担当 鳥嶋和彦（とりしま かずひこ）\\n鳥山のデビュー前からの担当編集者で、23回天下一武道会終了まで担当。鳥山からは「鬼、悪魔」と罵られながらも頭が上がらない存在である。ラブコメ好きで、『ドラゴンボール』でも悟空とブルマを恋愛させようとして、ラブコメが苦手な鳥山は困惑していた[79]。『ドラゴンボール』の連載にあたって鳥嶋は『未来少年コナン』を3話ずつダビングして鳥山に送っており、少年と少女の出会いが大きなドラマにつながっていくというストーリーの作り方の根幹のシステムが『ドラゴンボール』連載1回目の構成に役立ったかもしれないと鳥嶋は述懐している[80]。鳥嶋は後に、『ドラゴンボール』は『里見八犬伝』と『未来少年コナン』の変形であり、鳥山のことを他作家たちの積み重ねの上に成立した“偉大なるアレンジャー”と表現している[81]。また、鳥山が小さい悟空を成長させようとした時、「待ってくれ」と言い[18]、連載の危機を一番感じたが、上司を説得させて読者からの抗議もなかったため杞憂に終わったという[82]。\\n鳥嶋は、鳥山と大きな話の流れは決めていたが次週の話はネームが届くまでは分からず、読者視点で最初に感じたことを作家に伝えるのが大事であり、ストーリーを作るのは作家の仕事、編集は整理をするだけだと語っている[82]。一方で自身はメディアミックスに対して絶対的な自信を持っており、アニメ『ドラゴンボール』の出来、特にピッコロ大魔王を倒すシーンに強い不満を持ったことから、フジテレビ幹部と直談判してプロデューサーを降板させ『ドラゴンボールZ』の立ち上げにつながったという逸話がある[83]。また、連載終了後にバンダイが数億円を費やして企画したゲームを「これさぁ、悪いんだけど、捨ててくれる？」の一言で没にした逸話もある[84]。\\n副編集長昇格に伴い担当を外れたが、その後もことあるごとに鳥山の自宅に電話をしており、人造人間19号と人造人間20号が登場した際は「やっと敵が出てきたと思ったらジジイとデブじゃないですか」と言い、仕方なく鳥山が人造人間17号と人造人間18号を出したところ「今度はガキですか」と言い放ち、これがセル登場につながった[85]。上述の通り、『週刊少年ジャンプ』編集長代理時代に連載終了を決定したが、終了当時は『Vジャンプ』編集長であり、『週刊少年ジャンプ』には関与していなかった[86]。\\n二代目担当 近藤裕（こんどう ゆう）\\nラディッツ登場から完全体セル登場まで担当。少女誌で実績を上げた後、鳥嶋が退任に当たって直接『週刊少年ジャンプ』に引き抜いて担当に就任させた。鳥山によると真面目そうな印象だが趣味人であり、気が合ったという[82]。冷静沈着な性格で、少女誌にいた経験から、常に女性読者を意識したアドバイスを心がけた。「好きにやれ」ということで鳥嶋からの引き継ぎは何もなく、宇宙が舞台になることまでは決まっていたため「宇宙の地上げ屋」はどうかと提案し、鳥山が面白がってフリーザ誕生につながった[54]。近藤は「担当になってからは方向性は決まっていて、ストーリーマンガで闘いをエスカレートさせることだけを考えた」と語っている[85]。トランクス登場時のタイムトラベルストーリーについて鳥嶋は「あれは近藤が担当者じゃないとできなかった」と述べており[85]、鳥山も近藤によく相談していた[23]。鳥山がセルを出したところ「かっこ悪いですよ。もちろん変身しますよね」と言われ、第2形態にすると「今度の奴、馬鹿みたいじゃないですか、早く完全体にしましょう」と言われたので「完全体セルは近藤さん好みのかっこいいキャラにした」と鳥山は述べている[85]。近藤は鳥嶋の担当時代からの大前提として敵を大きくしないことを挙げており、敵が醜いと悟空が勝つと思われて予定調和になってしまうため、完全体だけは唯一鳥山にキャラ造形を意見したと語っている[54]。また鳥山が画集表紙用にドラゴンのウロコを一枚一枚塗った渾身のイラストを、表紙としてのインパクトに欠けるという理由で全て描き直させた[27]。「ぜんぜん駄目」が口癖[注釈 5]。\\n三代目担当 武田冬門（たけだ ふゆと）\\n完全体セル登場から最終回まで担当。『月刊少年ジャンプ』から異動してすぐに鳥山の担当になったが、鳥山との初対面で「それは申し訳ないことしましたね。もうすぐ『DB』を終わりにしようと思っているんです」と告げられていた[87]。『Dr.スランプ』が好きだった武田は鳥山が不本意で二枚目キャラクターを描き続けていたことを察し、「このままだと描きたいものをきちんと描かずに終わってしまいますよ。最後に好きなものを描いて締めませんか」と伝え、笑いを入れながら話が進む感じで魔人ブウ編が始まった[87]。武田自身がアイデアを出すことは特になく、鳥山も比較的自由にやらせてもらっていたようで、特に文句はないようである。また、ミスター・サタンに対し「このキャラ良いですね」と言ったことにより、当初はチョイ役で終わらせる予定だったサタンを、その後も登場させることになった[88]。\\n鳥嶋はピッコロ大魔王、近藤はフリーザ、武田は魔人ブウのモデルであるという説もあるが[27][注釈 6]、鳥山自身は「あまり意識した覚えは無い。根本にはあるかもしれないけど、無意識に反映させていたのかもしれない」と語っている[89]。\\n\\n社会的評価[編集]\\n日本[編集]\\nテレビアニメは11年間平均視聴率20%以上を維持し続け[90]、主題歌『CHA-LA HEAD-CHA-LA』を収録したCDは170万枚を売り上げた[91]。\\n人気は非常に高く、『週刊少年ジャンプ』連載中の頃は「フリーザ編」で行った少年ジャンプ1000票アンケートで815票という圧倒的人気を獲得[92]。少年ジャンプ1995年3-4号ではギネス世界記録にも登録された653万部の大記録の達成に2枚看板である『SLAM DUNK』と共に牽引役となった[93]。\\n連載終了後も本作が連載・放映されていた時期には生まれていない世代にも知名度が高く2002年に再放送された『ドラゴンボールZ』は平日夕方の時間帯にもかかわらず高視聴率を獲得し、完全版コミックス、ゲーム、DVDなどが大ヒットするなど子供たちの間でも大人気となっている[94]。2009年4月から始まった『ドラゴンボール改』は親世代の知名度が抜群であり、小学生の間でも男子・女子ともに高い平均視聴率を記録[95]。連載終了20年が経過してなおも小学生や子供たちにも『ドラゴンボール』の知名度は高く2015年7月から放送の『ドラゴンボール超』でその人気はさらに高まっており[96]、『スーパードラゴンボールヒーローズ』のキャラクター投票には全国から1万2000票以上が集まった[97]。\\n\\n売上[編集]\\nバンダイナムコホールディングス\\nバンダイのIP別売上高で2016年度の売上は611億円を記録し、『ONE PIECE』の倍以上の売上を記録した[98][99]。2019年3月通期におけるIP別売上高で1290億円を記録し、同社のIP別売上高でも『ガンダムシリーズ』、『ONE PIECE』、『スーパー戦隊』など他のコンテンツを引き離して首位となった[100]。\\n\\n\\n\\n決算年度\\n年度別売上高[101]\\n\\n\\n2013年3月期（2012年4月1日 - 2013年3月31日）\\n\\n89億円[102]\\n\\n\\n2014年3月期（2013年4月1日 - 2014年3月31日）\\n\\n114億円[102]\\n\\n\\n2015年3月期（2014年4月1日 - 2015年3月31日）\\n\\n194億円[102]\\n\\n\\n2016年3月期（2015年4月1日 - 2016年3月31日）\\n\\n349億円[103]\\n\\n\\n2017年3月期（2016年4月1日 - 2017年3月31日）\\n\\n611億円[103]\\n\\n\\n2018年3月期（2017年4月1日 - 2018年3月31日）\\n\\n979億円[104]\\n\\n\\n2019年3月期（2018年4月1日 - 2019年3月31日）\\n\\n1290億円[105]\\n\\n\\n2020年3月期（2019年4月1日 - 2020年3月31日）\\n\\n1349億円[106]\\n\\n\\n\\n\\n年度\\n国内トイホビー売上高[101]\\n\\n\\n2013年3月期\\n\\n48億円[102]\\n\\n\\n2014年3月期\\n\\n64億円[102]\\n\\n\\n2015年3月期\\n\\n58億円[102]\\n\\n\\n2016年3月期\\n\\n116億円[103]\\n\\n\\n2017年3月期\\n\\n124億円[104]\\n\\n\\n2018年3月期\\n\\n142億円[104]\\n\\n\\n2019年3月期\\n\\n204億円[105]\\n\\n\\n2020年3月期\\n\\n207億円[106]\\n\\n\\n東映アニメーション\\n東映の版権総合売上（国内版権、海外映像、海外版権の合計）では毎年『ドラゴンボール』は売上上位であり、2002年度[107]、2003年度[107]、2004年度[107]、2005年度[108]、2006年度[109]、2007年度[110]、2008年度[111]、2009年度[112]、2016年度[113]、2017年度[114]、でトップになっている。\\n漫画[編集]\\n単行本の国内累計発行部数は完全版を含めて1億6000万部以上（2015年時点）[10]、全世界累計発行部数は2億6000万部以上を記録（2020年時点）[11]。\\n\\n\\n\\n全世界累計発行部数推移\\n出典\\n\\n\\n2006年時点\\n2億部\\n[115]\\n\\n\\n2012年時点\\n2億3000万部\\n[116]\\n\\n\\n2016年時点\\n2億4000万部\\n[117]\\n\\n\\n2018年時点\\n2億5000万部\\n[118]\\n\\n\\n2020年時点\\n\\n2億6000万部\\n\\n[11]\\n\\n\\n各国の出版社の部数一覧\\n\\n\\n国名\\n出版社\\n部数\\n備考\\n出典\\n\\n\\n日本\\n集英社\\n1億6000万部以上\\n2015年時点、完全版込み\\n[10]\\n\\n\\nフランス\\nグレナ\\n3000万部\\n2017年時点\\n[119][120]\\n\\n\\n韓国\\nソウル文化社\\n2000万部以上\\n2013年時点\\n[121][122]\\n\\n\\nスペイン\\nPlaneta deAgostini\\n2000万部\\n2013年時点（2500万部との報道も[123]）\\n[124]\\n\\n\\nイタリア\\nスターコミックス\\n1600万部\\n2021年時点\\n[125]\\n\\n\\n中国\\n中国少年児童出版社\\n1000万部以上\\n2013年時点\\n[126][127]\\n\\n\\n台湾\\n東立出版社\\n1000万部以上\\n2009年時点\\n[128]\\n\\n\\n香港\\n文化傳信\\n840万部\\n（各巻20万部の売上、全42巻）\\n[129]\\n\\n\\nドイツ\\nカールセン出版社\\n800万部以上\\n（2015年時点、ペーパーバック版）\\n[130][131]\\n\\n\\nブラジル\\nConrad Editora\\n600万部\\n2002年時点\\n[132]\\n\\n\\nアメリカ\\nビズメディア\\n218万5千部以上\\n（2016年時点、無印版16冊 Z版26冊 全42冊）\\n[133]\\n\\n\\nデンマーク\\nForlaget Carlsen\\n150万部以上\\n2007年時点\\n[134][135]\\n\\n\\nスウェーデン\\nBonnier Carlsen\\n130万部\\n2006年時点\\n[135]\\n\\n\\nフィンランド\\nSangatsu Manga\\n約50万部\\n（2009年時点、全42巻の売上）\\n[136][137]\\n\\n\\nポーランド\\nJPF社\\n42万部以上\\n2001年から2002年頃（各巻の初版1万部以上 数万部との見方も）\\n[138]\\n\\n\\nイギリス\\nGollancz / Viz Media\\n約7万8千部\\n2005年から2010年までの数字\\n[139]\\n\\n\\nベトナム\\nキムドン出版社\\n年6万部\\n2009年頃\\n[140]\\n\\nゲーム[編集]\\n現在までに本作のゲームソフトの累計販売本数は『ドラゴンボール ゼノバース』シリーズの1500万本を初め[141]、全世界累計販売本数5000万本を越える[12]。日本国外での累計出荷本数は2015年12月時点で2400万本を記録している[142]。また2013年には「世界で最もビデオゲーム化されたコミック」としてギネス世界記録に認定されている[143]。\\n\\n\\n\\nタイトル\\n発売日\\n開発元\\n本数\\n出典\\n\\n\\nドラゴンボール ファイターズ\\n2018年2月1日\\nアークシステムワークス\\n1000万本\\n[144]\\n\\n\\nドラゴンボール ゼノバース2\\n2016年11月2日\\nディンプス\\n1000万本\\n\\n\\nドラゴンボール ゼノバース\\n2015年2月5日\\n500万本\\n[145]\\n\\n\\nドラゴンボールZ カカロット\\n2020年1月26日\\nサイバーコネクトツー\\n500万本\\n[146]\\n\\n\\nドラゴンボールZ\\n2003年2月13日\\nディンプス\\n350万本以上\\n[147]\\n\\n\\nドラゴンボールZ2\\n2004年2月7日\\n350万本以上\\n\\n\\nドラゴンボールZ3\\n2005年2月10日\\n350万本以上\\n\\n\\nドラゴンボールZ 超武闘伝\\n1993年3月20日\\nトーセ\\n141万本\\n[148]\\n\\n\\nドラゴンボールZ Sparking!\\n2005年10月6日\\nスパイク\\n136万7千本\\n[149]\\n\\n\\nドラゴンボールZ 超武闘伝2\\n1993年12月17日\\nトーセ\\n120万本\\n[148]\\n\\n\\nドラゴンボール 神龍の謎\\n1986年11月27日\\n120万本\\n[148]\\n\\n\\nドラゴンボールZ Sparking! NEO\\n2006年10月5日\\nスパイク\\n117万5千本\\n[150]\\n\\n\\nドラゴンボールZ Sparking! METEOR\\n2007年10月4日\\n104万本\\n[151]\\n\\n\\nドラゴンボールZ 超武闘伝3\\n1994年9月29日\\nトーセ\\n91万本\\n[148]\\n\\n\\nドラゴンボールZ 強襲!サイヤ人\\n1990年10月27日\\n90万本\\n\\nカードゲーム\\nデジタルキッズカードゲーム『スーパードラゴンボールヒーローズ』は2020年11月時点でシリーズ累計カード出荷数10億枚を突破[152]。またメルカリが発表した「メルカリトレンドワード2019上半期」で『スーパードラゴンボールヒーローズ』が1位に選ばれた[153]。\\n\\nスマートフォンゲーム\\n『ドラゴンボールZ ドッカンバトル』は2021年9月時点で全世界3億5000万DLを突破[154]。また2016年にはGoogle PlayAwardsのグローバルカテゴリー部門にノミネートされ[155]、2016年のApp Store売上ランキングで12位[156]、2016年アプリ市場レポートでゲームアプリ「iOS&Google Play」合計収益ランキングで10位となった[157]。\\n『ドラゴンボール レジェンズ』は2023年8月時点で全世界8000万DLを突破している[158]。\\n\\nアンケートランキング[編集]\\n\\n\\n年\\n調査機関\\n調査概要\\n対象名\\n順位\\n出典\\n\\n\\n2006年\\n日本コンパクトディスク・ビデオレンタル商業組合\\n「心に残るマイベストムービー」・TVアニメ部門\\nドラゴンボール\\n1位\\n[159]\\n\\n\\n2007年\\nオリコン\\n「1000人が選んだ!漫画史上“最強”キャラクターランキング!」\\n孫悟空\\n[160]\\n\\n\\n「ヒーローの必殺技といえば何か?」\\nかめはめ波\\n[161]\\n\\n\\n2008年\\n「実際にアニメ主人公になれるなら誰に?」\\n孫悟空\\n[162]\\n\\n\\n「今までで最も面白かったテレビアニメは?」\\nドラゴンボール\\n[163]\\n\\n\\ngooランキング\\n「宇宙最強だと思うアニメ・コミックキャラクター」\\n孫悟空\\n[164]\\n\\n\\n2009年\\nライフネット生命保険\\n「好きだったマンガは?」\\nドラゴンボール\\n[165]\\n\\n\\nオリコン\\n「漫画の名脇役ランキング」\\nクリリン\\n[166]\\n\\n\\n2010年\\n東京工芸大学\\n「クールジャパンとして世界に紹介したい日本文化は何ですか?」アニメ・漫画部門\\nドラゴンボール\\n[167]\\n\\n\\n2013年\\n聞く技術研究所\\n「マンガの魅力度比較調査」認知率、購読経験率、選好度\\nドラゴンボール\\n[168]\\n\\n\\n2014年\\nダ・ヴィンチニュース\\n「あなたが思う最強のジャンプマンガは？」\\nドラゴンボール\\n[169]\\n\\n\\n2015年\\n立教大学\\n「クールジャパンだと思うアニメ作品は?」「クールジャパンだと思うマンガ作品は?」\\nドラゴンボール\\n[170]\\n\\n\\n2017年\\ngooランキング\\n「マジで絶望感を与えられたジャンプの敵キャラといえば？」\\nフリーザ\\n[171]\\n\\n\\n「最強に魅力的だった！ジャンプのラスボスランキング」\\n魔人ブウ\\n[172]\\n\\n\\n2018年\\nオリコン\\n「子どもの頃に好きだったTVアニメ番組」\\nドラゴンボール\\n[173]\\n\\n\\n2019年\\nアニメ！アニメ！\\n「アニメに登場する最強の老人キャラといえば？」\\n亀仙人\\n[174]\\n\\n\\ngooランキング\\n「圧倒的カリスマ性のあるジャンプ主人公ランキング」\\n孫悟空\\n[175]\\n\\n\\n「これぞ「真の国民的漫画」と思う漫画ランキング」\\nドラゴンボール\\n[176]\\n\\n\\n「せりふ回しが天才的なジャンプ作品ランキング」\\nドラゴンボール\\n[177]\\n\\n\\n「ジャンプ史上最強の悪のカリスマランキング」\\nフリーザ\\n[178]\\n\\n\\n2020年\\n文春オンライン\\n「あなたが選ぶ『少年マンガ』ベスト1は？」\\nドラゴンボール\\n[179]\\n\\n受賞歴[編集]\\n\\n\\nセレモニー\\n回数・年\\n部門・賞\\n受賞対象\\n出典\\n\\n\\nPlayStation Awards\\n2003年\\nゴールドプライズ賞\\nドラゴンボールZ\\n[180]\\n\\n\\n2004年\\nゴールドプライズ賞\\nドラゴンボールZ2\\n\\n\\n2005年\\nゴールドプライズ賞\\nドラゴンボールZ3\\n\\n\\n2006年\\nゴールドプライズ賞\\nドラゴンボールZ Sparking!\\n\\n\\nビデオ・オブ・ザ・イヤー\\n2006年\\n最優秀アニメ賞\\nドラゴンボールZ・DVD\\n[181]\\n\\n\\nDVD・オブ・ザ・イヤー\\n2006年\\nTVアニメ・OVA部門3位\\nドラゴンボールZ・DVD\\n[181]\\n\\n\\n第39回日本アカデミー賞\\n2016年\\n優秀アニメーション作品賞\\nドラゴンボールZ 復活の「F」\\n[182]\\n\\n\\nゴールデングロス賞\\n第9回\\n日本映画部門・優秀銀賞\\nドラゴンボールZ 超サイヤ人だ孫悟空ドラゴンボールZ とびっきりの最強対最強\\n[183]\\n\\n\\n第10回\\n日本映画部門・優秀銀賞\\nドラゴンボールZ 激突!!100億パワーの戦士たち\\n\\n\\n第11回\\n日本映画部門・優秀銀賞\\nドラゴンボールZ 燃えつきろ!!熱戦・烈戦・超激戦\\n\\n\\n第12回\\n日本映画部門・優秀銀賞\\nドラゴンボールZ 危険なふたり!超戦士はねむれない\\n\\n\\n第13回\\n日本映画部門・優秀銀賞\\nドラゴンボールZ 復活のフュージョン!!悟空とベジータ\\n\\n\\n第33回\\n日本映画部門・優秀銀賞\\nドラゴンボールZ 復活の「F」\\n\\n\\nモバイルプロジェクト・アワード\\n2016年\\nモバイルコンテンツ部門・優秀賞\\nドラゴンボールZ ドッカンバトル\\n[184]\\n\\n\\n日本おもちゃ大賞\\n2017年\\nイノベイティブ・トイ部門 優秀賞\\nBotsNew Characters VR DRAGONBALL Z\\n[185]\\n\\n\\n日本ゲーム大賞\\n2017年\\nフューチャー部門\\nドラゴンボール ファイターズ\\n[186]\\n\\n\\n日本商品化権大賞\\n2017年\\n国内部門\\nドラゴンボールシリーズ（集英社・東映アニメーション）\\n[187]\\n\\n\\nJASRAC賞\\n2003年度\\n銀賞\\nドラゴンボールZ BGM\\n[188][189]\\n\\n\\n2007年度\\n国際賞\\n\\n\\n2014年度\\n国際賞\\n\\n\\n2017年度\\n国際賞\\n\\n\\n2018年度\\n国際賞\\n\\n\\nPlayStation Developers Choice Awards\\n2018年\\nベストビジュアルアーツ部門\\nドラゴンボール ファイターズ\\n[190]\\n\\n\\nGoogle Play ベスト オブ 2018\\n2018年\\nベストゲーム2018\\nドラゴンボール レジェンズ\\n[191]\\n\\n\\n第42回日本アカデミー賞\\n2019年\\n優秀アニメーション作品賞\\nドラゴンボール超 ブロリー\\n[192]\\n\\n\\nCrunchyrollアニメアワード\\n2019年\\nベストアニメシリーズ賞・1位\\nドラゴンボール超\\n[193]\\n\\n\\nCEDEC AWARDS\\n2019年\\nゲームデザイン部門・優秀賞\\nドラゴンボール ファイターズ\\n[194]\\n\\n\\n日本商品化権大賞2019\\n2020年\\nグローバル部門\\nドラゴンボール超 ブロリー\\n[6]\\n\\nその他[編集]\\n1988年にバンダイから初の自動販売機で販売するカードダスが登場し、中でも最大のヒットを飛ばしたのが「カードダス ドラゴンボールシリーズ」。1988年11月に第一弾が発売され、この本弾の人気を受けて「スーパーバトル」、「ジャンボカードダス」など様々な形・シリーズへと展開され大ブームを起こし[195]、1995年に20億枚を突破するなど大きな売り上げを記録した[196]。\\n『週刊少年ジャンプ』40周年記念号となった2008年34号で2008年連載中の作家21人にアンケートを取ったところ、好きなキャラクター・一番強いと思うキャラクター共に孫悟空が選ばれた。\\n2017年8月26日にフジテレビ系で放送された『昭和vs平成 アニメ&特撮&マンガヒーロー・ヒロイントップ20〜1億2千万人が選んだ永久保存版ランキング〜』の番組では昭和生まれ、平成生まれがそれぞれ選んだヒーロー・ヒロインのランキングが発表され、ヒーロー部門で昭和、平成共に孫悟空が1位に選ばれて世代を超えた人気となった[197]。\\n2007年に漫画全巻セットの販売サイト「全巻読破.com」が発表した最も全巻読破された人気コミックランキングでは『ドラゴンボール』（全42巻）が1位になり、2位は『ドラゴンボール』完全版（全34巻）となった[198]。\\n「漫画全巻ドットコム」を運営する株式会社TORICOによると2007年度の漫画全巻ドットコム内、約1300タイトルから最も読まれた漫画全巻セットのランキングで5位になった（全世界）[199]。\\n2013年3月にライフネット生命保険が全国の15歳〜49歳の男女1000名に『ドラゴンボール』に関する調査をしたところ、『ドラゴンボール』のテレビアニメを観た経験があると答えたのは10代が86.8%、20代が97.6%、30代が98.0%、40代が96.4%、全体で94.7%が観た経験があると回答し、世代を越えて愛されている国民的アニメと言える結果となった[200]。\\n日本国外での展開[編集]\\nコミックスは40カ国以上で発売され[201]、アニメは世界80カ国以上の国と地域で放送[3]。テレビ朝日放送の『決定!これが日本のベスト』での「世界に進出した日本の人気アニメ ベスト100」のアンケートでは『ドラゴンボール』が1位を獲得し[202]、オリコンが行った「世界に通用していると思う日本のアニメ」、「世界に通用しているマンガ＆アニメランキング」のアンケートではいずれも『ドラゴンボール』が圧倒的な得票数で1位に選ばれるなど[203][204]日本国外でも高い人気と知名度を誇っており、その人気は世界規模である[94]。キャラクターグッズは1996年初頭時点で日本国外100社以上から申請があった[205]。市場規模は2014年時点で全世界50億ドル以上を記録[206]。2019年の世界市場規模は約2500億円を記録しグローバルな市場を創出するなど商品化権ビジネスの発展に貢献した[6]。\\n\\n北米[編集]\\n アメリカ合衆国\\nアメリカでは1995年9月に米国内83局ネットで『ドラゴンボール』、1996年9月13日に『ドラゴンボールZ』が放送開始されたが[205][207]、いずれの放送も日本アニメの地位の低さおよび『ドラゴンボールZ』に関しては暴力的とみなされたことから当初は大手放送局ではなくローカル局で週1回、深夜や早朝5時台での放送を余儀なくされてインターネット上ではカルト的人気を得ていたものの視聴者数は思うように伸びなかった。しかし1998年に大手ケーブル局カートゥーン ネットワークで週5日の放送が始まると放送直後から爆発的人気を獲得し、1999年9月30日の放送で局の視聴率記録を塗り替えて全米を席巻するほどの人気となった[208][209]。『ドラゴンボールZ』は1990年代のアメリカの子供たちの多くがテレビで見たことがありアメリカでの人気は日本での人気に匹敵し[210]、アメリカの一般家庭にまで日本アニメを浸透させた[211]。\\n2000年以降も高い人気を誇っており2001年9月26日の放送で『ドラゴンボールZ』は約275万の家庭で視聴され、カートゥーン ネットワーク史上「最も見られた番組」となった[212]。2002年9月16日 - 9月22日の週間ランキングで全米大手ケーブル局の中で『ザ・シンプソンズ』などの番組を上回る1位の視聴者数を獲得[213]。2003年10月3日に放送が開始された『ドラゴンボールGT』も高視聴率を獲得し、『ドラゴンボール』シリーズはアメリカで成功を収めた[214][215]。\\nその人気の高さから米LYCOSの検索ランキングで「\"dragon ball\"」 のキーワードが2001年、2002年と「2年連続第1位を獲得」[216]。2003年6月には米LYCOSトップ50の最も多く検索された検索ワードランキングで全米トップ10以内に「200週間連続でランクイン」する快挙を達成した。これは『ドラゴンボール』がアメリカで絶え間ない人気であることを証明しており[217]、2005年にLYCOSが発表した過去10年間の検索数ランキングでも『ドラゴンボール』は総合2位、米Yahoo!の検索ランキングでも3位となる快挙を成し遂げて人気と知名度の高さをあらためて印象づける結果となった[218][219]。放送終了後も新作アニメを上回るほどの高い人気を維持し続けており、再放送もされるなど『ドラゴンボール』シリーズはファニメーションにとって最も有力なアニメ作品となっている[220]。\\nビデオゲームは2000年にINFOGRAMES（現ATARI）社が北米および国際市場でのビデオゲームの制作と販売のライセンスを獲得し[221]、北米開発のソフトが発売されてATARIは2005年度に本作関連で8500万ドルの売上を記録し、本作関連商品が収益の柱となっていた[222]。2009年にATARIとの契約満了に伴いバンダイナムコゲームス（現バンダイナムコエンターテインメント）が北米でのライセンスを取得して以降は同社より本作関連のゲームが発売されており[223]、2014年までにアメリカで『ドラゴンボール』シリーズのビデオゲームの販売本数は1500万本以上を記録した[206]。\\nトレーディングカードゲームは2000年にScore Entertainment社から販売され、『ドラゴンボールZ』のトレーディングカードは全米でトップの売上を誇っている[224]。2017年7月28日からはBANDAI Americaより『ドラゴンボール超』のトレーディングカードゲームがリリース[225][226] され、全米各地で『ドラゴンボール超』のカードゲーム大会やイベントが何度も行われるほど人気を得ている[227]。\\nアニメ『ドラゴンボール』シリーズのビデオとDVDの売上は2006年時点で2500万本の販売数を記録している。これはアメリカで発売されたアニメシリーズでは1位であり、日本国外の公式サイトである「Dragonballz.com」には1か月あたり100万人以上のアクセスがある[228]。米ニールセン・ビデオスキャンの分析データによるとアニメ版『ドラゴンボールZ・シーズン1』は2007年のアニメDVDの販売数で全米でトップを記録。同社の社長は「ドラゴンボールZは絶え間なく増え続けるファンをベースに持つ非常に人気の作品です。根強いファンと次世代のファンのおかげでドラゴンボールZはアメリカで最も人気のある作品の一つとして君臨し続けます。」と感想を述べた[229]。ファニメーションの社員はAnime News Networkのポッドキャストで「2011年に一番売れた日本のアニメDVD」は『ドラゴンボールZ』だと語った[230]。DVDとBlu-ray Discの販売数は2017年時点で3000万本を超える[231]。\\n2009年に20世紀フォックス制作のハリウッド映画『DRAGONBALL EVOLUTION』が世界で公開された。\\n2010年5月24日から米アニメ専門チャンネルのニックトゥーン（Nicktoons）で放送が始まった『ドラゴンボール改』（米タイトルは『DRAGON BALL Z KAI』）が好調なスタートを切った。9歳〜14歳、12歳〜17歳、9歳〜14歳（男）、12歳〜17歳（男）の4カテゴリで第1話の視聴率が同局の開局以来の最高視聴率を記録した[232]。\\n2014年8月5日 - 9日の4日間限定で劇場版『ドラゴンボールZ 神と神』が公開され、興行収入は220万1569ドルを記録。また近年米国で増えている日本アニメの短期集中イベント型の上映では最高金額となり、『ドラゴンボール』の米国での人気を感じさせる結果となった[233]。\\n2015年4月11日に劇場版『ドラゴンボールZ 復活の「F」』のロサンゼルスプレミアがハリウッドの名門劇場「エジプシャンシアター」で行われ、当日は500人を超える熱狂的なファンをはじめ世界各国からマスコミが詰めかけた[234]。同年8月4日より公開され、興行収入約800万ドルを記録した[235]。\\n2019年1月16日に劇場版『ドラゴンボール超 ブロリー』が公開され、公開初日に興行収入700万ドルを記録して「全米初登場1位」を達成[236]。21世紀以降公開の作品では初の快挙となった[237]。公開5日間で興収2000万ドルを突破し、日本アニメ専門のファニメーションによる1200館の中規模配給であったことからヴァラエティ誌、ハリウッドレポーター誌などの米国有力メディアも『ドラゴンボール超 ブロリー』をサプライズなヒットとして取り上げた[238]。\\n カナダ\\nカナダの子供たちの間でも『ドラゴンボール』や『NARUTO -ナルト-』などの日本の漫画とアニメは人気であり[239]、テレビアニメは1995年9月から放送開始した[205]。劇場版『ドラゴンボールZ 神と神』の北米公開は当初約400スクリーン規模を予定していたが、米国・カナダで高い人気を誇っていることもあり新たに350スクリーンほどがこれに加わり合計でおよそ800スクリーンとなった。これはイベント形式の公開ではかなり大規模となる[240]。\\n中南米[編集]\\n中南米でも『ドラゴンボール』は絶大な人気を誇っており、アニメはスペイン語やポルトガル語に翻訳されて繰り返し放送されている[241][242]。中南米で公開された『ドラゴンボールZ 神と神』は最初の週末だけで約8億5000万円の興行収入を達成し[243]、最終的な興行収入は中南米全体で1558万ドル以上（約17億3000万円）、全世界では約5000万ドル（54億円以上）を記録した[244]。\\n\\n メキシコ\\nメキシコでは1995年9月からテレビアニメが放送開始され、1996年初頭時点でアニメ視聴率1位となり劇場版も上映された[205]。『ドラゴンボールZ』は1997年9月2日にテレビサのCanal5で放送が開始して[245]以降、『ドラゴンボールGT』[246]、『ドラゴンボール超』などのシリーズはテレビサ局で放送されている[247]。\\nメキシコでの本作の人気は極めて高く、ファンの数は数百万人に上るとされる[245]。鳥山明はメキシコで最も有名な日本人1位に2018年9月8日にテレビ朝日で放送された『陸海空 地球征服するなんて』の「地球アンケート〜世界で一番有名な日本人は誰だ!?〜」で選ばれた[248]。また違法なコンテンツも出回っておりPornhub2017年のレポートでは昨年メキシコの本サイトでの「Dragon Ball Z」の検索数が2016年と比較して964%増加し、2017年にメキシコで最も検索されたトレンドはDragon Ball Zだったと明かした[245]。\\n2018年3月17日（現地時間）に『ドラゴンボール超』第130話がメキシコ全土の広場やイベント会場などで放送された。一部の自治体には東映アニメーションと在メキシコ日本国大使館から著作権の都合上放送しないようにとの手紙が送られたが、伝達が行われた場所も含めてケレタロ、ミチョアカン州、サン・ルイス・ポトシ、イダルゴ州、サカテカス、グアナフアト、ソノラ州、タマウリパス州などの多くの都市や州で放送されてその盛り上がりは全国のプロサッカーの試合を上回るほどであった。チワワ州シウダー・フアレスの広場で行われた放送には1万人以上が集まり、市長のArmando Cabadaは「Crunchyrollと東映アニメーションと交渉の末、許可を貰っての放送。」とのこと[249]。歴史地区のケレタロのゲレーロ庭園には3500人以上が訪れ、モレロスのアルマス広場でも大勢の人たちが集まった。ベラクルスでは元気玉の元気を集めるように会場の人たちが手を上げており、『ドラゴンボール』がメキシコ国民に愛されているといえる結果となった[250]。\\n2013年9月27日に公開された劇場版『ドラゴンボールZ 神と神』は累計興行収入446万5917万ドルを記録[244]、2019年1月10日に公開された劇場版『ドラゴンボール超 ブロリー』は公開3日間で観客動員数230万人以上、興行収入Mex$1億2360万（約7億円）を記録した[251]。\\n エクアドル\\nエクアドルの都市マチャラの広場で2018年3月17日（現地時間）に行われた『ドラゴンボール超』第130話の放送には1万人以上が集まった[250]。\\n エルサルバドル\\nエルサルバドルの首都サンサルバドルの広場で2018年3月17日（現地時間）に行われた『ドラゴンボール超』第130話の放送でも数千人以上が訪れた[250]。\\n アルゼンチン\\nアルゼンチンでは、1997年4月にケーブルチャンネル「Magic Kids」でメキシコ版のダビングが放送され、『ドラゴンボールZ』は1998年5月、『ドラゴンボールGT』は2000年から放送開始し、劇場版も上映されるなど、「Magic Kids史上最も成功したアニメ作品」となるほどアルゼンチン国内に多くのファンを抱え、絶大な人気を誇っている[252][253]。2013年9月にアルゼンチンで公開された劇場版『ドラゴンボールZ 神と神』は約305万ドルの興行収入を記録した[244]。\\nコミックスは2008年にIvrea社から出版されている。Ivrea社のライセンスマネージャーのハビエル・ヘレディアは「ドラゴンボールはもっとも売れているタイトルの一つで、再版の売上が現在の新作漫画の売上を凌駕するほどです」と語った[254]。\\n\\xa0コロンビア\\n2013年10月にコロンビアで公開された劇場版『ドラゴンボールZ 神と神』は封切り直後の週末に16万人が劇場に押し掛け、最終興行収入は110万ドル以上を記録した[244]。\\n ベネズエラ\\n2013年10月にベネズエラで公開された劇場版『ドラゴンボールZ 神と神』は約105万ドルの興行収入を記録した[244]。\\n\\xa0チリ\\nチリでは、1997年から2002年にかけてアニメ『ドラゴンボール』シリーズが民放のテレビ局メガで放送され、『ドラゴンボール』と『美少女戦士セーラームーン』の人気の高まりを受け、チリで乳製品の製造・販売を行っているソプロレは、自社製ヨーグルト容器のふたにこれらのイメージキャラクーを印刷し、コレクションアルバム用に販売していたことがある。2013年10月に『ドラゴンボールZ 神と神』がチリ国内66ヵ所の映画館で上映され、観客動員数でスペイン製映画に次ぎ4位を記録し、興行収入は135万ドル以上を記録した[244]。\\n ペルー\\nペルーでも『ドラゴンボール』は最も人気のあるアニメ作品の一つであり、「ゴハン」、「クリリン」、「ピッコロ」など、『ドラゴンボール』の登場人物にちなんで名前を名付けられた人が、500人以上いることが同国の政府機関の調べで明らかとなり、ペルー紙レプブリカは「信じられないことだが、この人気アニメに関係する名を持つ人が、我が国には何人もいる」と日本アニメの影響力の大きさを報じている。また、各国メディアによるとアルゼンチン、チリ、ブラジルでも登場人物にちなんで名付けられた人がいるという[241]。\\n2019年1月10日に劇場版『ドラゴンボール超 ブロリー』が公開され、封切りとなった水曜深夜の上映で3万4000枚以上のチケットを売上げ、これまで最高だった『アベンジャーズ/インフィニティ・ウォー』を超え、「ペルー史上最も成功した深夜上映」を達成[255]。公開初日の観客動員数は25万7420人を記録し、『アスマーレ2』などを抜き、ペルー史上二番目に多い観客動員数となった[256]。\\n ブラジル\\nブラジルでは、『ドラゴンボール』と『聖闘士星矢』は絶大な人気を誇っており、ブラジルでの両作品に対する熱気は日本のそれ以上の様子である[257]。アニメ『ドラゴンボール』シリーズは1996年から、いくつかのテレビ局で放送され高視聴率を収めており、1996年8月19日に大手テレビ局SBT、1999年に大手テレビ局バンデランテス、2002年にブラジル最大の放送局ヘジ・グローボ局で放送され[258]、2000年頃、バンデランテス局で放送の『ドラゴンボールZ』の視聴率は10%を記録した。その当時は1%が160万人相当で、視聴率10%は1600万人相当にのぼる[259]。\\nコミックスは2000年にConrad Editora社から出版が開始し、2011年5月にConrad Editora社は集英社との取引をキャンセルし『ドラゴンボール』や『ONE PIECE』などの出版が終了となった[260]。2003年当時15日ごとに出版されている新刊は各巻6万部が市場に供給されており、最大の売れ筋となっている[261]。同社から発売されたコミックスの売上は60冊刊行時点で累計約600万部を記録した[132]。2012年からはPanini Comics社より、コミックスが出版されている[262]。\\n パラグアイ\\nパラグアイでも『ドラゴンボール』は大人気であり、パラグアイで日本文化の漫画が圧倒的な人気を博し、その後の根強い愛好家を誕生させたのは『ドラゴンボールシリーズ』の到来によるもので、これに刺激されて2007年からマンガ・コスプレ・アニメ愛好家団体「Mack」を中心として大規模な芸術活動が始まっている[263][264]。\\n コスタリカ\\nコスタリカの子供たちの間では『ドラゴンボール』は知らない人がいないほど関心が高く人気を得ている[265]。\\n ドミニカ共和国\\nドミニカ共和国では、1998年からTelesistema局でテレビアニメが放送され、ドミニカ共和国の歴史上、最も人気のあるアニメ作品となった[266]。\\nヨーロッパ[編集]\\n フランス\\nフランスでは1987年9月2日にTF1にて、ドロテがパーソナリティを務める子供向け番組『クラブ・ドロテ』（Club Dorothée）の放送が開始され[267]、その番組内で1988年3月2日からアニメ版『ドラゴンボール』の放送が開始されるとたちまち人気を博し[268]、1989年当時、東映動画の国際部長だった林幸夫は「フランスではTF1で放送されて視聴率は67.5%を記録。昨年フランスで放送されたテレビアニメで第一位の人気だった」と証言している[269]。1988年にはアニメ雑誌『PIFジャーナル』のテレビフィルムアニメーション部門アニメグランプリ「金のトリュフ賞」を受賞[270]、1991年にはTF1局の番組『クラブドロテ』の優秀アニメーション賞第1位、1995年には『ドラゴンボールZ』が再び同賞第1位を受賞した[271]。1995年10月末から行われた『ドラゴンボールZ 復活のフュージョン!!悟空とベジータ』と『ドラゴンボールZ 龍拳爆発!!悟空がやらねば誰がやる』2作品一挙上映では、パリおよび近郊都市でのロングラン上映を含め、全仏140館で上映され、3週間で33万人を動員する大ヒットとなった[205]。『クラブ・ドロテ』の最盛期には4歳 - 14歳の65%が視聴するという、まさに「お化け番組」であり、放送終了後、子供たちは日本アニメの喪失感に襲われた[272]。\\n1993年5月17日から、グレナ社よりフランス語版コミックスが出版され[273]、1996年にテレビアニメの放送終了後にマンガの人気に火をつけた。テレビでアニメを見ることができなくなった子供たちの一部はマンガに流れ、それまで日本のアニメを見る層は必ずしもマンガを読む層ではなかったが、『クラブ・ドロテ』の終焉により、視聴率65%を支えていた視聴者の一部はマンガを読むようになった。中でも『ドラゴンボール』は大人気となり、『AKIRA』はマニア受けする作品であったが、マンガをフランスの大衆に根付かせたのは『ドラゴンボール』であり、こうしてビッグタイトルを得たグレナ社は、フランスのマンガ出版をリードする会社となった[272]。\\n\\n\\nフランス語版コミックス売上推移\\n出典\\n\\n\\n2005年、年間売上部数\\n151万6259部\\n[274]\\n\\n\\n2007年、年間売上部数\\n92万249部\\n[275]\\n\\n\\n2008年、年間売上部数\\n87万8807部\\n\\n\\n2009年、年間売上部数\\n73万4320部\\n[276]\\n\\n\\n2010年、年間売上部数\\n57万4965部\\n\\n\\n2011年、年間売上部数\\n35万4901部\\n[277]\\n\\n\\n2017年、年間売上部数\\n44万5000部\\n[278]\\n\\n\\n2021年、年間売上部数\\n186万7934部\\n[279]\\n\\n\\n2004年時点累計発行部数\\n1000万部\\n[280]\\n\\n\\n2012年時点累計発行部数\\n2000万部\\n[281]\\n\\n\\n2022年時点累計発行部数\\n2600万部\\n[282]\\n\\n\\n2023年時点累計発行部数\\n2800万部\\n[283]\\n\\n※ジャック・グレナによると、2017年時点で3000万部[119]、2019年時点で約3500万部[284]との事だが、グレナ社によると上記の2800万部が現在の部数。\\n2017年4月にグレナ社より発売された『ドラゴンボール超』コミックス第1巻は『ONE PIECE』、『ワンパンマン』などの作品を上回る、新作タイトルとしては異例の10万部以上を売上げ、2017年のフランスのコミックス売上ランキングで2位を記録した[285]。2018年1月に発売された『ドラゴンボール超』コミックス第3巻も10万部以上を売上げ、『ワンパンマン』や『約束のネバーランド』を上回り、日本の漫画では1番の売上を記録した[286]。\\n在フランス日本国大使館が毎年行っている「フランスで最も有名な日本人」の調査で鳥山明が選ばれた年もあって[287]、2004年当時、文化庁主催の特別講演で浜野保樹は「（選ばれているのは）ずっと鳥山明」と証言していた[288]。フランス・アングレームで2013年1月31日から2月3日まで開かれていた国際漫画祭で、鳥山は「40周年特別賞」を受賞した[289]。2019年5月30日にフランス文化省から、芸術・文学の領域での創造をフランスや世界での普及に傑出した功績のあった人物として、鳥山明はフランスの名誉勲章「芸術文化勲章・シュヴァリエ」を受章した[290][291]。\\nフランス・カンヌで2013年4月に開かれた世界最大級の国際テレビ番組見本市「MIPTV」50周年記念では、世界中の過去50年に放送されたテレビ番組の中から、世界のテレビ史に功績を残し影響を与えた番組として毎年1作ずつ選ぶ方式により、主催者側が選んだ「世界のテレビを変えた50作」として日本から『鉄腕アトム』『UFOロボ グレンダイザー』『加トちゃんケンちゃんごきげんテレビ』『ドラゴンボールGT』の4作が選ばれており、『ドラゴンボールGT』は1996年における世界中の番組から功績を残し影響を与えた作品として選ばれている[292][293]。\\n2013年8月21日 - 8月23日の期間中、パシフィコ横浜にて開催されたCEDEC2013で、セッションが事前にフランスのゲームサイトで募集したアンケートの結果が公開され、実に6400人から回答があり「一番最初に見た日本のアニメ／戦隊もの／映画は？」では圧倒的な票数で『ドラゴンボール』が1位を獲得し、「好きな日本のマンガは？」、「好きな日本のアニメは？」の調査でも、いずれも『ドラゴンボール』が1位を獲得した[294]。\\n2018年2月25日にパルク・デ・プランスで行われたリーグ・アン第27節、パリ・サンジェルマンFC対オリンピック・マルセイユとの試合で、PSGサポーターがゴール裏に巨大な孫悟空の絵（コレオグラフィー）を掲げたことが話題となっている。観客席には、6つのドラゴンボールをかたどった円形のフラッグも揃えられ、それぞれに「1986、1994、2013、2014、2015、2016」という数字も添えられている。数字はPSGがこれまでリーグアンで6回優勝した年を表し、7つの「ドラゴンボール」を集めれば願いが叶うという『ドラゴンボール』のストーリーに沿って、今季7度目のリーグ制覇を成し遂げたとすれば、チャンピオンズリーグ（CL）初優勝という悲願も叶うという意味が込められている[295]。\\n2019年7月4日から7月7日にかけて、パリ近郊で開催されたJapan Expoが今回で20回目の開催となったことに合わせてフランスの日刊紙ル・モンドが「日本の傑作漫画20選」を独自に選んで発表し、本作もその一つに選ばれた[296]。\\n ドイツ\\nドイツでは、現在も『ドラゴンボール』は絶大な人気を誇っており、テレビアニメはヨーロッパ最大のメディアグループRTLグループ所属のRTL IIにて、1999年8月30日から『ドラゴンボール』、2001年8月27日から『ドラゴンボールZ』、2006年10月20日から『ドラゴンボールGT』が放送され[297]、『ドラゴンボールZ』はRTL2で放送されていたリアリティ番組ビッグ・ブラザーの時間帯に放送を開始し、2002年に『ドラゴンボールZ』は最高の評価を得た[298]。2002年5月8日放送のエピソード257では117万人の視聴者を集め、14歳 - 49歳の間では、9.0%の市場シェアを獲得、同年6月5日のエピソードでは3歳以上で137万人が視聴し、291番目のエピソード「Auf eine neue！」では、6.5%の市場シェアを記録し、14歳 - 49歳は9.0%のシェアを達成した。ドイツでは、今日までテレビアニメで100万人を超える視聴者は想像もつかない規模であり、如何に『ドラゴンボールZ』の数字が大きなものだったのかを示した[299]。\\nコミックスは1997年にCarlsen Verlag社からドイツ語版のコミックスを刊行開始し、売上げは爆発的な伸びを見せ、2007年までに650万部を記録し、ドイツで日本漫画ブームの火つけ役となった[300]。2015年時点で800万部以上を記録し、「ドイツで最も人気のある漫画」である[130][131]。また、第1巻の売上は2021年5月時点で、38万6000部を記録。この数字は1冊の売上としてはドイツで販売されている漫画の中で最も売れている数字である[301]。\\n ポーランド\\nポーランドでは、2001年にJPF社からポーランド語版の漫画が販売されており、『ドラゴンボール』の漫画を隔週で出し続けた2001年 - 2002年はポーランド漫画市場の最盛期となり、通常、漫画を買わないポーランドの若年層までも『ドラゴンボール』だけは買う、という特殊な現象があった。『ドラゴンボール』がヒットした最盛期（2002年）には、同社の年間売上高が500万ズロチ（約2億2500万円）相当に達し、今日に至るまで、JPF社はポーランド・マンガ市場におけるリーダー的存在となった[302]。2017年にJPF社の編集長Andrzej Kownackiは「我が社で最も人気が高いのは『ドラゴンボール』で、現在までそれを上回る作品はいない」と語った[303]。2018年2月28日から『ドラゴンボール超』の漫画が発売されている[304]。\\n イタリア\\nイタリアでは、1989年に「Junior Tv」でアニメ『ドラゴンボール』の最初のエピソード1話から54話のみが放送され、1996年にイタリアの大手メディアグループメディアセットが権利を取得し、1996年から新たに放送が開始され[305]、1999年には大手テレビ局「Italia1」で『ドラゴンボールZ』と『ドラゴンボールGT』の放送が開始し、その後、何度も再放送されるなど『ドラゴンボール』シリーズはイタリアで絶大な人気を得ている。2005年12月から2009年6月まで「Italia1」で放送されたシリーズは、「平均視聴者数200万人、最高視聴者数350万人」を記録するなど、極めて高いシェアを獲得している[306]。\\n2016年12月23日から、「Italia1」で『ドラゴンボール超』の放送が開始され、12月23日放送のエピソード1で、147万人の視聴者と8.8%のシェアを獲得、12月30日放送のエピソード8は、175万1000人の視聴者と9.9%のシェアを獲得、2017年1月5日放送のエピソード14では、193万1000人の視聴者と10.21%のシェアを獲得し、その後も高い視聴者数とシェアを獲得しており、平均視聴者数は132万人に達する。イタリアのみならず『ドラゴンボール超』はフランス、スペイン、ポルトガルなど、ヨーロッパ各国でも高い視聴率を記録しており、東映アニメーションヨーロッパ社長のRyuji Kochiは「ドラゴンボールは、ヨーロッパ各地で絶賛され評価されており、ドラゴンボールシリーズは、3世代におよぶファンによって受け入れられている文化的な定番作品です。2017年の国際テレビ番組見本市「MIPTV」に参加する際には新しい放送パートナーシップを創り出すことを楽しみにしています」と語った[307][308]。\\nコミックスは1995年にスターコミックス社からページ数を少なくした分冊版が1995年から1997年にかけて全62巻出版された[309][310]。1998年からはDragon Ball Deluxe（豪華版）が2001年までに全42巻出版された[311]。このシリーズは1990年代後半から2000年代前半までの間に、各巻ごとに15万部以上を売り上げ、ベストセラーとなった[312]。スターコミックス社から出版されている単行本は2021年時点で1600万部の売上を記録[125]。\\nパニーニ社からも出版されており、パニーニ社のキオスク版は2002年当時、毎月50万部を売り上げ[313]、2007年2月時点でイタリアにおける売れ筋漫画ランキングで『ドラゴンボール』が1位となった[314]。\\n スペイン\\nスペインでは、1990年2月8日にTVGでガリシア語版のタイトル「As Bolas Máxicas」で放送開始、1990年2月15日にカタルーニャ州の放送局TV3でカタルーニャ語版のタイトル「Bola de Drac」で放送開始されるなど、いくつかの地方のテレビ局でアニメ『ドラゴンボール』の放送が開始されると、その暴力的な要素ゆえに多くの批判を引き起こしたが、一方であらゆる年代にわたる熱心なファン層をつくりだした[315]。特にカタルーニャでは、放送開始以来、若者の間で大きな人気を集め、社会現象となるほどの大ブームとなった[316]。その後、アンテナ3でスペイン全土で放送されて70%の視聴率を獲得した[205][317]。\\nコミックスは、1992年5月にプラネタ・デアゴスティーニ社から、カタルーニャ語とスペイン語に翻訳された毎週刊行のホワイトシリーズ（分冊版）が発売開始し、第1巻の発行部数はカタルーニャ語版10万部、スペイン語版5万部を記録し、爆発的な成功を収め、その大きな成功は他の出版社を勇気づけ、数多くの新しい日本の作品がリリースされることとなった[315][316]。隔週で刊行されたレッドシリーズは1冊あたり10万部以上の売上げを記録し、このシリーズはスペインの漫画記録をすべて破り、「スペイン出版史上60年ぶりの大ヒット」となった[205][318]。2013年時点での累計発行部数は2000万部を記録した[124]。\\n2017年から、Planeta Cómic社よりカタルーニャ語とスペイン語に翻訳された漫画『ドラゴンボール超』の2つのバージョンが出版されている。日本と同様の通常版と過去に出版されたレッドシリーズの続編として、1話ごとに単行本化したものが発売されている[319]。\\n2017年11月1日 - 5日の期間中、スペインで『ドラゴンボール』のコミックス出版25周年を記念して、コミック、アニメ、ゲームの本作に関するイベントが開催された[320]。\\nヨーロッパのプロサッカーリーグでも反響を呼んでおり、2016年9月13日にFCバルセロナのネイマールは自身のTwitterにリオネル・メッシとの2ショット写真とともに「FUSAO」（ポルトガル語でフュージョンを意味する）に炎マークに指を向かい合わせる絵文字を添え、さらに「Sayajin」（サイヤ人）のハッシュタグを添えて投稿し話題を呼んだ[321]。2017年9月16日にリーガ・エスパニョーラ公式SNSに柴崎岳と孫悟空のコラージュ画像が投稿され、大きな反響を呼んだ[322]。2018年6月1日にレアル・ベティスは、サッカー日本代表乾貴士の獲得を発表し、ベティスがSNSに公開した公式動画は、『ドラゴンボール』などを用いたものであり、公開から14時間ほどですでに140万回視聴され、世界的に著名な日本アニメだけにスペインだけに留まらず、イタリアのメディアも報じるなど、ヨーロッパ各国でも話題となっている[323]。\\n ポルトガル\\nポルトガルでは、1995年にSICテレビ局でテレビアニメが放送開始し、今日まで繰り返し再放送が行われるほど成功を収めている。2016年以降、同局にて『ドラゴンボール超』が放送されており、高視聴率を記録した[307][324]。コミックスはスペインの出版社Planeta DeAgostiniから出版されている。\\n イギリス\\nイギリスでは、2005年にGollancz Mangaからコミックスが出版され、漫画版『ドラゴンボールZ』の4巻まで出版し、以降はViz Mediaがライセンスを引き継ぐ形で出版している[139]。イギリスの制作会社「K＆K productions」が『ドラゴンボール』のファンムービーを製作し反響を呼んだ[325]。\\n2019年1月23日に劇場版『ドラゴンボール超 ブロリー』が公開され、観客動員数約10万人、興行収入約100万ポンドを記録した。Manga Entertainment社によると「日本の劇場用アニメ作品の興行収益としては『千と千尋の神隠し』に次ぐ歴代2位の収益」である[326]。\\n家庭用ゲームソフト『ドラゴンボール ファイターズ』はイギリスのUKチャート2018年1/21〜27のランキングで、『ドラゴンボール』シリーズ最高となる2位を獲得した[327]。2020年1月17日に英国で発売された『ドラゴンボールZ カカロット』は2020年1月18日付けの販売チャートで1位を獲得した[328]。\\n\\xa0デンマーク\\nデンマークではForlaget Carlsen社が1998年からデンマーク語で単行本を翻訳・発行を開始した。同国においては人口が550万人ほどであるにも拘らず、150万部を超える販売部数を記録している[134]。\\n\\xa0スウェーデン\\nスウェーデンでは、Bonnier Carlsen社からスウェーデン語で翻訳・発行され『ドラゴンボール』のコミックスが4巻までの合計で120万冊売れている[329]。\\n\\xa0フィンランド\\nフィンランドでは、2003年にSangatsu Manga社から単行本が出版されベストセラーとなったが、一時、亀仙人の児童に対するセクハラ描写が国会で問題になったことや[330]、4巻を出版した時点で「児童ポルノにあたる描写がある」という理由で一時期販売禁止になったことがある[331][332]。後に全巻が出版されたが、一部修正が施されている（フィンランド語版ウィキペディア参照）。アニメも放送されたが、こちらも児童ポルノを連想させるシーンが夕方の放送にふさわしくないという理由で、番組の途中で急遽放送が中断され夜中に再放送されたことがあった[333]。\\n\\xa0ハンガリー\\nハンガリーでは、Semic社から1999年に『ドラゴンボール』の漫画が連載され、出版されている。テレビアニメはRTL Klubチャンネルで『ドラゴンボール』と『ドラゴンボールZ』が放送された[334]。\\n中東・アフリカ[編集]\\n中東やアラブ世界では、アラブ首長国連邦のドバイに拠点を構えるアニメ専門チャンネルSpacetoonでテレビアニメが放送されており[335]、各国で人気を博している[336]。\\nアフリカにおいては、北アフリカなどで「Spacetoon」でアニメが放送された。南アフリカでも『ドラゴンボール』や『ポケットモンスター』は有名であり[337]、カメルーンの首都ヤウンデで開催された日本文化祭では、青年協力隊有志による『ドラゴンボール』の主題歌が演奏され会場全体が大盛り上がりであった[338]。ベナンではフランス語版の単行本が出版されている[339]。\\n2020年3月16日から、カートゥーン ネットワーク アフリカのキッズチャンネルでアニメ『ドラゴンボール超』の放送が開始している。キッズコンテンツディレクターのアリアン・スベッグは「ドラゴンボール超の世界的な人気は、アフリカの家庭やアニメファンにまっちするのに最適です」と語り、「ドラゴンボール超はまったく新しいドラゴンボール時代の幕開けであり、まったく新しい世代の子供たちのグループが今や友達と一緒にスーパーサイヤンを見ようとしていることを知っています」と語った[340][341]。\\n\\n イスラエル\\nイスラエルでは、2015年に本作のファンクラブが設立され、8300人が加入してるイスラエルで最大のファンクラブの1つであり、アニメ・マンガ共に盛んな人気を誇っている[342]。また、テレビアニメも放送されており、子供たちの間で最も人気のアニメとして挙げられている[343]。\\n映画『ドラゴンボール超 スーパーヒーロー』の上映イベントで、かめはめ波を1度に放つ人数記録に会場に集まった974人のファンにより、かめはめ波が披露され、従来の記録であった2019年にアメリカ・サンディエゴで達成された784人を上回り、ギネス世界記録を更新した[342]。\\nアジア[編集]\\n日本以外のアジアにおいては、中国や韓国などアジア各国で海賊版が多数出回り、タイでは20社に及ぶ出版社が海賊版を発行するという「タイのドラゴンボール争奪戦」というものが起こるなど[344]、版権元を悩ませている。アジアでの本作の呼び名は、中国本土では「龍珠」、または「七龍珠」、香港では「龍珠」、台湾では「七龍珠」、マレーシアでは「Mutiara Naga」（龍の真珠）と呼ばれている。\\n\\n 中国\\n中国でも1989年頃から長きに渡り複数の海賊版が横行し2005年時点で1億部以上が出回ったとも言われており[345]、2005年に中国少年児童出版社から「龍珠」とのタイトルで正規版の刊行が開始し、発売100日で100万部を達成した[346]。その後も増刷が繰り返されるほど人気が高く、2009年12月までに累計販売数は669万冊を記録。この数字は2009年時点で中国で販売されている日本の漫画作品の中でトップの数字である[347]。2013年時点での正規版累計発行部数は1000万部以上を記録[126]。\\n2014年7月に来日した映画監督のチャウ・シンチーは会見で、中国香港合作映画『西遊記〜はじまりのはじまり〜』を制作する上で『ドラゴンボール』から大いに影響を受けたと語っており[348]、同映画を絶賛した鳥山がポスターを描き下ろしている[349]。2017年には中国のメディアで2020年東京オリンピックの公式マスコットに孫悟空が選ばれたと報じられ、ネット上を賑わしているなど、中国でも『ドラゴンボール』やその登場人物を愛する人が少なくないことが改めて浮き彫りになった[350]。\\n2019年11月5日に中国テンセント社より、新作スマートフォンゲーム『龍珠最強之戦（ドラゴンボール最強バトル）』のサービスが開始された。事前登録者数は1300万アカウントを突破するなど大きな期待を集めている[351]。\\n 香港\\n香港では、1992年以降に文化傳信（英語:CULTURE COM）社から「龍珠」というタイトルで単行本が発売されており[352]、『ドラゴンボール』や『SLAM DUNK』は毎巻15万部を超える売上を記録した[353]。第1巻は重版が繰り返され30万部と大ヒットした[354]。\\n 中華民国\\n台湾でも『ドラゴンボール』の人気が高く、「七龍珠」と言えば、たいていの人が「ピンとくる」という[355]。漫画は1992年9月から東立出版社有限公司の週刊誌「宝島少年」で「七龍珠」とのタイトルで連載された。アニメは台湾電視公司で放送され、アニメの映像ソフトも発売されている[205]。2017年に完全版15周年を記念して、鳥山の複製サイン色紙付きの完全版ボックスが発売された[356]。\\n 韓国\\n韓国では、1989年にソウル文化社から連載がスタートしたコミックスの正規流通の販売数は1冊あたり約50万冊に達する。当時は海賊版も大々的に出回っており、出版元が10か所以上にのぼるほどの超人気作品であった[357]。ソウル文化社のグァクヒョンチャン局長は「1990年代初めのドラゴンボールの人気はすごかった。シリーズが公開されるたびに、いくつかの業者が海賊版まで製作、販売して警察に告発して苦労した。毎号10万部ほどだった漫画雑誌『IQジャンプ』がドラゴンボールを連載して以降、60万部も売れた」と語った[121]。2009年頃にはコミックスの販売部数が2000万部を記録した。韓国3大漫画出版社のソウル文化社と鶴山文化社の調査でも『ドラゴンボール』と『SLAM DUNK』は歴代コミック販売部数1、2位を占め、ソウル文化社と鶴山文化社の関係者たちは、この2作品の人気は今も衰えることを知らないと語った[121]。\\n2008年2月14日にバンダイコリアは、ソウル市内のホテルでプレスカンファレンスを行い、日韓共同で開発中の『ドラゴンボールオンライン』の内容をマスコミ向けに公開し、会場には世界的な人気を誇る『ドラゴンボール』で初となるMMORPGの発表会とあって韓国国内から約40社のメディアが集まり、本作に対する期待の高さを印象付けた。原作側を代表して集英社取締役の鳥嶋和彦は「韓国はドラゴンボールが日本以外で初めて出版され、そこから世界中に人気が広がるきっかけとなった国。その韓国でドラゴンボールオンラインを始められることをうれしく思います」とコメントした[358]。\\n 北朝鮮\\n北朝鮮では、2004年6月21日に朝鮮中央テレビで『ドラえもん』とほぼ同一と見られる映像が流れ、主題歌が流されているシーンでは『ドラゴンボール』の一場面が放送されたが、『ドラゴンボール』の放送権を持つフジテレビは「北朝鮮のテレビ局とのリレーションは全くない」と映像協力はしておらず、無断使用とみられる。北朝鮮では1日に1回アニメ番組を放送しているが、著作権といった概念がなく、日本への関心の高まりと分析される[359]。\\n\\xa0ベトナム\\nベトナムでは、1995年にキムドン社から「7 Viên Ngọc Rồng」（七つの龍の球）のタイトルで全67巻が出版され[360]、大ヒットを記録した。しかし、90年代当時に出回っていた日本の漫画はすべて海賊版であった。2005年にベトナムがベルヌ条約に加盟し、ベトナム各出版社は日本から正式にライセンスを取るようになり、これを機に海賊本は急激に姿を消していった[140]。2018年10月5日から漫画『ドラゴンボール超』が出版開始し、過去のシリーズも再発行されている[361]。\\n インドネシア\\nインドネシアでは、Elex Media Komputindo出版社からコミックスが出版された。2016年5月から色彩も新たにしたコミックスが同社より出版されている[362]。\\n タイ\\nタイでは、1996年1月からテレビアニメが放送開始した[205]。2014年に開催されたTOKYO GIRLS TOWNで日本代表のSOLIDEMOがタイで最も有名な日本のアニメソングのひとつと言われる『CHA-LA HEAD-CHA-LA』を熱唱し、集まったタイの観客たちは大熱狂であった[363]。\\n フィリピン\\nフィリピンでは、GMA-7でテレビアニメが放送され、好評を博した[205]。2018年の視聴率ランキングに『ドラゴンボールZ』と『ドラゴンボール改』がランクインするなど、現在も人気を得ている[364]。\\n オーストラリア\\nオーストラリアでは、ネットワーク・テンの子供向け番組Cheez TVでアニメが放送され、『ドラゴンボール』や『ポケットモンスター』などの作品が人気を博した[365]。\\n東映アニメーションはABC Australiaとの契約を結び、2018年11月3日からABC MEネットワークで『ドラゴンボール超』の放送が開始されている[366]。\\n上記で紹介した国々の他にロシア、ホンジュラス、ベネズエラ、グアテマラ、エルサルバドル、ニカラグア、コスタリカ、パナマ、エクアドル、パラグアイ、ボリビア、ウルグアイ、バチカン市国、スイス、トルコ、ギニア、キプロス、ベトナム、インドネシア、シンガポール、マレーシア、タイ、カンボジア、アフガニスタン、パプアニューギニア、アイスランド、東ティモール、ドミニカ共和国、中国、韓国、香港などの国と地域でテレビアニメが放送された[367]。\\n書誌情報[編集]\\n単行本[編集]\\n鳥山明 『ドラゴンボール』 集英社〈ジャンプ・コミックス〉、全42巻\\u3000\\n「孫悟空と仲間たち」1985年9月10日発売[368]、ISBN\\xa04-08-851831-4\\n「ドラゴンボール危機一髪」1986年1月10日発売[369]、ISBN\\xa04-08-851832-2\\n「天下一武道会はじまる!!」1986年6月10日発売[370]、ISBN\\xa04-08-851833-0\\n「大決勝戦」1986年10月9日発売[371]、ISBN\\xa04-08-851834-9\\n「マッスルタワーの恐怖」1987年1月9日発売[372]、ISBN\\xa04-08-851835-7\\n「ブルマの大失敗!!」1987年3月10日発売[373]、ISBN\\xa04-08-851836-5\\n「追跡!!ブルー将軍」1987年5月8日発売[374]、ISBN\\xa04-08-851837-3\\n「孫悟空突撃」1987年7月10日発売[375]、ISBN\\xa04-08-851838-1\\n「こまったときの占いババ」1987年9月10日発売[376]、ISBN\\xa04-08-851839-X\\n「第22回天下一武道会」1987年11月10日発売[377]、ISBN\\xa04-08-851840-3\\n「天下一のスーパーバトル!!」1988年2月10日発売[378]、ISBN\\xa04-08-851608-7\\n「ピッコロ大魔王の恐怖!」1988年4月8日発売[379]、ISBN\\xa04-08-851609-5\\n「孫悟空の逆襲!?」1988年6月10日発売[380]、ISBN\\xa04-08-851610-9\\n「さらなる飛躍」1988年8月10日発売[381]、ISBN\\xa04-08-851611-7\\n「群雄割拠!」1988年12月6日発売[382]、ISBN\\xa04-08-851612-5\\n「龍虎相討つ!」1989年2月10日発売[383]、ISBN\\xa04-08-851613-3\\n「かつてない恐怖」1989年5月10日発売[384]、ISBN\\xa04-08-851614-1\\n「孫悟飯とピッコロ大魔王」1989年7月10日発売[385]、ISBN\\xa04-08-851615-X\\n「いそげ!孫悟空」1989年11月10日発売[386]、ISBN\\xa04-08-851616-8\\n「天下分け目の超決戦!!」1990年1月10日発売[387]、ISBN\\xa04-08-851617-6\\n「めざせ!ナメックの星」1990年4月10日発売[388]、ISBN\\xa04-08-851618-4\\n「ナメック星人の抵抗」1990年7月10日発売[389]、ISBN\\xa04-08-851619-2\\n「恐怖のギニュー特戦隊」1990年10月8日発売[390]、ISBN\\xa04-08-851620-6\\n「悟空か!?ギニューか!?」1991年1月10日発売[391]、ISBN\\xa04-08-851414-9\\n「フリーザ超変身!!」1991年3月8日発売[392]、ISBN\\xa04-08-851415-7\\n「孫悟空…復活!!」1991年6月10日発売[393]、ISBN\\xa04-08-851416-5\\n「伝説の超サイヤ人」1991年8月7日発売[394]、ISBN\\xa04-08-851417-3\\n「未来から来た少年」1991年11月8日発売[395]、ISBN\\xa04-08-851418-1\\n「悟空、敗れる!」1992年3月10日発売[396]、ISBN\\xa04-08-851419-X\\n「邪悪な予感」1992年6月10日発売[397]、ISBN\\xa04-08-851420-3\\n「忍びよるセル」1992年8月4日発売[398]、ISBN\\xa04-08-851686-9\\n「セルの完全体 完成!!」1992年10月2日発売[399]、ISBN\\xa04-08-851687-7\\n「セルゲーム始まる」1992年12月26日発売[400]、ISBN\\xa04-08-851688-5\\n「悟空を超えた戦士」1993年6月4日発売[401]、ISBN\\xa04-08-851689-3\\n「さようなら戦士たち」1993年9月3日発売[402]、ISBN\\xa04-08-851700-8\\n「ニューヒーロー誕生!!」1993年11月4日発売[403]、ISBN\\xa04-08-851495-5\\n「動き始めた作戦」1994年4月4日発売[404]、ISBN\\xa04-08-851496-3\\n「宿命の対決 孫悟空対ベジータ」1994年8月4日発売[405]、ISBN\\xa04-08-851497-1\\n「さらば誇り高き戦士」1994年12月2日発売[406]、ISBN\\xa04-08-851498-X\\n「地球軍、最後の秘密兵器!!」1995年3月3日発売[407]、ISBN\\xa04-08-851499-8\\n「がんばれ超ゴテンクスくん」1995年6月2日発売[408]、ISBN\\xa04-08-851500-5\\n「バイバイ ドラゴンワールド」1995年8月4日発売[409]、ISBN\\xa04-08-851090-9\\n非売品\\n鳥山明描き下ろし脚本完全収録 巻『F』2015年4月18日発行、映画『ドラゴンボールZ 復活の「F」』入場者特典\\n当初は43巻まで発売する予定だったが、「早く読んでもらいたい」という鳥山の意向により42冊で完結することになり、41巻と42巻は通常より約50ページ厚いものになった[410]。\\n\\n完全版[編集]\\n鳥山明 『DRAGON BALL 完全版』 集英社〈完全版コミックス〉、全34巻\\n2002年12月4日発売[411]、ISBN\\xa04-08-873444-0\\n2002年12月4日発売[412]、ISBN\\xa04-08-873445-9\\n2002年12月28日発売[413]、ISBN\\xa04-08-873446-7\\n2002年12月28日発売[414]、ISBN\\xa04-08-873447-5\\n2003年2月4日発売[415]、ISBN\\xa04-08-873448-3\\n2003年2月4日発売[416]、ISBN\\xa04-08-873449-1\\n2003年3月4日発売[417]、ISBN\\xa04-08-873450-5\\n2003年3月4日発売[418]、ISBN\\xa04-08-873451-3\\n2003年4月4日発売[419]、ISBN\\xa04-08-873452-1\\n2003年4月4日発売[420]、ISBN\\xa04-08-873453-X\\n2003年5月1日発売[421]、ISBN\\xa04-08-873454-8\\n2003年5月1日発売[422]、ISBN\\xa04-08-873455-6\\n2003年6月4日発売[423]、ISBN\\xa04-08-873456-4\\n2003年6月4日発売[424]、ISBN\\xa04-08-873457-2\\n2003年7月4日発売[425]、ISBN\\xa04-08-873458-0\\n2003年7月4日発売[426]、ISBN\\xa04-08-873459-9\\n2003年8月4日発売[427]、ISBN\\xa04-08-873460-2\\n2003年8月4日発売[428]、ISBN\\xa04-08-873461-0\\n2003年9月4日発売[429]、ISBN\\xa04-08-873462-9\\n2003年9月4日発売[430]、ISBN\\xa04-08-873463-7\\n2003年10月3日発売[431]、ISBN\\xa04-08-873464-5\\n2003年10月3日発売[432]、ISBN\\xa04-08-873465-3\\n2003年11月4日発売[433]、ISBN\\xa04-08-873466-1\\n2003年11月4日発売[434]、ISBN\\xa04-08-873467-X\\n2003年12月4日発売[435]、ISBN\\xa04-08-873468-8\\n2003年12月4日発売[436]、ISBN\\xa04-08-873469-6\\n2004年1月5日発売[437]、ISBN\\xa04-08-873470-X\\n2004年1月5日発売[438]、ISBN\\xa04-08-873471-8\\n2004年2月4日発売[439]、ISBN\\xa04-08-873472-6\\n2004年2月4日発売[440]、ISBN\\xa04-08-873473-4\\n2004年3月4日発売[441]、ISBN\\xa04-08-873474-2\\n2004年3月4日発売[442]、ISBN\\xa04-08-873475-0\\n2004年4月2日発売[443]、ISBN\\xa04-08-873476-9\\n2004年4月2日発売[444]、ISBN\\xa04-08-873477-7\\n完全版の最終巻では、魔人ブウとの最終決戦における決着シーンと、最終話の悟空とウーブの旅立ちのシーンの数か所に鳥山が4ページ分加筆している。そのため、先に発売されている通常版と完全版とでは最終話のニュアンスが変わっており、鳥山が本来込めた意図が完全版ではより明確になっている。連載終了までの経緯で触れた、通常のコミックスの最終話にあった作者による完結の経緯の説明は、完全版では削除されている。\\n\\n完全版第34巻の追加部分\\n183頁1コマ目：魔人ブウのカット。\\n184頁6コマ目：ベジータの表情とセリフ変更。\\n185頁：悟空のコマ拡大、ベジータのカット追加。\\n229-231頁：悟空とウーブのやり取り変更。\\n232頁：作者の挨拶がベジータのカットに変更。\\nその他の変更点\\n原画の紛失により2色カラーの扉絵が一部CGで塗り直されている（其之五、其之八十六）。\\n其之五の扉絵のブルマのくわえタバコが削除。\\n巻末に掲載されている扉絵のアオリ文の削除（ただし、紛失した白黒ページのトビラ絵は『週刊少年ジャンプ』掲載時のものを使っているため線が荒く、アオリ文がそのまま掲載されている）。\\nピラフ一味のシュウ（ソバ）の名前を初期設定のソバに統一。これにより関連したセリフも差し替えられた（其之百十）。\\n完全版第25巻91頁3コマ目のセリフが「オレ」から「オラ」に修正。\\nセルゲームの日付が「Mの17日」から「5の26日」に変更[注釈 4]。\\n外国語版[編集]\\n\\n\\n国・地域\\n\\n出版社\\n\\n言語\\n\\n題名\\n\\n参照\\n\\n\\n アメリカ合衆国\\n\\nViz Media\\n\\n英語\\n\\nDRAGON BALL\\n\\n[445]\\n\\n\\n カナダ\\n\\n[446]\\n\\n\\n イギリス\\n\\n[139]\\n\\n\\n オーストラリア\\n\\n[447]\\n\\n\\n ニュージーランド\\n\\n[447]\\n\\n\\n インド\\n\\n[448]\\n\\n\\n フランス\\n\\nGlénat\\n\\nフランス語\\n\\n[273]\\n\\n\\n オランダ\\n\\nGlénat Benelux\\n\\nオランダ語\\n\\n[449]\\n\\n\\n スペイン\\n\\nPlaneta deAgostini\\n\\nスペイン語\\n\\n[450]\\n\\n\\n カタルーニャ州\\n\\nカタルーニャ語\\n\\nBola de Drac\\n\\n[451]\\n\\n\\n ポルトガル\\n\\nポルトガル語\\n\\nDRAGON BALL\\n\\n[452]\\n\\n\\n イタリア\\n\\nStar Comics\\n\\nイタリア語\\n\\n[125]\\n\\n\\n ドイツ\\n\\nCarlsen Verlag\\n\\nドイツ語\\n\\n[131]\\n\\n\\n\\xa0スウェーデン\\n\\nBonnier Carlsen\\n\\nスウェーデン語\\n\\n[453]\\n\\n\\n\\xa0デンマーク\\n\\nForlaget Carlsen\\n\\nデンマーク語\\n\\n[134]\\n\\n\\n\\xa0フィンランド\\n\\nSangatsu Manga\\n\\nフィンランド語\\n\\n[454]\\n\\n\\n\\xa0ノルウェー\\n\\nOutland Forlag\\n\\nノルウェー語/ブークモール\\n\\n[455]\\n\\n\\n ポーランド\\n\\nJaponica Polonica Fantastica\\n\\nポーランド語\\n\\n[303]\\n\\n\\n\\xa0ハンガリー\\n\\nSemic Interprint\\n\\nハンガリー語\\n\\n[456]\\n\\n\\n 韓国\\n\\nソウル文化社\\n\\n韓国語\\n\\n드래곤볼\\n\\n[121]\\n\\n\\n 中国\\n\\n中国少年児童出版社\\n\\n中国語\\n\\n龙珠\\n\\n[126]\\n\\n\\n 香港\\n\\n文化傳信\\n\\n中国語（繁体字）\\n\\n龍珠\\n\\n[354]\\n\\n\\n 台湾\\n\\n東立出版社\\n\\n七龍珠\\n\\n[355]\\n\\n\\n ブラジル\\n\\nPanini Manga Brazil\\n\\nポルトガル語\\n\\nDRAGON BALL\\n\\n[262]\\n\\n\\n アルゼンチン\\n\\nEditorial Ivrea\\n\\nスペイン語\\n\\n[457]\\n\\n\\n メキシコ\\n\\nPanini Manga México\\n\\n[458]\\n\\n\\n\\xa0コロンビア\\n\\nPanini Manga Colombia\\n\\n[459]\\n\\n\\n ペルー\\n\\nPanini Manga Perú\\n\\n[460]\\n\\n\\n\\xa0チリ\\n\\nPanini Manga Chile\\n\\n[461]\\n\\n\\n\\xa0ベトナム\\n\\nKim Dong\\n\\nベトナム語\\n\\n7 Viên Ngọc Rồng\\n\\n[462]\\n\\n\\n インドネシア\\n\\nElex Media Komputindo\\n\\nインドネシア語\\n\\nDRAGON BALL\\n\\n[463]\\n\\n\\n タイ\\n\\nNED comics\\n\\nタイ語\\n\\n[464]\\n\\n\\n シンガポール\\n\\nChuang Yi\\n\\n中国語（繁体字）\\n\\n七龍珠\\n\\n[465]\\n\\n\\n マレーシア\\n\\nComic Paradise\\n\\nマレー語\\n\\nMutiara Naga\\n\\n[466]\\n\\n\\n ロシア\\n\\nComix-ART\\n\\nロシア語\\n\\nDRAGON BALL\\n\\n[467]\\n\\nフルカラーコミックス[編集]\\n鳥山明 『ドラゴンボール フルカラー』 集英社〈ジャンプ・コミックス〉、全32巻\\n『ドラゴンボール フルカラー サイヤ人編』\\n2013年2月4日発売、ISBN\\xa0978-4-08-870707-5\\n2013年2月4日発売、ISBN\\xa0978-4-08-870708-2\\n2013年2月4日発売、ISBN\\xa0978-4-08-870709-9\\n『ドラゴンボール フルカラー フリーザ編』\\n2013年4月4日発売、ISBN\\xa0978-4-08-870712-9\\n2013年4月4日発売、ISBN\\xa0978-4-08-870713-6\\n2013年4月4日発売、ISBN\\xa0978-4-08-870714-3\\n2013年4月4日発売、ISBN\\xa0978-4-08-870715-0\\n2013年4月4日発売、ISBN\\xa0978-4-08-870716-7\\n『ドラゴンボール フルカラー 人造人間・セル編』\\n2014年4月4日発売、ISBN\\xa0978-4-08-880101-8\\n2014年4月4日発売、ISBN\\xa0978-4-08-880102-5\\n2014年4月4日発売、ISBN\\xa0978-4-08-880103-2\\n2014年5月2日発売、ISBN\\xa0978-4-08-880104-9\\n2014年5月2日発売、ISBN\\xa0978-4-08-880105-6\\n2014年5月2日発売、ISBN\\xa0978-4-08-880106-3\\n『ドラゴンボール フルカラー 魔人ブウ編』\\n2014年6月4日発売、ISBN\\xa0978-4-08-880107-0\\n2014年6月4日発売、ISBN\\xa0978-4-08-880108-7\\n2014年6月4日発売、ISBN\\xa0978-4-08-880109-4\\n2014年7月4日発売、ISBN\\xa0978-4-08-880110-0\\n2014年7月4日発売、ISBN\\xa0978-4-08-880111-7\\n2014年7月4日発売、ISBN\\xa0978-4-08-880112-4\\n『ドラゴンボール フルカラー 少年編』\\n2016年1月4日発売、ISBN\\xa0978-4-08-880571-9\\n2016年1月4日発売、ISBN\\xa0978-4-08-880572-6\\n2016年1月4日発売、ISBN\\xa0978-4-08-880573-3\\n2016年1月4日発売、ISBN\\xa0978-4-08-880599-3\\n2016年2月4日発売、ISBN\\xa0978-4-08-880601-3\\n2016年2月4日発売、ISBN\\xa0978-4-08-880602-0\\n2016年2月4日発売、ISBN\\xa0978-4-08-880603-7\\n2016年2月4日発売、ISBN\\xa0978-4-08-880620-4\\n『ドラゴンボール フルカラー ピッコロ大魔王編』\\n2016年3月4日発売、ISBN\\xa0978-4-08-880621-1\\n2016年3月4日発売、ISBN\\xa0978-4-08-880622-8\\n2016年3月4日発売、ISBN\\xa0978-4-08-880644-0\\n2016年3月4日発売、ISBN\\xa0978-4-08-880645-7\\nフルカラー版は、かつて集英社公式ウェブサイトジャンプランドでフラッシュアニメ形式で毎週公開され、週刊少年ジャンプ公式サイトのマンガオンラインでも期間限定で其之二十三まで公開されていたほか、Yahoo!JAPAN週刊少年ジャンプ特集「ドラゴンボールスペシャル」では、2010年4月から5月までの期間限定で、原作の登場キャラクター名や、すべての台詞、全4万語以上が収録され、検索結果では最大5コマ分のフルカラー原作漫画が表示される検索エンジン「マンガ検索」が公開されていた[468]。\\n彩色した原作コミックスは「DRAGON BALL カラー版」のタイトルで電子書籍としても刊行されており、YouTubeの公式チャンネル「MANGAPOLO」でも無料配信されている。また、カラー版の電子書籍では、ジャンプ・コミックスの第1巻 - 第4巻が「孫悟空修行編」、第5巻 - 第9巻が「レッドリボン軍編」、第10巻 - 第16巻が「ピッコロ大魔王編」、第17巻 - 第20巻が「サイヤ人編」、第21巻 - 第27巻が「フリーザ編」、第28巻 - 第35巻が「人造人間・セル編」、第36巻 - 第42巻が「魔人ブウ編」のシリーズで章分けされている。\\n\\nコミックスのコーナー[編集]\\nとりやまさんのDRAGON BALLコーナー\\n単行本第1巻から第12巻まで行われた。原作に関する質問や、本編では語られてない設定の質問など、読者からの質問に作者の鳥山明が答えていくコーナー。\\n扉ページ大特集\\n単行本の巻末に「扉ページ大特集」として『週刊少年ジャンプ』掲載時の各話の表紙がほぼそのままの形でまとめて掲載されている。なお、各巻の最初の話やページ構成の都合により、第2巻、第37巻、第38巻、第42巻では行われていない。\\n背表紙イラスト\\n単行本の背表紙のイラストは一つの絵として繋がっている。これは単行本の売上を伸ばすための鳥嶋のアイデア[469]。2009年5月から、鳥山が新たに描き下ろした背表紙と表紙のタイトルロゴを変更した新カバー重版が発行された[470]。内容は新書版と同じであるため、背表紙にヤジロベーが2回登場することに言及しているコメントが意味をなさないものとなっている。\\nドラゴンボール大全集[編集]\\n本作の連載終了を記念して出版された全7巻と補足版3巻からなる全集で、表紙は補巻を除き鳥山の描き下ろしである。内容はイラストレーションや世界観などである。『ドラゴンボール』ファンである著名人の寄稿文、各スタッフ座談会、鳥山明のコラムなどが付いた付属冊子の神龍通信付き。\\n\\n鳥山明『ドラゴンボール大全集』集英社、全7巻\\n「COMPLETE ILLUSTRATIONS」1995年6月25日第1刷発行、ISBN\\xa04-08-782751-8\\n「STORY GUIDE」1995年8月9日第1刷発行、ISBN\\xa04-08-782752-6\\n「TV ANIMATION PART1」1995年9月9日第1刷発行、ISBN\\xa04-08-782753-4\\n「WORLD GUIDE」1995年10月9日第1刷発行、ISBN\\xa04-08-782754-2\\n「TV ANIMATION PART2」1995年11月7日第1刷発行、ISBN\\xa04-08-782755-0\\n「MOVIES & TV SPECIAL」1995年12月9日第1刷発行、ISBN\\xa04-08-782756-9\\n「DRAGON BALL 大事典」1996年2月25日第1刷発行、ISBN\\xa04-08-782757-7\\n補足版全3巻\\n「大全集別巻 DBカードダス パーフェクトファイル PART1」1996年2月18日第1刷発行、ISBN\\xa04-08-102016-7\\n「大全集別巻 DBカードダス パーフェクトファイル PART2」1996年4月19日第1刷発行、ISBN\\xa04-08-102017-5\\n「大全集補巻 TV ANIMATION PART3」1996年8月18日第1刷発行、ISBN\\xa04-08-102019-1\\nドラゴンボール超全集[編集]\\n鳥山明『ドラゴンボール超全集』集英社、全4巻\\n「STORY & WORLD GUIDE」2013年2月4日発売、ISBN\\xa0978-4-08-782496-4\\n「ANIMATION GUIDE PART1」2013年3月5日発売、ISBN\\xa0978-4-08-782497-1\\n「ANIMATION GUIDE PART2」2013年4月4日発売、ISBN\\xa0978-4-08-782498-8\\n「超事典」2013年5月9日発売、ISBN\\xa0978-4-08-782499-5\\nDRAGON BALL総集編[編集]\\n週刊少年ジャンプ掲載時を再現した全18巻からなる総集編。各巻には巻頭特大ポスター付き。\\n\\n鳥山明 『DRAGON BALL総集編 超悟空伝』 集英社〈集英社マンガ総集編シリーズ〉、全18巻\\n2016年5月13日発売[471]、ISBN\\xa0978-4-08-111165-7\\n2016年5月13日発売[472]、ISBN\\xa0978-4-08-111166-4\\n2016年5月27日発売[473]、ISBN\\xa0978-4-08-111167-1\\n2016年6月10日発売[474]、ISBN\\xa0978-4-08-111168-8\\n2016年6月24日発売[475]、ISBN\\xa0978-4-08-111169-5\\n2016年7月8日発売[476]、ISBN\\xa0978-4-08-111170-1\\n2016年7月22日発売[477]、ISBN\\xa0978-4-08-111171-8\\n2016年8月5日発売[478]、ISBN\\xa0978-4-08-111172-5\\n2016年8月26日発売[479]、ISBN\\xa0978-4-08-111173-2\\n2016年9月9日発売[480]、ISBN\\xa0978-4-08-111174-9\\n2016年9月23日発売[481]、ISBN\\xa0978-4-08-111175-6\\n2016年10月14日発売[482]、ISBN\\xa0978-4-08-111176-3\\n2016年10月28日発売[483]、ISBN\\xa0978-4-08-111177-0\\n2016年11月11日発売[484]、ISBN\\xa0978-4-08-111178-7\\n2016年11月25日発売[485]、ISBN\\xa0978-4-08-111179-4\\n2016年12月9日発売[486]、ISBN\\xa0978-4-08-111180-0\\n2016年12月23日発売[487]、ISBN\\xa0978-4-08-111181-7\\n2017年1月13日発売[488]、ISBN\\xa0978-4-08-111182-4\\nその他の関連書籍[編集]\\nガイドブック\\n『テレビアニメ完全ガイド ドラゴンボール 天下一伝説』集英社、2004年7月2日、ISBN\\xa04-08-873705-9\\n『ドラゴンボール完全版公式ガイド Dragonball LANDMARK 少年編〜フリーザ編』集英社、2003年12月19日、ISBN\\xa04-08-873478-5\\n『ドラゴンボール完全版公式ガイド Dragonball FOREVER 人造人間編〜魔人ブウ編』集英社、2004年4月30日、ISBN\\xa04-08-873702-4\\n『ドラゴンボール 超エキサイティングガイド ストーリー編』集英社、2009年3月4日、ISBN\\xa0978-4-08-874803-0\\n『ドラゴンボール 超エキサイティングガイド キャラクター編』集英社、2009年4月3日、ISBN\\xa0978-4-08-874804-7\\n『ドラゴンボール極限バトルコレクション ラウンド01 少年編〜フリーザ編』集英社、2010年7月2日、ISBN\\xa0978-4-08-874840-5\\n『ドラゴンボール極限バトルコレクション ラウンド02 セル編〜魔人ブウ編』集英社、2010年8月4日、ISBN\\xa0978-4-08-874841-2\\n『30th ANNIVERSARY ドラゴンボール 超史集 -SUPER HISTORY BOOK-』集英社、2016年1月21日、ISBN\\xa0978-4-08-792505-0\\n画集\\n『ドラゴンボール アニメイラスト集 金色の戦士』発行：ホーム社、販売：集英社、2010年4月16日、ISBN\\xa0978-4-83-428413-3\\n『ドラゴンボール 超画集』集英社、2013年5月9日、ISBN\\xa0978-4-08-782520-6\\nムック\\n『カラーランド ドラゴンボール ブルマと孫悟空の巻』[489] 集英社、1986年4月\\n『ドラゴンボール 冒険SPECIAL』集英社、1987年12月1日\\n『Vジャンプ増刊号 ドラゴンボール超 超スタートガイド』集英社、2015年7月3日\\n『DRAGON BALL ジャンプ ベストシーンTOP10』集英社、2018年11月2日発売、ISBN\\xa0978-4-08-102271-7\\n絵本\\n『DRAGON BALL シールえほん おはなしブック』ホーム社、2010年7月23日、ISBN\\xa0978-4-83-424017-7\\n『DRAGON BALL シールえほん キャラブック』ホーム社、2010年8月20日、ISBN\\xa0978-4-83-424018-4\\n『DRAGON BALL シールえほん クイズブック』ホーム社、2010年8月20日、ISBN\\xa0978-4-83-424019-1\\nフランスでの書籍\\n『AKIRA TORIYAMA et DRAGON BALL - L\\'homme derrière le manga』Pix\\'n Love、2019年4月4日[490]ISBN\\xa0978-2-37-188065-8\\n『LES RECETTES LÉGENDAIRES DE DRAGON BALL』[491]fr:Glénat Manga、2019年10月2日、ISBN\\xa0978-2-344-02795-0\\nその他の書籍\\n『ドラゴンボール占い 〜占いババにおまかせ〜』発行：ホーム社、販売：集英社、2010年3月31日、ISBN\\xa0978-4-8342-8410-2\\n『ドラゴンボール公式クイズブック DRAGON BALL 590 QUIZ BOOK』集英社、2015年5月1日、ISBN\\xa0978-4-08-880405-7\\n関連漫画[編集]\\nドラゴンボールSD[編集]\\n\\n\\nドラゴンボールSD\\n\\n\\nジャンル\\n\\nコメディ\\n\\n\\n漫画\\n\\n\\n原作・原案など\\n\\n鳥山明\\n\\n\\n作画\\n\\nオオイシナホ\\n\\n\\n出版社\\n\\n集英社\\n\\n\\n掲載誌\\n\\n最強ジャンプ\\n\\n\\n発表期間\\n\\n2010年12月 - 連載中\\n\\n\\n巻数\\n\\n既刊9巻（2023年3月現在）\\n\\n\\nテンプレート - ノート\\n\\n\\n『ドラゴンボールSD』（ドラゴンボールエスディー）は、原作・監修/鳥山明、漫画/オオイシナホによるスピンオフ作品。『最強ジャンプ』第1号（2010年12月3日）から連載開始。『最強ジャンプ』は当初は季刊ペースで刊行していたが、2012年1月号（2011年12月3日発売）から月刊化、2014年11月号（2014年10月3日発売）から隔月刊化、2021年9月号（2021年8月4日発売）から再び月刊化した。\\n原作のキャラクターをSD化したリメイク作品。ストーリーは原作に沿って展開されているが、一部キャラクターの設定が異なっていたり、原作時では使われていなかった、ニートやおネエやイケメンといった現代の言葉も登場するなどアレンジされている。毎回のページ数は20ページに満たないが、原作のシーンが丸まるカットされていたり省力されていたりするため、ハイテンポで話が進んでいる。原作よりもコミカルになっており、原作ではシリアスな場面もコミカル風に描かれている。\\n\\nドラゴンボール超[編集]\\n\\n\\nドラゴンボール超\\n\\n\\nジャンル\\n\\nバトル・SF\\n\\n\\n漫画\\n\\n\\n原作・原案など\\n\\n鳥山明\\n\\n\\n作画\\n\\nとよたろう\\n\\n\\n出版社\\n\\n集英社\\n\\n\\n掲載誌\\n\\nVジャンプ\\n\\n\\n発表期間\\n\\n2015年8月号 - 連載中\\n\\n\\n巻数\\n\\n既刊21巻（2023年8月現在）\\n\\n\\nテンプレート - ノート\\n\\n\\n『ドラゴンボール超』（ドラゴンボールスーパー）は、原作/鳥山明、漫画/とよたろうによる、TVアニメ『ドラゴンボール超』に先駆けて始まった公式コミカライズ作品。『Vジャンプ』2015年8月号から連載中。2019年5月時点で発行部数は510万部を記録している[492]。\\n鳥山明のプロットを基に、とよたろうが話を膨らませて描いている。その際、毎回ネームを鳥山明がチェックしている[493]。其之四十二話まではテレビアニメと共通ストーリーだが、其之四十三話から其之六十七話まで、漫画版オリジナルストーリーの「銀河パトロール囚人編」が連載され、其之六十八話から其之八十七までは「生残者グラノラ編」が連載された。2023年10月時点でも同誌で連載中である。\\n\\n番外編[編集]\\nTRUNKS THE STORY -たった一人の戦士-\\n未来でのトランクスの物語。鳥山明作『ドラゴンボール』単行本33巻、完全版34巻に収録。\\n『Dr.スランプ』\\n鳥山明の前作であり、そのキャラクターや、舞台が本作に登場したこともある。\\nネコマジンZ\\n鳥山明作『ネコマジン』に本作のキャラクターが登場している。\\nこちらナメック星ドラゴン公園前派出所\\n秋本治作『こちら葛飾区亀有公園前派出所』とのコラボレーション作品。『超こち亀』（2006年9月15日発売）に収録。\\nCROSS EPOCH\\n尾田栄一郎作『ONE PIECE』とのコラボレーション作品。『週刊少年ジャンプ』2007年4・5合併号掲載。『ONE PIECE 10th Treasures』（2007年7月27日発売）に収録。\\nDRAGON BALL－ 放たれた運命の子供\\n孫悟空が地球に送り込まれる前の物語。鳥山明作『銀河パトロール ジャコ』のコミックス（2014年4月4日発売）に、描き下ろしおまけ漫画として収録。\\nスピンオフ[編集]\\nドラゴンボール オッス!帰ってきた孫悟空と仲間たち!!\\n「ジャンプスーパーアニメツアー08」で上映されたオリジナルアニメを、監修/鳥山明、作画/オオイシナホで漫画化。『Vジャンプ』2009年5月号、6月号の付録コミックスで前編・後編を収録。\\nドラゴンボール エピソード オブ バーダック\\n原作・監修/鳥山明、作画/オオイシナホによるスピンオフ作品。『Vジャンプ』にて2011年8月号から10月号まで連載された。『最強ジャンプ』2014年3月号の付録で一冊にコミックス化されている。イベント用にアニメも製作された。\\nドラゴンボールヒーローズ\\nデジタルキッズカードゲーム『ドラゴンボールヒーローズ』の公式コミカライズ作品。下記2作品の詳細については『ドラゴンボールヒーローズ#漫画版』の項目を参照。\\nドラゴンボールヒーローズ Victory Mission（ビクトリーミッション）\\n漫画/とよたろうによる公式コミカライズ作品。『Vジャンプ』2012年11月号から連載開始し、2015年1月号→『Vジャンプ+』、2015年2月号まで計28話が掲載された。\\nドラゴンボールヒーローズ 超（スーパー）カリスマミッション!\\n漫画/ながやま由貴による公式コミカライズ作品。『最強ジャンプ』2014年4月号から『超カリスマミッション!』を掲載開始し、『最強ジャンプ』2016年7月号まで連載された。\\nスーパードラゴンボールヒーローズ\\nデジタルキッズカードゲーム『スーパードラゴンボールヒーローズ』の公式コミカライズ作品。詳細については『スーパードラゴンボールヒーローズ』の項目を参照。\\nドラゴンボールZ 復活の「F」\\n原作/鳥山明、漫画/とよたろうによる、映画『ドラゴンボールZ 復活の「F」』に先駆けて始まった公式コミカライズ読み切り作品。『Vジャンプ』2015年4月号から6月号まで3号連続で掲載された。\\nドラゴンボールディスクロス 神力ゴッドMAX!!\\n漫画/広瀬かつきによる『ドラゴンボール ディスクロス』の公式コミカライズ作品。『最強ジャンプ』2015年5月号から2016年11月号まで連載された。\\nドラゴンボールフュージョンズ the MANGA!!\\n原作・監修/バンダイナムコエンターテインメント、漫画/音木ひろしによる、『ドラゴンボールフュージョンズ』発売に先駆けて始まった公式コミカライズ作品。『最強ジャンプ』2016年5月号から2018年5月号まで連載された。\\nドラゴンボール ゼノバース2 THE MANGA\\n漫画/とよたろうによる『ドラゴンボール ゼノバース2』の公式コミカライズ作品。公式攻略本『ドラゴンボール ゼノバース2 PS4版 ヒストリアガーディアンズ超ガイド』（2016年11月2日発売）に読み切り漫画が掲載された。\\nDRAGON BALL外伝 転生したらヤムチャだった件\\n原作/鳥山明、漫画/ドラゴン画廊・リーによる、『少年ジャンプ+』で配信されたヤムチャを主人公に据えたスピンオフ作品[494]。\\n1.2017年11月2日発売、ISBN\\xa0978-4-08-881261-8\\nDeスポファイターZ\\n企画協力/バンダイナムコエンターテインメント、漫画/音木ひろしによる『ドラゴンボール ファイターズ』の公式コミカライズ作品。『最強ジャンプ』2018年9月号から2020年9月号まで連載された。全2巻。\\n1.2019年12月4日発売、ISBN\\xa0978-4-08-882153-5\\n2.2020年10月2日発売、ISBN\\xa0978-4-08-882447-5\\nアニメ[編集]\\nアニメの製作は東映動画→東映アニメーションが行い、放送局はフジテレビ系列、放映時刻は『ドラゴンボール』、『ドラゴンボールZ』、『ドラゴンボールGT』が毎週水曜日 19:00 - 19:30（JST）、『ドラゴンボール改』、『ドラゴンボール超』が毎週日曜日 9:00 - 9:30（JST・関東地方の場合）となっている。原作部分のアニメ化作品である『ドラゴンボール』と『ドラゴンボールZ』は11年に渡り、平均視聴率は20%超[2]。2022年現在までにテレビシリーズ全798話+スペシャル3話+劇場版21作という長期シリーズになった。\\n次回予告は、悟空役の野沢雅子による「オッス、オラ悟空!」のセリフで始まるのが基本。予告の最後は、『初代』、『超』は悟空の「絶対見てくれよな」、『Z』は悟飯のコメントでしめていた。ナレーターは一貫して八奈見乗児が務めていたが、『超』の途中からは八奈見の病気療養に伴い龍田直樹が担当している。\\n\\nアニメシリーズ一覧[編集]\\nドラゴンボールのロゴマーク\\nドラゴンボール\\n1986年2月26日 - 1989年4月19日。全153話。\\n原作のうち、連載開始から第23回天下一武道会までのアニメ化に当たる。\\n後に『ドラゴンボールZ』などとの区別のため、東映公式では『元祖』と略称されることもある。\\nドラゴンボールZのロゴマーク\\nドラゴンボールZ\\n1989年4月26日 - 1996年1月31日。全291話・通算444回 + スペシャル2話。\\nサイヤ人編から原作の最終話までのアニメ化作品。シリーズの中ではもっとも高い人気を博し、人気の面で絶頂を迎えたといえる作品である。\\nタイトルの「Z」には鳥山の「これで最後にしたい」という思いが込められている[22]。\\nドラゴンボールGTのロゴマーク\\nドラゴンボールGT\\n1996年2月7日 - 1997年11月19日。全64話・通算508回 + スペシャル1話。\\n『ドラゴンボールZ』の続編として放送された。前作『Z』の最終話から5年後の世界が舞台のアニメオリジナルの作品。\\nドラゴンボール改\\n第1期：2009年4月5日 - 2011年3月27日。全97話 + 未放送1話。\\n第2期：2014年4月6日 - 2015年6月28日。全61話。\\n『ドラゴンボールZ』のデジタルリマスター版。ストーリーを原作漫画の構成に近づけて再構成している。\\nドラゴンボール超のロゴマーク\\nドラゴンボール超\\n2015年7月5日 - 2018年3月25日。全131話。\\n『ドラゴンボールGT』以来18年ぶりのオリジナルストーリーの完全新作で、原作者の鳥山明のストーリー原案による初のテレビシリーズ。\\nドラゴンボールDAIMA\\n2024年秋開始予定。原作者の鳥山明がストーリーや設定、デザインの多くを手掛けている[495]。\\n特別編[編集]\\nハイパーアニメ DRAGON BALL\\n個展「鳥山明の世界」用に製作された約3分のアニメ。TV版や劇場版の映像に新作CGをミックスさせている[496]。\\nドラゴンボール オッス!帰ってきた孫悟空と仲間たち!!\\nジャンプスーパーアニメツアー08用のオリジナルアニメ。鳥山明原案の魔人ブウを倒してから2年後の物語。\\n上映時間は35分、主題歌はjealkbが担当。2008年9月21日-11月23日[注釈 7]。\\nドラゴンボール エピソード オブ バーダック\\n2011年12月開催の『ジャンプフェスタ\\'12』で上映されたスピンオフアニメ。\\n後にフォースプロジェクト公式サイトで配信、『最強ジャンプ』2012年3月号の付録でDVDソフト化した。\\nトリコ×ONE PIECE×ドラゴンボールZ 超コラボスペシャル!!\\n『トリコ』と『ONE PIECE』とのコラボレーションアニメ。\\n前編「走れ最強軍団! トリコとルフィと悟空!」後編「史上最強コラボVS海の大食漢」が『ドリーム9』枠で2013年4月7日に放送。\\nスーパードラゴンボールヒーローズ プロモーションアニメ\\n「監獄惑星編」：2018年7月1日 - 2018年12月22日。全6話\\n「宇宙争乱編」：2019年1月10日 - 2020年1月9日。全13話 + 特別編1話。\\n「宇宙創成編」：2020年3月5日 - 2021年2月25日。全12話\\n「新時空大戦編」：2021年3月17日 - 2021年12月18日。全8話\\n「時の界王神編」：2022年2月23日 -\\nデジタルキッズカードゲーム『スーパードラゴンボールヒーローズ』をアニメ化。2018年7月1日から、イベント会場や公式サイトで配信中[15]。\\nOVA[編集]\\nドラゴンボール 悟空の消防隊\\nドラゴンボール 悟空の交通安全\\n約10分の防災ビデオ作品。『ドラゴンボール』を参照。\\nドラゴンボールZ あつまれ!悟空ワールド\\n1992年発売。てれびっこ用ソフトウェアとしてVHS形式でリリースされたオリジナルアニメ。\\n公式ビジュアルガイド ドラゴンボールZ外伝 サイヤ人絶滅計画\\nファミリーコンピュータで発売された同名作品の攻略ビデオ。\\nドラゴンボール 超サイヤ人絶滅計画\\n上記OVAのリメイクアニメ。\\nアニメ映画[編集]\\n映画は東映が配給・制作、東映アニメーション、集英社、バンダイ、バンダイナムコグループ、バンダイナムコエンターテイメント、バードスタジオ〈現：バード・スタジオ〉、読売広告社、フジテレビジョン、ソニー・ミュージックエンタテインメント、BANDAI SPIRITS、エイベックス、ライジングプロダクションが一部の作品を除き制作および制作参加に関わる。また、事業再編や持株会社化に伴い、以下のように制作参加が承継、または制作サイドが変更されている事例もある。\\n\\nフジテレビジョン：『最強への道』までは宣伝協力、『神と神』からは制作に関与。\\nバンダイナムコエンターテイメント：『神と神』まではバンダイナムコゲームス、『復活の「F」』・『ブロリー』はバンダイナムコグループ、『スーパーヒーロー』からはバンダイナムコエンターテイメント\\n東映まんがまつり、東映アニメフェアのメイン作品として上映された。第17作『最強への道』までの総動員数は4900万人を記録している[497]。1995年7月公開『悟空がやらねば誰がやる』までの劇場版シリーズ16作の累計記録は、劇場版ビデオ50万本以上、上映館数8000館以上、劇場版パンフレット800万部以上、延べ制作スタッフ3000人以上、興行収入400億円以上と、それぞれ1996年初頭時点におけるアニメ映画史上1位を記録しており、1991年からの5年連続日本映画収入ベスト10入りを果たしている[205]。\\n\\n\\n東映まんがまつり→東映アニメフェア（第1期）\\n\\n\\n\\nタイトル\\n公開日\\n監督\\n脚本\\n同時上映作品\\n\\n\\n第1作\\n\\nドラゴンボール 神龍の伝説\\n1986年12月20日\\n西尾大介\\n井上敏樹\\nゲゲゲの鬼太郎 激突!!異次元妖怪の大反乱キン肉マン 正義超人vs戦士超人\\n\\n\\n第2作\\n\\nドラゴンボール 魔神城のねむり姫\\n1987年7月18日\\n照井啓司\\n光戦隊マスクマン超人機メタルダー聖闘士星矢\\n\\n\\n第3作\\n\\nドラゴンボール 摩訶不思議大冒険\\n1988年7月9日\\n竹之内和久\\n由木義文\\nビックリマン 無縁ゾーンの秘法闘将!!拉麵男仮面ライダーBLACK 恐怖！悪魔峠の怪人館\\n\\n\\n第4作\\n\\nドラゴンボールZ\\n1989年7月15日\\n西尾大介\\n小山高生\\n悪魔くんひみつのアッコちゃん 海だ! おばけだ!! 夏祭り機動刑事ジバン\\n\\n\\n第5作\\n\\nドラゴンボールZ この世で一番強いヤツ\\n1990年3月10日\\n悪魔くん ようこそ悪魔ランドへ!!魔法使いサリー\\n\\n\\n第6作\\n\\nドラゴンボールZ 地球まるごと超決戦\\n1990年7月7日\\nPink みずドロボウあめドロボウ剣之介さま\\n\\n\\n第7作\\n\\nドラゴンボールZ 超サイヤ人だ孫悟空\\n1991年3月9日\\n橋本みつお\\nまじかる☆タルるートくん\\n\\n\\n第8作\\n\\nドラゴンボールZ とびっきりの最強対最強\\n1991年7月20日\\nドラゴンクエスト ダイの大冒険まじかる☆タルるートくん 燃えろ!友情の魔法大戦\\n\\n\\n第9作\\n\\nドラゴンボールZ 激突!!100億パワーの戦士たち\\n1992年3月7日\\n西尾大介\\nドラゴンクエスト ダイの大冒険 起ちあがれ!!アバンの使徒まじかる☆タルるートくん すき・すき♡タコ焼きっ!\\n\\n\\n第10作\\n\\nドラゴンボールZ 極限バトル!!三大超サイヤ人\\n1992年7月11日\\n菊池一仁\\nドラゴンクエスト ダイの大冒険 ぶちやぶれ!!新生6大将軍ろくでなしBLUES\\n\\n\\n第11作\\n\\nドラゴンボールZ 燃えつきろ!!熱戦・烈戦・超激戦\\n1993年3月6日\\n山内重保\\nDr.スランプ アラレちゃん んちゃ!ペンギン村はハレのち晴れ\\n\\n\\n第12作\\n\\nドラゴンボールZ 銀河ギリギリ!!ぶっちぎりの凄い奴\\n1993年7月10日\\n上田芳裕\\nDr.スランプ アラレちゃん んちゃ!ペンギン村より愛をこめて幽☆遊☆白書\\n\\n\\n第13作\\n\\nドラゴンボールZ 危険なふたり!超戦士はねむれない\\n1994年3月12日\\n山内重保\\nDr.スランプ アラレちゃん ほよよ!!助けたサメに連れられて…SLAM DUNK\\n\\n\\n第14作\\n\\nドラゴンボールZ 超戦士撃破!!勝つのはオレだ\\n1994年7月9日\\n上田芳裕\\nDr.スランプ アラレちゃん んちゃ!!わくわくハートの夏休みスラムダンク 全国制覇だ! 桜木花道\\n\\n\\n第15作\\n\\nドラゴンボールZ 復活のフュージョン!!悟空とベジータ\\n1995年3月4日\\n山内重保\\nスラムダンク 湘北最大の危機! 燃えろ桜木花道ママレード・ボーイ\\n\\n\\n第16作\\n\\nドラゴンボールZ 龍拳爆発!!悟空がやらねば誰がやる\\n1995年7月15日\\n橋本みつお\\nスラムダンク 吠えろバスケットマン魂!! 花道と流川の熱き夏NINKU -忍空-\\n\\n\\n第17作\\n\\nドラゴンボール 最強への道\\n1996年3月2日\\n山内重保\\n松井亜弥\\nご近所物語\\n\\n\\n劇場版アニメ（第2期）\\n\\n\\n\\nタイトル\\n公開日\\n監督\\n脚本\\n主題歌\\n興行収入\\n興行収入\\n\\n\\n曲名\\n歌手\\n\\n\\n第18作\\n\\nドラゴンボールZ 神と神\\n2013年3月30日\\n細田雅弘\\n渡辺雄介\\nCHA-LA HEAD-CHA-LA\\nFLOW\\n29.9億円\\n$50,461,371[244]\\n\\n\\n第19作\\n\\nドラゴンボールZ 復活の「F」\\n2015年4月18日\\n山室直儀\\n鳥山明\\n『Z』の誓い\\nももいろクローバーZ\\n37.4億円\\n$61,768,190\\n\\n\\n第20作\\n\\nドラゴンボール超 ブロリー\\n2018年12月14日\\n長峯達也\\nBlizzard\\n三浦大知\\n40.0億円\\n\\n$122,747,755\\n\\n\\n第21作\\n\\nドラゴンボール超 スーパーヒーロー\\n2022年6月11日\\n児玉徹郎\\nなし\\n25.1億円\\n$86,562,140\\n\\nメディア[編集]\\nテレビ番組[編集]\\n\\n\\n放送日\\n番組名\\n放送局\\n備考\\n\\n\\n1990年頃\\n『なるほど!ザ・ワールド』\\nフジテレビ\\n現地でのフランス語版の吹き替えの様子や、日本のスタジオでフランス語版悟空の声を務めるBrigitte Lecordierと野沢雅子が共演した[498]。\\n\\n\\n1990年7月18日\\n『邦ちゃんのやまだかつてないテレビ』\\nフジテレビ\\n「アニメ実写版劇場」悟空と山田邦子の共演。\\n\\n\\n1993年12月31日\\n『FNS大感謝祭\\'93』\\nフジテレビ\\n孫一家が一年の放送をダイジェストで振り返る年末スペシャル。\\n\\n\\n1994年1月1日\\n『第31回新春かくし芸大会』\\nフジテレビ\\n白組（この年は紅白対抗）の出し物として「DRACON BALL XYZ」というパロディドラマを放送。悟空役は近藤真彦だが、冒頭では実写悟空のパートを野沢雅子が声を当てていた。ナレーションはアニメと同じく八奈見乗児。\\n\\n\\n1994年1月2日[499]\\n『\\'94新春アニメスペシャル』\\nフジテレビ\\n悟空と『ちびまる子ちゃん』まる子（声：TARAKO）が映画を紹介するオリジナルアニメ。\\n\\n\\n2005年4月9日\\n『世界クイズビジネス』\\nフジテレビ\\n『マニアッQ』のコーナーで、DBマニアが本作に関するマニアックな問題を出し合うクイズ対決。\\n\\n\\n2006年3月25日\\n『脳内エステ IQサプリ』\\nフジテレビ\\n鏡像による間違い探し「IQミラーまちがい7」用オリジナルアニメ。\\n\\n\\n2007年4月7日\\n『日本偉人大賞2007 歴史を変えた超エライ人SP「伝説の最強偉人賞」』\\nフジテレビ\\n聖徳太子、卑弥呼、武蔵坊弁慶、天草四郎の4人の偉人が日本一を賭け戦う『ドラゴンボール』のパロディアニメ。\\n\\n\\n2007年9月20日・9月27日\\n『雨上がり決死隊のトーク番組アメトーーク!』「アメトーーーーーーク!ゴールデン3時間SP」\\nテレビ朝日\\nゴールデンSPの回にドラゴンボール芸人が出演。\\n\\n\\n2013年1月3日\\n『サイエンスファンタジー カガクる！』「ドラゴンボールの“かめはめ波”でホントに月は破壊できるのか!?」\\nフジテレビ\\n新春SP番組。\\n\\n\\n2013年3月1日\\n『MAG・ネット』\\nNHK総合テレビ\\n『MAG・ネット〜マンガ・アニメ・ゲームのゲンバ〜』での特集[500]。\\n\\n\\n2013年3月24日\\n『ほこ×たて「ドラゴンボール編集者・アニメ制作者 VS ドラゴンボールマニア軍団」』\\nフジテレビ\\n『マニア VS 本人』でのドラゴンボールクイズ対決。\\n\\n\\n2013年4月27日\\n『漫道コバヤシ「〜映画「ドラゴンボールZ神と神」公開記念!出でよ神龍!!鳥山明先生、アンケート答えておくれーーーっ!!!!!SP〜」』\\nフジテレビONE\\nドラゴンボール特集回。鳥山明のスペシャルアンケートも実施。\\n\\n\\n2015年4月24日\\n『漫道コバヤシ「地上波特別編 ドラゴンボールZ復活の「F」公開記念スペシャル」』\\nフジテレビONE\\n『漫道コバヤシ』第15回のドラゴンボール関連部分をメインに再編集した地上波特別版。地上波版のみ鳥山明スペシャルアンケートを追加\\n\\n\\n2015年7月19日\\n『ドラゴンボールで科学する！夏休み!!摩訶不思議スペシャル』\\n関西テレビ放送\\nナレーションは鶴ひろみが務め、アニメの名シーンとともにアトラクションや展示を紹介。\\n\\n\\n2018年2月28日\\n『10万円でできるかな「10万円分スクラッチくじ買ったら元取れるかな？」』\\nテレビ朝日\\nドラゴンボールスクラッチの特集にDB芸人が出演。\\n\\n\\n2018年12月9日\\n『映画「ドラゴンボール超 ブロリー」公開記念 オラたちのドラゴンボール講座』\\nアニマックス\\nドラゴンボールの魅力に迫る1時間特番[501]。\\n\\n\\n2019年5月25日\\n『ミュージックフェア』\\nフジテレビ\\n氷川きよし、宮野真守、山田涼介、乃木坂46によるドラゴンボール名曲メドレーが披露された[502]。\\n\\n\\n2019年12月31日\\n『第70回NHK紅白歌合戦』\\nNHK総合テレビジョン\\n映画『ドラゴンボール超 ブロリー』の主題歌「Blizzard」を三浦大知が披露。氷川きよしは神龍に乗ってアニメ『ドラゴンボール超』の主題歌「限界突破×サバイバー」を披露した[503]。\\n\\n\\n2021年5月15日\\n『超逆境クイズバトル!! 99人の壁』\\nフジテレビ\\nクイズ99人の壁SPに俳優の山田孝之とフィギュア原型師軍団が出演し、本作のクイズバトルが放送された[504]。\\n\\n\\n2021年7月19日\\n『教えてもらう前と後』\\nTBS系列\\nDB芸人がDB大ファンの自宅に訪問する企画[505]。\\n\\nCM[編集]\\nロート製薬・「ロート子どもソフト」\\n目薬のCMに『ドラゴンボール』、『ドラゴンボールZ』、『ドラゴンボールGT』が登場。（1986年 - 1997年）\\nバンダイ\\n「ドラゴンボール ドンジャラ」（1980年代後半）\\n「ドンジャラ パーフェクト20」（1993年）\\n「ドラゴンボール きゃらかーんシリーズ」（1990年代前半）\\n「カードダスステーション システムファイル」（1995年）\\n「グミカシリーズ ドラゴンボールグミ」（2003年）\\nエスビー食品\\n「S&B」の5/8チップのCMに『ドラゴンボール』、『ドラゴンボールZ』が登場。（1988年 - 1989年頃）\\n小泉産業\\n「コイズミ」の学習机に『ドラゴンボールZ』、『ドラゴンボールGT』が登場。（1990年代前半 - 1997年）\\n日清食品・カップヌードル\\n『ベジータスーパーヤサイ人になろう』編。（2015年）\\nフォード・モーター\\n「フォード・フォーカスSE」。（2016年）\\nACN\\n「フリーザの驚き」篇（2016年 - ）\\nドラゴンボールスクラッチ\\n新登場篇。（2017年）\\n天下一運だめし「悟空」篇、「フリーザ」篇、「ベジータ」篇。（2018年）\\n花王\\n『ベジータの新たなる戦い』編。（2018年）\\n資生堂\\n男性用化粧品ブランド uno。（2018年）\\n東芝ライフスタイル\\n東芝冷蔵庫「VEGETA」とのコラボ企画。「新鮮★5つ星ベジータキャンペーン」が東芝生活家電チャンネルなどで配信。（2018年）\\nその他、アニメ、グッズ、ゲーム、カードダスなど、数多くの本作のCMが製作されている。\\n\\n実写映画[編集]\\n\\n\\nタイトル\\n公開日\\n制作国\\n監督\\n主題歌\\n興行収入\\n\\n\\n曲名\\n歌手\\n\\n\\n드래곤볼/日本語:ドラゴンボール\\n1990年12月12日\\n大韓民国\\n왕룡/読み:ワンリョン\\n名称なし\\n名称なし\\n不明\\n\\n\\n新七龍珠\\n1991年11月\\n中華民国\\n陳俊良\\n變一個我們要的城市\\n陽帆\\n不明\\n\\n\\n七龍珠\\n謝小魚&迷你兵團\\n\\n\\nDRAGONBALL EVOLUTION\\n2009年3月13日\\nアメリカ合衆国\\nジェームズ・ウォン\\nRule\\n浜崎あゆみ\\n$55,720,772（約62億円）\\n\\nドキュメンタリー映画\\n\\n\\nタイトル\\n公開日\\n制作国\\n監督\\n備考\\n\\n\\nSONGOKUMANIA: EL BIG BANG DEL MANGA\\n2016年\\nスペイン・カタルーニャ州\\nOriol Estrada Rangil\\n1990年代初頭にカタルーニャにドラゴンボールが進出し空前の人気が始まり、国の歴史上最も売れている日本の漫画になった。映画ではアニメの放送と漫画の出版に携わった人々とファンにインタビューをした長編ドキュメンタリー[506]。2016年シッチェス・カタロニア国際映画祭上映作品[507]。\\n\\nゲームシリーズ一覧[編集]\\n1986年にエポック社からシリーズ第1作目となる『ドラゴンボール ドラゴン大秘境』が発売して以降、現在までに数多くの作品が発売され、テレビゲーム、携帯型ゲーム、アーケードゲーム、ソーシャルゲーム、オンラインゲームなど多様なジャンルが扱われている。また、日本国外限定で発売されたソフトのほか、本作の登場キャラクターと『週刊少年ジャンプ』作品とのクロスオーバー作品などもある。それらの外部出演作品については『週刊少年ジャンプ#関連ゲーム』の項目を参照。\\n\\n家庭用ゲーム機向けソフト[編集]\\n\\n\\nタイトル\\n対応機種\\n発売日\\n発売元\\n\\n\\nドラゴンボール ドラゴン大秘境\\nスーパーカセットビジョン\\n1986年9月27日\\nエポック社\\n\\n\\nドラゴンボール 神龍の謎\\nファミリーコンピュータ\\n1986年11月27日\\nバンダイ\\n\\n\\nドラゴンボール 大魔王復活\\n1988年8月12日\\n\\n\\nドラゴンボール3 悟空伝\\n1989年10月27日\\n\\n\\nドラゴンボールZ 強襲!サイヤ人\\n1990年10月27日\\n\\n\\nドラゴンボールZII 激神フリーザ!!\\n1991年8月10日\\n\\n\\nドラゴンボールZIII 烈戦人造人間\\n1992年8月7日\\n\\n\\nドラゴンボールZ 激闘天下一武道会 データック専用ミニカセット\\n1992年12月29日\\n\\n\\nドラゴンボールZ外伝 サイヤ人絶滅計画\\n1993年8月6日\\n\\n\\nドラゴンボールZ 超サイヤ伝説\\nスーパーファミコン\\n1992年1月25日\\n\\n\\nドラゴンボールZ 超武闘伝\\n1993年3月20日\\n\\n\\nドラゴンボールZ 超武闘伝2\\n1993年12月17日\\n\\n\\nドラゴンボールZ 超武闘伝3\\n1994年9月29日\\n\\n\\nドラゴンボールZ 超悟空伝 -突激編-\\n1995年3月24日\\n\\n\\nドラゴンボールZ 超悟空伝 -覚醒編-\\n1995年9月22日\\n\\n\\nドラゴンボールZ HYPER DIMENSION\\n1996年3月29日\\n\\n\\nドラゴンボールZ 武勇烈伝\\nメガドライブ\\n1994年4月1日\\n\\n\\nドラゴンボールZ 真サイヤ人絶滅計画 -地球編-\\nプレイディア\\n1994年9月23日\\n\\n\\nドラゴンボールZ 真サイヤ人絶滅計画 -宇宙編-\\n1994年12月16日\\n\\n\\nドラゴンボールZ 偉大なる孫悟空伝説\\nPCエンジン\\n1994年11月11日\\n\\n\\nドラゴンボールZ Ultimate Battle 22\\nPlayStation\\n1995年7月28日\\n\\n\\nドラゴンボールZ 真武闘伝\\nセガサターン\\n1995年11月17日\\n\\n\\nドラゴンボールZ 偉大なるドラゴンボール伝説\\nPlayStationセガサターン\\n1996年5月31日\\n\\n\\nドラゴンボール FINAL BOUT\\nPlayStation\\n1997年8月21日\\n\\n\\nドラゴンボールZ\\nPlayStation 2\\n2003年2月13日\\n\\n\\nニンテンドーゲームキューブ\\n2003年11月28日\\n\\n\\nドラゴンボールZ2\\nPlayStation 2\\n2004年2月7日\\n\\n\\nドラゴンボールZ3\\n2005年2月10日\\n\\n\\nドラゴンボールZ Sparking!\\n2005年10月6日\\n\\n\\n超ドラゴンボールZ\\n2006年6月29日\\nバンナム\\n\\n\\nドラゴンボールZ Sparking! NEO\\n2006年10月5日\\n\\n\\nWii\\n2007年1月1日\\n\\n\\nドラゴンボールZ Sparking! METEOR\\nPlayStation 2\\n2007年10月4日\\n\\n\\nWii\\n\\n\\nドラゴンボールZ バーストリミット\\nPlayStation 3\\n2008年6月5日\\n\\n\\nXbox 360\\n\\n\\nドラゴンボールZ インフィニットワールド\\nPlayStation 2\\n2008年12月4日\\n\\n\\nドラゴンボール 天下一大冒険\\nWii\\n2009年7月23日\\n\\n\\nドラゴンボール レイジングブラスト\\nPlayStation 3/Xbox 360\\n2009年11月12日\\n\\n\\nドラゴンボール レイジングブラスト2\\n2010年11月11日\\n\\n\\nドラゴンボール アルティメットブラスト\\n2011年12月8日\\n\\n\\nドラゴンボールZ BATTLE OF Z\\nPlayStation 3\\n2014年1月23日\\n\\n\\nXbox 360\\n\\n\\nドラゴンボール ゼノバース\\nPlayStation 3\\n2015年2月5日\\n\\n\\nPlayStation 4\\n\\n\\nXbox 360\\n\\n\\nXbox One\\n\\n\\nドラゴンボール ゼノバース2\\nPlayStation 4\\n2016年11月2日\\n\\n\\nNintendo Switch\\n2017年9月7日\\n\\n\\nドラゴンボール ファイターズ\\nPlayStation 4\\n2018年2月1日\\n\\n\\nXbox One\\n\\n\\nNintendo Switch\\n2018年9月27日\\n\\n\\nスーパードラゴンボールヒーローズ ワールドミッション\\nNintendo Switch\\n2019年4月4日\\n\\n\\nドラゴンボールZ カカロット\\nPlayStation 4\\n2020年1月16日\\n\\n\\nXbox One\\n\\n\\nNintendo Switch\\n2021年9月22日\\n\\n\\nドラゴンボール ザ ブレイカーズ\\nPlayStation 4\\n2022年10月13日\\n\\n\\nNintendo Switch\\n\\n\\nXbox One\\n\\n\\nSteam\\n\\n\\nドラゴンボールZ Sparking!（仮称）[508]\\n未定\\n未定\\n\\n携帯ゲーム機向けソフト[編集]\\n\\n\\nタイトル\\n対応機種\\n発売日\\n発売元\\n\\n\\nドラゴンボールZ 悟空飛翔伝\\nゲームボーイ\\n1994年11月25日\\nバンダイ\\n\\n\\nドラゴンボールZ 悟空激闘伝\\n1995年8月25日\\n\\n\\nドラゴンボールZ 伝説の超戦士たち\\nゲームボーイカラー\\n2002年8月9日\\nバンプレスト\\n\\n\\nドラゴンボール\\nワンダースワンカラー\\n2003年11月20日\\nバンダイ\\n\\n\\nドラゴンボールZ 舞空闘劇\\nゲームボーイアドバンス\\n2004年3月26日\\nバンプレスト\\n\\n\\nドラゴンボール アドバンスアドベンチャー\\n2004年11月18日\\n\\n\\nドラゴンボールZ 舞空烈戦\\nニンテンドーDS\\n2005年12月1日\\nバンナム\\n\\n\\nドラゴンボールZ 真武道会\\nPlayStation Portable\\n2006年4月20日\\n\\n\\nドラゴンボールZ 遥かなる悟空伝説\\nニンテンドーDS\\n2007年3月21日\\n\\n\\nドラゴンボールZ 真武道会2\\nPlayStation Portable\\n2007年6月7日\\n\\n\\nドラゴンボールDS\\nニンテンドーDS\\n2008年9月18日\\n\\n\\nDRAGONBALL EVOLUTION\\nPlayStation Portable\\n2009年3月19日\\n\\n\\nドラゴンボール改 サイヤ人来襲\\nニンテンドーDS\\n2009年4月29日\\n\\n\\nドラゴンボールDS2 突撃!レッドリボン軍\\n2010年2月11日\\n\\n\\nドラゴンボール タッグバーサス\\nPlayStation Portable\\n2010年9月30日\\n\\n\\nドラゴンボール改 アルティメット武闘伝\\nニンテンドーDS\\n2011年2月3日\\n\\n\\nドラゴンボールヒーローズ アルティメットミッション\\nニンテンドー3DS\\n2013年2月28日\\n\\n\\nドラゴンボールZ BATTLE OF Z\\nPlayStation Vita\\n2014年1月23日\\n\\n\\nドラゴンボールヒーローズ アルティメットミッション2\\nニンテンドー3DS\\n2014年8月7日\\n\\n\\nドラゴンボールZ 超究極武闘伝\\n2015年6月11日\\n\\n\\nドラゴンボールフュージョンズ\\n2016年8月4日\\n\\n\\nドラゴンボールヒーローズ アルティメットミッションX\\n2017年4月27日\\n\\n日本国外向けゲームソフト[編集]\\n\\n\\nタイトル\\n対応機種\\n発売日\\n開発\\n\\n\\nDRAGONBALL Z THE LEGACY OF GOKU\\nゲームボーイアドバンス\\n2002年5月14日\\nATARI\\n\\n\\nDragon Ball Z Collectible Card Game\\n2002年5月29日\\n\\n\\nen:Dragon Ball Z: Taiketsu\\n2003年11月24日\\n\\n\\nDRAGONBALL Z THE LEGACY OF GOKU II\\n2004年7月23日\\n\\n\\nDRAGONBALL Z Buu\\'s Fury\\n2004年9月14日\\n\\n\\nen:Dragon Ball Z: Sagas\\nPlayStation 2\\n2005年3月22日\\n\\n\\nニンテンドーゲームキューブ\\n\\n\\nXbox\\n\\n\\nDRAGONBALL GT Transformation\\nゲームボーイアドバンス\\n2005年8月9日\\n\\n\\nen:Dragon Ball Z: For Kinect\\nXbox 360\\n2012年10月2日\\nスパイク・チュンソフト\\n\\nアーケードゲーム[編集]\\n\\n\\nタイトル\\nジャンル\\n稼働開始日\\n発売元\\n\\n\\nドラゴンボールZ V.R.V.S\\n対戦型格闘ゲーム\\n1994年\\nセガ\\n\\n\\nドラゴンボールZ\\n1993年\\nバンプレスト\\n\\n\\nドラゴンボールZ2 Super Battle\\n1994年\\n\\n\\n超ドラゴンボールZ\\n3D対戦型格闘ゲーム\\n2005年12月22日\\n\\n\\nキャラメダルアイランド ドラゴンボールZ ぶっちぎりの超決戦\\nメダルゲーム\\n2006年12月21日\\n\\n\\nデータカードダス ドラゴンボールZ\\nデータカードダス\\n2005年3月\\nバンダイ\\n\\n\\nデータカードダス ドラゴンボールZ2\\n2006年5月\\n\\n\\nデータカードダス ドラゴンボールZ 爆烈IMPACT\\n2007年3月\\n\\n\\nデータカードダス ドラゴンボールZ W爆烈IMPACT\\n2008年5月14日\\n\\n\\nデータカードダス ドラゴンボール改 ドラゴンバトラーズ\\n2009年6月4日\\n\\n\\nドラゴンボールヒーローズ\\nトレーディングカードアーケードゲーム\\n2010年11月11日\\nバンダイナムコ\\n\\n\\nドラゴンボール ZENKAIバトルロイヤル\\n3D対戦型格闘ゲーム\\n2011年5月25日\\n\\n\\nドラゴンボール ディスクロス\\nガシャポン\\n2014年11月20日\\n\\n\\nスーパードラゴンボールヒーローズ\\nトレーディングカードアーケードゲーム\\n2016年11月17日\\n\\nスマートフォン向けゲーム[編集]\\n\\n\\nタイトル\\n配信開始日\\n配信元\\n\\n\\nドラゴンボール タップバトル\\n2013年3月25日\\nバンダイナムコゲームス\\n\\n\\nドラゴンボール アルティメットスワイプ\\n2014年4月9日\\n\\n\\nドラゴンボールZ ドッカンバトル\\n2015年1月30日\\nバンダイナムコエンターテインメント\\n\\n\\nドラゴンボール レジェンズ\\n2018年5月24日\\n\\n\\nドラゴンボールZ ブッチギリマッチ\\n2018年7月25日\\nBXD\\n\\n\\n龙珠 觉醒（龍珠Z 覚醒）※中国国内での配信\\n2019年2月28日[509]\\nバンダイナムコ上海\\n\\n\\n龙珠 最强之战（龍珠 最强之战）※中国国内での配信\\n2019年11月5日[510]\\n\\n電子ゲーム[編集]\\n\\n\\nタイトル\\n発売日\\n発売元\\n\\n\\nドラゴンボール ピラフの逆襲\\n1986年\\nエポック社\\n\\n\\nドラゴンボール 対決孫悟空\\n\\n\\nドラゴンボール たおせ!ピッコロ大魔王\\n1988年\\nバンダイ\\n\\n\\nLSI GAME ポケットクラブ P-1 ドラゴンボール 勝抜け!!天下一武道会\\n1989年\\n\\n\\nポケットクラブ P-1 ドラゴンボールZ ガンバレ!孫悟飯\\n1989年9月\\n\\n\\nドラゴンボールZ LSIシミュレーション ドラゴン大決戦\\n1990年4月\\n\\n\\nポケットクラブ P-1 ドラゴンボールZ 怒りの界王拳!\\n1990年5月\\n\\n\\nポケットクラブ P-1 ミニ ドラゴンボールZ サイヤ人の猛攻\\n1990年\\n\\n\\nドラゴンボールZ 出現!ギニュー特戦隊\\n1990年\\n\\n\\nドラゴンボールZ バトルスカウター\\n\\n\\nポケットクラブ P-1 ドラゴンボールZ スカウターバトル\\n1991年2月\\n\\n\\nドラゴンボールZ 兇悪フリーザ襲来!\\n1991年3月\\n\\n\\nポケットクラブ P-1 ミニ ドラゴンボールZ ナメック星超決戦\\n1991年\\n\\n\\nLSI バーコードウォーズ ドラゴンボールZ\\n1991年8月\\n\\n\\nポケットクラブ P-1 ミニ ドラゴンボールZ 超サイヤ人登場\\n1991年10月\\n\\n\\nスーパーバーコードウォーズドラゴンボールZ\\n1992年8月\\n\\n\\nポケットクラブ P-1 ワイドスクリーン ドラゴンボールZ 倒せ!ガーリックJr.\\n1992年\\n\\n\\nポケットクラブ P-1 ワイドスクリーン ドラゴンボールZ 対決人造人間\\n\\n\\nドラゴンボールZ 最強対決!セルvs悟空\\n\\n\\nドラゴンボールZ Z戦士大修業!\\n1993年9月\\n\\n\\nドラゴンボールZ 戦慄!生物戦士\\n1993年\\n\\n\\nドラゴンボールZ クイズワールド\\n\\n\\nドラゴンボールZ パワー炸裂孫悟飯!\\n\\n\\nドラゴンボールZ 修行だ悟飯!めざせ天下一\\n\\n\\nドラゴンボールZ TOUCH PANEL GAME\\n1994年\\n\\n\\nDRAGON BALL Z P-1 MINI 2\\n\\nパソコンゲーム\\n\\n\\n\\nタイトル\\n対応機種\\nサービス開始日\\n運営元\\n\\n\\nアニメデザイナー ドラゴンボールZ\\nピピンアットマーク\\n1996年\\nバンダイ\\n\\n\\nドラゴンボールオンライン\\nパソコン\\n2010年1月14日\\nバンダイコリア\\n\\n\\nドラゴンボールZ クロスキーパーズ\\n2018年3月20日\\nYahoo!ゲーム\\n\\n体感ゲーム\\n\\nLet\\'s! TV プレイ\\n\\n\\nタイトル\\n発売日\\n発売元\\n\\n\\nドラゴンボールZ バトル体感かめはめ波〜おめぇとフュージョン〜\\n2005年11月12日\\nバンダイ\\n\\n\\nドラゴンボールZ バトル体感かめはめ波2〜オッスおめぇ悟空 天下一武道会〜\\n2006年10月28日\\n\\n\\nドラゴンボールZ スカウターバトル体感かめはめ波〜おらとおめぇとスカウター〜\\n2007年11月10日\\n\\n\\nドラゴンボールZ×ONE PIECE バトル体感ゴムゴムのかめはめ波〜おめぇの声でおらを呼ぶ〜\\n2008年11月15日\\n\\nイベント・企画[編集]\\nジャンプマルチワールド\\n1993年7月28日から8月15日に東京ドーム・プリズムホールで開催されたイベント。『DBZ ゲームロボ』ブースでは原作者・鳥山明がマルチワールド用にデザインした、ロボット型のオリジナル専用筐体[511] のゲームがプレイできた（後にアーケード化）。また、『DB VRバトルゲーム』ブースでは自分の動きをキャラクターが実際に再現するゲームが遊べた（後に技の出し方をレバー入力に変更した対戦ゲームドラゴンボールZ V.R.V.Sとしてアーケード化）。\\nジャンプランド\\nジャンプランドは、2002年11月から2009年5月31日までバンダイネットワークスと集英社が『ドラゴンボール』、『ONE PIECE』などの人気キャラクターを使ったweb版テーマパーク[512]。\\nケータイJUMPLANDとジャンプランドの詳細についてはアトラクションおよびミニゲームの項目を参照。\\nドラゴンボール立佞武多\\n2004年8月4日から8月8日に青森県五所川原市で開催された五所川原立佞武多祭りで、下絵を鳥山明が描いた孫悟空と神龍の立佞武多が出陣した。「友情、努力、勝利」を表現し、同年12月18日・19日に開催されたジャンプフェスタ2005でも披露された。\\nJ-WORLD TOKYO\\n2013年7月11日に池袋サンシャインシティにオープンしたJ-WORLD TOKYOで、2019年2月17日に本館が閉園するまで本作の様々なイベント・アトラクションが行われた。詳細についてはJ-WORLD TOKYO#アトラクション一覧を参照。\\nドラゴンボールで科学する！\\n2014年から、『ドラゴンボール』の科学をテーマにしたイベントが日本各地で開催され、日本国外では台湾でも開催された。施設内では、カプセルコーポレーションの特設ラボ・「先端科学研究所」で、科学を使った様々なイベントが実施されている[513]。\\n\\n\\n所在地\\n開催地\\n期間\\n\\n\\n愛知県名古屋市\\n名古屋市科学館\\n2014年7月16日 - 8月31日\\n\\n\\n中華民国台北市\\n松山文創園区\\n2015年1月24日 - 4月6日\\n\\n\\n東京都港区\\nフジテレビ22階フォーラム\\n2015年4月29日 - 5月10日\\n\\n\\n大阪府大阪市\\nグランフロント大阪\\n2015年7月18日 - 8月31日\\n\\n\\n鹿児島県鹿児島市\\n山形屋文化ホール2号館6階\\n2017年7月22日 - 8月30日\\n\\nさっぽろ雪まつり2016\\n北海道札幌で、2016年2月5日から2月18日まで開催されたさっぽろ雪まつりにてイベント開催中、孫悟空とベジータの大雪像が展示された[514]。\\n放て！元気玉チャレンジ！\\n2016年12月17日・18日にジャンプフェスタ2017で開催された。光る的に元気玉を命中させるアトラクション[515]。\\nJR東日本 そうさ今こそ！ DRAGON BALLスタンプラリー\\n2017年1月10日から2月27日にかけて、JR東日本とのコラボ企画でスタンプラリーが開催された。イベントでは、山手線を中心とした63駅と東京モノレールの2駅にスタンプが設置されており、すべてのスタンプを集めてゴールを目指すイベント。関連イベントとして、東京駅と、その周辺の商業施設でグルメフェア「ドラゴンボールメニュー大集合」も開催された[516]。\\nドラゴンボール/Dr.スランプ アラレちゃん STORE at ISETAN\\n2017年5月2日から5月7日まで、新宿伊勢丹にて『Dr.スランプ アラレちゃん』とのコラボイベントが開催された。イベント期間中は、野沢雅子と小山茉美によるトークショーの開催にイベント限定グッズやコラボカフェでは、キャラクターや場面にちなんだオリジナルメニューも販売された[517]。\\nドラゴンボールVR 秘伝かめはめ波\\n2017年7月14日に新宿歌舞伎町にオープンした国内最大級のVR施設「VR ZONE SHINJUKU」で、最新のVR技術・装置により、『ドラゴンボール』ワールドでのかめはめ波の本当の凄さを全身で体感できる。孫悟空直々に修業をつけてもらい、習得したかめはめ波で仲間とバトルや、またVR仙豆（別売り）を持って参加すると、実際に仙豆を食べる体験ができる[518]。\\nDRAGON BALL バトル・オブ・サイヤン〜みんなでつくる元気玉〜\\n2017年7月15日から8月31日までの期間中、お台場みんなの夢大陸で開催された。本作の過去のバトルシーンが上映された他、来場者全員で元気玉を作るイベントなど実施された[519]。\\nドラゴンボール天下一武道祭2017\\n2017年8月10日 - 8月27日の期間中、池袋サンシャインシティにて開催された。アトラクションコーナーでは、『ドラゴンボール超修業チャレンジ』、『ホイポイカプセル！悟空のバトルメモリー』、謎解きラリー『合体ザマスをやっつけろ！』など様々なアトラクションが実施された[520]。\\nドラゴンボールラン\\n2017年9月10日に東京・幕張海浜公園、同年9月23日に名古屋エリア愛知りんくうビーチにて実施された。イベントでは、様々な修行を積みながら約3kmのコース上に散らばった7つのドラゴンボールを見つけてゴールを目指すイベント[521]。\\n力を合わせてドラゴンボールを集め神龍を降臨させよ！\\n2017年12月16日・12月17日に幕張メッセで開催されたジャンプフェスタ2018で行われたアトラクション。その他、本作のゲームの試遊体験などが行われた[522]。\\nドラゴンボール 超悟空伝\\n劇場版『ドラゴンボール超 ブロリー』の公開に合わせ、2018年12月14日から2019年1月7日まで東京ソラマチで、『ドラゴンボール』の歴史を振り返るイベントが行われた[523]。\\nドラゴンボール ゲームスバトルアワー\\n初のドラゴンボールゲームの全世界同時配信型オンラインイベントが日本時間2021年3月7日午前3時から12時間に渡って開催された[524]。\\nドラゴンボール ゲームスバトルアワー 2022\\n前年に引き続き、本作のゲームやフィギュア、マンガや映画やアニメなど、さまざまな『ドラゴンボール』のコンテンツが楽しめる、全世界同時配信型オンラインイベントが2022年2月19日・20日の2日間に渡って開催された[525]。\\nドラゴンボール ゲームスバトルアワー 2023\\n3度目の開催となる本作のゲームイベントが、2023年3月4日・5日（現地時間）アメリカ・ネバダ州ラスベガスにて開催された[526]。\\nドラゴンボール ゲームスバトルアワー 2024\\n4度目の開催となる本作のゲームイベントが、2024年1月27日・28日（現地時間）アメリカ・ロサンゼルスにて開催予定[527]。\\n日本国外でのイベント[編集]\\nかめはめ波コンテスト\\nニュージーランドの首都ウェリントンのTSBバンク・アリーナで開催されている、SFとコミックの祭典「アルマゲドン・パルプ・カルチャー・エキスポ」で2001年から毎年行われているイベントである。実際にかめはめ波を出しているかのようなパフォーマンスをし、それを競う大会である[528]。\\nドラゴンボールのキャラクターに最多人数で扮する\\n2013年に、スペイン最大のマンガイベント「Saló de Manga」で行われたギネス世界記録に挑戦するイベントである[529]。\\n小雲x悟空のMCP夏日祭（アラレと悟空のMCP夏の祭典）\\n2017年7月9日 - 8月31日までの期間中、香港メトロシティセンターで『Dr.スランプ アラレちゃん』とのコラボイベントが開催された。イベントではキャラクターの展示や、コラボグッズ、フードメニューも販売された[530]。\\nScream Like Goku（悟空みたいに叫ぼう）\\n2017年9月1日、ニューヨーク市・マンハッタンにあるワシントン・スクエア公園で開催され、イベントが開催されたワシントン・スクエア公園では大勢の人たちが集まり盛り上がりを見せた[531]。また、カナダバンクーバー、オーストラリア各地でも同様のイベントが開催された[532]。\\nドラゴンボール シンフォニックアドベンチャー\\n2017年5月から世界各国で行われているアニメ『ドラゴンボール』シリーズの曲を用いたコンサート[533]。2020年3月27日にイリノイ州シカゴで開催予定だったコンサートは、COVID-19の流行のため中止となった[534]。\\n\\n\\n開催国\\n開催都市\\n劇場名\\n開催日\\n\\n\\nフランス\\nパリ\\nグランド・レックス劇場\\n2017年5月6日\\n\\n\\nスペイン\\nバルセロナ\\nバルセロナ・インタナショナルコンベンションセンター\\n2018年3月3日\\n\\n\\nフランス\\nパリ\\nグランド・レックス劇場\\n2018年10月27日\\n\\n\\nベルギー\\nブリュッセル\\nPalais 12\\n2018年10月30日\\n\\n\\nドイツ\\nデュッセルドルフ\\nMitsubishi Electric Hall\\n2018年11月1日\\n\\n\\nスイス\\nローザンヌ\\nボーリュ劇場\\n2018年11月3日\\n\\n\\nスペイン\\nバルセロナ\\nAuditori Forum\\n2019年5月11日\\n\\n\\nアメリカ合衆国\\nイリノイ州シカゴ\\nRosemont Theatre\\n中止[534]\\n\\nCAPSULE CON\\n2017年10月14日・15日に、パリ・エルミタージュ通りで『ドラゴンボール』のフェスティバルが開催された。イベントでは、フィギュアの展示、ビデオゲームのトーナメント、コスプレコンテスト、クイズ、カラオケ、コンサートなど様々な企画が実施された[535]。\\nkameha con\\n2018年5月4日 - 6日までの期間中、テキサス州・「アービングコンベンションセンター（英語版）」にて、『ドラゴンボール』のコンベンションが開催された。期間中はアメリカ版アニメの吹き替えを担当した声優たちと日本からゲストとして参加した堀川りょうなどによるトークショーやコスプレコンテスト、ゲーム大会などが行われた[536]。\\nDRAGON BALL NORTH AMERICA TOUR 2018（ドラゴンボール北米ツアー2018）\\n2018年7月から12月まで、北米の7つの都市で『ドラゴンボール』のイベントが開催された。会場は、天下一武道会をイメージした装飾が施され、フィギュア「S.H.Figuarts」シリーズを販売するほか、『ドラゴンボール』のゲームを体験できる。各イベントでは、劇場版『ドラゴンボール超 ブロリー』の予告映像が公開された[537]。\\n\\n\\n開催地\\n会場\\n開催日\\n\\n\\nサンディエゴ\\nコミコン・インターナショナル\\n2018年7月19日 - 7月22日\\n\\n\\nワシントンD.C.\\nオタコン\\n2018年8月10日 - 8月12日\\n\\n\\nトロント\\nFAN EXPO CANADA\\n2018年8月30日 - 9月2日\\n\\n\\nポートランド\\nROSE CITY COMIC CON\\n2018年9月7日 - 9月9日\\n\\n\\nニューヨーク\\nニューヨーク・コミコン\\n2018年10月4日 - 10月7日\\n\\n\\nダラス\\nDallas FanDays\\n2018年10月19日 - 10月21日\\n\\n\\nロサンゼルス\\nグローマンズ・チャイニーズ・シアター\\n2018年12月13日\\n\\nメイシーズ・サンクスギヴィング・デイ・パレード\\nアメリカ・ニューヨーク市で毎年開催されている大手百貨店メイシーズが主催する感謝祭パレード\\n\\n\\nイベント名\\n開催日\\n備考\\n\\n\\nMacy\\'s Thanksgiving Day Parade 2018\\n2018年11月22日\\n孫悟空のバルーンが登場。漫画が原作のキャラクターとしては日本から初めての登場である[538]。\\n\\n\\nMacy\\'s Thanksgiving Day Parade 2019\\n2019年11月28日\\n孫悟空のバルーンが登場。日本のキャラクターとしては『ポケットモンスター』のピカチュウと共に選ばれた[539]。\\n\\n\\nMacy\\'s Thanksgiving Day Parade 2021\\n2021年11月25日\\n2年ぶりの開催となったメイシーズ主催の感謝祭パレードに本作から孫悟空のバルーンが登場[540]。\\n\\nDRAGONBALL WORLD ADVENTURE\\n2018年に北米で行われたイベント「DRAGON BALL NORTH AMERICA TOUR 2018」の全世界拡大版。2019年7月にアメリカ・サンディエゴでのイベントを皮切りに世界6カ国8都市の会場でイベントが順次行われた[541]。\\n\\n\\n開催地\\n会場\\n開催日\\n\\n\\nサンディエゴ\\nコミコン・インターナショナル\\n2019年7月18日 - 7月21日\\n\\n\\n上海\\n上海新国際博覧センター\\n2019年8月2日 - 8月5日\\n\\n\\nメキシコシティ\\nCentro Citibanamex\\n2019年8月2日 - 8月4日\\n\\n\\n香港\\n香港時代廣場\\n2019年8月8日 - 9月1日\\n\\n\\nケルン\\nkolenmesse\\n2019年8月20日 - 8月24日\\n\\n\\nニューヨーク\\nニューヨーク・コミコン\\n2019年10月3日 - 10月6日\\n\\n\\nバルセロナ\\nFira Barcelona\\n2019年10月31日 - 11月3日\\n\\n\\n日本\\n幕張メッセ\\n2019年12月21日・22日\\n\\nSaiyaCon UK\\n2019年9月20日から9月22日までの期間、イギリスで『ドラゴンボール』に焦点を当てたコンベンションが開催された。英語版アニメの吹き替え声優がゲストとして参加する他、様々な催しが行われた[542]。\\nニューヨーク・コミコン\\n2023年10月12日から15日までの期間、アメリカ・ニューヨークで開催されるコミコンにて本作のスペシャルステージが10月13日(日本時間)に開催予定。本作に関する新規映像や、今後のDBシリーズの新しい展開についての情報が発表予定[543]。\\n展覧会[編集]\\n鳥山明の世界\\n1993年から漫画家個人としては異例の展覧会が日本各地で開催された。展覧会では400点に及ぶ原画やオリジナル映像が展示され日本中の『ドラゴンボール』ファンが注目した。また、当時連載中の『ドラゴンボール』のみならず、『Dr.スランプ』のほか、『貯金戦士キャッシュマン』や短編などの原画を展示。さらに『ドラゴンクエスト』のイラストや人形劇、アニメとCGを合わせた特別映像など、鳥山明作品目白押しの内容であった[544]。\\n開催場所は鳥山明個展開催歴の項目を参照。\\n鳥山明 The World 8of DRAGON BALL\\n劇場版『ドラゴンボールZ 神と神』が公開されることを記念して、全国3都市で開催された。展覧会では一星球から七星球まで7つのゾーンに分かれており、映画公開を記念して、それぞれカラーイラスト約30点に加えアニメのセル画・設定資料など約300点を一堂に展示し、『ドラゴンボール』の名シーンをアニメとコミックで見比べることができる[545]。\\n\\n\\n開催地\\n期間\\n\\n\\n日本橋髙島屋\\n2013年3月27日 - 4月15日\\n\\n\\n阪神百貨店梅田本店\\n2013年4月17日 - 23日\\n\\n\\n名古屋松坂屋美術館\\n2013年7月27日 - 9月1日\\n\\n週刊少年ジャンプ展 VOL.2 -1990年代、発行部数653万部の衝撃\\n2018年に『週刊少年ジャンプ』創刊50周年を記念して、2018年3月19日から6月17日までの期間、六本木ヒルズ森アーツセンターギャラリーにて開催された。原画の展示の他、ガシャポンフィギュアやゲームソフトといった関連商品も合わせて展示された[546]。\\nThe Citi exhibition Manga\\n日本のマンガをテーマにした展覧会が、イギリス・ロンドンにある大英博物館で2019年5月23日から8月26日にかけて開催された。国外で開催されるマンガの展覧会として史上最大規模とのこと。会場には大英博物館内にあるセインズベリー・エキシビションズ・ギャラリーを使用。1100平方メートルの場内に、約50名の作家、約70タイトルによる総計約240点の原画および複製原画、描き下ろし作品などが6つのゾーンに分けて展示される[547]。\\nカフェ・レストラン[編集]\\nドラゴンボール×TOWER RECORDS\\n2016年11月にテレビアニメ『ドラゴンボール』の放送開始30周年を記念して、タワーレコードとのコラボレーションカフェが、タワーレコードカフェ渋谷店などで期間限定でオープンした。また、全国のタワーレコードの店舗ではコラボグッズが発売されている[548]。\\n\\n\\n店舗名\\n期間\\n\\n\\nTOWER RECORDS CAFE 表参道店\\n2016年11月1日 - 11月30日\\n\\n\\nTOWER RECORDS CAFE 梅田 NU 茶屋町店\\n2016年11月1日 - 11月30日\\n\\n\\nTOWER RECORDS CAFE 渋谷店\\n2016年11月8日 - 11月30日\\n\\nドラゴンボールメニュー大集合\\n2017年1月にJR東京駅構内とその周辺の商業施設で『ドラゴンボール』の世界観をモチーフにしたメニューが楽しめるグルメフェアが開催された。同フェアでは、JR東日本主催の「JR東日本 そうさ今こそ！ DRAGON BALLスタンプラリー」との連動企画であり、マンガ飯やアイテム、サービスなど全16種類が登場する[549]。\\n\\n\\n施設名\\n期間\\n\\n\\nグランスタ\\n2017年1月10日 - 2月27日\\n\\n\\nグランスタ 丸の内\\n2017年1月10日 - 2月27日\\n\\n\\nグランルーフ\\n2017年1月10日 - 2月27日\\n\\n\\nグランルーフ フロント\\n2017年1月10日 - 2月27日\\n\\nドラゴンボールカフェ＆ダイナー\\n2017年12月に大阪市梅田の桃谷樓 ヒルトンプラザWEST店に『ドラゴンボール』の世界を楽しむことができるカフェ＆ダイナーが期間限定でオープンした。また、レストラン併設二か所とキデイランドで『ドラゴンボールカフェ＆ダイナー期間限定ショップ』も開催された[550]。\\n\\n\\n店舗名\\n期間\\n\\n\\n中国料理 桃谷樓 ヒルトンプラザWEST店\\n2017年12月8日 - 2018年1月31日\\n\\n\\nナチュラルキッチン表参道\\n2018年1月15日 - 2018年2月28日\\n\\n\\nショップ店舗名\\n期間\\n\\n\\nKIDDY LAND 吉祥寺店\\n2017年12月8日 - 2018年1月31日\\n\\n\\nKIDDY LAND 大阪梅田店\\n2017年12月8日 - 2018年2月28日\\n\\n\\nKIDDY LAND 原宿店\\n2017年12月8日 - 2018年3月22日\\n\\nSoupa Sayen\\nフロリダ州オーランドでオープンしている『ドラゴンボール』をテーマにしたアジア料理店。店内には『ドラゴンボール』の装飾が施され、アニメが流れるなど『ドラゴンボール』一色となっており、全米各地から人が訪れるなど話題を呼んだ[551]。\\nDRAGON BALL超 CAFE\\n2018年11月15日に中国・上海にて中国国内では初となる『ドラゴンボール超』のカフェがオープンした。店内は『ドラゴンボール超』をテーマにしたデザインが施され、本作のキャラクターをモチーフにしたメニューや限定グッズも用意された[552]。\\n関連商品[編集]\\n玩具[編集]\\nアニメが開始した1986年春からエポック社とバンダイの2社がそれぞれ玩具を発売していたが、翌年にはエポック社が撤退しバンダイ単独で玩具展開がなされた。しかし、無印では想定ほどの成績を上げられず、中盤以降は新たな玩具展開を見込んでいた。その後ゲームソフト販売による穴埋めや累計20億枚の販売枚数を記録したカードダスのヒットがきっかけとなり、カードダスと連動したスカウターの玩具を皮切りに数年ぶりに玩具が店頭に並ぶことになった[553]。「カードダス ドラゴンボールシリーズ」のヒットを皮切りに[195]、「エンスカイ ドラゴンボールカードシリーズ」、「ドラゴンボールカードゲーム」、「ドラゴンボール超カードゲーム」、「ミラクルバトルカードダス」、「データカードダス ドラゴンボールシリーズ」、「ドラゴンボールヒーローズ」、「ICカードダス ドラゴンボール」、「スーパードラゴンボールヒーローズ」へとカードゲームは進化しながら登場している[554]。\\n昭和の頃のDB玩具の代表作は、シンプルな携帯液晶ゲームのLSIゲームや、ボードゲームなどである。また、生活用品の玩具など、今では珍しいタイプの玩具もあった[555]。フィギュアは、テレビアニメ放送開始の初期の頃はミニフィギュアなど、集めやすいおもちゃが中心で、『ドラゴンボールZ』以降は頭身が高く動かして遊べるアクションフィギュアが人気を博した。2003年以降はクオリティが上昇し、ミニフィギュアは価格が安くコンビニなどで手に取りやすい環境だったため、幅広い年齢層にヒットした[556]。2000年代は技術が上がり、デジタルも進化した分、より精巧で洗練されたおもちゃが登場し、子供たちに人気を博した[557]。\\n\\nタイアップ[編集]\\nドラゴンボール☆ANiMO\\n2007年8月20日から、本作の総合携帯サイトが開始された。着メロの他、テレビシリーズ全話が観ることのできる動画配信「ドラゴンボールTV」などが提供されている[558]。\\nドラゴンボールモバイル\\nバンダイネットワークスより、2007年10月15日からiモード向けゲームサイト「ドラゴンボールモバイル」を開始した[559]。『ドラゴンボール RPG』、『ドラゴンボールウォーズ』ほか、ダウンロード形式のゲームを複数配信。\\nポッカコーヒー\\n「ポッカコーヒー DRAGON BALL CAN」（第一弾 2011年6月3日発売[560]）（第二弾 2011年11月上旬発売[561]）\\n日経エンタテインメント!\\n2013年5月号の表紙を孫悟空が飾り、「ドラゴンボール“復活”の全貌」のタイトルで本作の特集が組まれた。\\nパズル&ドラゴンズ\\nガンホー・オンライン・エンターテイメントから配信されているパズル&ドラゴンズとのコラボレーション。\\n第1弾（2014年6月2日から6月15日[562]）\\n第2弾（2014年9月22日から10月5日[563]）\\n第3弾（2014年12月29日から2015年1月11日[564]）\\n第4弾（2015年3月16日から3月29日[565]）\\nタニタ\\n2015年7月1日にタニタは、家庭用体組成計の新商品3機種を7月1日に発売するのに伴い、『ドラゴンボール』から孫悟空を起用した新聞広告を同日付の読売新聞朝刊に出稿した[566]。\\n丸美屋食品工業\\n『ドラゴンボール ふりかけミニパック』『ドラゴンボール カレー＜ビーフ甘口＞』『ドラゴンボール カレー＜ビーフ中辛＞』（2015年11月5日発売）[567]。\\n栗山米菓\\n『DBばかうけヤサイコンソメ味』、『DB星たべよわたあめ味』（2016年10月3日発売[568]）\\nBotsNew Characters VR DRAGONBALL Z\\n2017年6月28日にメガハウスよりVR・ARを駆使した体験機が発売された[569]。\\nビックリマン\\nロッテから発売されているビックリマンとのコラボレーション。イラストは全てビックリマンイラストレータによる描き下ろしとなっている[570]。発売1カ月で550万個以上を出荷し、累計販売数で約700万個を記録した[571]。\\n「ドラゴンボールマンチョコZ」（2018年10月23日西日本（静岡除く）先行発売、2018年12月18日東日本（静岡含む）発売[572]）\\n「ドラゴンボールマンチョコ超」（2018年10月23日東日本（静岡含む）先行発売、2018年12月18日西日本発売[572]）\\n「ドラゴンボールマンZ特別セット」（2018年12月18日[573]）\\n「ドラゴンボールマン超特別セット」（2018年12月18日[573]）\\n「ドラゴンボールマンチョコ超」第2弾（2022年5月24日東日本（静岡含む）先行発売[574]、2022年7月12日西日本発売[575]）\\nニューエラ・キャップ・カンパニー\\nベースボールキャップの老舗ブランド「ニューエラ」との商品が登場。孫悟空をはじめ、作中に登場するキャラクターやタイトルロゴをモチーフにデザインされたアパレルアイテムが、計16点ラインナップしている。（2019年7月4日発売[576]）\\nCONVERSE STARS\\nコンバースのファッションブランド「CONVERSE STARS（コンバース スターズ）」とのコラボレーション。Tシャツ、iPhoneケース、ソックス、タオルなどがラインナップしている。（2019年8月24日発売[577]）\\nDAM\\n歌唱力で孫悟空を勝利に導くバトルゲーム「DRAGONBALL カラオケ天下一歌唱会」を搭載した業務用機種が2019年10月1日から発売[578]。\\nユニクロ\\nユニクロのグラフィックTシャツブランド「UT」と『ドラゴンボール』のコラボレーション。デザインはコラージュアーティストの河村康輔が担当[579]。\\n「ドラゴンボール UT」（2019年11月22日発売）\\nフォートナイト\\nEpic Gamesから販売・配信されているフォートナイトとのコラボレーション。\\n第1弾（2022年8月16日から2022年9月18日[580][581]）\\n第2弾（2023年1月31日から開催中[582]）\\nPUBG\\nバトルロイヤルゲーム「PUBG MOBILE」とのコラボが2023年7月13日から9月4日まで行われている。期間中『ドラゴンボール超』をテーマにしたテーマモードや、本作の様々な舞台が用意されている[583]。\\nマクドナルド\\n2023年9月27日より、台湾全土のマクドナルドにて対象の商品を買うと、10万パック限定で「ドラゴンボールZ キャラクターブラインドカードパック」を入手できるキャンペーンが行われている[584]。\\n脚注[編集]\\n[脚注の使い方]\\n注釈[編集]\\n\\n\\n^ 鳥山によるとフリーザ編の構想ができ始めたのはマジュニア戦の途中あたりであり、読者アンケートの順位が上がってきたため「これは早々に終われそうにないぞ」と考え出したという[28]。\\n\\n^ 連載終了後の2009年に発売された『DRAGON BALL 超エキサイティングガイド キャラクター編』には亀仙人の趣味に「インターネット」があり、2013年に劇場公開された『ドラゴンボールZ 神と神』では携帯電話について言及されている。\\n\\n^ 完全版コミックでは「5の26日」と月名が数字に修正されている。\\n\\n^ a b 単行本も途中の重版から「5の26日」に修正されている。\\n\\n^ 『犬マユゲでいこう』より。\\n\\n^ 特に、ブウについては連載中に鳥山が巻末コメントで触れている。\\n\\n^ アニメツアー08版公式サイトでは2008年11月24日から2009年1月31日まで無料配信されていた。\\n\\n\\n出典[編集]\\n\\n\\n^ “平成最初の『ジャンプ』が漫画アプリで読める 『DB』『ジョジョ』『タルるートくん』ら15作品”. ORICON NEWS. 2021年6月15日閲覧。\\n\\n^ a b c d “ドラゴンボールZ DVD 単巻初登場!!”. 2016年11月5日閲覧。\\n\\n^ a b 「バンダイプレスリリース アニメ「ドラゴンボール」シリーズ、世界展開絶好「超」！」バンダイナムコ、2018年12月14日。\\n\\n^ 「国民的漫画『ドラゴンボール』雑学まとめ、フリーザ様の部下の名前の共通点は○○だった」music.jpニュース、2016年12月9日。\\n\\n^ 「「ドラゴンボール 超」英語版、海外同時配信へ DAISUKI、クランチロールなどでスタート」アニメーションビジネス・ジャーナル、2016年10月21日。\\n\\n^ a b c “ヒプマイ、経済効果100億円超 『日本商品化権大賞』各部門賞発表でワンピース、DBなど”.   オリコン (2020年1月23日). 2020年1月23日閲覧。\\n\\n^ 「『ドラゴンボール超 ブロリー』北米デイリーランキングNo.1！日本アニメ映画がアメリカで1位を獲得したのは『劇場版ポケットモンスター ミュウツーの逆襲』以来20年ぶり」アニメイトタイムズ、2019年1月18日。\\n\\n^ 「ジャンプ復刻版ラスト飾るのは、悟空とラオウのあの名セリフ登場した2冊」コミックナタリー 2017年9月16日。\\n\\n^ 「【出版】本当の出版不況は、まだ来ていない」朝日新聞デジタル、2009年2月10日。\\n\\n^ a b c 「ドラゴンボールコミックス＆ブックデータ」『30th ANNIVERSARY ドラゴンボール超史集 -SUPER HISTORY BOOK-』集英社、2016年1月21日、210-211頁。\\n\\n^ a b c 「「鬼滅の刃」22巻で1億部突破…「ONE PIECE」「DRAGON BALL」に続き」読売新聞オンライン、2020年9月24日。\\n\\n^ a b 「Dragon Ball Z Kakarot Review: A Treat For DBZ Fans But Not The RPG Players May Have Hoped For」Gfinity、2021年4月21日。\\n\\n^ 「8周年を迎えた「ドラゴンボールZ ドッカンバトル」の世界累計収益は37億ドル（約5000億円）を突破。バンダイナムコの収益を牽引する存在に」4Gamer.net、2023年2月24日。\\n\\n^ “データカードダス「ドラゴンボールヒーローズ」が10周年。記念のオンラインイベントが11月15日より開催へ”. 4Gamer.net (2020年11月5日). 2021年1月4日閲覧。\\n\\n^ a b 「イントロダクション-スーパードラゴンボールヒーローズプロモーションアニメ」スーパードラゴンボールヒーローズユニバースミッション公式サイト、2019年3月1日閲覧。\\n\\n^ G. Allen Johnson「‘Dragon Ball Super: Broly,’ 20th film of anime empire, opens in Bay Area」Datebook（サンフランシスコ・クロニクル）、2019年1月17日。\\n\\n^ a b c d ジャンプ・コミック出版編集部編「鳥山明 ON THE ROAD」『ドラゴンボール完全版公式ガイド Dragonball LANDMARK 少年編〜フリーザ編』集英社〈ジャンプ・コミックス〉、2003年12月24日、146-157頁。ISBN\\xa04-08-873478-5。\\n\\n^ a b c 「スペシャル座談会プロジェクトZ アニメ『ドラゴンボールZ』の過去・現在・未来」『DRAGON BALL Z DVD BOX Z VOLUME 1 Dragonbook』、2003年、100-107頁。\\n\\n^ a b 週刊少年ジャンプ特別編集「ドラゴンボール誕生秘話」『DRAGON BALL 冒険SPECIAL』集英社、1987年12月1日、136-137頁。\\n\\n^ 「鳥山明インタビュー」『SHONEN JUMP（北米版）』創刊号。\\n\\n^ 週刊少年ジャンプ特別編集「なるほど!?ザ・ドラゴンボール」『DRAGON BALL 冒険SPECIAL』138頁。\\n\\n^ a b c d 鈴木晴彦編「鳥山明×中鶴勝祥対談」『テレビアニメ完全ガイド『DRAGON BALL Z』孫悟空伝説』集英社〈ジャンプ・コミックス〉、2003年10月8日、90-102頁。ISBN\\xa04-08-873546-3。\\n\\n^ a b c 渡辺彰則編「鳥山明的超会見」『ドラゴンボール大全集 第2巻』集英社、1995年8月9日、262-264頁。ISBN\\xa04-08-782752-6。\\n\\n^ “「テコ入れ」で歴史的ヒットになった「ジャンプマンガ」3選 ジャンル違い過ぎてびっくり！”. マグミクス. 2022年12月15日閲覧。\\n\\n^ “「テコ入れ」で歴史的ヒットになった「ジャンプマンガ」3選 ジャンル違い過ぎてびっくり！”. マグミクス. 2022年12月15日閲覧。\\n\\n^ 「週刊少年ジャンプ1990年45号」、集英社、1990年10月22日。\\n\\n^ a b c 「神龍通信 第1号 歴代担当者座談会」『ドラゴンボール大全集 1巻』別冊付録、集英社、1995年。\\n\\n^ 「DRAGON BALLと鳥山明」『30th ANNIVERSARY ドラゴンボール超史集 -SUPER HISTORY BOOK-』集英社、92頁。\\n\\n^ 「DRAGON BALL」『30th ANNIVERSARY ドラゴンボール超史集 -SUPER HISTORY BOOK-』集英社、6-7頁。\\n\\n^ 西村繁男『さらば わが青春の『少年ジャンプ』』\\n\\n^ 「親の顔がみてみたい 夏休み企画3週まるまる ドラゴンボールスペシャル」『週刊ファミ通』、エンターブレイン刊、2006年。\\n\\n^ 「ドラゴンボールの鳥山明氏 \"魔人ブウ\"後の心境を告白「闘いの漫画描く気なくなった」」ORICON STYLE、2014年3月28日。\\n\\n^ 『STUDIO VOICE』2008年2月号、INFASパブリケーションズ社、2008年1月4日発売。\\n\\n^ 『ジャンプ』最終話で巻頭カラーは“4作”だけ！ 歴史的名作を振り返る\\n\\n^ 西村繁男『さらば わが青春の『少年ジャンプ』』\\n\\n^ 「「DRAGONBALL」は永遠に不滅です！」『週刊プレイボーイ』1995年6月6日No.5、集英社、229頁。\\n\\n^ 「ドラゴンボールヒット年表 ドラゴンボール\"復活\"の全貌」『日経エンタテインメント!』2013年5月号No.194、日経BP社、2013年4月4日、18-19頁。\\n\\n^ a b 「終わらないDBワールド」『30th ANNIVERSARY ドラゴンボール超史集 -SUPER HISTORY BOOK-』集英社、2018年12月10日、72頁。\\n\\n^ a b Vジャンプ編集部編「鳥山明も振り返ってみたDRAGONBALL!!」『ドラゴンボール超全集4』集英社（愛蔵版コミックス）、2013年5月14日、346-349頁。ISBN\\xa0978-4-08-782499-5。\\n\\n^ a b 「鳥山明INTERVIEW DRAGON BALLと鳥山明」『30th Anniversary ドラゴンボール超史集』集英社、2016年1月26日、88-93頁。ISBN\\xa0978-4-08-792505-0。\\n\\n^ 「明るいニュースを提供 - 読売ADリポート」読売新聞広告局ポータルサイト、2005年9月。\\n\\n^ a b c 「いまへとつながるDB新展開へ」『30th ANNIVERSARY ドラゴンボール超史集 -SUPER HISTORY BOOK-』集英社、2018年12月13日、80頁。\\n\\n^ 「5月9日は“悟空の日”に！日本記念日協会が認定」シネマトゥデイ、2015年5月9日。\\n\\n^ 「集英社「ドラゴンボール室」新設 単独作品の部署は初の試み」ORICON、2016年10月13日。\\n\\n^ 「組織変更及び人事異動に関するお知らせ」東映アニメーション、2018年3月23日。\\n\\n^ 「「ドラゴンボール」の企画・製作を独立 東映アニメーション組織変更で新部署を設立」アニメーションビジネス・ジャーナル、2018年3月24日。\\n\\n^ 鳥山明「其之二十七 ランチのクシャミ」『DRAGON BALL 第3巻』集英社〈ジャンプ・コミックス〉、1986年6月15日、39頁。ISBN\\xa04-08-851833-0。\\n\\n^ a b c d 週刊少年ジャンプ特別編集「超豪華3大マル秘特集 鳥山明スペシャル（2）マンガ「わしとアニメ」」『ドラゴンボールZ アニメ・スペシャル』集英社、8-9頁。\\n\\n^ 渡辺彰則編「ドラゴンボール 世界観用語解説」『ドラゴンボール大全集 7巻』集英社、1996年2月25日、44, 46頁。ISBN\\xa04-08-782757-7。\\n\\n^ ジャンプ・コミック出版編集部編「マンガ「DRAGON BALL」の真実〜トリヤマはこう考えていたよスペシャル〜」『DRAGON BALL 超エキサイティングガイド ストーリー編』集英社、2009年3月9日、92頁。ISBN\\xa0978-4-08-874803-0。\\n\\n^ ジャンプ・コミック出版編集部編「マンガ「DRAGON BALL」の真実〜トリヤマはこう考えていたよスペシャル〜part2」『DRAGON BALL 超エキサイティングガイド キャラクター編』集英社〈ジャンプ・コミックス〉、2009年4月8日、93頁。ISBN\\xa0978-4-08-874804-7。\\n\\n^ 渡辺彰則編「孫悟空戦闘力成長の軌跡」『ドラゴンボール大全集 7巻』83頁。\\n\\n^ ジャンプ・コミック出版編集部編「マンガ「DRAGON BALL」の真実〜トリヤマはこう考えていたよスペシャル〜」『DRAGON BALL 超エキサイティングガイド ストーリー編』集英社、2009年3月9日、88頁。ISBN\\xa0978-4-08-874803-0。\\n\\n^ a b c Vジャンプ編集部編「DRAGON BALL EDITORS INTERVIEW no.2 2代目担当編集 近藤裕」『30th Anniversary ドラゴンボール超史集』集英社、2016年1月26日、54-55頁。ISBN\\xa0978-4-08-792505-0。\\n\\n^ a b c 渡辺彰則編「ドラゴンボールの世界〈用語解説〉」『ドラゴンボール大全集 7巻』50頁。\\n\\n^ a b c d 鳥山明「巻末企画 DRAGON BALL 龍球問答」『DRAGON BALL フルカラー ピッコロ大魔王編1』集英社〈ジャンプ・コミックス〉、2016年3月4日、222-223頁。\\n\\n^ 渡辺彰則編「鳥山明的超会見」『ドラゴンボール大全集 第1巻』集英社、1995年6月26日、205頁。ISBN\\xa04-08-782751-8。\\n\\n^ 「大全集1に掲載されなかった貴重なイラスト達 鳥山明先生の天下一漫画指南!!」『ドラゴンボール大全集7巻』集英社、1996年2月25日、168頁。\\n\\n^ 「ドラゴンボール超インタビュー「とりとよ放談」」VジャンプWEB、2019年3月2日閲覧。\\n\\n^ ジャンプ・コミック出版編集部編「DBと鳥山明」『ドラゴンボール完全版公式ガイド Dragonball FOREVER 人造人間編〜魔人ブウ編 ALL BOUTS & CHARACTERS』集英社、2004年5月5日、集英社、149頁。\\n\\n^ 渡辺彰則編「鳥山明がお送りする DBキャラ秘密の話」『ドラゴンボール大全集7巻』122頁。\\n\\n^ 渡辺彰則編「VARIETY OF DB 鳥山明先生アニメ用メモ大公開!!」『ドラゴンボール大全集 第5巻』集英社、1995年11月7日、68頁。ISBN\\xa04-08-782755-0。\\n\\n^ 『ジャンプ流！ 秘伝ガイド Vol.01 まるごと鳥山明』 集英社、2015年、18頁。\\n\\n^ 「『鳥山明 満漢全席』あとがき」『鳥山明 満漢全席』貳、集英社、2008年9月23日、336-337頁。ISBN\\xa0978-4-08-618773-2。\\n\\n^ ジャンプ・コミック出版編集部編「特別コラム 鳥山明 わしが お答えしまっせ」『テレビアニメ究極ガイド DRAGON BALL 極限バトルコレクション ラウンド02 セル編〜魔人ブウ編』集英社、2010年8月9日、89頁。ISBN\\xa0978-4-08-874841-2。\\n\\n^ Vジャンプ編集部編「DRAGON BALLと鳥山明」『30th Anniversary ドラゴンボール超史集』93頁。\\n\\n^ 鈴木晴彦編「鳥山明アニメデザイン集」『テレビアニメ完全ガイド『DRAGON BALL Z』孫悟空伝説』集英社〈ジャンプ・コミックス〉、2003年10月8日、134-144頁。ISBN\\xa04-08-873546-3。\\n\\n^ “鳥山明先生からのコメント”. ドラゴンボール超ブロリー. 2018年7月10日閲覧。\\n\\n^ ドラゴンボールオフィシャルサイト [@DB30th] (2018年3月15日). \"早速、作ってみたよ！\". X（旧Twitter）より2018年3月31日閲覧。 \\n\\n^ 「この先どうなるインタビュー」『神龍通信 第7号（ドラゴンボール大全集7巻別冊付録）』、集英社、1996年2月25日、2頁。\\n\\n^ 渡辺彰則編『ドラゴンボール大全集 5巻』13頁。\\n\\n^ 渡辺彰則編「鳥山明的超会見」『ドラゴンボール大全集 5巻』211頁。\\n\\n^ a b 渡辺彰則編「鳥山明的超会見」『ドラゴンボール大全集 6巻』集英社、1995年12月9日、213頁。ISBN\\xa04-08-782756-9。\\n\\n^ a b 近藤裕編「DRAGON BALL魂 其之二 ◆鳥山先生 劇場版かく語りき」『Vジャンプ 2004年7月号』集英社、2004年7月1日、205頁。\\n\\n^ 「企画の力 森下孝三東映アニメーション取締役副会長 ドラゴンボール\"復活\"の全貌」『日経エンタテインメント!』2013年5月号No.194、日経BP社、2013年4月4日、22-23頁。\\n\\n^ “原作・脚本・キャラクターデザイン：鳥山明”. ドラゴンボールZ 復活の「F」. 2018年7月5日時点のオリジナルよりアーカイブ。2019年3月4日閲覧。\\n\\n^ Vジャンプ編集部編「VIDEO GAME SELECTION」『30th Anniversary ドラゴンボール超史集』集英社（愛蔵版コミックス）、平成28年（2016年）1月26日、ISBN\\xa0978-4-08-792505-0、182頁。\\n\\n^ 鳥山明「とりやまさんのDRAGON BALL なんでもかんでもコーナー」『DRAGON BALL 第4巻』集英社〈ジャンプ・コミックス〉、1986年10月15日、191頁。ISBN\\xa04-08-851834-9。\\n\\n^ 鳥山明「めずらしくわしがマジメにかたるDr.スランプのヒミツ その(6) センベエさんとミドリさんの結婚」『Dr.スランプ 第16巻』集英社〈ジャンプ・コミックス〉、1985年1月15日、130頁。ISBN\\xa04-08-851196-4。\\n\\n^ “そもそも「編集者」って何なんだ!? 『ドラゴンボール』を手がけた伝説の編集者・鳥嶋和彦が語る、優秀な漫画編集者の条件とは。”.   電ファミニコゲーマー (2021年9月24日). 2022年4月21日閲覧。\\n\\n^ “【全文公開】伝説の漫画編集者マシリトはゲーム業界でも偉人だった！ 鳥嶋和彦が語る「DQ」「FF」「クロノ・トリガー」誕生秘話”.   電ファミニコゲーマー (2016年4月4日). 2021年3月13日閲覧。\\n\\n^ a b c 『30th Anniversary ドラゴンボール超史集』集英社、2016年1月26日、38-41頁。ISBN\\xa0978-4-08-792505-0。\\n\\n^ 「初代担当 鳥嶋和彦氏 秘話を語る」『サンケイスポーツ特別版 ドラゴンボールZ 復活の「F」新聞』28面。\\n\\n^ 「これさぁ、悪いんだけど、捨ててくれる？」――『ジャンプ』伝説の編集長が、数億円を費やした『ドラゴンボールのゲーム事業』を容赦なく“ボツ”にした真相\\n\\n^ a b c d 「神龍通信 第2号 歴代担当者+鳥山明座談会」『ドラゴンボール大全集 2巻』別冊付録、集英社、1995年。\\n\\n^ 『ジャンプ』元編集長・鳥嶋和彦『ONE\\u3000PIECE』『NARUTO』が生まれた裏事情。ライバルを『マガジン』から『コロコロ』に変えたことでみえたものとは\\n\\n^ a b 『30th Anniversary ドラゴンボール超史集』集英社、2016年1月26日、70-71頁。ISBN\\xa0978-4-08-792505-0。\\n\\n^ 『鳥山明○作劇場「改」』其乃壱、188頁。\\n\\n^ ジャンプ・コミック出版編集部編「鳥山明 WITH DRAGON BALL」『ドラゴンボール完全版公式ガイド Dragonball FOREVER 人造人間編〜魔人ブウ編 ALL BOUTS & CHARACTERS』集英社〈ジャンプ・コミックス〉、2004年5月5日、146-155頁。ISBN\\xa04-08-873702-4。\\n\\n^ ジャンプ・コミック出版編集部編「THE SECRET IN Z 知られざる『Z』」『テレビアニメ完全ガイド DRAGONBALL Z 孫悟空伝説』集英社、2003年10月8日、198頁。\\n\\n^ NHK「トップランナー」制作班（編）『トップランナー Vol.9』、KTC中央出版、1999年、95頁。ISBN\\xa04-87758-126-X。\\n\\n^ 「1989-1992」『30th ANNIVERSARY ドラゴンボール超史集 -SUPER HISTORY BOOK-』集英社、2018年12月19日、40頁。\\n\\n^ 「ギネス記録となった全盛期の少年ジャンプを振り返る！」exciteニュース. 2015年12月7日。\\n\\n^ a b 「第68期中間事業報告書」東映アニメーション、2019年3月1日閲覧。\\n\\n^ 「小学生に大人気「ドラゴンボール改こどもハブラシ」新発売」J-CASTニュース、2014年9月28日。\\n\\n^ 「電撃オンラインにDBH開発陣のインタビューが掲載!」スーパードラゴンボールヒーローズ公式サイト、2019年3月1日閲覧。\\n\\n^ 「「SDBHオールスター選抜大投票」結果発表!!」スーパードラゴンボールヒーローズ公式サイト、2019年3月1日閲覧。\\n\\n^ 「「ドラゴンボール」の売り上げが「ワンピース」に圧勝の年間500億! バンダイの決算書から見えた脅威の右肩上がり」GetNavi web、2017年2月15日。\\n\\n^ 「今でも『ドラゴンボール』は『ワンピース』よりも強い!?バンダイナムコの決算で衝撃！」Business Journal、2017年5月13日。\\n\\n^ 「バンナムHDの2019年3月期のIP別売上高、『ドラゴンボール』が1290億円突破 四半期でも過去最高更新 『ドッカンバトル』や『レジェンズ』、玩具好調」Social Game Info、2019年5月9日。\\n\\n^ a b 「バンダイナムコホールディングスIRライブラリ決算短信」バンダイナムコホールディングス、2019年3月1日閲覧。\\n\\n^ a b c d e f “株式会社バンダイナムコホールディングス 2015年3月期、決算短信 補足資料”.   バンダイナムコホールディングス (2015年5月8日). 2019年5月1日閲覧。\\n\\n^ a b c “株式会社バンダイナムコホールディングス 2017年3月期、決算短信 補足資料”.   バンダイナムコホールディングス (2017年5月10日). 2019年5月1日閲覧。\\n\\n^ a b c “株式会社バンダイナムコホールディングス 2018年3月期、決算短信 補足資料”.   バンダイナムコホールディングス (2018年5月9日). 2019年5月1日閲覧。\\n\\n^ a b “株式会社バンダイナムコホールディングス 2019年3月期、決算短信 補足資料”.   バンダイナムコホールディングス (2019年5月9日). 2019年5月23日閲覧。\\n\\n^ a b “バンナムHDの『ドラゴンボール』関連の売上高、20年3月期は「新作映像の展開はなかったが過去最高を更新」”.   Social Game Info (2020年5月26日). 2020年7月1日閲覧。\\n\\n^ a b c “東映アニメーション株式会社 2005年3月期決算 計数資料”.   東映アニメーション (2005年5月16日). 2019年3月4日閲覧。[リンク切れ]\\n\\n^ “東映アニメーション株式会社 2006年3月期決算 計数資料”.   東映アニメーション (2006年5月16日). 2019年3月4日閲覧。[リンク切れ]\\n\\n^ 「東映アニメーション2007年3月期決算。計数資料」東映アニメーション、2007年5月18日。\\n\\n^ “東映アニメーション株式会社 2008年3月期決算 計数資料”.   東映アニメーション (2008年5月15日). 2019年3月4日閲覧。[リンク切れ]\\n\\n^ “東映アニメーション株式会社 2009年3月期決算 計数資料”.   東映アニメーション (2009年5月20日). 2019年3月4日閲覧。[リンク切れ]\\n\\n^ “東映アニメーション株式会社 2010年3月期決算 計数資料”.   東映アニメーション (2010年5月14日). 2019年3月4日閲覧。[リンク切れ]\\n\\n^ “東映アニメーション株式会社 2017年3月期決算 計数資料”.   東映アニメーション (2017年5月15日). 2019年3月4日閲覧。[リンク切れ]\\n\\n^ “東映アニメーション株式会社 2018年3月期決算 計数資料”.   東映アニメーション (2018年5月16日). 2019年3月4日閲覧。[リンク切れ]\\n\\n^ 「国際比較日本力」『イミダス2007』集英社、2006年11月2日。\\n\\n^ 「映画「ドラゴンボールZ」17年ぶり新作！空白の10年間描く」コミックナタリー、2012年7月14日。\\n\\n^ 「集英社「ドラゴンボール室」新設 単独作品の部署は初の試み」ORICON NEWS、2016年10月13日。\\n\\n^ 『DRAGON BALL ジャンプ ベストシーンTOP10』「伝説の漫画ドラゴンボール!」「限界突破で広がるドラゴンワールド!!!!」集英社ムック、2018年11月2日、8-11頁。ISBN\\xa0978-4-08-102271-7。\\n\\n^ a b 「Retour sur la conférence de presse autour de Dragon Ball Super」Manga news.com、2017年4月5日。\\n\\n^ Glénat Manga [@Glenat_Manga] (2017年3月30日). \"\"Dragon Ball, c\\'est 30 millions d\\'exemplaires vendus en France\"\". X（旧Twitter）より2019年3月24日閲覧。 \\n\\n^ a b c d 「청소년 심리 교묘히 자극…인기 ‘한몸에’ 」한한국경제매거진、2009年3月。\\n\\n^ 「드래곤볼 신들의전쟁 “비루스와 손오공, 지구의 운명 걸고 세기의 대결”」아시아투데이、2013年9月14日。\\n\\n^ 「Dragon Ball, o la historia de un gran éxito」Zona Negativa、2006年3月11日\\n\\n^ a b 「出版社に聞く、スペイン・マンガ事情」AIDE新聞、2014年5月15日。\\n\\n^ a b c “Editoriindipendenti, il primo per copie vendute è Star Comics”.   Yahoo! Finanza (2021年1月13日). 2021年4月6日閲覧。\\n\\n^ a b c 「七龙珠之父隐退 漫迷：神龙快留他」新浪娱乐、2013年3月29日。\\n\\n^ 「七龙珠之父隐退 漫迷：神龙快留他（正版销量千万册《七龙珠》在华最抢手）」新浪公司、2013年3月29日。\\n\\n^ 「K BOOK 日本妹愛紗：進入社會工作後 《七龍珠》回憶無法抹滅」蘋果日報、2009年2月28日。\\n\\n^ 「《七龙珠》快评：悟空的生死是最大的误传(图)」新浪娱乐、2009年3月13日。\\n\\n^ a b 「CARLSEN Comic und Manga Herbst/ Winter 2015/2016」CARLSEN Verlag、45頁。2019年3月1日閲覧。\\n\\n^ a b c 「Dragon Ball」Carlsen Verlag、2019年3月1日閲覧。\\n\\n^ a b 「Como desenhar Mangá」Folha de S.Paulo、2002年11月26日。\\n\\n^ 「Dragon Ball Full Color Freeza Arc, Vol. 3[リンク切れ]」SIMONAN&SCHUSTER Digital Catalog、2019年3月4日閲覧。\\n\\n^ a b c 「「デンマークにおける日本マンガ市場」」在デンマーク日本大使館、2007年10月2日。\\n\\n^ a b 「A Land of Avid Readers」Publishers Weekly、2006年9月15日。\\n\\n^ 「Vain suomalaiset manga-harrastajat kinusivat vanhaa koiraa」Hopeanuoli.com、2019年3月1日閲覧。\\n\\n^ 「Jeesuksesta tehtiin manga-sarjakuva」Yle.fi、2009年10月7日。\\n\\n^ 「ポーランドにおけるマンガ市場基礎調査」日本貿易振興機構（ジェトロ）、2008年3月。\\n\\n^ a b c 「英国におけるコンテンツ市場の実態」日本貿易振興機構、2011年3月。\\n\\n^ a b 「ベトナムにおけるコンテンツ市場の実態」日本貿易振興機構（ジェトロ）、2008年3月。\\n\\n^ “全地球人対応版「ＤＲＡＧＯＮ ＢＡＬＬ ＯＦＦＩＣＩＡＬ ＳＩＴＥ」オープンのご案内”.   PR TIMES (2021年5月9日). 2021年5月14日閲覧。\\n\\n^ 「ドラゴンボール ビデオゲームデータ」『30th ANNIVERSARY ドラゴンボール超史集 -SUPER HISTORY BOOK-』集英社、216頁。\\n\\n^ 『ギネス世界記録2013』角川マガジンズ、2012年、J-06頁。\\n\\n^ “「ドラゴンボール ファイターズ」「ドラゴンボール ゼノバース２」累計出荷本数1,000万本突破記念キャンペーンを開催!!”.   ドラゴンボールオフィシャルサイト (2023年5月10日). 2023年5月10日閲覧。\\n\\n^ 「「ドラゴンボールゲーム祭り」生配信決定!」ドラゴンボール ゼノバース2。2019年1月29日閲覧。\\n\\n^ “［TGS2022］「ドラゴンボール ザ ブレイカーズ」への魔人ブウ参戦などが発表されたバンダイナムコのスペシャル番組詳報。「KAKAROT」では新DLC情報も”.   4Gamer.net (2022年9月18日). 2023年3月6日閲覧。\\n\\n^ 「株式会社ディンプスの採用・求人情報【会社概要】」GeekOut。2019年1月29日閲覧。\\n\\n^ a b c d 「DRAGON BALL スーパーデータ DRAGON BALL VIDEO GAME DATA」『30th Anniversary ドラゴンボール超史集』集英社、216頁。\\n\\n^ “バンダイナムコホールディングス 2006年3月期 通期 決算短信 補足資料” (PDF).   バンダイナムコホールディングス (2006年5月11日). 2019年3月4日閲覧。\\n\\n^ “バンダイナムコホールディングス 2007年3月期 通期 決算短信 補足資料” (PDF).   バンダイナムコホールディングス (2007年5月19日). 2019年3月4日閲覧。\\n\\n^ 「2007年度 トップ10タイトル」バンダイナムコホールディングス2008年3月期補足資料、2008年5月8日。2019年1月29日閲覧。\\n\\n^ “ドラゴンボールヒーローズ：10年でカード累計出荷数10億枚突破”.   MANTANWEB (2020年11月5日). 2021年7月3日閲覧。\\n\\n^ 「メルカリ，2019年上半期のトレンドワードを発表。1位は「スーパードラゴンボールヒーローズ」」4Gamer.net、2019年6月27日。\\n\\n^ 「バンナム、『ドッカンバトル』で「全世界3億5000万DL突破!!地球まるごと！特大震撼キャンペーン」開催中\\u3000ナメック星編で活躍したキャラ達が登場」gamebiz、2021年9月16日。\\n\\n^ 「「Google I/O」で優れたゲームやアプリを紹介するGoogle PlayAwardsを実施…『ドッカンバトル』と『ポケとる』らがノミネート」Social Game Info、2016年5月16日。\\n\\n^ 「2016年のApp Store売上ランキング首位は『モンスターストライク』に！ 『Pokémon GO』や『シャドウバース』『白猫テニス』など新作も登場」Social Game Info、2016年12月07日。\\n\\n^ 「App Annie「2016年アプリ市場レポート」を発表。全世界のアプリDL数は900億件超え，収益は40%増，ユーザーあたりの収益は日本がトップに」4Gamer.net、2017年1月17日。\\n\\n^ 「「ドラゴンボール レジェンズ」が全世界8000万ユーザー突破でエピソードCP開催中！ 映画『SAND LAND（サンドランド）』日本公開記念連動ログインボーナスもスタート！」ドラゴンボール オフィシャルサイト、2023年8月18日。\\n\\n^ 「65,000人が選ぶ「マイベストムービー」発表-グランプリは「24」」市ケ谷経済新聞、2008年3月18日。\\n\\n^ 「1000人が選んだ!漫画史上“最強”キャラクターランキング!」、オリコン、2007年6月22日。\\n\\n^ 「ヒーローの必殺技。使えるとしたら誰に?」ORICON、2007年4月8日。\\n\\n^ “1度使ってみたい「かめはめ波」と「四次元ポケット」?”. オリコン ライフ.   ORICON (2008年4月14日). 2008年6月17日時点のオリジナルよりアーカイブ。2019年3月24日閲覧。\\n\\n^ 「ドラゴンボール、ガンダムを制して1位」テックインサイト、2008年4月2日。\\n\\n^ 「宇宙最強だと思うアニメ・コミックのキャラクターランキング」gooランキング、2008年9月26日。\\n\\n^ 「昭和50年代生まれの男性が懐かしく感じるものは？」ITmedia ビジネスオンライン、2009年6月4日。\\n\\n^ 「漫画の名脇役ランキング、1位はドラゴンボールの「クリリン」」ORICON、2009年5月24日。\\n\\n^ “東京工芸大学、クール・ジャパンに関する調査” (PDF).   東京工芸大学 (2010年5月18日). 2012年2月4日時点のオリジナルよりアーカイブ。2019年3月24日閲覧。\\n\\n^ 「『週刊少年ジャンプ』マンガの魅力度比較調査～『ドラゴンボール』の圧勝！」聞く技術研究所、2013年1月7日。\\n\\n^ 「【ランキング】あなたが思う「最強のジャンプマンガ」は？ 強豪ひしめく中、第1位はやはり…！？」ダ・ヴィンチニュース、2014年11月12日。\\n\\n^ 「クールジャパンに関する調査」ネオマーケティング、2015年8月26日。\\n\\n^ 「マジで絶望感を与えられたジャンプの敵キャラといえば？ 3位魔人ブウ」goo、2017年3月10日。\\n\\n^ 「最強に魅力的だった！ジャンプのラスボスランキング」ニコニコニュース 2018年1月11日。\\n\\n^ 「子どものころ好きだったアニメ1位は『ドラゴンボール』、強い敵と戦う姿に多くの世代が魅了」ORICON、2018年4月21日。\\n\\n^ 「アニメに登場する最強の老人キャラといえば？ 3位「シンフォギア」風鳴訃堂、2位「HUNTER×HUNTER」ネテロ、1位は…」アニメ！アニメ！、2019年9月16日。\\n\\n^ 「圧倒的カリスマ性のあるジャンプ主人公ランキング 1位から10位」gooランキング、2019年5月8日。\\n\\n^ 「これぞ「真の国民的漫画」と思う漫画ランキング 1位から10位」gooランキング、2019年7月15日。\\n\\n^ 「せりふ回しが天才的なジャンプ作品ランキング」gooランキング、2019年9月27日。\\n\\n^ 「ジャンプ史上最強の「悪のカリスマ」ランキング」gooランキング、2019年11月30日。\\n\\n^ “「あなたが選ぶ少年マンガ ベスト1は？」結果発表……「鬼滅の刃」は7位、2位は「スラムダンク」、では1位は？”. 文集オンライン (2020年7月3日). 2020年7月4日閲覧。\\n\\n^ 「PlayStation Awards 「過去の受賞タイトル」」Sony、2019年3月1日閲覧。\\n\\n^ a b 「大ヒットアニメ「ドラゴンボールZ」単巻DVDビデオ・オブ・ザ・イヤー2006「最優秀アニメ賞」「グランプリ第10位」DVD・オブ・ザ・イヤー2006「TVアニメ・OVA部門第3位」受賞！」東映アニメーション、2007年4月23日。\\n\\n^ 「『劇場版 東映グループ作品『海難1890』『ドラゴンボールＺ 復活の「Ｆ」』『起終点駅 ターミナル』『百円の恋』が第39回日本アカデミー賞 優秀賞を受賞！」東映、2016年1月18日。\\n\\n^ 「ゴールデングロス賞」全国興行生活衛生同業組合連合会、2019年3月1日閲覧。\\n\\n^ 「GearVRが「モバイルプロジェクトアワード」ハード部門最優秀賞 コンテンツはAbemaTVが最優秀賞、ドラゴンボールZドッカンバトルも優秀賞に」Social Game Info、2016年7月4日。\\n\\n^ 「「日本おもちゃ大賞2017」メガハウスが大賞・優秀賞 計3商品受賞！「BotsNew Characters VR DRAGONBALL Z」はイノベイティブ・トイ部門優秀賞！」VR Inside、2017年5月30日。\\n\\n^ 「［TGS 2017］「巨影都市」「PUBG」など10作品が選出。来場者投票で選ぶ「日本ゲーム大賞2017 フューチャー部門」受賞作が発表に」4Gamer.net、2017年9月24日。\\n\\n^ 「日本商品化権大賞2017、「ドラゴンボールシリーズ」「怪盗グルーシリーズ」「ポケモン」が受賞」オフィスマガジン online、2018年1月30日。\\n\\n^ 「【JASRAC賞】著作物使用料分配額1位は「恋」 星野源が初の金賞「とても幸せ」」ORICON、2018年5月23日。\\n\\n^ 「【JASRAC賞】著作物使用料分配額1位は安室奈美恵さん「Hero」」ORICON、2019年5月22日。\\n\\n^ 「『モンスターハンター：ワールド』が2部門受賞！ “PlayStation Developers Choice Awards 2018”で6部門が表彰」ファミ通、2018年5月25日。\\n\\n^ ドラゴンボール レジェンズ公式 [@db_legends_jp] (2018年12月7日). \"【Google Play ベスト ゲーム2018受賞!!】\". X（旧Twitter）より2019年3月24日閲覧。 \\n\\n^ 「ドラゴンボール超 ブロリー：日本アカデミー賞の優秀アニメーション作品賞受賞 「復活の『F』」に続き2作品連続」MANTANWEB（まんたんウェブ）、2019年1月15日。\\n\\n^ 「ABOUT THE ANIME AWARDS」2019ANIME AWARDS公式、2019年6月11日閲覧。\\n\\n^ 「CEDEC AWARDS 2019発表授賞式リポート。桜井政博氏ら受賞者の喜びの声をお届け【CEDEC 2019】」ファミ通、2019年9月6日。\\n\\n^ a b 「ドラゴンボール カードダスシリーズ」『30th ANNIVERSARY ドラゴンボール超史集 -SUPER HISTORY BOOK-』集英社、162頁。\\n\\n^ 「プレスリリース デジタルデータと融合した新しいカード遊びが誕生!」株式会社バンダイ、2004年12月8日。\\n\\n^ 「アニメヒーロー１位は世代超えてドラゴンボール孫悟空！[リンク切れ]」スポーツ報知、2017年8月26日。\\n\\n^ 「2007年、最も全巻読破されたコミックランキング第1位は「ドラゴンボール」」MarkeZine、2008年2月18日。\\n\\n^ 「2007年度、最も読まれた漫画全巻セットは「クローズ」」ValuePress!、2008年4月14日。\\n\\n^ 「ドラゴンボールに関する調査」ライフネット生命、2013年3月28日。\\n\\n^ “（熱血！マンガ学）DRAGON BALL 悟空の「成長物語」一大産業に【大阪】”. 好書好日.   朝日新聞社 (2008年5月13日). 2011年7月28日時点のオリジナルよりアーカイブ。2019年3月24日閲覧。\\n\\n^ “世界に進出した日本の人気アニメ ベスト100”. 決定!これが日本のベスト100全国一斉○○テスト.   テレビ朝日. 2004年12月11日時点のオリジナルよりアーカイブ。2019年3月24日閲覧。\\n\\n^ 「世界に通用していると思う日本のアニメ、1位『ドラゴンボール』」ORICON NEWS、2009年8月2日。\\n\\n^ 「世界に通用しているマンガ＆アニメランキング『日本が世界に誇る！傑作マンガ＆アニメの頂点は？』」ORICON NEWS、2012年8月3日。\\n\\n^ a b c d e f g h i j k 『ドラゴンボール最強への道・劇場版ご近所物語前売』前売り特典小冊子。\\n\\n^ a b 「Dragonball Z - Season 9 - Blu-ray」ファニメーション、2019年3月1日閲覧。\\n\\n^ 「20 Years Ago, Dragon Ball Z Came to America to Stay」CBR.com、2016年9月18日。\\n\\n^ Mark Lasswell, \"Year of the Dragon,\" TV GuideSally Beatty, \"Kids Are Glued to a Violent Japanese Cartoon Show,\" The Wall Street Journal, 1999.\\n\\n^ 「Violent Japanese Cartoon Show Draws Kids\\' Eyes, Parents\\' Scorn」The Wall Street Journal、1999年12月3日。\\n\\n^ 「Dragon Ball: 15 Crazy Things You Didn’t Know About The American Version」Screen Rant、2018年3月20日。\\n\\n^ 「日本発ANIME米でのビジネスはどこまで本格化したのか？」AvantiPress、2013年1月11日。\\n\\n^ 「DBZ RULES」ICV2、2001年10月17日。\\n\\n^ 「Dragonball Z Tops Ratings」Anime News Network、2002年9月28日。\\n\\n^ 「DRAGON BALL GT ON THE CARTOON NETWORK」ICV2、2003年8月13日。\\n\\n^ 「DRAGON BALL GT\\'S AWESOME DEBUT」ICV2、2003年11月13日。\\n\\n^ 「DBZ TOPS LYCOS 50 FOR 2002」ICV2、2002年12月8日。\\n\\n^ 「DRAGON BALL CELEBRATES 200 WEEKS ON THE LYCOS TOP 50」ICV2、2003年6月25日。\\n\\n^ 「検索ワード過去10年ランク ドラゴンボールが2位」アニメ!アニメ!、2005年9月21日。\\n\\n^ 「Britney loses out to PlayStation」BBC、2002年12月30日。\\n\\n^ 「米CNでドラゴンボールZの再放送開始」アニメ!アニメ!、2006年2月14日。\\n\\n^ 「DRAGON BALL Z FINALLY COMES HOME」IGN、2000年11月15日。\\n\\n^ 「アタリ、「ドラゴンボール」のライセンス問題で350万ドルを支払い」 インサイド、2007年12月11日。\\n\\n^ 「Namco Bandai Gets N. American Dragon Ball Game Rights」Anime News Network、2009年7月4日。\\n\\n^ 「SCORE ADVANCES INTO MASS MERCHANTS WITH DBZ CCG」ICV2、2001年10月14日。\\n\\n^ “THE \\'DRAGON BALL\\' UNIVERSE RETURNS IN NEW TCG”. 2019年10月16日閲覧。\\n\\n^ “DRAGONBALL SUPER CARD GAME Booster Pack”. 2019年10月16日閲覧。\\n\\n^ 「EVENT」DRAGON BALL SUPER CARD GAME、2019年3月1日閲覧。\\n\\n^ 「The Biggest, Baddest Dragon Ball Z Giveaway on Earth」Raving Toy Maniac、2019年3月1日閲覧。\\n\\n^ 「Dragon Ball Z Season One the Number One Anime Seller Year-to-Date」ANIME NEWS NETWORK, 2007年5月17日。\\n\\n^ 「北米のマンガ事情第10回 『セーラームーン』が北米でなぜ今売れているのか。」アニメ!アニメ!ビズ 2012年1月15日。\\n\\n^ 「\\'Dragon Ball\\'s\\' voice of Goku speaks for himself」Los Angeles Times、2017年6月30日。\\n\\n^ 「「ドラゴンボール改」が米国で好発進、放送局で開局以来最高視聴率」ナリナリドットコム、2010年6月4日。\\n\\n^ 「ドラゴンボールZ 神と神、米国公開4日間で興収2億円超、追加上映も決定」アニメ!アニメ!、2014年8月12日。\\n\\n^ 「映画の本場ハリウッドに野沢雅子と悟空が降臨」東映、2015年4月13日。\\n\\n^ 「Box Office Mojo Dragon Ball Z:Resurrection \\'F\\'」Box Office Mojo、2019年3月1日閲覧。\\n\\n^ 「Daily Box Office」Box Office Mojo、2019年3月1日閲覧。\\n\\n^ 「ドラゴンボール超 ブロリー：北米のデーリーランキング1位 日本アニメで今世紀初の快挙！」まんたんウェブ、2019年1月18日。\\n\\n^ 「「ドラゴンボール超」米国5日間興収が23億円、ジブリ作品全てを超える」アニメーションビジネス・ジャーナル、2019年1月21日。\\n\\n^ 「世界の学校を見てみようカナダ編」外務省、2015年11月。\\n\\n^ 「「ドラゴンボールZ 神と神」 800スクリーンで8月5日に米国・カナダ公開」アニメ!アニメ!、2014年7月18日。\\n\\n^ a b 「ドラゴンボールから命名、ペルーに多数 「フリーザ」も」『朝日新聞』朝日新聞社、2017年12月12日。2019年3月24日閲覧。オリジナルの2017年12月12日時点におけるアーカイブ。\\n\\n^ 「「ドラゴンボール」から「キルラキル」各国の日本アニメ事情：ビジネスセミナー「AnimeJapan×JETRO×Project Anime」」アニメ!アニメ!、2015年3月22日。\\n\\n^ 「【目覚めよ日本力】「日の丸アニメ」根強い人気 海外にはない“大人向け”も理由」イザ.産経デジタル、2013年11月3日。\\n\\n^ a b c d e f g 「中南米における映像コンテンツ産業の現状」日本貿易振興機構、2014年11月。\\n\\n^ a b c 「Por qué \"Dragon Ball Z\" está entre lo más buscado en los sitios porno de México」Infobae、2018年8月11日。\\n\\n^ 「Dragon Ball GT regresa a la televisión mexicana」FayerWayer、2019年2月12日。\\n\\n^ 「Recordamos cuando México disfrutó Dragon Ball Super como un partido de futbol」テレビサ、2019年12月5日。\\n\\n^ 陸海空 地球征服するなんて [@chikyu_seifuku_] (2018年9月8日). \"『地球アンケート～世界で一番有名な日本人は誰だ！？～』(メキシコ編)\". X（旧Twitter）より2019年3月24日閲覧。 \\n\\n^ Armando Cabada [@armando_cabada] (2018年3月17日). \"Con el poder de las Esferas del Dragón, logramos cumplir el deseo de la juventud Juarense\". X（旧Twitter）より2019年3月24日閲覧。 \\n\\n^ a b c 「Así se vivió el capítulo 130 de Dragon Ball Super a lo largo de México」codigoespagueti.com、2018年3月19日。\\n\\n^ 「La película de Dragon Ball recaudó durante el fin de semana 123.6 millones de pesos y registró la asistencia de 2.3 millones de personas」López-Dóriga Digital、2019年1月14日。\\n\\n^ 「Argentina dragon ball」EL LITORAL、2009年3月7日。\\n\\n^ 「TOP10 LO MEJOR DE MAGICKIDS ANIMÉ」Malditos Nerds、2014年8月27日。\\n\\n^ 「Dragon Ball, el fenómeno nipón que pasa por generaciones, cumple 35 años」Huarpe、2019年11月20日。\\n\\n^ 「DDragon Ball Super: Broly derrotó a Avengers: Infinity War y logra récord de ventas de medianoche en el Perú」RPP、2019年1月10日。\\n\\n^ 「\"Dragon Ball Super: Broly\": se convierte en el segundo mejor estreno del cine peruano」El Comercio、2019年1月12日。\\n\\n^ 「「ドラゴンボールZ 神と神」10月ブラジル公開 ブラジルゲームショウに公開記念ゲーム登場」アニメ!アニメ!、2013年10月30日。\\n\\n^ 「Vamos conquistar as esferas do dragão? Saga Dragon Ball celebra 30 anos de TV」DIARIO de PERNAMBUCO、2016年2月26日。\\n\\n^ 「越境する日本文化 マンガ・アニメ（２）＝激増する〃Otaku〃たち＝マンガ読者人口５百万人」ニッケイ新聞、2003年1月22日。\\n\\n^ 「Conrad | Cancelamentos e novidades」omelete、2011年5月9日。\\n\\n^ 「越境する日本文化 マンガ・アニメ（４）＝鼻息荒いマンガ出版業界＝日系が始め伯人が市場拡大」ニッケイ新聞、2003年1月24日。\\n\\n^ a b 「Resultado da busca por dragon ball」Guia dos Quadrinhos、2019年3月2日閲覧。\\n\\n^ 「世界の学校を見てみようパラグアイ共和国」外務省、2013年7月。\\n\\n^ 「【第21回パラグアイ便り】『パラグアイの若者を引きつける日本マンガ文化事情』」在パラグアイ日本国大使館、2016年4月。\\n\\n^ 「世界の学校を見てみよう！コスタリカ共和国（Republic of Costa Rica）」外務省、2013年7月。\\n\\n^ 「SOBRE NOSOTROS」Telesistema公式、2019年11月4日閲覧。\\n\\n^ 「Le \"Club Dorothée\" fête ses 30 ans」RTBF Webcréation、2017年9月2日。\\n\\n^ “L\\'ÉVÉNEMENT POUR LES 30 ANS DE DRAGON BALL À PARIS”. fugujapon. 2018年7月14日時点のオリジナルよりアーカイブ。2019年3月24日閲覧。\\n\\n^ 「足りません、映像ソフト 確保へ業界は“国際戦略”」『朝日新聞』1989年12月2日付夕刊、17面。\\n\\n^ 「Comment «\\xa0Dragon Ball\\xa0» a traversé les générations」ル・モンド、2014年7月10日。\\n\\n^ 『東映アニメーション50年史』凸版印刷、2006年。\\n\\n^ a b 「マンガはなぜ赦されたのか -フランスにおける日本のマンガ- 第3回「グレナはなぜマンガ出版に乗り出したのか」」アニメ!アニメ!ビズ、2015年4月19日。\\n\\n^ a b 「Dragon Ball (sens français) - Tome 1」Glénat公式、2019年10月7日閲覧。\\n\\n^ 「欧州におけるコンテンツ市場の実態68ページ」日本貿易振興機構、2007年3月。\\n\\n^ 「フランスを中心とする欧州におけるコンテンツ市場の実態」日本貿易振興機構、2009年3月。\\n\\n^ 「フランスを中心とする欧州のコンテンツ市場」日本貿易振興機構、2011年3月。\\n\\n^ “フランスを中心とする欧州のコンテンツ市場調査（2011-2012）”.   日本貿易振興機構 (2013年3月). 2019年3月4日閲覧。\\n\\n^ 「Dossier Bilan de l’année manga 2017 en France\\xa0: les tops, les flops, l’état du marché…」Manga Mag、2018年2月20日。\\n\\n^ “«DRAGON BALL Z»\\xa0: LA PASSION TOUJOURS VIVE, PLUS DE TROIS DÉCENNIES PLUS TARD”.   cnews (2022年4月27日). 2022年5月27日閲覧。\\n\\n^ 「フランスにおける日本アニメを中心とするコンテンツの浸透状況」日本貿易振興機構、2005年3月。\\n\\n^ 「Spécial Salon du livre de Paris mars 2012」BIEF、2012年5月。\\n\\n^ 「Les ventes de One Piece dépassent enfin celles de Dragon Ball en France」L\\'éclaireur、2022年3月10日。\\n\\n^ 「Pourquoi la folie Dragon Ball est bien partie pour durer, quarante ans après la création du manga」Ouest-France、2023年3月1日。\\n\\n^ 「\"Dans l\\'édition, le numérique est un flop total\" (Jacques Glénat, Editions Glénat)」La Tribune、2019年5月2日。\\n\\n^ 「Bilan de l’année manga 2017 en France」Manga Mag、2018年2月20日。\\n\\n^ 「Le marché de la BD a fait en 2018 son meilleur score depuis 15 ans」ActuaBD、2019年1月20日\\n\\n^ パリ産業情報センター 「一般調査報告書 - フランスにおけるマンガについて」 愛知県、2010年12月10日。\\n\\n^ 「文化庁主催 コンテンツ流通促進シンポジウム「著作物の流通・契約システムに関する研究会」」 文化庁、2004年6月28日。\\n\\n^ 「仏国際漫画祭、特別賞に鳥山明さんドラゴンボール」日本経済新聞、2013年2月4日。\\n\\n^ 「Akira Toriyama nommé Chevalier de l\\'Ordre des Arts et des Lettres」ハフポスト、2019年5月31日。\\n\\n^ 「「ドラゴンボール」鳥山明さん、仏芸術文化勲章を受章」朝日新聞デジタル、2019年6月3日。\\n\\n^ 「「鉄腕アトム」「ドラゴンボール」が「歴史を変えたテレビ番組」に選出!」シネマトゥデイ、2013年3月28日。\\n\\n^ “アトム、グレンダイザー、ドラゴンボール、加トケンが『世界のテレビを変えた50作』に選出”.   International Business Times. 2014年12月20日時点のオリジナルよりアーカイブ。2018年4月6日閲覧。\\n\\n^ 「フランス人は日本文化が大好き!? “「日本のゲームが海外に通用しない」なんてウソだ！”リポート【CEDEC 2013】」ファミ通、2013年8月23日。\\n\\n^ 「PSGゴール裏に巨大「孫悟空」出現！ 酒井宏樹も出場の試合で異例の応援」フットボールチャンネル、2018年2月26日。\\n\\n^ 「「ジャパンエキスポ」もいまや巨大イベントフランス新聞「ル・モンド」が発表「日本の傑作漫画20選」」COURRiER Japon、2019年7月8日。\\n\\n^ 「RTL II Special: Liste aller RTL II Anime-Serien」Anime2You、2015年4月21日。\\n\\n^ 「HEUTE VOR 16 JAHREN: «DRAGON BALL Z» FEIERT DEUTSCHLANDPREMIERE BEI RTL 2」MAnime.de、2017年8月27日。\\n\\n^ 「QUOTEN-ARCHIV: DER QUOTENREKORD VONDRAGON BALLZ」MAnime.de、2018年12月8日。\\n\\n^ 「Deutsche Mangas」SPIEGEL ONLINE、2007年12月11日。\\n\\n^ 「Verkaufszahlen zum „Dragon Ball“-Manga bekannt」Manga Passion、2021年5月4日。\\n\\n^ 「ポーランドにおけるマンガ市場基礎調査」日本貿易振興機構、2008年3月。\\n\\n^ a b 「WYWIAD Z WYDAWNICTWEM J.P.FANTASTICA」Kosz z książkami、2017年8月7日。\\n\\n^ “J.P. Fantastica （rok 2018）]”. J.P. Fantastica. 2018年3月30日時点のオリジナルよりアーカイブ。2019年3月24日閲覧。\\n\\n^ 「Letteralmente ‘SFERA DEL DRAGO’: serie tratta dal manga ‘Dragon Ball’ di Akira Toriyama, racconta di」Einstein Journal、2017年7月25日。\\n\\n^ 「DRAGON BALL Z, RITORNANO LE SETTE SFERE DEL DRAGO IN TV E IN FUMETTERIA」Everyeye.it、2011年6月27日。\\n\\n^ a b 「TOEI ANIMATION CELEBRATES RECORD RATINGS FOR “DRAGON BALL SUPER” ACROSS EUROPE」Licesing Magazine、2017年4月22日。\\n\\n^ 「Dragon Ball Super: Gli ascolti su Italia 1」Passione Anime、2018年1月20日。\\n\\n^ “Star Comics,dragon ball,volume1”.   Star Comics. 2020年7月1日閲覧。\\n\\n^ “Star Comics,dragon ball,volume62”.   Star Comics. 2020年7月1日閲覧。\\n\\n^ “DRAGON BALL DELUXE 1”.   Anime Click. 2020年7月1日閲覧。\\n\\n^ “フランスとイタリアにおける「日本」と「マンガ」のイメージマンガ読者／非読者調査の第1次主要結果報告（P201）”.   日本マンガ学会. 2020年7月1日閲覧。\\n\\n^ フランクフルト・ブックフェア コミック「日本発」へ熱い視線「急成長」印税50億円 朝日新聞(大阪版)2002年10月29日付朝刊 14面〜15面\\n\\n^ 「イタリアにおけるコミック・アニメ市場基礎調査」日本貿易振興機構、2007年3月。\\n\\n^ a b 「イベロ・マンガ スペインでの主流からニッチとしての女性マンガとガフオタクまで」京都精華大学国際マンガ研究センター、2013年12月30日。\\n\\n^ a b 「Japón hipnotizacon‘Bola de Drac」LAVANGUARDIA、1992年5月9日。\\n\\n^ 「西遊記公開記念！SmaSTATION!!ランキング『大人が選ぶアニメヒーローベスト30』」SmaSTATION!!、2007年7月14日。2019年3月4日閲覧。\\n\\n^ 「Dragon Ball: historia de su gran éxito」Akira Comics、2017年3月30日。\\n\\n^ “DRAGON BALL. SERIE ROJA”. TEBEOSFERA. 2018年9月1日時点のオリジナルよりアーカイブ。2019年3月24日閲覧。\\n\\n^ 「EL SALÓ DEL MANGA DE BARCELONA CELEBRA ELS 25 ANYS DEL MANGA DE DRAGON BALL A ESPANYA」Comic Barcelona、2017年10月29日。\\n\\n^ 「“超サイヤ人”メッシとネイマールが「フュージョン」…日本アニメは世界共通」ゲキサガ、2016年9月14日。\\n\\n^ 「柴崎岳が「超サイヤ人」に！？リーガ公式「孫悟空コラ」に反響」J-CASTニュース、2017年9月19日。\\n\\n^ 「乾のベティス加入動画が伊でも話題！ アニメキャラ登場する「中毒性のある内容」」サンスポ、2018年6月2日。\\n\\n^ 「\"Dragon Ball\" vai regressar à SIC」Move Notícias、2016年6月29日。\\n\\n^ 「イギリスで制作中のファンムービー『実写版ドラゴンボールZ』がすごすぎる！ ハリウッドを余裕で超えるレベルで笑った」ロケットニュース24、2012年9月11日。\\n\\n^ 「英国・フランスにおけるコンテンツ産業調査」日本貿易振興機構（ジェトロ）、2019年3月。\\n\\n^ 「UKチャート1/21～27：「モンスターハンター：ワールド」が見事初登場1位を獲得、“ドラゴンボールファイターズ”も2位に」doope、2018年1月29日。\\n\\n^ “Dragon Ball Z: Kakarot Tops UK Sales Charts”.   SegmentNext (2020年1月21日). 2020年1月21日閲覧。\\n\\n^ 「〈ふたつのＭ－マンガと村上春樹１〉北欧に響く「かめはめ波」」『朝日新聞』朝日新聞社、2006年11月21日。2019年3月24日閲覧。オリジナルの2006年12月14日時点におけるアーカイブ。\\n\\n^ 「タンミ社で聞くフィンランドのマンガ事情」AIDE新聞、2017年12月29日。\\n\\n^ “トキコのフィンランドEメール日記Vol.16 accessdate=2019-03-24”. 北信州ネット. 2008年6月12日時点のオリジナルよりアーカイブ。\\n\\n^ 「MTV3.fi[リンク切れ]」MTV Uutiset、2003年5月21日。\\n\\n^ 『北欧スタイル』2006年9号、107頁。\\n\\n^ 「ハンガリーにおけるコンテンツ市場基礎調査」日本貿易振興機構、2007年3月。\\n\\n^ 「“見る”から“作る”へ── 東京が舞台のアニメも制作中！アラブ世界の日本のアニメ事情」note、2016年2月17日。\\n\\n^ 「海外アニメ関係者が語る日本アニメ海外進出のカギ」東スポWeb、2013年3月22日。\\n\\n^ 「世界の学校を見てみよう、南アフリカ共和国（Republic of South Africa）」外務省、2013年10月。\\n\\n^ 「大使年末のご挨拶」在カメルーン日本国大使館、2016年12月28日。\\n\\n^ 「ベナンの出版・図書事情」NPO法人IFE、2009年4月11日。2019年3月4日閲覧。\\n\\n^ “Dragon Ball Super to battle it out for the first time on Cartoon Network Africa!”.   WarnerMedia (2020年3月5日). 2020年4月17日閲覧。\\n\\n^ “Dragon Ball Super debuts on Cartoon Network Africa”.   Communication Week (2020年3月7日). 2020年4月17日閲覧。\\n\\n^ a b “Israelis break Kamehameha world record for Dragon Ball Super: Super Hero”.   The Jerusalem Post (2022年8月21日). 2022年9月6日閲覧。\\n\\n^ 「平成21年度イスラエルの消費市場とビジネスグループ」日本貿易振興機構、2010年3月。\\n\\n^ 『東大オタク学講座』（1997年9月26日版）。\\n\\n^ 「岐路のアジア 第3部・ 漫画「日本発」根付く共通文化」『朝日新聞』（大阪版）2005年12月6日付朝刊、8面、国際欄。\\n\\n^ 「2005年9月22日号、中国版「ドラゴンボール」／発売100日で100万部」新文化通信社、2019年3月4日閲覧。\\n\\n^ 「中国における日本製コンテンツ放映・上映・発売状況等データ」日本貿易振興機構、2010年1月、12頁。\\n\\n^ “チャウ・シンチー監督、自身の新作『西遊記』は「『ドラゴンボール』からひらめきを受けた」”. NewsWalker.   KADOKAWA (2014年7月22日). 2018年3月11日閲覧。\\n\\n^ “鳥山明が映画「西遊記−はじまりのはじまり−」のポスターを書き下ろし―中国紙”.   Record China (2014年11月11日). 2018年3月11日閲覧。\\n\\n^ 「東京五輪マスコットに孫悟空？ 中国ネット民「ドラゴンボールの方が西遊記より有名。あってもなんら不思議はない」」exciteニュース、2017年5月24日。\\n\\n^ 「中国Tencent、新作3DMMOアクションRPG『龙珠最強之戦』のサービス開始 事前登録1300万超の期待作が始動」Social Game Info、2019年11月6日。\\n\\n^ 「文化傳信Facebook」2019年3月4日閲覧。\\n\\n^ 「日本マンガ的要素の現地化. 〜香港のマンガとポピュラーカルチャー」The Chinese University of Hong Kong、37頁。2019年3月4日閲覧。\\n\\n^ a b 「永恒的龍珠」All About Comics、2009年5月5日\\n\\n^ a b 「「ドラゴンボールを科学する」特別展・・・台湾・台北でも開催、人出見込まれる春節期も＝台湾メディア」searchina、2014年12月25日。\\n\\n^ “七龍珠完全版15週年紀念盒裝版 經典再現！”.   東立出版社. 2019年3月4日閲覧。\\n\\n^ 「【連載第21回】韓国最新オンラインゲームレポート、バンダイコリア、「ドラゴンボールオンライン」の最新情報を公開7つのドラゴンボールを集めると願いが叶う!? 最新SSとムービーが公開!」GAME Watch、2008年2月27日。\\n\\n^ 「ソウル直送レポート、MMORPG『ドラゴンボールオンライン』プレスカンファレンス開催」インサイド、2008年2月4日。\\n\\n^ 「あれ！？北朝鮮で「ドラえもん」放送？[リンク切れ]」テレビ朝日、2019年3月4日閲覧。\\n\\n^ 「7 Viên ngọc rồng (67 tập)」Thương Mái Trường Xưa、2019年3月4日閲覧。\\n\\n^ “DRAGON BALL SUPER -TẬP5”.   Kim Đồng. 2019年3月4日閲覧。\\n\\n^ “Dragon Ball Vol. 1”.   Elex Media Komputindo. 2019年3月4日閲覧。\\n\\n^ 「イケメン日本代表SOLIDEMOCHA-LA HEAD-CHA-LAでタイを熱狂」BARKS、2014年5月23日。\\n\\n^ 「“24 ORAS WEEKEND” SURGES TO SATURDAY’S NUMBER 1; “PILIPINAS GOT TALENT” STILL RULES WEEKEND PRIMETIME」LionhearTV、2018年3月7日。\\n\\n^ 「Why Australia Needs to Bring Back \\'Cheez TV\\' Now More Than Ever」VICE NEWS、2016年10月27日。\\n\\n^ 「‘Dragon Ball Super’ Makes Australian Debut on ABC ME」Animation Magazine、2018年11月15日。\\n\\n^ 「About The Special Disc_DRAGON BALL Z 海外版」『DRAGON BALL Z DVD BOX Z VOLUME 1 Dragonbook』、2003年、125頁。\\n\\n^ “ドラゴンボール 1”.   集英社. 2021年3月12日閲覧。\\n\\n^ “ドラゴンボール 2”.   集英社. 2021年3月12日閲覧。\\n\\n^ “ドラゴンボール 3”.   集英社. 2021年3月12日閲覧。\\n\\n^ “ドラゴンボール 4”.   集英社. 2021年3月12日閲覧。\\n\\n^ “ドラゴンボール 5”.   集英社. 2021年3月12日閲覧。\\n\\n^ “ドラゴンボール 6”.   集英社. 2021年3月12日閲覧。\\n\\n^ “ドラゴンボール 7”.   集英社. 2021年3月12日閲覧。\\n\\n^ “ドラゴンボール 8”.   集英社. 2021年3月12日閲覧。\\n\\n^ “ドラゴンボール 9”.   集英社. 2021年3月12日閲覧。\\n\\n^ “ドラゴンボール 10”.   集英社. 2021年3月12日閲覧。\\n\\n^ “ドラゴンボール 11”.   集英社. 2021年3月12日閲覧。\\n\\n^ “ドラゴンボール 12”.   集英社. 2021年3月12日閲覧。\\n\\n^ “ドラゴンボール 13”.   集英社. 2021年3月12日閲覧。\\n\\n^ “ドラゴンボール 14”.   集英社. 2021年3月12日閲覧。\\n\\n^ “ドラゴンボール 15”.   集英社. 2021年3月12日閲覧。\\n\\n^ “ドラゴンボール 16”.   集英社. 2021年3月12日閲覧。\\n\\n^ “ドラゴンボール 17”.   集英社. 2021年3月12日閲覧。\\n\\n^ “ドラゴンボール 18”.   集英社. 2021年3月12日閲覧。\\n\\n^ “ドラゴンボール 19”.   集英社. 2021年3月12日閲覧。\\n\\n^ “ドラゴンボール 20”.   集英社. 2021年3月12日閲覧。\\n\\n^ “ドラゴンボール 21”.   集英社. 2021年3月12日閲覧。\\n\\n^ “ドラゴンボール 22”.   集英社. 2021年3月12日閲覧。\\n\\n^ “ドラゴンボール 23”.   集英社. 2021年3月12日閲覧。\\n\\n^ “ドラゴンボール24”.   集英社. 2021年3月12日閲覧。\\n\\n^ “ドラゴンボール 25”.   集英社. 2021年3月12日閲覧。\\n\\n^ “ドラゴンボール 26”.   集英社. 2021年3月12日閲覧。\\n\\n^ “ドラゴンボール 27”.   集英社. 2021年3月12日閲覧。\\n\\n^ “ドラゴンボール 28”.   集英社. 2021年3月12日閲覧。\\n\\n^ “ドラゴンボール 29”.   集英社. 2021年3月12日閲覧。\\n\\n^ “ドラゴンボール 30”.   集英社. 2021年3月12日閲覧。\\n\\n^ “ドラゴンボール 31”.   集英社. 2021年3月12日閲覧。\\n\\n^ “ドラゴンボール 32”.   集英社. 2021年3月12日閲覧。\\n\\n^ “ドラゴンボール 33”.   集英社. 2021年3月12日閲覧。\\n\\n^ “ドラゴンボール 34”.   集英社. 2021年3月12日閲覧。\\n\\n^ “ドラゴンボール 35”.   集英社. 2021年3月12日閲覧。\\n\\n^ “ドラゴンボール 36”.   集英社. 2021年3月12日閲覧。\\n\\n^ “ドラゴンボール 37”.   集英社. 2021年3月12日閲覧。\\n\\n^ “ドラゴンボール 38”.   集英社. 2021年3月12日閲覧。\\n\\n^ “ドラゴンボール 39”.   集英社. 2021年3月12日閲覧。\\n\\n^ “ドラゴンボール 40”.   集英社. 2021年3月12日閲覧。\\n\\n^ “ドラゴンボール 41”.   集英社. 2021年3月12日閲覧。\\n\\n^ “ドラゴンボール 42”.   集英社. 2021年3月12日閲覧。\\n\\n^ 「CHIBIダス!!第7弾 ドラゴンボールミュージアム」『週刊少年ジャンプ』1996年13号、集英社、16頁。\\n\\n^ “DRAGON BALL 完全版 1”.   集英社. 2021年3月12日閲覧。\\n\\n^ “DRAGON BALL 完全版 2”.   集英社. 2021年3月12日閲覧。\\n\\n^ “DRAGON BALL 完全版 3”.   集英社. 2021年3月12日閲覧。\\n\\n^ “DRAGON BALL 完全版 4”.   集英社. 2021年3月12日閲覧。\\n\\n^ “DRAGON BALL 完全版 5”.   集英社. 2021年3月12日閲覧。\\n\\n^ “DRAGON BALL 完全版 6”.   集英社. 2021年3月12日閲覧。\\n\\n^ “DRAGON BALL 完全版 7”.   集英社. 2021年3月12日閲覧。\\n\\n^ “DRAGON BALL 完全版 8”.   集英社. 2021年3月12日閲覧。\\n\\n^ “DRAGON BALL 完全版 9”.   集英社. 2021年3月12日閲覧。\\n\\n^ “DRAGON BALL 完全版 10”.   集英社. 2021年3月12日閲覧。\\n\\n^ “DRAGON BALL 完全版 11”.   集英社. 2021年3月12日閲覧。\\n\\n^ “DRAGON BALL 完全版 12”.   集英社. 2021年3月12日閲覧。\\n\\n^ “DRAGON BALL 完全版 13”.   集英社. 2021年3月12日閲覧。\\n\\n^ “DRAGON BALL 完全版 14”.   集英社. 2021年3月12日閲覧。\\n\\n^ “DRAGON BALL 完全版 15”.   集英社. 2021年3月12日閲覧。\\n\\n^ “DRAGON BALL 完全版 16”.   集英社. 2021年3月12日閲覧。\\n\\n^ “DRAGON BALL 完全版 17”.   集英社. 2021年3月12日閲覧。\\n\\n^ “DRAGON BALL 完全版 18”.   集英社. 2021年3月12日閲覧。\\n\\n^ “DRAGON BALL 完全版 19”.   集英社. 2021年3月12日閲覧。\\n\\n^ “DRAGON BALL 完全版 20”.   集英社. 2021年3月12日閲覧。\\n\\n^ “DRAGON BALL 完全版 21”.   集英社. 2021年3月12日閲覧。\\n\\n^ “DRAGON BALL 完全版 22”.   集英社. 2021年3月12日閲覧。\\n\\n^ “DRAGON BALL 完全版 23”.   集英社. 2021年3月12日閲覧。\\n\\n^ “DRAGON BALL 完全版 24”.   集英社. 2021年3月12日閲覧。\\n\\n^ “DRAGON BALL 完全版 25”.   集英社. 2021年3月12日閲覧。\\n\\n^ “DRAGON BALL 完全版 26”.   集英社. 2021年3月12日閲覧。\\n\\n^ “DRAGON BALL 完全版 27”.   集英社. 2021年3月12日閲覧。\\n\\n^ “DRAGON BALL 完全版 28”.   集英社. 2021年3月12日閲覧。\\n\\n^ “DRAGON BALL 完全版 29”.   集英社. 2021年3月12日閲覧。\\n\\n^ “DRAGON BALL 完全版 30”.   集英社. 2021年3月12日閲覧。\\n\\n^ “DRAGON BALL 完全版 31”.   集英社. 2021年3月12日閲覧。\\n\\n^ “DRAGON BALL 完全版 32”.   集英社. 2021年3月12日閲覧。\\n\\n^ “DRAGON BALL 完全版 33”.   集英社. 2021年3月12日閲覧。\\n\\n^ “DRAGON BALL 完全版 34”.   集英社. 2021年3月12日閲覧。\\n\\n^ “Dragon Ball,Vol.1”. viz.com. 2022年2月9日閲覧。\\n\\n^ “Dragon Ball,Vol.3”. Simon & Schuster. 2022年2月9日閲覧。\\n\\n^ a b “Dragon Ball(3-in-1 Edition),Vol.1”. Simon & Schuster. 2022年2月9日閲覧。\\n\\n^ “Dragon BallZ,Vol.26”. Simon & Schuster. 2022年2月10日閲覧。\\n\\n^ “Glénat Benelux”. Anime News Network. 2022年2月11日閲覧。\\n\\n^ “SERIE DRAGON BALL ULTIMATE”. planetadelibros. 2022年2月9日閲覧。\\n\\n^ “SERIE BOLA DE DRAC ULTIMATE”. planetadelibros. 2022年2月9日閲覧。\\n\\n^ “Planeta DeAgostini Comics”. Anime News Network. 2022年2月11日閲覧。\\n\\n^ “Dragon Ball42:Avskedet”. Bonnier Carlsen. 2022年2月10日閲覧。\\n\\n^ “Dragon Ball(manga)”. tokio.fi. 2022年2月10日閲覧。\\n\\n^ “Dragon Ball3-i-1NO( 1-2-3)”. Outland. 2022年2月10日閲覧。\\n\\n^ “Dragonball2000.(nem teljes évfolyam)”. ANTIKVÁRIUM.HU. 2022年2月11日閲覧。\\n\\n^ “DRAGON BALL”. Editorial Ivrea. 2022年2月9日閲覧。\\n\\n^ “Dragon Ball-#1”. Panini México. 2022年2月9日閲覧。\\n\\n^ “DRAGON BALL N.26”. Panini Colombia. 2022年2月9日閲覧。\\n\\n^ “Dragon Ball-#1”. Panini Perú. 2022年2月9日閲覧。\\n\\n^ “Pack Dragon Ball”. Panini Chile. 2022年2月9日閲覧。\\n\\n^ “DRAGON BALL-TẬP42(2020)”. NXB KIM ĐỒNG. 2022年2月9日閲覧。\\n\\n^ @Elex Media Komputindoの2016年9月3日のツイート、2022年2月10日閲覧。\\n\\n^ “NED Comics DRAGON BALL ดราก้อนบอล เล่ม 7”. lazada. 2022年2月10日閲覧。\\n\\n^ 「Chuang Yi Publishing in Liquidation」Anime News Network、2014年2月21日。\\n\\n^ 「『ドラゴンボール超』新作映画はピッコロが主役!? 活躍する意外なキャラは…」めるも、2021年5月10日。\\n\\n^ “Comix-ART”. Anime News Network. 2022年2月11日閲覧。\\n\\n^ 「“ドラゴンボールの「マンガ検索」が登場!!”. Yahoo!JAPAN特集 編集部から (2010年4月28日). 2016年11月5日閲覧。\\n\\n^ “伝説の漫画編集者マシリトはゲーム業界でも偉人だった！ 鳥嶋和彦が語る「DQ」「FF」「クロノ・トリガー」誕生秘話”. 電ファミニコゲーマー (2016年4月4日). 2018年6月18日閲覧。\\n\\n^ “「DRAGON BALL」単行本、背表紙描き下ろしで新装重版”. コミックナタリー (2009年4月28日). 2021年2月2日閲覧。\\n\\n^ “DRAGON BALL総集編 超悟空伝 Legend1”.   集英社. 2021年3月12日閲覧。\\n\\n^ “DRAGON BALL総集編 超悟空伝 Legend2”.   集英社. 2021年3月12日閲覧。\\n\\n^ “DRAGON BALL総集編 超悟空伝 Legend3”.   集英社. 2021年3月12日閲覧。\\n\\n^ “DRAGON BALL総集編 超悟空伝 Legend4”.   集英社. 2021年3月12日閲覧。\\n\\n^ “DRAGON BALL総集編 超悟空伝 Legend5”.   集英社. 2021年3月12日閲覧。\\n\\n^ “DRAGON BALL総集編 超悟空伝 Legend6”.   集英社. 2021年3月12日閲覧。\\n\\n^ “DRAGON BALL総集編 超悟空伝 Legend7”.   集英社. 2021年3月12日閲覧。\\n\\n^ “DRAGON BALL総集編 超悟空伝 Legend8”.   集英社. 2021年3月12日閲覧。\\n\\n^ “DRAGON BALL総集編 超悟空伝 Legend9”.   集英社. 2021年3月12日閲覧。\\n\\n^ “DRAGON BALL総集編 超悟空伝 Legend10”.   集英社. 2021年3月12日閲覧。\\n\\n^ “DRAGON BALL総集編 超悟空伝 Legend11”.   集英社. 2021年3月12日閲覧。\\n\\n^ “DRAGON BALL総集編 超悟空伝 Legend12”.   集英社. 2021年3月12日閲覧。\\n\\n^ “DRAGON BALL総集編 超悟空伝 Legend13”.   集英社. 2021年3月12日閲覧。\\n\\n^ “DRAGON BALL総集編 超悟空伝 Legend14”.   集英社. 2021年3月12日閲覧。\\n\\n^ “DRAGON BALL総集編 超悟空伝 Legend15”.   集英社. 2021年3月12日閲覧。\\n\\n^ “DRAGON BALL総集編 超悟空伝 Legend16”.   集英社. 2021年3月12日閲覧。\\n\\n^ “DRAGON BALL総集編 超悟空伝 Legend17”.   集英社. 2021年3月12日閲覧。\\n\\n^ “DRAGON BALL総集編 超悟空伝 Legend18”.   集英社. 2021年3月12日閲覧。\\n\\n^ 『30th Anniversary ドラゴンボール超史集 -SUPER HISTORY BOOK-』集英社〈愛蔵版コミックス〉、2016年1月26日、213頁。ISBN\\xa0978-4-08-792505-0。\\n\\n^ 「Akira Toriyama et Dragon Ball - L\\'homme derrière le manga」Pix\\'n Love、2019年9月10日閲覧。\\n\\n^ “Les recettes légendaires de Dragon Ball\\xa0: Quelques extraits de l\\'ouvrage”.   toute l\\'actualité de Dragon Ball Super (2019年9月26日). 2019年9月28日閲覧。\\n\\n^ Vジャンプ2019年07月号、DBジャンプ特集『DBと世界』集英社、2019年5月21日発行。\\n\\n^ “ドラゴンボール超インタビュー「とりとよ放談」inVJ”.   Vジャンプ. 2020年4月30日閲覧。\\n\\n^ “ドラゴンボール外伝 転生したらヤムチャだった件”. 少年ジャンプ＋. 2017年8月17日閲覧。\\n\\n^ “完全新作アニメシリーズ『ドラゴンボールDAIMA(ダイマ)』が2024年秋に展開決定！”.   ドラゴンボール オフィシャルサイト (2023年10月13日). 2023年10月13日閲覧。\\n\\n^ 渡辺彰則編「VARIETY OF DB」『ドラゴンボール大全集 第5巻』集英社、1995年11月7日、202頁。ISBN\\xa04-08-782755-0。\\n\\n^ 「世界中で大ヒットを記録しつづける超人気アニメーション「ドラゴンボールＺ」のTVシリーズがついにDVD-BOXで登場！」東映アニメーション、2002年11月6日。\\n\\n^ 2019年1月23日7:54のBrigitte Lecordierのツイート\\n\\n^ 『下野新聞 縮刷版』下野新聞社、1994年1月1日。\\xa0、ラジオ・テレビ欄（1月2日）\\n\\n^ 「NHK番組MAG・ネット最終回は「ドラゴンボール」特集」コミックナタリー、2013年2月26日。\\n\\n^ 「映画『ドラゴンボール超 ブロリー』公開記念！ケンドーコバヤシ、竹若元博（バッファロー吾郎）、板倉俊之（インパルス）、前島亜美、丹生明里（けやき坂46）がアニマックス集結！」アニメ!アニメ!、2018年11月30日。\\n\\n^ 「氷川きよし、宮野真守、山田涼介、乃木坂46が「ドラゴンボール」名曲メドレー」音楽ナタリー、2019年5月24日。\\n\\n^ 「ビジュアル系・氷川きよし大暴れ 神龍に乗って「限界突破した」「来年もうなぎ上り」」Sponichi Annex、2020年1月1日。\\n\\n^ “山田孝之『99人の壁』参戦で『ドラゴンボール』クイズに挑む 佐藤二朗は心配「親目線になってきた」”.   オリコン (2021年5月15日). 2021年5月28日閲覧。\\n\\n^ “＜ドラゴンボール＞「“神”LOVER」登場\\u3000コレクション1万点＆1800冊の少年ジャンプも\\u3000DB芸人が自宅潜入\\u3000今夜「教えてもらう前と後」”.   MANTANWEB (2021年7月19日). 2021年8月1日閲覧。\\n\\n^ 「SONGOKUMANIA: EL BIG BANG DEL MANGA」Festival Nits de cinema、2019年9月10日閲覧。\\n\\n^ 「Songokumanía: el Big Bang del Manga」catalanfilms、2019年9月10日閲覧。\\n\\n^ “「ドラゴンボールZ Sparking!」シリーズ新作の制作が決定!!ティザー映像を公開!!”.   ドラゴンボール オフィシャルサイト (2023年3月6日). 2023年3月6日閲覧。\\n\\n^ “终于等到你！正版授权《龙珠觉醒》手游2月28日首发”. 龙珠Z 覚醒. 2019年9月16日閲覧。\\n\\n^ “中国で配信された『ドラゴンボール』の新作MMORPGがいろいろスゴイと話題”. ファミ通App. 2019年11月9日閲覧。\\n\\n^ Vジャンプ編集部「鳥山明とVジャンプ」『30th Anniversary ドラゴンボール超史集 -SUPER HISTORY BOOK-』集英社〈愛蔵版コミックス〉、2016年1月26日、83頁。ISBN\\xa0978-4-08-792505-0。\\n\\n^ “集英社のデジタルコンテンツサイト『JUMPLAND（ジャンプランド）』12月1日よりLaLaBitにて提供開始”. 2019年11月6日閲覧。\\n\\n^ “ドラゴンボールで科学する!”. ドラゴンボールで科学する!公式サイト. 2019年3月4日閲覧。\\n\\n^ 「超巨大な「ドラゴンボール」や「進撃の巨人」が待ってるぞ！ 『さっぽろ雪まつり』は2016年2月5日開催だッ!!」excite.ニュース、2016年2月3日。\\n\\n^ 「12月17日（土）・18日（日）幕張メッセにて開催！「ジャンプフェスタ2017」東映アニメーションブース詳細情報!!」東映アニメーション、2016年12月16日。\\n\\n^ 「JR東日本×『ドラゴンボール』スタンプラリーに大反響！「ぜってえコンプリートすっぞ！」「息子と一緒に回りたい」」ダヴィンチニュース、2017年1月14日。\\n\\n^ 「懐かしい！楽しい！「ドラゴンボール」「Dr.スランプ アラレちゃん」期間限定イベント」伊勢丹新宿店ブログ、2017年5月3日。\\n\\n^ 「【VR】『マリオカート』や『ドラゴンボール』に『エヴァンゲリオン』まで！“VR ZONE SHINJUKU”が7/14オープン」ファミ通app、2017年6月13日。\\n\\n^ 「ドラゴンボール超」TV・映画公式 [@db_super2015] (2017年7月14日). \"「お台場みんなの夢大陸」開幕！\". X（旧Twitter）より2019年3月24日閲覧。 \\n\\n^ “ドラゴンボール天下一武道祭2017”.   ドラゴンボール天下一武道祭実行委員会. 2019年3月4日閲覧。\\n\\n^ “ドラゴンボールランとは-DRAGON BALL RUN”.   ドラゴンボールラン実行委員会. 2019年3月4日閲覧。\\n\\n^ 「【ジャンプフェスタ2018情報】『ドラゴンボール』ファンのためのレポート!!【ブース編】」ドラゴンボールオフィシャルサイト、2017年12月16日。\\n\\n^ “ドラゴンボール超悟空伝”. ドラゴンボール超悟空伝. 2019年3月4日閲覧。\\n\\n^ “【3/7開催】『ドラゴンボール』コンテンツの魅力を集結した全世界同時配信型オンラインイベント“ドラゴンボールゲームスバトルアワー”の詳細が発表”. 2021年3月7日閲覧。\\n\\n^ “全世界同時配信型オンラインイベント「DRAGON BALL Games Battle Hour 2022」が2月19日(土)・20日(日)に開催!!”.   ドラゴンボール オフィシャルサイト (2022年2月18日). 2022年3月29日閲覧。\\n\\n^ “『DRAGON BALL』ゲームの祭典「DRAGON BALL Games Battle Hour 2023」が開催決定！”.   ドラゴンボール オフィシャルサイト (2022年12月4日). 2023年3月6日閲覧。\\n\\n^ “ドラゴンボール ゲームスバトルアワー 2024”.   ドラゴンボール ゲームスバトルアワー 2024公式サイト. 2023年10月15日閲覧。\\n\\n^ “HISTORY - ARMAGEDDON EXPO”. Armageddon Expo. 2019年3月4日閲覧。\\n\\n^ “いま、世界で注目の記録？ 4月16日号”.   ギネスワールドレコード (2013年4月16日). 2019年3月4日閲覧。\\n\\n^ 「小雲 x 悟空のMCP夏日祭 經典角色萌爆現身」Cosmopolitan、2017年6月20日。\\n\\n^ 「アメリカの公園で「みんなで孫悟空みたいに叫ぶ」というイベントが開催され、会場が騒然。」iFLYER、2017年9月4日。\\n\\n^ 「Goku fans gather in Brisbane to scream like their favourite Dragon Ball Z character」ABC News、2017年10月9日。\\n\\n^ “DRAGON BALL SYMPHONIC ADVENTURE TOUR SCHEDULE”. 2018年6月13日時点のオリジナルよりアーカイブ。2019-03-04 website=Overlook Events閲覧。\\n\\n^ a b “Coronavirus Update: ‘Dragon Ball Symphonic Adventure’ Concert In Chicago Called Off Citing COVID-19 Outbreak”. International Business Times (2020年3月12日). 2020年4月18日閲覧。\\n\\n^ 「Le Festival DRAGON BALL fait par des fans pour des fans\\xa0!」helloasso、2017年10月14日。\\n\\n^ “kamehacon 2018”. kameha con.   SilvrFire LLC. 2019年3月4日閲覧。\\n\\n^ “Dragon BallTour2018inNorth AmericaTour”. Dragon Ball North America Tour 2018 Official Web Site. 2019年3月4日閲覧。\\n\\n^ @FUNimation (2018年11月1日). \"Macys Thanksgiving Day Parade\". X（旧Twitter）より2019年3月23日閲覧。 \\n\\n^ “In photos: Macy\\'s Thanksgiving Day Parade 2019”. CNN (2019年11月28日). 2019年12月3日閲覧。\\n\\n^ “GOKU’S RETURN TO MACY’S THANKSGIVING DAY PARADE IS CONFIRMED BY DRAGON BALL”. Game-News24 (2021年10月8日). 2021年10月31日閲覧。\\n\\n^ 「DRAGONBALL WORLD ADVENTURE」DRAGONBALL WORLD ADVENTURE Official Web Site、2019年5月23日閲覧。\\n\\n^ 「Be Part Of TheACTION!」SaiyaCon UK、2019年6月25日閲覧。\\n\\n^ “『DRAGON BALL』がニューヨークコミコン2023に出展！”. ドラゴンボール オフィシャルサイト. 2023年9月29日閲覧。\\n\\n^ 「エキシビジョン AKIRA TORIYAMA」『30th ANNIVERSARY ドラゴンボール超史集 -SUPER HISTORY BOOK-』集英社、84-85頁。\\n\\n^ 「鳥山明と『ドラゴンボール』の歴史を凝縮した「鳥山明 The World of DRAGON BALL」開幕、300点以上を一挙展示」マイナビニュース、2013年3月29日。\\n\\n^ “30代が「週刊少年ジャンプ展」に行ったら、エモすぎて腰を抜かした”. KAI-YOU (2018年3月19日). 2019年11月4日閲覧。\\n\\n^ 「海外特派員リポート「ドラゴンボール大うけ！」大英博物館で日本漫画展」毎日新聞、2019年6月8日。\\n\\n^ 「ドラゴンボール初のコラボカフェ、タワーレコードカフェ渋谷・表参道・梅田NU茶屋町店内に限定オープン」FASHION PRESS、2016年10月27日。\\n\\n^ 「「ドラゴンボールメニュー大集合」東京駅で2月27日まで[リンク切れ]」TSUTAYA、2017年1月12日、2019年3月4日閲覧。\\n\\n^ “ドラゴンボール カフェ&ダイナー 公式サイト 限定カフェメニューやグッズをご紹介！”. ドラゴンボールカフェ&ダイナー公式サイト.   スパークル. 2019年3月4日閲覧。\\n\\n^ 「直訳するとスーパーサイヤ人!? アメリカのラーメン屋を紹介した動画が話題沸騰中」getnavi.web、2016年6月10日。\\n\\n^ “全国首家龙珠咖啡馆登陆魔都”. China International Licensing Expo 中国授权展. 2019年11月9日閲覧。\\n\\n^ 『日本TVアニメーション全史』（2014年12月30日、世界文化社発行）201ページ。\\n\\n^ 「ドラゴンボール ゲームマスターピース CARD GAME」『30th ANNIVERSARY ドラゴンボール超史集 -SUPER HISTORY BOOK-』集英社、160頁、161頁。\\n\\n^ 「ドラゴンボール 玩具図鑑」『30th ANNIVERSARY ドラゴンボール超史集 -SUPER HISTORY BOOK-』集英社、198頁。\\n\\n^ 「DB立体物 ピックアップヒストリー」『30th ANNIVERSARY ドラゴンボール超史集 -SUPER HISTORY BOOK-』集英社、192-193頁。\\n\\n^ 「ドラゴンボール 玩具図鑑」『30th ANNIVERSARY ドラゴンボール超史集 -SUPER HISTORY BOOK-』集英社、200頁。\\n\\n^ 「「ドラゴンボール」総合携帯サイトスタート 成長するがコンセプト（8/20）」アニメ!アニメ!、2007年8月20日。\\n\\n^ 「ドラゴンボール公式携帯ゲームサイト「ドラゴンボールモバイル」開始」ITmedia、2007年10月15日。\\n\\n^ “ポッカの“顔缶”に『ドラゴンボール』版登場”.   オリコン (2011年6月3日). 2021年5月24日閲覧。\\n\\n^ “ポッカ「ドラゴンボール缶」再び、フリーザ＆セル編など合計30種類。”.   Narinari.com (2011年10月28日). 2021年5月28日閲覧。\\n\\n^ “『パズドラ』×『ドラゴンボール改』コラボ企画から登場キャラの新たな画像を掲載！ ベジータ、トランクス、ピッコロなど”.   電撃オンライン (2014年5月30日). 2022年8月17日閲覧。\\n\\n^ “『パズドラ』ドラゴンボールコラボ第2弾は魔人ブウ編ダンジョン”.   ファミ通App (2014年9月19日). 2022年8月17日閲覧。\\n\\n^ “『パズドラ』×『ドラゴンボール改』コラボ第3弾は…ラディッツ、ゴテンクス、ナッパ、ビーデルが新登場だ”.   ファミ通App (2014年12月22日). 2022年8月17日閲覧。\\n\\n^ “『パズドラ』×『ドラゴンボール』コラボ第4弾で超ベジットきたー!!!!!”.   ファミ通App (2015年3月13日). 2022年8月17日閲覧。\\n\\n^ 「孫悟空が新聞で「筋肉の質」アピール タニタ、体組成計の新商品キャンペーン」マーケティング研究室、2015年7月2日。\\n\\n^ 「『ドラゴンボール ふりかけミニパック』 『ドラゴンボール カレー＜ビーフ甘口＞』 『ドラゴンボール カレー＜ビーフ中辛＞』 2015年11月5日（木）新発売」産経新聞、2015年10月5日。\\n\\n^ “ドラゴンボールコラボ商品 2016年10月3日新発売”. ベフコ.   栗山米菓 (2016年10月3日). 2020年1月23日閲覧。\\n\\n^ ““かめはめ波”がVRで撃てる「BotsNew VR DRAGONBALL Z」、スカウターで戦闘力”. AV Watch.   インプレス (2017年4月13日). 2017年5月11日閲覧。\\n\\n^ “ビックリマンと『ドラゴンボール』が夢のコラボ!!「ドラゴンボールマンチョコ」ついに発売!”. ドラゴンボールオフィシャルサイト.   集英社 (2018年10月19日). 2018年10月23日閲覧。\\n\\n^ 「ドラゴンボールマンチョコ、売り上げ700万個の陰に「飽きさせない工夫」」ITmedia ビジネスオンライン、2019年3月1日。\\n\\n^ a b “ドラゴンボール×ビックリマン「ドラゴンボールマンチョコ」発売だぞ!!”.   LOTTE (2018年10月23日). 2022年7月12日閲覧。\\n\\n^ a b “ロッテオンラインショップ限定、数量限定の『ドラゴンボールマンＺ特別セット』・『ドラゴンボールマン超特別セット』を12月18日（火）正午発売決定！！”.   PR TIMES (2018年12月17日). 2022年7月12日閲覧。\\n\\n^ “夢のフュージョン再び！ 『ドラゴンボールマンチョコ超』5月24日発売”.   YAHOO!ニュース (2022年5月20日). 2022年7月12日閲覧。\\n\\n^ “ビックリマン×ドラゴンボール超 スーパーヒーロー「ドラゴンボールマンチョコ超」発売！！”.   LOTTE (2022年5月24日). 2022年7月12日閲覧。\\n\\n^ 「『ドラゴンボール』×「ニューエラ」のコラボコレクションが登場！」ドラゴンボール オフィシャルサイト、2019年7月4日。\\n\\n^ 「「CONVERSE STARS」×『ドラゴンボール』コラボアイテムが8月24日(土)から発売開始！」ドラゴンボール公式サイト、2019年8月19日。\\n\\n^ “カラオケ業界初の音声認識搭載「LIVE DAM Ai」。バトル“天下一歌唱会”も”.   impress. 2019年10月16日閲覧。\\n\\n^ 「「ユニクロ」と『ドラゴンボール』がコラボレーション！2019年11月から発売開始!!」ドラゴンボール オフィシャルサイト、2019年9月17日。\\n\\n^ “『フォートナイト』×『ドラゴンボール』コラボが本日（8/16）より開催。アイテム“かめはめ波”や“筋斗雲”、グライダー“神龍”などスーパーな要素が盛りだくさん！”.   ファミ通App (2022年8月16日). 2022年8月17日閲覧。\\n\\n^ 「かめはめ波も撃てる「フォートナイト」×「ドラゴンボール」コラボ開始。孫悟空やベジータとアドベンチャーアイランドを冒険」4Gamer.net、2022年8月16日。\\n\\n^ “『フォートナイト』×『ドラゴンボール』コラボ第2弾が開催。孫悟飯＆ピッコロが登場し、かめはめ波と筋斗雲も復活！”.   ファミ通App (2023年1月31日). 2023年3月6日閲覧。\\n\\n^ “「PUBG MOBILE」に『ドラゴンボール超』のキャラクターが登場中!!”.   ドラゴンボール オフィシャルサイト (2023年8月11日). 2023年8月11日閲覧。\\n\\n^ “麥當勞與七龍珠Z超強合體 9/27席捲全台限量「七龍珠Z角色盲卡包 」期間限定四款包裝鐵粉必蒐藏！”.   台湾マクドナルド公式. 2023年10月5日閲覧。\\n\\n\\n外部リンク[編集]\\n\\n\\n\\nウィキメディア・コモンズには、ドラゴンボールに関連するカテゴリがあります。\\n\\n【公式】ドラゴンボール オフィシャルサイト\\nドラゴンボールオフィシャルサイト (@DB_official_jp) - Twitter\\nドラゴンボール - メディア芸術データベース\\nアニメ\\nドラゴンボール\\nドラゴンボールZ\\nドラゴンボールGT\\nドラゴンボール改\\nドラゴンボール超\\n映画「ドラゴンボール超 スーパーヒーロー」公式(@DB_super2015) - Twitter\\n漫画\\nVジャンプドラゴンボール超 特設サイト\\nとよたろう(@TOYOTARO_Vjump) - Twitter\\ndragon_ball_jump_official - YouTubeチャンネル\\nグッズ\\n【公式】DRAGONRADAR(@goodsradar) - Twitter\\n商品検索 -ドラゴンボール- - 株式会社バンダイ公式サイト\\n検索 -ドラゴンボール- - カードダスドットコム\\nゲーム\\nドラゴンボール ゲームポータルサイト - バンダイナムコエンターテインメント\\n「ドラゴンボール」家庭用ゲーム公式(@dbgame_official) - Twitter\\nスーパードラゴンボールヒーローズ公式サイト|SDBH\\nドラゴンボールヒーローズ公式チャンネル - YouTube\\n【公式】スーパードラゴンボールヒーローズ(@dbh_10th) - Twitter\\n表話編歴ドラゴンボールアニメ\\nテレビアニメ\\nドラゴンボール\\nドラゴンボールZ\\nドラゴンボールGT\\nドラゴンボール改\\nドラゴンボール超\\nドラゴンボールDAIMA\\nTVSP・OVA\\nたったひとりの最終決戦〜フリーザに挑んだZ戦士 孫悟空の父〜\\n絶望への反抗!!残された超戦士・悟飯とトランクス\\nサイヤ人絶滅計画\\n超サイヤ人絶滅計画（リメイク）\\n監獄惑星編\\n宇宙争乱編\\n劇場版アニメ\\n神龍の伝説\\n魔神城のねむり姫\\n摩訶不思議大冒険\\nZ\\nこの世で一番強いヤツ\\n地球まるごと超決戦\\n超サイヤ人だ孫悟空\\nとびっきりの最強対最強\\n激突!!100億パワーの戦士たち\\n極限バトル!!三大超サイヤ人\\n燃えつきろ!!熱戦・烈戦・超激戦\\n銀河ギリギリ!!ぶっちぎりの凄い奴\\n危険なふたり!超戦士はねむれない\\n超戦士撃破!!勝つのはオレだ\\n復活のフュージョン!!悟空とベジータ\\n龍拳爆発!!悟空がやらねば誰がやる\\n最強への道\\n神と神\\n復活の「F」\\nブロリー\\nスーパーヒーロー\\nイベント用アニメ\\nオッス!帰ってきた孫悟空と仲間たち!!\\nエピソード オブ バーダック\\n\\n\\n実写映画\\nEVOLUTION\\n\\n\\n登場人物\\n孫悟空少年編 初出\\n孫悟空\\nブルマ\\n亀仙人\\nウーロン\\nヤムチャ\\nプーアル\\nチチ\\nピラフ一味\\n神龍\\nクリリン\\nランチ\\nレッドリボン軍\\n則巻アラレ\\n桃白白\\n孫悟飯（里親）\\n天津飯\\n餃子\\nピッコロ大魔王編 初出\\nピッコロ（大魔王）\\nヤジロベー\\nピッコロ（マジュニア）\\nサイヤ人編 初出\\n\\n孫悟飯（実子）\\nサイヤ人\\nラディッツ\\nベジータ\\nナッパ\\n界王 \\nフリーザ編 初出\\n\\nフリーザ一味\\nフリーザ\\nギニュー特戦隊\\n人造人間・セル編 初出\\n\\nトランクス\\n人造人間\\nドクター・ゲロ\\n17号\\n18号\\nセル\\nミスター・サタン\\n魔人ブウ編 初出\\nビーデル\\n孫悟天\\nバビディ\\nダーブラ\\n魔人ブウ\\nゴテンクス\\nベジット\\nパン\\nアニメオリジナル\\n超の登場人物\\nバーダック\\nツフル人\\nブロリー\\nゴジータ\\nゲームオリジナル\\nトワ\\n\\n\\n\\n設定・用語\\n年表\\n年表\\n技・概念\\n技一覧\\nかめはめ波\\n融合\\n気\\n道具\\nドラゴンボール\\n筋斗雲\\n仙豆\\n地名\\n地理一覧\\n地球\\nカプセルコーポレーション\\nカリン塔\\nナメック星\\n大会\\n天下一武道会\\nあの世一武道会\\n\\n\\n\\n音楽\\nアニメ\\nテレビ主題歌\\nDB\\n魔訶不思議アドベンチャー! / ロマンティックあげるよ\\nZ\\nCHA-LA HEAD-CHA-LA / でてこい とびきりZENKAIパワー!\\nWE GOTTA POWER / 僕達は天使だった\\nGT\\nDAN DAN 心魅かれてく\\nひとりじゃない\\nDon\\'t you see!\\nBlue Velvet\\n錆びついたマシンガンで今を撃ち抜こう\\n改\\nDragon Soul\\n空・前・絶・後 Kuu-Zen-Zetsu-Go\\nYeah! Break! Care! Break!\\n心の羽根\\n拝啓、ツラツストラ\\n純情\\nOh Yeah!!!!!!!\\nGALAXY\\nDon\\'t Let Me Down\\n超\\n超絶☆ダイナミック!\\nハローハローハロー\\nスターリングスター\\n薄紅\\nForever Dreaming\\nよかよかダンス\\n炒飯MUSIC\\n限界突破×サバイバー\\n悪の天使と正義の悪魔\\nBoogie Back\\n遥\\n70cm四方の窓辺\\nLAGRIMA\\n\\n劇場版主題歌\\n奇蹟のビッグ・ファイト\\nドラゴンパワー∞\\n最強のフュージョン\\n俺がやらなきゃ誰がやる\\n『Z』の誓い\\nBlizzard\\n曲集\\nDB\\n全曲集\\n音楽集\\n最強への道 (サントラ)\\n全曲集 (2003年盤)\\nZ\\nヒット曲集\\nヒット曲集ベスト\\nBEST REMIX2006 1/2 スペシャル\\nコンプリート・ソングコレクション\\nベストソングコレクション\\n音楽集\\nBGMコレクション\\n改\\nSONG COLLECTION\\nCOMPLETE SONG COLLECTION\\nサウンドトラック\\n全般\\n大全集\\n神 BEST\\n\\n\\nゲーム\\nゲーム主題歌\\nPower Of Dreamer\\n俺はとことん止まらない!!\\nSuper Survivor\\n光のさす未来へ!\\nProgression\\nBattle of Omega\\nゲームサントラ\\n超武闘伝\\nFINAL BOUT\\nZ & Z2\\nZ3\\nバーストリミット\\nインフィニットワールド\\n\\n実写映画\\nRule\\n\\n\\n\\nゲーム\\nカードダス\\nエンスカイ\\nミラクルバトルカードダス\\n\\n\\n関連作品\\nDr.スランプ\\nネコマジン\\n銀河パトロール ジャコ\\nCROSS EPOCH\\nドラゴンボールSD\\nトリコ×ONE PIECE×ドラゴンボールZ 超コラボスペシャル!!\\n\\n\\n関連項目\\n鳥山明（作者）\\nフジテレビ\\n東映アニメーション（東映）\\nCX水曜19時台アニメ\\nCX日曜9時台アニメ\\n新春アニメ劇場\\n日本偉人大賞\\nFNS27時間テレビ（2017年）\\n\\n\\n カテゴリ\\n表話編歴ドラゴンボールのコンピュータゲーム任天堂据置機\\nFC\\n\\n神龍の謎\\n大魔王復活\\n悟空伝\\n強襲!サイヤ人\\n激神フリーザ!!\\n烈戦人造人間\\n激闘天下一武道会\\nサイヤ人絶滅計画\\nクロスオーバー\\nファミコンジャンプ\\nファミコンジャンプII\\n\\nSFC\\n超サイヤ伝説\\n超武闘伝\\n超武闘伝2\\n超武闘伝3\\n超悟空伝 -突激編-\\n超悟空伝 -覚醒編-\\nHYPER DIMENSION\\nGC\\n\\nドラゴンボールZ\\nSagas（日本未発売）\\nクロスオーバー\\nバトルスタジアム D.O.N\\n\\nWii\\nSparking! NEO\\nSparking! METEOR\\n天下一大冒険\\nSwitch\\nゼノバース2\\nファイターズ\\nワールドミッション\\nカカロット\\nブレイカーズ\\n\\nエポック社据置機\\nSCV\\nドラゴン大秘境\\n\\nNEC据置機\\nPCE\\n偉大なる孫悟空伝説\\n\\nセガ据置機\\nMD\\n武勇烈伝\\nSS\\n真武闘伝\\n偉大なるドラゴンボール伝説\\n\\nバンダイ据置機\\nプレイディア\\n真サイヤ人絶滅計画\\nピピンアットマーク\\nアニメデザイナー\\n\\nソニー据置機\\nPS\\nUltimate Battle 22\\n偉大なるドラゴンボール伝説\\nFINAL BOUT\\nPS2\\n\\nZ\\nZ2\\nZ3\\nSagas（日本未発売）\\nSparking!\\n超\\nSparking! NEO\\nSparking! METEOR\\nインフィニットワールド\\nクロスオーバー\\nバトルスタジアム D.O.N\\n\\nPS3\\n\\nバーストリミット\\nレイジングブラスト\\nレイジングブラスト2\\nアルティメットブラスト\\nBATTLE OF Z\\nゼノバース\\nクロスオーバー\\nビクトリーバーサス\\n\\nPS4\\n\\nゼノバース\\nゼノバース2\\nファイターズ\\nカカロット\\nブレイカーズ\\nクロスオーバー\\nビクトリーバーサス\\nJUMP FORCE\\n\\n\\nマイクロソフト据置機\\nXbox\\nSagas（日本未発売）\\nXbox 360\\nバーストリミット\\nレイジングブラスト\\nレイジングブラスト2\\nアルティメットブラスト\\nKinect（日本未発売）\\nBATTLE OF Z\\nゼノバース\\nXbox One\\n\\nゼノバース\\nゼノバース2\\nファイターズ\\nカカロット\\nブレイカーズ\\nクロスオーバー\\nJUMP FORCE\\n\\n\\n任天堂携帯機\\nGB/GBC\\n\\n悟空飛翔伝\\n悟空激闘伝\\n伝説の超戦士たち\\nクロスオーバー\\nカルトジャンプ\\n\\nGBA\\nTHE LEGACY OF GOKU（日本未発売）\\nCollectible Card Game（日本未発売）\\nTAIKETSU（日本未発売）\\n舞空闘劇\\nTHE LEGACY OF GOKU II\\nBuu\\'s Fury（日本未発売）\\nアドバンスアドベンチャー\\nGT Transformation（日本未発売）\\nDS\\n\\n舞空烈戦\\n遥かなる悟空伝説\\nDS\\nサイヤ人来襲\\nDS2 突撃!レッドリボン軍\\nアルティメット武闘伝\\nクロスオーバー\\nジャンプスーパースターズ\\nジャンプアルティメットスターズ\\n\\n3DS\\nアルティメットミッション\\nアルティメットミッション2\\nJレジェンド列伝\\n超究極武闘伝\\nフュージョンズ\\nアルティメットミッションX\\n\\nバンダイ携帯機\\nWSC\\nドラゴンボール\\n\\nソニー携帯機\\nPSP\\n真武道会\\n真武道会2\\nEVOLUTION\\nタッグバーサス\\nPS Vita\\n\\nBATTLE OF Z\\nクロスオーバー\\nビクトリーバーサス\\n\\n\\n専用機器\\n\\nスーパーバーコードウォーズ\\nバトル体感かめはめ波\\nバトル体感かめはめ波2\\nドラゴンレーダーモバイル\\nスカウターバトル体感かめはめ波\\nクロスオーバー\\nバトル体感ゴムゴムのかめはめ波\\n\\nアーケード\\n\\n対戦格闘 Z\\nSuper Battle\\nV.R.V.S\\n超\\nZENKAIバトルロイヤル\\nTCAG\\nデータカードダス Z\\nデータカードダス Z2\\n爆裂IMPACT\\nW爆烈IMPACT\\nドラゴンバトラーズ\\nヒーローズ\\nスーパーDBH\\nガシャポン\\nディスクロス\\n\\n\\nPC\\n\\nアニメデザイナー\\nDBオンライン（日本未配信）\\nクロスオーバー\\nジャンプフォース\\n\\n\\n携帯電話\\nフィーチャー・フォン\\nDB RPG\\n超DB RPG\\nウォーズ\\nスマートフォン\\n\\nRPG～少年編～\\nドッカンバトル\\nレジェンズ\\n最强之战（中国国内向け）\\n覚醒（中国国内向け）\\nクロスオーバー\\nオレコレクション!\\nジャンプチ ヒーローズ\\nジャンジャンスタジアム\\n\\n\\nブラウザゲーム\\nブッチギリマッチ\\nクロスキーパーズ\\n\\n表話編歴鳥山明漫画作品\\n長期連載\\nDr.スランプ\\u200e（カテゴリ）\\nドラゴンボール\\u200e\\u200e（カテゴリ）\\n短期連載・読み切り\\n鳥山明のヘタッピマンガ研究所\\nPINK \\n剣之介さま\\n貯金戦士キャッシュマン\\nGO!GO!ACKMAN\\nCOWA!\\nカジカ\\nネコマジン\\nSAND LAND\\n銀河パトロール ジャコ\\n短編集\\n鳥山明○作劇場\\n\\nキャラクター\\n則巻アラレ\\n孫悟空\\nブルマ\\n亀仙人\\nウーロン\\nヤムチャ\\nプーアル\\nチチ\\nピラフ一味\\n神龍\\nクリリン\\nランチ\\nレッドリボン軍\\n桃白白\\n孫悟飯（里親）\\n天津飯\\n餃子\\nピッコロ大魔王\\nヤジロベー\\nピッコロ\\nラディッツ\\n孫悟飯\\nベジータ\\nナッパ\\n界王\\nフリーザ\\nフリーザ一味\\nギニュー特戦隊\\nトランクス\\nドクター・ゲロ\\n17号\\n18号\\nセル\\nミスター・サタン\\nビーデル\\n孫悟天\\nバビディ\\nダーブラ\\n魔人ブウ\\nゴテンクス\\nベジット\\nパン\\nブロリー\\nスライム\\nドラゴン\\n竜王\\nカンダタ\\nトルネコ\\nアシスタント\\nひすゎし（現：田中久志）\\nまつやまたかし\\n関連人物\\n鳥嶋和彦\\n桂正和\\nさくまあきら\\n中鶴勝祥\\n山室直儀\\n芦田豊雄\\n関連作品\\nドラゴンクエストシリーズ\\n小助さま力丸さま -コンペイ島の竜-\\nアップルポップ\\nクロノ・トリガー\\nトバルNo.1\\nブルードラゴン\\nRule/Sparkle\\n桂正和×鳥山明共作短編集 カツラアキラ\\nCROSS EPOCH\\n関連項目\\n集英社\\n週刊少年ジャンプ\\n月刊少年ジャンプ\\nVジャンプ\\n手塚賞\\n天下一漫画賞\\n\\n カテゴリ\\n表話編歴最強ジャンプ連載中の作品 （2022年10月4日現在）オリジナル作品\\nアンラッキー不幸田先生\\n怪奇空間ゾゾゾゾーン\\n気になるあの子はカエル好き\\nSAND LAND\\n大門寺と問題児\\nミツルクエスト！\\nスピンオフ作品\\nキメツ学園!\\n僕のヒーローアカデミアスピンオフ チームアップミッション\\nONE PIECE学園\\nタイアップ作品\\nおしりダンディ ザ・ヤング\\nスーパードラゴンボールヒーローズ アバターズ!!\\nスーパードラゴンボールヒーローズ ウルトラゴッドミッション!!!!\\nスパイダーマン：絆\\nドラゴンクエスト ダイの大冒険 クロスブレイド\\nファイアーエムブレム エンゲージ\\nモンスターストライク バーストファンタジスタ\\n遊☆戯☆王ゴーラッシュ!!\\nLet\\'s競歩 あばれる君\\nYouTube連載(再掲含む)\\nキャプテン翼 KIDS DREAM\\n地獄先生ぬ〜べ〜S\\nドラゴンボールSD\\nFischer\\'s×ONE PIECE 7つなぎの大秘宝\\n\\n表話編歴Vジャンプ連載中の漫画作品（2022年11月21日現在）通常連載\\n犬マユゲでいこう\\nドラゴンクエスト ダイの大冒険 勇者アバンと獄炎の魔王\\nドラゴンクエスト トレジャーズ アナザーアドベンチャー ファラドの宝島\\nドラゴンボール超\\nビクトリー・アサダの超一流への道\\nBORUTO-ボルト- -NARUTO NEXT GENERATIONS-\\n遊☆戯☆王OCG STORIES\\n遊☆戯☆王OCGストラクチャーズ\\nApp限定連載\\nデジモンワールド リ：デジタイズ エンコード\\n\\n表話編歴オリコン週間コミックチャート第1位（1995年8月28日付）2月\\n6日 GS美神 極楽大作戦!! 15\\n13日 花より男子 9\\n20日・27日 るろうに剣心 -明治剣客浪漫譚- 3\\n3月\\n6日 金田一少年の事件簿 11\\n13日 赤ちゃんと僕 10\\n20日・27日 SLAM DUNK 23\\n4月\\n3日 天使なんかじゃない 8\\n10日 H2 11\\n17日 寄生獣 10\\n24日 るろうに剣心 -明治剣客浪漫譚- 4\\n5月\\n1日 行け!稲中卓球部 6\\n8日 金田一少年の事件簿 12\\n15日・22日・29日 ファイブスター物語 VII\\n6月\\n5日 うしおととら 24\\n12日 赤ちゃんと僕 11\\n19日・26日 SLAM DUNK 24\\n7月\\n3日 SLAM DUNK 24\\n10日 H2 12\\n17日 BASARA 15\\n24日 聖伝-RG VEDA- 9\\n31日 行け!稲中卓球部 7\\n8月\\n7日 金田一少年の事件簿 13\\n14日 魔法陣グルグル 5\\n21日 美味しんぼ 52\\n28日 ドラゴンボール 42\\n9月\\n4日・11日 H2 14\\n18日 花より男子 11\\n25日 SLAM DUNK 25\\n10月\\n2日 SLAM DUNK 25\\n9日・16日 金田一少年の事件簿 14\\n23日・30日 るろうに剣心 -明治剣客浪漫譚- 7\\n11月\\n6日・13日 X 7\\n20日 クレヨンしんちゃん 13\\n27日 BØY 14\\n12月\\n4日 はじめの一歩 30\\n11日 名探偵コナン 7\\n18日・25日 SLAM DUNK 26\\n\\n1995\\n1996\\n1997\\n1998\\n1999\\n2000\\n2001\\n2008\\n2009\\n2010\\n2011\\n2012\\n2013\\n2014\\n2015\\n2016\\n2017\\n2018\\n2019\\n2020\\n2021\\n2022\\n2023\\n典拠管理: 国立図書館 \\nフランス\\nBnF data\\n日本\\n\\n\\n\\n\\n\\n「https://ja.wikipedia.org/w/index.php?title=ドラゴンボール&oldid=97541391」から取得\\nカテゴリ: ドラゴンボール漫画作品 と1984年の漫画週刊少年ジャンプの漫画作品少年ジャンプ+鳥山明の漫画作品格闘技漫画アクション漫画超能力を題材とした漫画作品冒険漫画ドラゴン・竜を題材とした漫画作品隠しカテゴリ: 外部リンクがリンク切れになっている記事/2019年3月Infobox animanga/画像表示BNF識別子が指定されている記事BNFdata識別子が指定されている記事NDL識別子が指定されている記事\\n\\n\\n\\n\\n\\n\\n 最終更新 2023年10月22日 (日) 04:40 （日時は個人設定で未設定ならばUTC）。\\nテキストはクリエイティブ・コモンズ 表示-継承ライセンスのもとで利用できます。追加の条件が適用される場合があります。詳細については利用規約を参照してください。\\n\\n\\nプライバシー・ポリシー\\nウィキペディアについて\\n免責事項\\n行動規範\\n開発者\\n統計\\nCookieに関する声明\\nモバイルビュー\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n本文の横幅制限を有効化／無効化\\n\\n\\n\\n\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "web[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "522725b5-454b-4fb3-aeb8-67b64ee2b3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_web = WebBaseLoader(\"https://ja.wikipedia.org/wiki/%E3%83%89%E3%83%A9%E3%82%B4%E3%83%B3%E3%83%9C%E3%83%BC%E3%83%AB\").load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c1105da7-f57f-4749-b68e-39d6948a354c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(split_web)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c76787d4-e74a-4553-8281-73117e9745b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ドラゴンボール - Wikipedia\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nコンテンツにスキップ\\n\\n\\n\\n\\n\\n\\n\\nメインメニュー\\n\\n\\n\\n\\n\\nメインメニュー\\nサイドバーに移動\\n非表示\\n\\n\\n\\n\\t\\t案内\\n\\t\\n\\n\\nメインページコミュニティ・ポータル最近の出来事新しいページ最近の更新おまかせ表示練習用ページアップロード (ウィキメディア・コモンズ)\\n\\n\\n\\n\\n\\n\\t\\tヘルプ\\n\\t\\n\\n\\nヘルプ井戸端お知らせバグの報告寄付ウィキペディアに関するお問い合わせ\\n\\n\\n\\n\\n\\n言語\\n\\n言語間リンクはページの先頭にあるページ名の向かい側に設置されています。\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n検索\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n検索\\n\\n\\n\\n\\n\\n\\n\\n\\nアカウント作成ログイン\\n\\n\\n\\n\\n\\n\\n個人用ツール\\n\\n\\n\\n\\n\\n アカウント作成 ログイン\\n\\n\\n\\n\\n\\n\\t\\tログアウトした編集者のページ もっと詳しく\\n\\n\\n\\n投稿記録トーク\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n目次\\nサイドバーに移動\\n非表示\\n\\n\\n\\n\\nページ先頭\\n\\n\\n\\n\\n\\n1概要\\n\\n\\n\\n\\n\\n\\n\\n2あらすじ\\n\\n\\n\\nあらすじサブセクションを切り替えます\\n\\n\\n\\n\\n\\n2.1孫悟空少年編\\n\\n\\n\\n\\n\\n\\n\\n2.2ピッコロ大魔王編\\n\\n\\n\\n\\n\\n\\n\\n2.3サイヤ人編\\n\\n\\n\\n\\n\\n\\n\\n2.4フリーザ編\\n\\n\\n\\n\\n\\n\\n\\n2.5人造人間・セル編\\n\\n\\n\\n\\n\\n\\n\\n2.6魔人ブウ編\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n3登場人物\\n\\n\\n\\n\\n\\n\\n\\n4歴史\\n\\n\\n\\n歴史サブセクションを切り替えます\\n\\n\\n\\n\\n\\n4.1連載開始までの経緯\\n\\n\\n\\n\\n\\n\\n\\n4.2連載開始から連載終了までの経緯\\n\\n\\n\\n\\n\\n\\n\\n4.3連載終了後の展開\\n\\n\\n\\n\\n\\n\\n\\n4.4リバイバルブーム到来\\n\\n\\n\\n\\n\\n\\n\\n4.5新展開へ\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n5設定\\n\\n\\n\\n\\n\\n\\n\\n6用語\\n\\n\\n\\n\\n\\n\\n\\n7制作背景\\n\\n\\n\\n\\n\\n\\n\\n8歴代担当編集者\\n\\n\\n\\n\\n\\n\\n\\n9社会的評価\\n\\n\\n\\n社会的評価サブセクションを切り替えます\\n\\n\\n\\n\\n\\n9.1日本\\n\\n\\n\\n\\n\\n\\n\\n9.2売上\\n\\n\\n\\n\\n\\n9.2.1漫画\\n\\n\\n\\n\\n\\n\\n\\n9.2.2ゲーム\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n9.3アンケートランキング\\n\\n\\n\\n\\n\\n\\n\\n9.4受賞歴\\n\\n\\n\\n\\n\\n\\n\\n9.5その他\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n10日本国外での展開\\n\\n\\n\\n日本国外での展開サブセクションを切り替えます\\n\\n\\n\\n\\n\\n10.1北米\\n\\n\\n\\n\\n\\n\\n\\n10.2中南米\\n\\n\\n\\n\\n\\n\\n\\n10.3ヨーロッパ\\n\\n\\n\\n\\n\\n\\n\\n10.4中東・アフリカ\\n\\n\\n\\n\\n\\n\\n\\n10.5アジア\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n11書誌情報\\n\\n\\n\\n書誌情報サブセクションを切り替えます\\n\\n\\n\\n\\n\\n11.1単行本\\n\\n\\n\\n\\n\\n\\n\\n11.2完全版\\n\\n\\n\\n\\n\\n\\n\\n11.3外国語版\\n\\n\\n\\n\\n\\n\\n\\n11.4フルカラーコミックス\\n\\n\\n\\n\\n\\n\\n\\n11.5コミックスのコーナー\\n\\n\\n\\n\\n\\n\\n\\n11.6ドラゴンボール大全集\\n\\n\\n\\n\\n\\n\\n\\n11.7ドラゴンボール超全集\\n\\n\\n\\n\\n\\n\\n\\n11.8DRAGON BALL総集編\\n\\n\\n\\n\\n\\n\\n\\n11.9その他の関連書籍\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n12関連漫画\\n\\n\\n\\n関連漫画サブセクションを切り替えます\\n\\n\\n\\n\\n\\n12.1ドラゴンボールSD\\n\\n\\n\\n\\n\\n\\n\\n12.2ドラゴンボール超\\n\\n\\n\\n\\n\\n\\n\\n12.3番外編\\n\\n\\n\\n\\n\\n\\n\\n12.4スピンオフ\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n13アニメ\\n\\n\\n\\nアニメサブセクションを切り替えます\\n\\n\\n\\n\\n\\n13.1アニメシリーズ一覧\\n\\n\\n\\n\\n\\n\\n\\n13.2特別編\\n\\n\\n\\n\\n\\n\\n\\n13.3OVA\\n\\n\\n\\n\\n\\n\\n\\n13.4アニメ映画\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n14メディア\\n\\n\\n\\nメディアサブセクションを切り替えます\\n\\n\\n\\n\\n\\n14.1テレビ番組\\n\\n\\n\\n\\n\\n\\n\\n14.2CM\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n15実写映画\\n\\n\\n\\n\\n\\n\\n\\n16ゲームシリーズ一覧\\n\\n\\n\\nゲームシリーズ一覧サブセクションを切り替えます\\n\\n\\n\\n\\n\\n16.1家庭用ゲーム機向けソフト\\n\\n\\n\\n\\n\\n\\n\\n16.2携帯ゲーム機向けソフト\\n\\n\\n\\n\\n\\n\\n\\n16.3日本国外向けゲームソフト\\n\\n\\n\\n\\n\\n\\n\\n16.4アーケードゲーム\\n\\n\\n\\n\\n\\n\\n\\n16.5スマートフォン向けゲーム\\n\\n\\n\\n\\n\\n\\n\\n16.6電子ゲーム\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n17イベント・企画\\n\\n\\n\\nイベント・企画サブセクションを切り替えます\\n\\n\\n\\n\\n\\n17.1日本国外でのイベント\\n\\n\\n\\n\\n\\n\\n\\n17.2展覧会\\n\\n\\n\\n\\n\\n\\n\\n17.3カフェ・レストラン\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n18関連商品\\n\\n\\n\\n関連商品サブセクションを切り替えます\\n\\n\\n\\n\\n\\n18.1玩具\\n\\n\\n\\n\\n\\n\\n\\n18.2タイアップ\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n19脚注\\n\\n\\n\\n脚注サブセクションを切り替えます\\n\\n\\n\\n\\n\\n19.1注釈\\n\\n\\n\\n\\n\\n\\n\\n19.2出典\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n20外部リンク\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n目次の表示・非表示を切り替え\\n\\n\\n\\n\\n\\n目次の表示・非表示を切り替え\\n\\n\\n\\n\\n\\n\\n\\nドラゴンボール\\n\\n\\n\\n102の言語版\\n\\n\\n\\n\\nAfrikaansAlemannischአማርኛAragonésالعربيةالدارجةمصرىAsturianuAzərbaycancaBoarischБеларускаяБългарскиবাংলাBrezhonegBosanskiCatalàCebuanoکوردیČeštinaCymraegDanskDeutschދިވެހިބަސްΕλληνικάEnglishEsperantoEspañolEestiEuskaraفارسیSuomiFrançaisArpetanGalegoעבריתहिन्दीHrvatskiKreyòl ayisyenMagyarՀայերենInterlinguaBahasa IndonesiaÍslenskaItalianoJawaಕನ್ನಡ한국어KurdîLatinaLadinoLëtzebuergeschLadinLietuviųLatviešuМакедонскиമലയാളംМонголमराठीBahasa Melayuမြန်မာဘာသာNāhuatlNapulitanoPlattdüütschNederlandsNorsk nynorskNorsk bokmålOccitanOromooਪੰਜਾਬੀPapiamentuPicardPolskiPortuguêsRomânăРусскийСаха тылаSarduSrpskohrvatski / српскохрватскиSimple EnglishSlovenčinaSlovenščinaSoomaaligaShqipСрпски / srpskiSundaSvenskaతెలుగుไทยTagalogTürkçeУкраїнськаاردوVènetoTiếng ViệtWinaray吴语ייִדישYorùbá中文文言Bân-lâm-gú粵語\\n\\nリンクを編集\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nページノート\\n\\n\\n\\n\\n\\n日本語\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n閲覧編集履歴表示\\n\\n\\n\\n\\n\\n\\n\\nツール\\n\\n\\n\\n\\n\\nツール\\nサイドバーに移動\\n非表示\\n\\n\\n\\n\\t\\t操作\\n\\t\\n\\n\\n閲覧編集履歴表示\\n\\n\\n\\n\\n\\n\\t\\t全般\\n\\t\\n\\n\\nリンク元関連ページの更新状況ファイルをアップロード特別ページこの版への固定リンクページ情報このページを引用短縮URLを取得するウィキデータ項目\\n\\n\\n\\n\\n\\n\\t\\t印刷/書き出し\\n\\t\\n\\n\\nブックの新規作成PDF 形式でダウンロード印刷用バージョン\\n\\n\\n\\n\\n\\n\\t\\t他のプロジェクト\\n\\t\\n\\n\\nコモンズ\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n出典: フリー百科事典『ウィキペディア（Wikipedia）』\\n\\n\\n\\n\\n\\n\\n\\nこの項目では、鳥山明の漫画について説明しています。その他の用法については「ドラゴンボール (曖昧さ回避)」をご覧ください。\\n\\n\\n\\n\\nドラゴンボールDRAGON BALL\\n旧コミックス版ロゴマーク\\n\\nジャンル\\n\\n少年漫画・冒険・バトルSF漫画・ファンタジー\\n\\n\\n漫画\\n\\n\\n作者\\n\\n鳥山明\\n\\n\\n出版社\\n\\n集英社\\n\\n\\n\\n\\n\\nその他の出版社\\n\\n\\n      Viz Media\\n    Glénat\\n  Planeta DeAgostini\\n   Carlsen\\n Sangatsu Manga\\n Schibsted Forlagene\\n Outland（2016年 - ）\\n Japonica Polonica Fantastica\\n Gollancz Manga（2005年 - 2007年）\\n Semic Interprint\\n Star Comics\\n Grupo Editorial Vid\\n Panini Comics México（2015年 - ）\\n Panini Comics Colombia\\n Panini Comics Venezuela\\n Editorial Ivrea\\n Conrad Editora（2000年 - 2011年）\\n Panini Comics Brazil（2012年 - ）\\n 中国少年児童出版社\\n 文化伝信\\n 東立出版社\\n ソウル文化社\\n NED Comics\\n Comics House（1995年 - 2016年）\\n Comic Paradise（2017年 - ）\\n Elex Media Komputindo\\n Kim Dong Publishing House\\n   Chuang Yi（ - 2014年）\\n Eksmo / Comix-ART\\n\\n\\n\\n\\n掲載誌\\n\\n週刊少年ジャンプ\\n\\n\\nレーベル\\n\\nジャンプ・コミックス\\n\\n\\n発表号'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_web[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6c50026a-9ac7-4c32-b20a-9b4009021120",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import YoutubeLoader\n",
    "youtube = YoutubeLoader.from_youtube_url(\n",
    "   youtube_url=\"https://www.youtube.com/watch?v=I2UZutRrtEE\",\n",
    "   language=\"ja\"\n",
    ").load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "601cd764-3c1e-4b8c-9fba-0f055edd371d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='では早速なんですけれども始めさせて いただきます私からはラングチェイン エージェントを使って自社ツールと チャットGPTを連携するというタイトル で発表させていただきますChatGPT 自体は皆さんご存知のように非常に優れた 能力を持っていますが最新のデータに アクセスできないとか特定の数学的な推論 が得意でないなどいくつかの課題が存在し ますこれらの課題は自社プロダクトに チャートGPTを導入するなどチャット GPTを社会実装しようとした際に解決し なければなりません今回お伝えするラグ チェインエイジェントを導入すると ChatGPTと外部ツールをうまく連携 させることができるようになりChat GPTが抱える課題を克服しチットGPT の可能性をさらに広げることができます 本日はラングチェインエージェントをどう 活用することでチャットGPTの能力を 拡張できるのか具体的にご紹介していき ますそれでは始めていきますこちらが私の プロフィールとなります内容はいつもと 同じなのでスキップさせていただきます はいでは具体的な話に入る前にですね今回 のテーマの結論に先に触れておきます結論 なんですけれどもラグチェインには様々な エージェントの種類が存在するが自社 ツールとチャットGPTを効果的に連結 する際汎用的なエージェントタイプである ゼロショットリアクトまたはオAI ファンクションを利用することが簡単と なりますゼロショットリアクトとOpen AIファンクションを比較するとOpen AIファンクションの方がチットGPT からより適切かつ精度の高い答えを 引き出しやすくなっていますこちらはデモ のでお見せしますねでそしてえっとここで ChatGPTと自社ツール連携で非常に 重要となるものとしてツールの説明という ものがありますと通常のプロンプトチャト GPTを使う時のプロンプトと同様に ツールの特性や機能をChatGPTに 正確かつ効果的に伝えることで自社ツール とチャットGPTの連携の成功率が格段に 向上していきますこのポイントに着目し ながら具体的な方法論について今日は 深掘りしていきたいと思いますそれでは これらのポイントを年頭にきつつ今回の 発表をお聞きください本日の発表は以下の 3つのセクションから構成されています 初めにチットGPTの基本的な概要につい て触れます次にラングチェイン エイジェントの特徴について紹介し最後に デモンストレーションを行いますデモでは 特にツールの説明について着目して いただけると幸いですそれでは最初の トピックに移りましょうここではチット GPTの全体的な特徴を振り返っていき ますすでにご存知の内容も多いと思うん ですけれども一般的なはチャットGPTの 性質っていうものをご紹介していきます チットGPTは実用的な大規模言語モデル llmで現在多くのビジネスに活用されて きています例えばベネッセ ホールディングスでは車内AIChat ベネッセGPTを開発しグループ社員 1.5万人に向けて提供しているという ようなプレスを出していたりとか立メカ 大学では大学の英語事業において機械翻訳 とChatGPTを組み合わせたサービス が試験導入されているであったりとか他に も色々なサービスがチャトGPTを 組み込み始めておりChatGPTの実用 化っていうものがすごい勢いで広がってい ますChatGPTを活用する際によく 言われることとしてはチャットGPTから 良い結果回答を得るためには良い質問が 必要であるということですでこれは プロンプトエンジニアリングと呼ばれる 領域で今最も伸びている業種の1つと言え ますプロンプトエンジニアリングではどの ような項目をプロンプトに入れるべきか またプロンプトを複数回うまく使いこ なくして良い回答をるテクニックなどが 研究開発されていますリアクトであったり とかいろんなことを聞いたことあると思う んですけれどもプロンプトの種類っていう のがどんどんどんど開発されているという ことですでチャットGPTの活用は多に 渡っておりその可能性は広がりつつあり ますでプロンプトエンジニアリングの テクニックを活用することでチャット GPTとの適切なコミュニケーションが 可能になりますプロンプト エンジニアリングでは色々なテクニックが 存在するのですが今回はプロンプト エンジニアリング自体がメインのテーマで はないのでプロンプトエジライニングの中 で抑えるべき基本的な項目とそしてよく 使われるまフーショットプロンティングと 呼ばれるような手法を簡単にだけ紹介して いきますはいまず基礎として抑えていき たいこととしてプロンプトに何を与える べきかっていうものをいくつか紹介して いきますで1点目としては具体的で明確に 質問することですで例えばその日本の歴史 において重要な出来事は何ですかという 質問よりも日本の戦国時代における重要な 出来事について教えてくださいという具体 的に質問し方が的確なコ答が得られますと で2点目に状況やコンテクストを明示する ことですて背景情報があるとチャット GPTはコンテクストをより理解し適切な 回答が返ってきますとで3点目期待する 回答の形式を指定するとこれにより望む 情報が整理されて帰ってきますリスト形式 で返してくださいであったりとか ジェイソン形式で返してくださいであっ たりとかまそういうことを質問する時に プロンプトの中に入れるということですね で4点目範囲を限定すること範囲が広す すぎると回答も後半で一般的になりがちに なりますなので範囲を狭めるということが 重要となってきますで最後5点目自性や 認証を明確にすることですと例えば子供で も分かるようにしてくださいとか中学生で も分かるようにしてくださいとかなんか そういう風にどの視点で書て思ってみるか を示したりであったりとか何年の情報が 欲しいとかそういうことを指定することに よって回答が明確なものが帰ってきやすく なるということですで次にプロンティ テクニックの1つののフューショット プロンティについて簡単に説明します フューショットプロンティはモデルに少数 の例を示すことで特定のタスクの解決方法 を学習させるアプローチになりますこれに よりモデルは様々な問に対して適切な回答 を生成することができますここに例として 上げてるんですけれども例えばレストラン 最高でしたこれは感情ポジティブですこの 映画は本当に時間の無駄だった感情 ネガティブですというようにいくつかの例 を与えて出したいものでそれぞれの文に 対しての感情っていうものをこのように 並べていきますてで最後に聞きたいものと してそのサービスは非常に遅く不満ですっ ていうものがあった時にどんな感情で すかっていうことを聞くと感情ネガティブ という風に返ってくるというところですで こういう風にすることによってモデルって いうものが新しい文章がポジティブか ネガティブかっていうのをま過去の例を元 に判断することができるようになるという ことですでこの方法によってですねフュー ショットプロンティはモデルに多様な タスクを効率的に学習させることができ 柔軟な対応が可能になってくるということ でですでここまでいくつかのプロンティの テクニックであったりとかをお話ししてき ましたもちろん他にもたくさんあってです ねチェインオブソツであったりとかあと セルフアスクであったりとかいろんなもの があるんですけれども今回のメインテーマ ではないので一旦プロンティグの話はここ で終わりにしてでここでちょっと一息つい てですねこれらのテクニックが持つ限界に ついて考えてみましょうでまず1点目なん ですけれどもプロンプトのテクニックは 日々進化し開発されていますとこれによっ てチットGPTは多様なタスクや質問に 対応でできるようになってきていますただ 全ての作業やタスクをチャットGPTに 依存すること自体が現実的ではありません とえ例えば先ほどの例で出てきた文章から の感情抽出に関してはチャートGPTに 無理やりさせることが適切かと言われると そうでもないかもしれないAWSコプリン のような勘定分析に特化した学習をして いるAPIっていうものがあってそれを 使った方がいい結果が返ってくるかもしれ ませんっていうのがまず1つ目ですねで次 に2点目としてそのChatGPTが持つ 情報っていうものは訓練データに限定され ていてチットGPTはそれ以外のデータに ついては知らないというところですなので えっとチャットGPTは過去のデータで 学習されておりその学習データ以降に出て きた情報に関してはチットGPTに尋ね られませんとよく言われるものとしては 2021年のデータですかねまでのデータ で学習してるので例えば2022年であっ たりとか2023年のデータについて聞い たとしてもチャットGPTがうまく答え られないというようなところですね最新の 価格的な研究であったりとかニュース記事 とか特定の地域の天気情報であったりとか チットGPTの訓練データに含まれてい ないような情報っていうものはChat GPTだけでは取得できませんし インターネットにあるデータだけではなく て例えば今回のテーマである自社のツール と連携するっていう時のためには自社の データを使いたいみたいな話とかあると 思うんですけれども自社データについては チャットGPTが知るわけもないという ことでえっとChatGPTに自社の データについて聞いたとしてもChat GPTはもちろん答えることができません とこれらのチャGPTの限界を理解する ことでチットGPTの適切な使用方法で あったりとかそれらをどのようなシナリオ で活用するべきかっていうのが見えてくる ということですねでChatgpdの概要 の最後なんですけれどもChatgpdや その他大記号言語モデルllm自体の課題 をこちらにまとめますでまず1点目なん ですけれども先ほどと被るんですが ChatGPTは最新の情報にアクセスが できないと例えば為替や株価のように国 一刻と変化していく情報に対してチト GPTははリアルタイムで対応することが できませんで2つ目の課題としては ChatGPTが独自の情報源にアクセス する能力を持たないということです企業の データベースに保存されている顧客名簿で あったりとか特定のプライベートな情報に はアクセスすることができませんで3つ目 に水論の正確性に課題があるというところ ですチャットGPTは時折り簡単な算術 計算でさえも間違えることがありますこれ は特に正確な情報や結果が求められる タスクにおいて大きな問題となりますねで そして最後にチャットgpdができない こととかのデータが足りないんだったら ファインチューニングすればいいんじゃ ないかっていうような意見もあると思うん ですけれどもファインチューニングする ことによって汎用性が劣化してしまうと いうことがありますとでChatGPTを 特定のタスク例えば自社データを食わせる であったりとか特定のタスクに特化した データを食わせてファインチューニング すると他の多様なタスクに対する性能が 低下すると言われていますでこれらの課題 を解決するための1つの手段として今回お 話しするラングチェインエージェントって いうものがありますでここここからは ラングチェインエイジェントを使って チットGPTの性能を生かしつつ苦手な ものは他のツールで解決していくっていう ことについてお話ししていきますで参考 までにですねここにバッと上げている課題 に関してはMrKLシステムズていう有名 な論文があってそ論文から引っ張ってきた ものとなりますMrKLシステムズって いうのはミラクルシステムズと呼ぶもので チャットGPTと他のツールを連携して どんどんどんどん課題を解いていくって いうことを提示しているロムとなってい ますそれではラングチェインエージェント についてのトピックに移っていきますまず ラングチェインエージェントの前にですね ラングチェインとは何かと言うとラング チェインとは言語モデルを利用する アプリケーションのためのフレームワーク ですでラングチェインについては前回の 勉強会でもご紹介しているので基礎的な 内容を知りたい方はYouTubeで前回 の勉強会の動画をご覧くださいでラング チェインエージェントはラングチェインの 中の1つの機能なんですけれどもラング チェインの中でも非常に面白くて重要な 役割を果していますランチェの主なタスク は次にどんなアクションを取るべきかを大 記号言語モデルllmに決定させそれを 実行するということですで具体的な プロセスは以下の通りですとまず各ツール ができることと質問を指定したレスポンス のフォーマットでllmに送信します聞き ますとチットGPTなどのllmに聞き ますそしてllmChatGPTから帰っ てきたレスポンスをパースして次の アクションを決めるということをしますで このプロセスによってラングチェインジと はユーザーの4級に応じて効率的かつ正確 なアクションを実行できるようになって いるというところですでここでラング チェインエージェントがどのように動く かっていうもののイメージを具体的な例と して1つ持ってきましたま正確に正しい 動き方をしてるわけではないんですけれど も大体こういうような動きをするんだよっ ていうこともご理解ください例えばチット GPTに対してコミュニケーションを取る のがラングチェインのエージェントとなる んですけれどもラングチェイン エージェントにですねまずこう今日東京で で出かける時時に適切な服装は何ですかて いうのを聞きますでそうするとラング チェインエージェントが聞きたい内容今日 東京で出かける時に適切な服装っていう ものとあと自分が持っているツールって いうものをプロンプトに入れてチャット GPTに聞いてくれますとで自分が持っ てるツールっていうものは例えば Google検索のツールっていうも持っ てますとGoogle検索のツールでは 最新の情報を引っ張ってくることができ ますと私が持ってるのはGoogle検索 のツールで最新の情報が引っ張ってこれ ますそしてで今回聞質問としては東京で 出かける時に適切な服装って何でかていう ものを聞きますとでその時にチャット GPTはどのように返してくるかというと でまずは検索ツールでインプットは東京の 気温っっていうもので調べなさいっていう ものをエージェントの方に返してきますで エージェントはチャットGPTからから 教えてもらったじゃあえ検索ツールを使え ばいいのかっていうところで検索ツールを 使おうとしますでインプットとしては チャトGPTが教えてくれたように東京の 気温っていうものをインプットとして入れ てで検索ツールから帰ってきた22度って いうものを変してもらいますとでそして またえっとチャットGPTにえこのツール に入れた答えってものが22°でした次何 すればいいんですかであったりとか最終的 にどうなんですすかっていうのをチャット GPTに聞いてチャットGPTが十分な 情報を得たっていう風に判断するとでは 22°なので薄の長袖でがいいでしょうっ ていうものをエージェントとしに返してで あとはえ答えとしてラングチェインの エージェントが東京は22度なので素の 長袖でがいいでしょうっていうものをその まま返してくるというような流れになり ます特徴的なものとしてはチャットGPT だと今日の天気であったりとか東京の天気 であったりていうものは取れないんですね でそこをGoogle検索のツールって いうものを利用することによって新しい データっていうのを取れるようにしてると いうところですねもう1つ押えておきたい こととしてはこの問を解く時に自分が持っ ているツールっていうもの一覧を渡して どのツールを使えばいいかっていうのこと 自体もチャットGPTに判断してもらうっ ていうところが面白いところとなってい ますはいでこれがラングチェイン エージェントリアクトフレームワークとか 呼ばれたりするようなやり方ですねはい これらのこと全部ラングチェインの エージェントがやってくれるというところ ですでラングチェインエージェントって いうものは様々なタイプのエージェントが 用意されていますとここでエージェントの タイプっていうものを紹介するんです けれども解きたい課題に応じて エージェントを使い分けることによって 精度の高い回答を得られるようになると いうことですここで6個ほど上げています でまず1番汎用的なものとしてはゼロ ショットリアクトエージェントというもの ですでこのエージェントはリアクト フレームワークを利用してツールの説明に 基づいてどのツールを使用すべきか判断し ます先ほどの例で出てきたものと同じです ねこれによって特定のトレーニングデータ なしで多様なツールの適切なこう利用が 可能になってきます次にストラクチャード インプットリアクタエージェントですで このエージェントは複数の入力を使う エージェントを活用することができますで これによってより複雑なツールの理由用が 簡単になりタスクの効率が向上しますと 続いてOpenAIファンクション エージェントですこのエージェントはオ AIのファンクションコーリングの機能を 使っており関数が呼び出されるタイミング であったりとかを検出したりとか適切な 入力を関数に渡すような微調整がえオープ AI自体チットGPT自体がされていて それを使うことができますとOpenAI のえファンクションコーリングこの エージェントが使うOpenAIの ファンクションコーリングについてはこの 後のスライドでもう少し詳しく説明します で次にコンバーションエージェントですで このエージェントは会話での使用目的とし て設計されています何かを聞いて何か答え を出すっていうようなま単純なチャット GPTで何かこう答えを作ってくださいと かそういうのとは違くて会話的な インタラクションを通じて効果的な コミュニケーションを可能にするような エージェントとなっていますそして次に あげるものとしてはセルフアクwith sarchエージェントですねでそこの エージェントはですねセルフアクという 質問を自問自としながら分割することに よって正しい解を導き出す方法を使って 情報を検索するエージェントですセルフア クっていうプロンティグの技術があるん ですねまそれを使ってちゃんとした正しい 答えを導き出すエージェントとなってい ますで最後に紹介するものがリアクト ドキュメントストアエージェントですで このエージェントはドックストア ドキュメントストアですねと対話するため にリアクトフレームワークを使用してき ますえこれによって文書の管理であったり とか検索が一元化されて効率的に情報 アクセスが可能となりますこちらに関して はまた今後の勉強会でも取り扱っていき たいかなという風に思ってるんですけれど も文書検索管理っていうものに特化した エージェントとなっていますで以上がラン チェインエージェントの各エージェントの 使用となりますでそれぞれのタイプが 異なるシナリオやタスクに適しており ラングチェインの柔軟性と多様性を象徴し ているものとなります今回のセッションで はですね最も汎用的なゼロショット リアクトとチャットGPT自体に色々判断 させるファンクションコーリングを使った オープAIファンクション2を利用して いき ますでは先ほど説明を省いてしまったん ですけれどもOpenAIファンクション コーリンググっていうのはOpenAI ファンクションコーリングじゃないですね OpenAIファンクションですね OpenAIファンクションとは何か エージェントタイプの1つであるOpen AIファンクションとは何かについてお 話ししますこちらはChatGPTを提供 しているOpenAIのファンクション コーリングという機能を利用していますで ファンクションコーリングっていうものは 2023年の6月にリリースされた機能で ラングチェインエージェントが担っていっ たツールを渡してチャットGPTに聞いて 次のステップを決定するやり取りってい ものをチットGPT自体が行えるように ファインチューニングされているものと なりますでこの機能では東京の天気を教え てくれというような先ほどと同じように ですね質問と共にどういう関数を持って いるのかその関数の説明をチトGPTに 直接投げるということをやりますなので 先ほどのラングチェインエイジェントが やってることと同じようなことをやれる ようになっていてチットGPTが ファンクションをどのように受け取るのか そのファンクションのパラメータであっ たりとか説明とかをよりチャトGPTが 理解しやすいようにAPIとして受け取る ことができるようになっているのでより 適切な判断をチャットGPTがしやすく なっているというところがメリットとなり ますなので今メリットをお話ししてしまっ たんですけれどもファンクション コーリングを使うメリットとしては ChatGPTにツールの挙動をより正確 に伝えやすくなっているというところで これによってChatGPTが機能の ツールのえファンクションの使用や動作を より正確に理解しやすくなっていて適切な 判断をしやすくなっているとていうのとで もう1つのメリットとしてはチャット GPTっていうものがラングチェイン エージェンドって元々チャットGPTが 返してきた個体を利用者が頑張って定期 表現を使って解析する必要があったんです がそれをする必要がなくなったっていう ところが利点としてありますとでチャット GPTが実際にラングチェインを使って どのツールを使えばいいですかていうのを 聞くんですけどそれをどのようにパースし てるかというとこのように頑張ってですね えっとレギュラーエクスプレッションを 使って正規表現を使ってパースしたりとか して次のアクションを決めてたりするって いうのがラングチェが今までやっていた ことであるとでこういうパースをしなきゃ いけないっていうことをしなくて済む つまりパースしなきゃいけなかったので今 まではそのパースすることでえっとうまく パースできなくてミスってしまうっていう こともあったんですけどそういうことが なくなるっていうことが期待されるという ところです はいはいちょっと駆け足になってしまった んですがここまでで20分ぐらいかかって しまいましたねえここからがレモに入り ますで実際にですねラングチェイン エージェントを使ってチャトGPTと自社 ツールを連結するような感じのえデモって いうものをお見せしていきますで使う エージェントとしてはゼロショット リアクトとオーエファンクションを使って いきますであとは今回のプレゼンの冒頭の 方でもお話ししたようにChatGPTに ツールの説明をどのように渡せばいいのか であったりとかその辺りを持ち替えて いただければ幸いです はいではではやっていきますちょっと時間 がなくなってきたので駆け足でいきますね でまずは設定ファイル読んでいきますこれ 何をやってるかと言うとえOpenAIの APIキーであったりとかを読んでいます でまずはですねえっとゼロショットの方を 見せしていきたいんですがおマジないとし てですねおじないというかま前回の勉強会 と同じようにですねラングチェイン エージェントを使うためのやり方をお見せ していきますで実際今回使うモデルとして はチットOpenAPAIというか ChatGPTのえGPT3.5のtbo 0613というものを使っていきますで 外部のツールとしてはGoogleサーチ のAPIっていうものを今回用意しました ここであのサプAPIっていうものを書い ているものがえGoogleのAPIと なりますで聞きたい質問としては今日の 東京と北海道の天気を調べて東京から 北海道の出張で来ていくべきを教えて くださいっていうものを聞きたいと思い ますでラングチェインエージェント自体を 走らせてみますでこれがゼロショット リアクトエージェントを使った場合どの ようになるかっていうのをお見せしますで エージェントタイプに関しては イニシャライズエージェントの エージェントっていうえ引数に対して エージェントタイプのこのゼロショット リアクトディスクリプションていうものを 渡すとエージェントを選択することができ ますちなみになんですけれどもえこれって ただあの文字列が返ってくるだけですかね あのゼロショットリアクト ディスクリプションていうものが返って くるだけのものになりますなので文字列で 与えても同じですはいでは実行してみ ましょうチトgpdはもちろん今日の天気 とか今日の東京とか北海道の天気っていう のは知らないので来ていくべき服装って いうことは分からないわけですね気温も 分からないのででこれでラングチェイン エージェントが私はGoogle検索の ツールを持ってますよでそれを使って使う ことができますでこの問題課題っていう ものを解くためにはどうすればいいですか てのを聞くっていうことですねでここで ざーっと出てきてるんですけれども実際に 書いてきた答えとしてはtheWisto isCloudyaboutcrear withtempof歌詞になっちゃって ますけどまこのように帰ってきますと 英語で帰ってきちゃってますねでこういう 風にえどんなアドレスをれ切ればいい かっていうものがちゃんと帰ってきてい ますと前にやった時はそんなに綺麗に帰っ てきてなかったんですけれども今回は うまく帰ってきていますはいこちらがゼロ ショットリアクトディスクリプションで やった場合の結果になりますでどういう ことをやってるかっていうのなこの辺りを 見ていただくといいのかなという風には 思いますでチットGPTにまずラング チェインエージェントが問題とツールを 渡してチットGPTに何をすればいい かっていうのを聞きますでチャットGPT から帰ってきた答えとしては次の アクションとしてはサーチをしてください ですサーチのインプットとしてはウザー 東京todayていうものを渡してくださ いっていうのを渡してますで次の アクションとしてはサーチをしてください でそのインプットとしてはウザ北海道 todayていうものを渡すようにして くださいとで最終的にその帰ってきた答 っていうものをチャットGPTに渡して 最終的な文が出てくるということですはい でこれが1つ目ですねアエージェント タイプ1つ目のえゼロショットリアクト ディスクリプションで元々ラングチェイン エイジェントがリアクトフレームワークで ツールを渡したりとかしてチャットGPT とうまく連携しながら外部ツールを使う ようにしたえ機能となっていますでこれが ですねえ最近出てきた6月にリリースされ たOpenAIのファンクションコーリン グっていうものを使うとどうなるかって いうのをお見せします はいでOpenAIファンクション OpenAIのファンクションコーリング を使うためにはエージェントタイプの OpenAIファンクションズっていう ものを渡しますでそうするとえこのように 動きますで実際にやってることとしては ラングチェインエージェントがOpen AIのファンクションコーリングっていう ものを使ってうまくチャットGPTと やり取りしながら答えを導き出していくっ ていうことをやっていますはい出てきた 答えはこちらですねで同じようにですね どのようにやっているかっていうものは ここら辺の途中で出てきているんです けれども途中結果でえサーチとしてはえ クエリー東京の今日の天気っていうものを 調べてくださいでサーチっていうツルを 使って今日の北海道今日の天気っていう ものを調べてくださいでこれらが帰ってき た答えっていうものをえチャットGPTに 返してチャトGPTがその与えられた情報 を元に東京の今日の天気は曇りですが後に は晴れる予報ですで気温は接し30°歌 86°でコス確率はどうのこうのっていう ものがあってであとは東京は暑くなる可能 性があるので軽い服装が適しています ただし北海道は比較的涼しいので ジャケットなどを持っていくことがお勧め しますというような感じに帰ってきてます ま見て分かると思うんですけれどもま日本 語にな質問が日本語だったので日本語で ちゃんと返してくれるっていうのは もちろんのことなんですけれども書いてき た答えっていうものに関してより詳しく 返してくれているっていうことが分かると 思いますなので使ってみた所管としては ですねここで言うオAIファンクションの ファンクションコーリングっていうのの ファンクションっていうのはラング チェインエージェントでいうツールと同じ なんですけれどもそのファンクションで あったりとかツールを渡す時にですね渡し て何かを判断判させたいチャットGPTに 判断してもらいたいっていう時はえ エージェントタイプゼロショットリアクト ディスクリプションよりもエージェント タイプオAIファンクションの方がより いい結果が返ってきやすいっていうことが 分かると思い ますもう少しあの詳しく見ていきます ちなみにですねOpenAIにどんな ファンクションを渡してるかっていうのは イニシャライズエージェントのところで エージェントを定義してるんですけども そのエージェントの中からエージェントっ ていうものとファンクションズってものを 実行するとどんなえファンクションが渡さ れてかっていうのを見ることができますで 今回渡されたファンクションっていうのは ネームサーチっていうファンクションが 渡されていてどんなことができるかって いうのでサチエンジンですっていうような ものをやってますであとはパラメーターと してはこういうものを渡していきますって いうのが分かりますとはいでここまでが 基本的なラングチェインエージェントを 使って外部ツールを連携するっていうお話 をしてきましたとで次にですねえ自社で 作ったツールっていうものを連携させ るっていところについてお見せしていき ますで一旦はですねレコメンドアイテムっ ていうものを考えてみようと思いますで ここ何をやりたいかって言うとレコメンド アイテムまこの中身はほとんど意味のない ものになってるんですけれどもレコメンド アイテムっていう関数を自社で持っていて でレコメンドアイテムっていうものは自社 のデータベースなどにアクセスして日付を 持ったにこの日のレコメンドっていうもの はこういうものですっていうものを返す ような関数っていうところになりますとな のでえっとこのレコメンドアイテムって いうところをこの関数ををえChat GPTのフローの中に組み込みたいって いうことをやっていきますでどのように ラングチェインエージェントを使って ChatGPTに連携すればいいかという とツールっていうものにえ変換していく 必要がありますとでレコメンドアイテム ツールっていうものをえツールfrom ファンクションズっていうものを使って どのようなファンクションを実行したい ですかレコメンドアイテムっていう ファンクションを実行したいですまこう いう風にですねこの今回のあまり意味の ないファンクションなんですけれどもこれ を実行しますとでツールの名前としてはえ レコメンドアイテムっていうものを渡し ますでツールのディスクリプション何を やってくれるかっていうことに関してはお すめの商品を教えてくれますっていうのを ツールとして定義するというところです はいでこれをちょっとツールズっていうま ツールまとめて渡さないといけないで ツールの配列の中に入れておきます実際に ですねラングチェインエージェントにどの ようにツールを渡せばいいかっていうとま 先ほどもカラっとやってたんですけれども このツール1覧っていうのを最初に渡して 引数として渡しているのでまこのようにし てどんなツールが使えるかっていうものを ラングチェインのAに渡しでチャット GPTと連携していきますはいでえっと 今回聞きたいこととしてはえおすすめの 商品を教えてくださいっていうものを投げ てみようと思いますで使うエージェントと しては先ほどゼロシトリアクトよりもより いい結果が返ってきたオーエ ファンクションズってものを選びます はいはいでは実行し ますはいで書いてきたものとしてはですね コメドアイテムってものが実行されて withファッションという謎のものをえ 入力に入れてで実際この引数がですね デートの中にファッションが入ってで プリントファッションっていうところでこ でファッションが出てきてしまってるとで ただおすめの商品は今回レコメンド アイテムで書いてきたAppleですって いうのが書いてきてることが分かると思い ますはい見て分かるようにですねなんか よくわからない引数は与えてしまってる なっていうところがありますでこを どんどん解決していこうと思いますで次に やることとしては今回なんでこのように変 なファッションとかいう引数を与えて しまったかというと引数に関する情報が ないんですね与えられてないというところ になりますとなので引数何与えればいいん ですかみたいなところが情報としてないが ゆえにチャットGPTもレコメンド アイテムを使うことは分かるとレコメンド アイテムを使えばいいのは分かるんだけど レコメンドアイテムに対してちょっと 分からないからカテゴリー情報でも渡して みようかなっていうのでファッションを 渡してしまっているというような状態に なりますで例えばまファンクションを見た としても今回使ってるファンクションに 関してはレコメンドアイテムでおすめの 商品を教えてくれますでパラメーターの 情報は全くありませんっていう状態なので どんなパラメーターを渡せばいいかって いうのはオープAIファンクションは 分からないというところですねじゃあこれ に対してどうすればいいかっていうのをお 見せしますでえっと結構簡単でしてパダ ティックっていうものをご存知ですかね こう最近えっとファストAPIとかですか ねこう結構パであったりとかそのヒントを 与えるっていうことがまPython主流 になってきてると思うんですけれども フダンティックを使っていきますでえっと ご注意していただきたいこととしては ファインディッてもうV2が出てるんです けれどもV2を使うとラングチェイン エージェントを動きませんとなので パティックV1を指定して方に関する情報 をえ与えるためのそのベイスモデルとか フィールドを使ってえやっていきますで これ何をやってるかと言うとま今回の インプットに対してデイトっていうものが ありますがデイトていうものはお勧めした 商品を絞るために使われる日付ですって いうものを与えていますこれをえっと アーグススキーマ先ほどのツールを定義 する時にアグススキーマっていう引きを 使ってこのレコメンドアイテムインットっ ていうベースモデルから継承した レコメンドアイテムインプットっていう インプットの報引数の情報を持ったクラ スっていうものを渡すということをします とでこうするとどうなるかっていうのをお 見せしていき ますはいじゃあどう変わる かいきますはい実行します全く同じですね 実行するものとしてはで今回はレコメンド アイテムっていうものに対して先ほどと 同じレコメンドアイテムっていうものが 選ばれましたとコアイテムに対してデイト が2020年の12月1日っていうものを 渡しているっていうことが分かりますで それによってですね気付がちゃんと渡して くれたっていうことがわか分かるわけです ねで今回あのここであのデートっていう ものはディスクリプションでお勧めしたい 商品を絞るために使われる日付っていう ことを伝えたのでチャットGPTの方があ これは日付のことなんだっていうところで 引数はファッションのようなカテゴリーを 渡すんではなくてデートの引数っていう ものを渡すことができてるというところ ですはいでこちらがデトのまあ2022年 の12月1日もはや日付が意味が分から ないですけれどもこういうものが渡されて いるというところですねでおすめ商品は Appleですという風にでこういう風に ですねこうツールの説明をどんどん どんどん入れていってええ解決していく 必要があるというところですねで同じよう にですねちょっとエージェントの ファンクションがどのように渡されるてる かっていうのをお見せしますとで今回渡さ れたのはレコメンドアイテムインプトって いうのをえパイダンテックの方で定義して 渡しているのでえ実際にえっと ファンクションOpenAIのえ ファンクションコーリングにどのように 渡されてるかというとパラメーターとして ですねこういう風なレコメンドアイテム インプットっていうものが渡されていて プロパティとしてはデートがあってデー トっていうのはお勧めしたい商品を絞る ために使われる日付っていうものが入れ られてえ飛ばされてるということが分かる と思いますはい で他にはですねこのようにツールフロン ファンクションで作るっていうこともある んですけれども同じようにですね デコレーターを使うっていうこともでき ますとデコレーターの方が結構シンプルに 書けるので私は結構デコレーターを使って 書くことが多いですとでデコレーター何を すればいいかというとデコターっていうの はま関数の前にですねアマークツールなん ちゃらかんちゃらっていうものがあってで それを使ってえっとこのツールってのは何 ができるかっていうものをえドッ ストリングで与えるんですねな先ほどと 同じにするとレコメンドアイテムツールっ ていうものがあったら中身は同じですね プリントデイトとAppっていうものを 返しますとプリントデイトしてApple っていうものを返しますとででやることと してはおすめ商品を教えてくれます全く 同じ内容ですねでこのツールの名前って いうものはデコレーターの引数として レコメンドアイテムとして渡していると いうところですで同じようにですね ツールズの一覧として入れてでこれをえ 実行してみ ましょうはいこれデコレーター使った場合 です ね実行するものは全部同じですで同じよう にこれも実行できますという風にデコレー ターってかなりこうシンプルにかけてで ファンクションの中のドックストリングス とかを使ってくれるので結構あの家読性と かもう悪くないかなという風には思います 先ほどと同じようにですねこレコメンド アイテムってものはちゃんと選んでくれた んですけれどもレコメンドアイテムに渡し ているデートっていうのは2021年10 月15日という意味の分からない日付を 渡してしまっていますとこれはなぜかと言 とまもちろんそのおすすめ商品を教えて くださいって言ってるので勝手に日付を 決めて聞いてしまっているというところ ですね はいでデコレーターの方もですね同じよう にファンクションを見てみるとえっとこう いう風になるという感じですねただあの 先ほどと同じようにですねパダンティック とか使っていないのでプロパティの パラメーターとかは適当になってしまって いるというような感じになりますただ今回 の場合はですねこうデコレーターの場合は フロムファンクションの方を使ったこっち の場合ですねこのフロムファンクションを 使った時と違ってきちんとデートを入れて くれているっていうことが特徴的かなと いう風には思いますフロンファンクション を使った場合っていうのはパダンティック を渡さないとデートっていうものに対して ファッションを入れたりとかよく分から ないものを入れたりすることがあったと 思うんですけれどもデコレーターを使った 場合はこのデートっていうものを渡した時 にきちんとこうデートを返してくれるよう な情報っていうものを渡せてくれている ような感じですねいずれにせを正しい共同 を求めるためにはこのままあまり情報を 与えないで実行するってのは適切ではない ので特に自社ツールサービスとして提供 する側としてはですねなのでそういう意味 ではきちんとバイダンティックなどを使っ て適切な情報を渡しながら関数っていう ものを渡していく必要があるかなという風 に思いますなのでえっと先ほどと同じよう にですねデコレーターを使った場合も パイナティックの情報っていうものを渡す ことができるのでデコレーターの引き数に アーグススキーマていうものを渡してで そのパイランティックの情報を渡すことで 適切な答えを返すことができるようになる というところです同じようにですねま結果 も変わらないので はいまこういう風に変えてきました ちょっと答えがどんどんどんどん変わって きてますApple製品だったりとか AppleStoreとかオンライン ショップとかうんまここら辺に関しては 本当に適切な答えがまだ返ってきてない なっていうような状態だとは思います エージェントのファンクションを見るとえ きちんとファナティックで渡した情報って いうのが渡っていることが分かると思い ますこのようにですねこのデートっていう ものはデートっていう引き数はお勧めし たい商品を絞るために使われる日付ですっ ていうのが渡っているというところです もう少しですね今までこうおすめの商品を 教えてくださいっていう風に言っていたの でデートっていうものが1月10日であっ たりとかよくわかんない日付になっていた のではないかっていうことを推測してでは 昨日のおすすめ商品を教えてくださいって いうものを聞いてみますてそうするとどう なるかと言うとえ昨日のおすめ商品を教え てくださいって言ってるのにレコメンド アイテムに渡されてるのは2021の10 月20日っていうものが渡されれてること が分かりますとチャットGPTにこう昨日 とか今日とか昨日とか渡したら日付を ちゃんと入れてくれるのかなと期待するっ ていうことがあると思うんですけれども 実際はそんな入れてくれないっていうこと がまこの結果から分かるということですね もう少し例えばディスクリプションとかを 適切にすればうまくいくのかもしれないん ですけど今回は違う手段でえっと解決 しようと思いますで今回どういう風に解決 するかと言うとデートタイムを使って 新しい日付けを取得するような関数自社 ツールってものを設けようと思います ゲットデートっていうツールっていうもの を作ってでそのツールは何をするかという とま今日や昨日など日付を取得する時に 使います引き数には今日を起点として何日 か前をNで与えますとでここのそのドック ストリングスにですねこう引数に関する 情報を書いてるんですけども実際はですね パダンティックで引き数の説明した方が ベタだとは思いますただえっとドック スリンに書いてツールの説明として与える だけでも結構チャットGPTは賢いので うまく判断してくれるということですでお 見せしますはいこの日付関数を入れると どうなるかと言うとこういう風な感じです ねはい今日のおすめの商品を教えてくださ いっていう風にするとtodayて書い てき来てこれもうまく動いてないですね こういうことが結構ありますとうまく動か ないことがあるとでもう1回実行してみ ましょうかはいでもならではですね ちょっと30分で終える予定が46分に なってしまったんですがもう少しで終わる ので続けます前回のやつだとですね直接 レコメンドアイテムを呼び出してデートに 対してtoデイていうものを渡してしまっ てたんですけれども今回はうまく動いてい てまずは日付を取得するためにゲットデイ トっていうものを呼び出しますとで今日な ので今日からの起点のえN日前だったらN に0を渡せばいいということが分かるとだ からゲットデートに0を渡して帰ってきた ものが2023年の9月30日っていう ものが帰ってきてで9月30日のえお勧め 商品は何ですがま書いてくるものは全部 AppleなのでAppleってものが 帰ってきてることが分かると思います同じ ようにですねじゃあどういう ファンクションが渡されてたかっていうの をお見せするとサクっとですねで今回あの ファンクション2つ渡されていて レコメンドアイテムっていう ファンクションとゲットデイトっていう ファンクションが渡されていますで それぞれのファンクションの説明がこの ように与えられているということが分かり ますもう少しツールを複雑にしていって ですね奇数日だったらオレンジ偶数日だっ たらえAppleっていうものを返すよう なツールにちょっとだけレコメンド アイテムを変えみようと思い ますはいではえこれを実行するとですね 今日はえ9月30日なのでもちろん9月 30日偶数日ですね偶数日なので Appleが返ってくるきちんと帰ってき ますねAppleが帰ってきましたでは 昨日の場合はどうなのか 昨日はい昨日の場合は29日なので1日前 ってものをゲットデイトで取得して29日 ってものが書いていますで29日を使って え昨日のおすめ商品オレンジっていうもの を取ることができるというところ ですやとうまく動きました ねでもう少しだけちょっと時間が1時間 ぐらい喋ってしまうような感になるんです けれどもう少しだけお話させてくださいで これだけだともちろんまだまだ連携が 少ないかなっていうところがあってで次に じゃあAppleだったら100円 オレンジだったら200円っていうような ものを商品の値段を返すような関数って いうものを組み込んでみましょうでツール としては元々グビだったらAppleキビ だったらオレンジを返すようなものとあと は日付を取得するツールであとは今回定義 したAppleとオレンジAppleだっ たら100円オレンジだったら200円 っていうのを返すツールっていうものを 定義しますでこれでエージェントのですね おすめの商品の値段まで教えてくださいっ ていうことをやるとそうするとまず最初に え昨日なのでゲットデートでN=1を渡し て1日前のデートを取ってきますで9月 29日ですで次にレコメンドアイテムって いうツールを呼び出してレコメンド アイテムにえ9月29日を渡してで最後に ですねアイテムプライスっていうので アイテムネームをえオレンジにとして渡し てでオレンジはは200円なのでえ昨日の おすめ商品であるオレンジの値段は 200円ですっていう最終的な答えが返っ てきましたというところになりますだいぶ 柔軟なものができるようになってきたって いうことが理解できると思いますで他には ですね最後なんですけれども取得した結果 を吐き出したいとかデータベースに 書き込みたいとかあったりすると思うん ですけどもそういうことももちろん簡単に できますと基本的にはファンクションが あってそのファンクション中身は自分で 書いていくので何でもすることができると いうところですねちょっとあの output.tchっていうところに 書き込むようなものを記事的にですね データベースに書き込んでいるようなもの として紹介しようと思いますで今回は さらに追加するツールとしてはですね セーブデータっていうツールを追加します とセーブデータっていうものは何なのかと いうとここにも説明書いてあるんです けれども日付と商品名と商品の値段を 受け取ってデータベースに書き込みますっ ていうようなものをツールとして作りまし たデータベースといながらもアウトプット テキストにただ書き込むだけのものになる んですけどもデートアイテムネーム アイテムプライスを書き込むだけのツール となりますま実際に自社ツールを使う時に はここにSQL分であったりとかを書いて データベスに書き込むとかをやったりする ことになると思いますこちらもですね ちょっと簡易的にですねフダンティックを 使わずにえドックストリングだけで何を やるかってのを渡して書き込めるかどう かってのをお見せしていこうと思いますで 同様にですね同じように何をしたいかと 言うと今日のおすめ商品の値段を調べて データベースに書き込んでくださいって いうことを実行し ますで最初に動くものとしてはまず日付を 取得するゲットデイトが動いてN=0で 今日の日付を取ります9月30日ですと9 月30日が取れたら9月30日の レコメンドアイテムは何ですかていうので レコメンドアイテムのツールを起動して 書いてきたものがAppleですとであ次 にやることしてはAppleの値段は いくらですかていうものをアイテム プライスに聞いてアイテムプライスが返し てきた答えが100円ですとで100円 っっていうものをえセーブデータに渡して セーブデータに渡すものとしてはデートと アイテムネームとアイテムプライスこれは 日付と商品目と商品の値段を受け取 りっていう風に書いてあるのでこういう ようなものを基数として与えて データベースに書き込みますていうことを この操作でやるということですねなので 細かいことを書いた方がミスは少ないん ですけれどもあんまり書かなくても動いて くれるっていうのがまやっぱりこう チャットGPTのうまいところかなという 風には思いますで最終的に帰ってきたこと としては今日のえおすすめ商品の値段は 100円ですとでデータベースに正常に 書き込まれましたっていうので データベースではないんですけどれも テキストファイルっていうものを中身見て みましょうと今日の日付2023年9月 30日でおすすめの商品Appleで最終 的に100円っていうのが書き込まれた ことが確認できましたとはいとても長く なってしまったんですけれどもこちらで テモは終わりとさせていただきたいと思い ますはい私の発表は以上となります ありがとうございました', metadata={'source': 'I2UZutRrtEE'})]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "youtube"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49be6780-6bf0-49fe-97f0-508d0ed54f17",
   "metadata": {},
   "source": [
    "## Summarize Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ba9ec2d6-b307-4b6b-b50c-e075e90f44ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.7, model=\"gpt-3.5-turbo-0613\")\n",
    "summarize_chain = load_summarize_chain(llm=llm, chain_type=\"refine\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3785ef37-94ef-4b45-9c64-4f52fc1b7006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RefineDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\"では早速なんですけれども始めさせて いただきます私からはラングチェイン エージェントを使って自社ツールと チャットGPTを連携するというタイトル で発表させていただきますChatGPT 自体は皆さんご存知のように非常に優れた 能力を持っていますが最新のデータに アクセスできないとか特定の数学的な推論 が得意でないなどいくつかの課題が存在し ますこれらの課題は自社プロダクトに チャートGPTを導入するなどチャット GPTを社会実装しようとした際に解決し なければなりません今回お伝えするラグ チェインエイジェントを導入すると ChatGPTと外部ツールをうまく連携 させることができるようになりChat GPTが抱える課題を克服しチットGPT の可能性をさらに広げることができます 本日はラングチェインエージェントをどう 活用することでチャットGPTの能力を 拡張できるのか具体的にご紹介していき ますそれでは始めていきますこちらが私の プロフィールとなります内容はいつもと 同じなのでスキップさせていただきます はいでは具体的な話に入る前にですね今回 のテーマの結論に先に触れておきます結論 なんですけれどもラグチェインには様々な エージェントの種類が存在するが自社 ツールとチャットGPTを効果的に連結 する際汎用的なエージェントタイプである ゼロショットリアクトまたはオAI ファンクションを利用することが簡単と なりますゼロショットリアクトとOpen AIファンクションを比較するとOpen AIファンクションの方がチットGPT からより適切かつ精度の高い答えを 引き出しやすくなっていますこちらはデモ のでお見せしますねでそしてえっとここで ChatGPTと自社ツール連携で非常に 重要となるものとしてツールの説明という ものがありますと通常のプロンプトチャト GPTを使う時のプロンプトと同様に ツールの特性や機能をChatGPTに 正確かつ効果的に伝えることで自社ツール とチャットGPTの連携の成功率が格段に 向上していきますこのポイントに着目し ながら具体的な方法論について今日は 深掘りしていきたいと思いますそれでは これらのポイントを年頭にきつつ今回の 発表をお聞きください本日の発表は以下の 3つのセクションから構成されています 初めにチットGPTの基本的な概要につい て触れます次にラングチェイン エイジェントの特徴について紹介し最後に デモンストレーションを行いますデモでは 特にツールの説明について着目して いただけると幸いですそれでは最初の トピックに移りましょうここではチット GPTの全体的な特徴を振り返っていき ますすでにご存知の内容も多いと思うん ですけれども一般的なはチャットGPTの 性質っていうものをご紹介していきます チットGPTは実用的な大規模言語モデル llmで現在多くのビジネスに活用されて きています例えばベネッセ ホールディングスでは車内AIChat ベネッセGPTを開発しグループ社員 1.5万人に向けて提供しているという ようなプレスを出していたりとか立メカ 大学では大学の英語事業において機械翻訳 とChatGPTを組み合わせたサービス が試験導入されているであったりとか他に も色々なサービスがチャトGPTを 組み込み始めておりChatGPTの実用 化っていうものがすごい勢いで広がってい ますChatGPTを活用する際によく 言われることとしてはチャットGPTから 良い結果回答を得るためには良い質問が 必要であるということですでこれは プロンプトエンジニアリングと呼ばれる 領域で今最も伸びている業種の1つと言え ますプロンプトエンジニアリングではどの ような項目をプロンプトに入れるべきか またプロンプトを複数回うまく使いこ なくして良い回答をるテクニックなどが 研究開発されていますリアクトであったり とかいろんなことを聞いたことあると思う んですけれどもプロンプトの種類っていう のがどんどんどんど開発されているという ことですでチャットGPTの活用は多に 渡っておりその可能性は広がりつつあり ますでプロンプトエンジニアリングの テクニックを活用することでチャット GPTとの適切なコミュニケーションが 可能になりますプロンプト エンジニアリングでは色々なテクニックが 存在するのですが今回はプロンプト エンジニアリング自体がメインのテーマで はないのでプロンプトエジライニングの中 で抑えるべき基本的な項目とそしてよく 使われるまフーショットプロンティングと 呼ばれるような手法を簡単にだけ紹介して いきますはいまず基礎として抑えていき たいこととしてプロンプトに何を与える べきかっていうものをいくつか紹介して いきますで1点目としては具体的で明確に 質問することですで例えばその日本の歴史 において重要な出来事は何ですかという 質問よりも日本の戦国時代における重要な 出来事について教えてくださいという具体 的に質問し方が的確なコ答が得られますと で2点目に状況やコンテクストを明示する ことですて背景情報があるとチャット GPTはコンテクストをより理解し適切な 回答が返ってきますとで3点目期待する 回答の形式を指定するとこれにより望む 情報が整理されて帰ってきますリスト形式 で返してくださいであったりとか ジェイソン形式で返してくださいであっ たりとかまそういうことを質問する時に プロンプトの中に入れるということですね で4点目範囲を限定すること範囲が広す すぎると回答も後半で一般的になりがちに なりますなので範囲を狭めるということが 重要となってきますで最後5点目自性や 認証を明確にすることですと例えば子供で も分かるようにしてくださいとか中学生で も分かるようにしてくださいとかなんか そういう風にどの視点で書て思ってみるか を示したりであったりとか何年の情報が 欲しいとかそういうことを指定することに よって回答が明確なものが帰ってきやすく なるということですで次にプロンティ テクニックの1つののフューショット プロンティについて簡単に説明します フューショットプロンティはモデルに少数 の例を示すことで特定のタスクの解決方法 を学習させるアプローチになりますこれに よりモデルは様々な問に対して適切な回答 を生成することができますここに例として 上げてるんですけれども例えばレストラン 最高でしたこれは感情ポジティブですこの 映画は本当に時間の無駄だった感情 ネガティブですというようにいくつかの例 を与えて出したいものでそれぞれの文に 対しての感情っていうものをこのように 並べていきますてで最後に聞きたいものと してそのサービスは非常に遅く不満ですっ ていうものがあった時にどんな感情で すかっていうことを聞くと感情ネガティブ という風に返ってくるというところですで こういう風にすることによってモデルって いうものが新しい文章がポジティブか ネガティブかっていうのをま過去の例を元 に判断することができるようになるという ことですでこの方法によってですねフュー ショットプロンティはモデルに多様な タスクを効率的に学習させることができ 柔軟な対応が可能になってくるということ でですでここまでいくつかのプロンティの テクニックであったりとかをお話ししてき ましたもちろん他にもたくさんあってです ねチェインオブソツであったりとかあと セルフアスクであったりとかいろんなもの があるんですけれども今回のメインテーマ ではないので一旦プロンティグの話はここ で終わりにしてでここでちょっと一息つい てですねこれらのテクニックが持つ限界に ついて考えてみましょうでまず1点目なん ですけれどもプロンプトのテクニックは 日々進化し開発されていますとこれによっ てチットGPTは多様なタスクや質問に 対応でできるようになってきていますただ 全ての作業やタスクをチャットGPTに 依存すること自体が現実的ではありません とえ例えば先ほどの例で出てきた文章から の感情抽出に関してはチャートGPTに 無理やりさせることが適切かと言われると そうでもないかもしれないAWSコプリン のような勘定分析に特化した学習をして いるAPIっていうものがあってそれを 使った方がいい結果が返ってくるかもしれ ませんっていうのがまず1つ目ですねで次 に2点目としてそのChatGPTが持つ 情報っていうものは訓練データに限定され ていてチットGPTはそれ以外のデータに ついては知らないというところですなので えっとチャットGPTは過去のデータで 学習されておりその学習データ以降に出て きた情報に関してはチットGPTに尋ね られませんとよく言われるものとしては 2021年のデータですかねまでのデータ で学習してるので例えば2022年であっ たりとか2023年のデータについて聞い たとしてもチャットGPTがうまく答え られないというようなところですね最新の 価格的な研究であったりとかニュース記事 とか特定の地域の天気情報であったりとか チットGPTの訓練データに含まれてい ないような情報っていうものはChat GPTだけでは取得できませんし インターネットにあるデータだけではなく て例えば今回のテーマである自社のツール と連携するっていう時のためには自社の データを使いたいみたいな話とかあると 思うんですけれども自社データについては チャットGPTが知るわけもないという ことでえっとChatGPTに自社の データについて聞いたとしてもChat GPTはもちろん答えることができません とこれらのチャGPTの限界を理解する ことでチットGPTの適切な使用方法で あったりとかそれらをどのようなシナリオ で活用するべきかっていうのが見えてくる ということですねでChatgpdの概要 の最後なんですけれどもChatgpdや その他大記号言語モデルllm自体の課題 をこちらにまとめますでまず1点目なん ですけれども先ほどと被るんですが ChatGPTは最新の情報にアクセスが できないと例えば為替や株価のように国 一刻と変化していく情報に対してチト GPTははリアルタイムで対応することが できませんで2つ目の課題としては ChatGPTが独自の情報源にアクセス する能力を持たないということです企業の データベースに保存されている顧客名簿で あったりとか特定のプライベートな情報に はアクセスすることができませんで3つ目 に水論の正確性に課題があるというところ ですチャットGPTは時折り簡単な算術 計算でさえも間違えることがありますこれ は特に正確な情報や結果が求められる タスクにおいて大きな問題となりますねで そして最後にチャットgpdができない こととかのデータが足りないんだったら ファインチューニングすればいいんじゃ ないかっていうような意見もあると思うん ですけれどもファインチューニングする ことによって汎用性が劣化してしまうと いうことがありますとでChatGPTを 特定のタスク例えば自社データを食わせる であったりとか特定のタスクに特化した データを食わせてファインチューニング すると他の多様なタスクに対する性能が 低下すると言われていますでこれらの課題 を解決するための1つの手段として今回お 話しするラングチェインエージェントって いうものがありますでここここからは ラングチェインエイジェントを使って チットGPTの性能を生かしつつ苦手な ものは他のツールで解決していくっていう ことについてお話ししていきますで参考 までにですねここにバッと上げている課題 に関してはMrKLシステムズていう有名 な論文があってそ論文から引っ張ってきた ものとなりますMrKLシステムズって いうのはミラクルシステムズと呼ぶもので チャットGPTと他のツールを連携して どんどんどんどん課題を解いていくって いうことを提示しているロムとなってい ますそれではラングチェインエージェント についてのトピックに移っていきますまず ラングチェインエージェントの前にですね ラングチェインとは何かと言うとラング チェインとは言語モデルを利用する アプリケーションのためのフレームワーク ですでラングチェインについては前回の 勉強会でもご紹介しているので基礎的な 内容を知りたい方はYouTubeで前回 の勉強会の動画をご覧くださいでラング チェインエージェントはラングチェインの 中の1つの機能なんですけれどもラング チェインの中でも非常に面白くて重要な 役割を果していますランチェの主なタスク は次にどんなアクションを取るべきかを大 記号言語モデルllmに決定させそれを 実行するということですで具体的な プロセスは以下の通りですとまず各ツール ができることと質問を指定したレスポンス のフォーマットでllmに送信します聞き ますとチットGPTなどのllmに聞き ますそしてllmChatGPTから帰っ てきたレスポンスをパースして次の アクションを決めるということをしますで このプロセスによってラングチェインジと はユーザーの4級に応じて効率的かつ正確 なアクションを実行できるようになって いるというところですでここでラング チェインエージェントがどのように動く かっていうもののイメージを具体的な例と して1つ持ってきましたま正確に正しい 動き方をしてるわけではないんですけれど も大体こういうような動きをするんだよっ ていうこともご理解ください例えばチット GPTに対してコミュニケーションを取る のがラングチェインのエージェントとなる んですけれどもラングチェイン エージェントにですねまずこう今日東京で で出かける時時に適切な服装は何ですかて いうのを聞きますでそうするとラング チェインエージェントが聞きたい内容今日 東京で出かける時に適切な服装っていう ものとあと自分が持っているツールって いうものをプロンプトに入れてチャット GPTに聞いてくれますとで自分が持っ てるツールっていうものは例えば Google検索のツールっていうも持っ てますとGoogle検索のツールでは 最新の情報を引っ張ってくることができ ますと私が持ってるのはGoogle検索 のツールで最新の情報が引っ張ってこれ ますそしてで今回聞質問としては東京で 出かける時に適切な服装って何でかていう ものを聞きますとでその時にチャット GPTはどのように返してくるかというと でまずは検索ツールでインプットは東京の 気温っっていうもので調べなさいっていう ものをエージェントの方に返してきますで エージェントはチャットGPTからから 教えてもらったじゃあえ検索ツールを使え ばいいのかっていうところで検索ツールを 使おうとしますでインプットとしては チャトGPTが教えてくれたように東京の 気温っていうものをインプットとして入れ てで検索ツールから帰ってきた22度って いうものを変してもらいますとでそして またえっとチャットGPTにえこのツール に入れた答えってものが22°でした次何 すればいいんですかであったりとか最終的 にどうなんですすかっていうのをチャット GPTに聞いてチャットGPTが十分な 情報を得たっていう風に判断するとでは 22°なので薄の長袖でがいいでしょうっ ていうものをエージェントとしに返してで あとはえ答えとしてラングチェインの エージェントが東京は22度なので素の 長袖でがいいでしょうっていうものをその まま返してくるというような流れになり ます特徴的なものとしてはチャットGPT だと今日の天気であったりとか東京の天気 であったりていうものは取れないんですね でそこをGoogle検索のツールって いうものを利用することによって新しい データっていうのを取れるようにしてると いうところですねもう1つ押えておきたい こととしてはこの問を解く時に自分が持っ ているツールっていうもの一覧を渡して どのツールを使えばいいかっていうのこと 自体もチャットGPTに判断してもらうっ ていうところが面白いところとなってい ますはいでこれがラングチェイン エージェントリアクトフレームワークとか 呼ばれたりするようなやり方ですねはい これらのこと全部ラングチェインの エージェントがやってくれるというところ ですでラングチェインエージェントって いうものは様々なタイプのエージェントが 用意されていますとここでエージェントの タイプっていうものを紹介するんです けれども解きたい課題に応じて エージェントを使い分けることによって 精度の高い回答を得られるようになると いうことですここで6個ほど上げています でまず1番汎用的なものとしてはゼロ ショットリアクトエージェントというもの ですでこのエージェントはリアクト フレームワークを利用してツールの説明に 基づいてどのツールを使用すべきか判断し ます先ほどの例で出てきたものと同じです ねこれによって特定のトレーニングデータ なしで多様なツールの適切なこう利用が 可能になってきます次にストラクチャード インプットリアクタエージェントですで このエージェントは複数の入力を使う エージェントを活用することができますで これによってより複雑なツールの理由用が 簡単になりタスクの効率が向上しますと 続いてOpenAIファンクション エージェントですこのエージェントはオ AIのファンクションコーリングの機能を 使っており関数が呼び出されるタイミング であったりとかを検出したりとか適切な 入力を関数に渡すような微調整がえオープ AI自体チットGPT自体がされていて それを使うことができますとOpenAI のえファンクションコーリングこの エージェントが使うOpenAIの ファンクションコーリングについてはこの 後のスライドでもう少し詳しく説明します で次にコンバーションエージェントですで このエージェントは会話での使用目的とし て設計されています何かを聞いて何か答え を出すっていうようなま単純なチャット GPTで何かこう答えを作ってくださいと かそういうのとは違くて会話的な インタラクションを通じて効果的な コミュニケーションを可能にするような エージェントとなっていますそして次に あげるものとしてはセルフアクwith sarchエージェントですねでそこの エージェントはですねセルフアクという 質問を自問自としながら分割することに よって正しい解を導き出す方法を使って 情報を検索するエージェントですセルフア クっていうプロンティグの技術があるん ですねまそれを使ってちゃんとした正しい 答えを導き出すエージェントとなってい ますで最後に紹介するものがリアクト ドキュメントストアエージェントですで このエージェントはドックストア ドキュメントストアですねと対話するため にリアクトフレームワークを使用してき ますえこれによって文書の管理であったり とか検索が一元化されて効率的に情報 アクセスが可能となりますこちらに関して はまた今後の勉強会でも取り扱っていき たいかなという風に思ってるんですけれど も文書検索管理っていうものに特化した エージェントとなっていますで以上がラン チェインエージェントの各エージェントの 使用となりますでそれぞれのタイプが 異なるシナリオやタスクに適しており ラングチェインの柔軟性と多様性を象徴し ているものとなります今回のセッションで はですね最も汎用的なゼロショット リアクトとチャットGPT自体に色々判断 させるファンクションコーリングを使った オープAIファンクション2を利用して いき ますでは先ほど説明を省いてしまったん ですけれどもOpenAIファンクション コーリンググっていうのはOpenAI ファンクションコーリングじゃないですね OpenAIファンクションですね OpenAIファンクションとは何か エージェントタイプの1つであるOpen AIファンクションとは何かについてお 話ししますこちらはChatGPTを提供 しているOpenAIのファンクション コーリングという機能を利用していますで ファンクションコーリングっていうものは 2023年の6月にリリースされた機能で ラングチェインエージェントが担っていっ たツールを渡してチャットGPTに聞いて 次のステップを決定するやり取りってい ものをチットGPT自体が行えるように ファインチューニングされているものと なりますでこの機能では東京の天気を教え てくれというような先ほどと同じように ですね質問と共にどういう関数を持って いるのかその関数の説明をチトGPTに 直接投げるということをやりますなので 先ほどのラングチェインエイジェントが やってることと同じようなことをやれる ようになっていてチットGPTが ファンクションをどのように受け取るのか そのファンクションのパラメータであっ たりとか説明とかをよりチャトGPTが 理解しやすいようにAPIとして受け取る ことができるようになっているのでより 適切な判断をチャットGPTがしやすく なっているというところがメリットとなり ますなので今メリットをお話ししてしまっ たんですけれどもファンクション コーリングを使うメリットとしては ChatGPTにツールの挙動をより正確 に伝えやすくなっているというところで これによってChatGPTが機能の ツールのえファンクションの使用や動作を より正確に理解しやすくなっていて適切な 判断をしやすくなっているとていうのとで もう1つのメリットとしてはチャット GPTっていうものがラングチェイン エージェンドって元々チャットGPTが 返してきた個体を利用者が頑張って定期 表現を使って解析する必要があったんです がそれをする必要がなくなったっていう ところが利点としてありますとでチャット GPTが実際にラングチェインを使って どのツールを使えばいいですかていうのを 聞くんですけどそれをどのようにパースし てるかというとこのように頑張ってですね えっとレギュラーエクスプレッションを 使って正規表現を使ってパースしたりとか して次のアクションを決めてたりするって いうのがラングチェが今までやっていた ことであるとでこういうパースをしなきゃ いけないっていうことをしなくて済む つまりパースしなきゃいけなかったので今 まではそのパースすることでえっとうまく パースできなくてミスってしまうっていう こともあったんですけどそういうことが なくなるっていうことが期待されるという ところです はいはいちょっと駆け足になってしまった んですがここまでで20分ぐらいかかって しまいましたねえここからがレモに入り ますで実際にですねラングチェイン エージェントを使ってチャトGPTと自社 ツールを連結するような感じのえデモって いうものをお見せしていきますで使う エージェントとしてはゼロショット リアクトとオーエファンクションを使って いきますであとは今回のプレゼンの冒頭の 方でもお話ししたようにChatGPTに ツールの説明をどのように渡せばいいのか であったりとかその辺りを持ち替えて いただければ幸いです はいではではやっていきますちょっと時間 がなくなってきたので駆け足でいきますね でまずは設定ファイル読んでいきますこれ 何をやってるかと言うとえOpenAIの APIキーであったりとかを読んでいます でまずはですねえっとゼロショットの方を 見せしていきたいんですがおマジないとし てですねおじないというかま前回の勉強会 と同じようにですねラングチェイン エージェントを使うためのやり方をお見せ していきますで実際今回使うモデルとして はチットOpenAPAIというか ChatGPTのえGPT3.5のtbo 0613というものを使っていきますで 外部のツールとしてはGoogleサーチ のAPIっていうものを今回用意しました ここであのサプAPIっていうものを書い ているものがえGoogleのAPIと なりますで聞きたい質問としては今日の 東京と北海道の天気を調べて東京から 北海道の出張で来ていくべきを教えて くださいっていうものを聞きたいと思い ますでラングチェインエージェント自体を 走らせてみますでこれがゼロショット リアクトエージェントを使った場合どの ようになるかっていうのをお見せしますで エージェントタイプに関しては イニシャライズエージェントの エージェントっていうえ引数に対して エージェントタイプのこのゼロショット リアクトディスクリプションていうものを 渡すとエージェントを選択することができ ますちなみになんですけれどもえこれって ただあの文字列が返ってくるだけですかね あのゼロショットリアクト ディスクリプションていうものが返って くるだけのものになりますなので文字列で 与えても同じですはいでは実行してみ ましょうチトgpdはもちろん今日の天気 とか今日の東京とか北海道の天気っていう のは知らないので来ていくべき服装って いうことは分からないわけですね気温も 分からないのででこれでラングチェイン エージェントが私はGoogle検索の ツールを持ってますよでそれを使って使う ことができますでこの問題課題っていう ものを解くためにはどうすればいいですか てのを聞くっていうことですねでここで ざーっと出てきてるんですけれども実際に 書いてきた答えとしてはtheWisto isCloudyaboutcrear withtempof歌詞になっちゃって ますけどまこのように帰ってきますと 英語で帰ってきちゃってますねでこういう 風にえどんなアドレスをれ切ればいい かっていうものがちゃんと帰ってきてい ますと前にやった時はそんなに綺麗に帰っ てきてなかったんですけれども今回は うまく帰ってきていますはいこちらがゼロ ショットリアクトディスクリプションで やった場合の結果になりますでどういう ことをやってるかっていうのなこの辺りを 見ていただくといいのかなという風には 思いますでチットGPTにまずラング チェインエージェントが問題とツールを 渡してチットGPTに何をすればいい かっていうのを聞きますでチャットGPT から帰ってきた答えとしては次の アクションとしてはサーチをしてください ですサーチのインプットとしてはウザー 東京todayていうものを渡してくださ いっていうのを渡してますで次の アクションとしてはサーチをしてください でそのインプットとしてはウザ北海道 todayていうものを渡すようにして くださいとで最終的にその帰ってきた答 っていうものをチャットGPTに渡して 最終的な文が出てくるということですはい でこれが1つ目ですねアエージェント タイプ1つ目のえゼロショットリアクト ディスクリプションで元々ラングチェイン エイジェントがリアクトフレームワークで ツールを渡したりとかしてチャットGPT とうまく連携しながら外部ツールを使う ようにしたえ機能となっていますでこれが ですねえ最近出てきた6月にリリースされ たOpenAIのファンクションコーリン グっていうものを使うとどうなるかって いうのをお見せします はいでOpenAIファンクション OpenAIのファンクションコーリング を使うためにはエージェントタイプの OpenAIファンクションズっていう ものを渡しますでそうするとえこのように 動きますで実際にやってることとしては ラングチェインエージェントがOpen AIのファンクションコーリングっていう ものを使ってうまくチャットGPTと やり取りしながら答えを導き出していくっ ていうことをやっていますはい出てきた 答えはこちらですねで同じようにですね どのようにやっているかっていうものは ここら辺の途中で出てきているんです けれども途中結果でえサーチとしてはえ クエリー東京の今日の天気っていうものを 調べてくださいでサーチっていうツルを 使って今日の北海道今日の天気っていう ものを調べてくださいでこれらが帰ってき た答えっていうものをえチャットGPTに 返してチャトGPTがその与えられた情報 を元に東京の今日の天気は曇りですが後に は晴れる予報ですで気温は接し30°歌 86°でコス確率はどうのこうのっていう ものがあってであとは東京は暑くなる可能 性があるので軽い服装が適しています ただし北海道は比較的涼しいので ジャケットなどを持っていくことがお勧め しますというような感じに帰ってきてます ま見て分かると思うんですけれどもま日本 語にな質問が日本語だったので日本語で ちゃんと返してくれるっていうのは もちろんのことなんですけれども書いてき た答えっていうものに関してより詳しく 返してくれているっていうことが分かると 思いますなので使ってみた所管としては ですねここで言うオAIファンクションの ファンクションコーリングっていうのの ファンクションっていうのはラング チェインエージェントでいうツールと同じ なんですけれどもそのファンクションで あったりとかツールを渡す時にですね渡し て何かを判断判させたいチャットGPTに 判断してもらいたいっていう時はえ エージェントタイプゼロショットリアクト ディスクリプションよりもエージェント タイプオAIファンクションの方がより いい結果が返ってきやすいっていうことが 分かると思い ますもう少しあの詳しく見ていきます ちなみにですねOpenAIにどんな ファンクションを渡してるかっていうのは イニシャライズエージェントのところで エージェントを定義してるんですけども そのエージェントの中からエージェントっ ていうものとファンクションズってものを 実行するとどんなえファンクションが渡さ れてかっていうのを見ることができますで 今回渡されたファンクションっていうのは ネームサーチっていうファンクションが 渡されていてどんなことができるかって いうのでサチエンジンですっていうような ものをやってますであとはパラメーターと してはこういうものを渡していきますって いうのが分かりますとはいでここまでが 基本的なラングチェインエージェントを 使って外部ツールを連携するっていうお話 をしてきましたとで次にですねえ自社で 作ったツールっていうものを連携させ るっていところについてお見せしていき ますで一旦はですねレコメンドアイテムっ ていうものを考えてみようと思いますで ここ何をやりたいかって言うとレコメンド アイテムまこの中身はほとんど意味のない ものになってるんですけれどもレコメンド アイテムっていう関数を自社で持っていて でレコメンドアイテムっていうものは自社 のデータベースなどにアクセスして日付を 持ったにこの日のレコメンドっていうもの はこういうものですっていうものを返す ような関数っていうところになりますとな のでえっとこのレコメンドアイテムって いうところをこの関数ををえChat GPTのフローの中に組み込みたいって いうことをやっていきますでどのように ラングチェインエージェントを使って ChatGPTに連携すればいいかという とツールっていうものにえ変換していく 必要がありますとでレコメンドアイテム ツールっていうものをえツールfrom ファンクションズっていうものを使って どのようなファンクションを実行したい ですかレコメンドアイテムっていう ファンクションを実行したいですまこう いう風にですねこの今回のあまり意味の ないファンクションなんですけれどもこれ を実行しますとでツールの名前としてはえ レコメンドアイテムっていうものを渡し ますでツールのディスクリプション何を やってくれるかっていうことに関してはお すめの商品を教えてくれますっていうのを ツールとして定義するというところです はいでこれをちょっとツールズっていうま ツールまとめて渡さないといけないで ツールの配列の中に入れておきます実際に ですねラングチェインエージェントにどの ようにツールを渡せばいいかっていうとま 先ほどもカラっとやってたんですけれども このツール1覧っていうのを最初に渡して 引数として渡しているのでまこのようにし てどんなツールが使えるかっていうものを ラングチェインのAに渡しでチャット GPTと連携していきますはいでえっと 今回聞きたいこととしてはえおすすめの 商品を教えてくださいっていうものを投げ てみようと思いますで使うエージェントと しては先ほどゼロシトリアクトよりもより いい結果が返ってきたオーエ ファンクションズってものを選びます はいはいでは実行し ますはいで書いてきたものとしてはですね コメドアイテムってものが実行されて withファッションという謎のものをえ 入力に入れてで実際この引数がですね デートの中にファッションが入ってで プリントファッションっていうところでこ でファッションが出てきてしまってるとで ただおすめの商品は今回レコメンド アイテムで書いてきたAppleですって いうのが書いてきてることが分かると思い ますはい見て分かるようにですねなんか よくわからない引数は与えてしまってる なっていうところがありますでこを どんどん解決していこうと思いますで次に やることとしては今回なんでこのように変 なファッションとかいう引数を与えて しまったかというと引数に関する情報が ないんですね与えられてないというところ になりますとなので引数何与えればいいん ですかみたいなところが情報としてないが ゆえにチャットGPTもレコメンド アイテムを使うことは分かるとレコメンド アイテムを使えばいいのは分かるんだけど レコメンドアイテムに対してちょっと 分からないからカテゴリー情報でも渡して みようかなっていうのでファッションを 渡してしまっているというような状態に なりますで例えばまファンクションを見た としても今回使ってるファンクションに 関してはレコメンドアイテムでおすめの 商品を教えてくれますでパラメーターの 情報は全くありませんっていう状態なので どんなパラメーターを渡せばいいかって いうのはオープAIファンクションは 分からないというところですねじゃあこれ に対してどうすればいいかっていうのをお 見せしますでえっと結構簡単でしてパダ ティックっていうものをご存知ですかね こう最近えっとファストAPIとかですか ねこう結構パであったりとかそのヒントを 与えるっていうことがまPython主流 になってきてると思うんですけれども フダンティックを使っていきますでえっと ご注意していただきたいこととしては ファインディッてもうV2が出てるんです けれどもV2を使うとラングチェイン エージェントを動きませんとなので パティックV1を指定して方に関する情報 をえ与えるためのそのベイスモデルとか フィールドを使ってえやっていきますで これ何をやってるかと言うとま今回の インプットに対してデイトっていうものが ありますがデイトていうものはお勧めした 商品を絞るために使われる日付ですって いうものを与えていますこれをえっと アーグススキーマ先ほどのツールを定義 する時にアグススキーマっていう引きを 使ってこのレコメンドアイテムインットっ ていうベースモデルから継承した レコメンドアイテムインプットっていう インプットの報引数の情報を持ったクラ スっていうものを渡すということをします とでこうするとどうなるかっていうのをお 見せしていき ますはいじゃあどう変わる かいきますはい実行します全く同じですね 実行するものとしてはで今回はレコメンド アイテムっていうものに対して先ほどと 同じレコメンドアイテムっていうものが 選ばれましたとコアイテムに対してデイト が2020年の12月1日っていうものを 渡しているっていうことが分かりますで それによってですね気付がちゃんと渡して くれたっていうことがわか分かるわけです ねで今回あのここであのデートっていう ものはディスクリプションでお勧めしたい 商品を絞るために使われる日付っていう ことを伝えたのでチャットGPTの方があ これは日付のことなんだっていうところで 引数はファッションのようなカテゴリーを 渡すんではなくてデートの引数っていう ものを渡すことができてるというところ ですはいでこちらがデトのまあ2022年 の12月1日もはや日付が意味が分から ないですけれどもこういうものが渡されて いるというところですねでおすめ商品は Appleですという風にでこういう風に ですねこうツールの説明をどんどん どんどん入れていってええ解決していく 必要があるというところですねで同じよう にですねちょっとエージェントの ファンクションがどのように渡されるてる かっていうのをお見せしますとで今回渡さ れたのはレコメンドアイテムインプトって いうのをえパイダンテックの方で定義して 渡しているのでえ実際にえっと ファンクションOpenAIのえ ファンクションコーリングにどのように 渡されてるかというとパラメーターとして ですねこういう風なレコメンドアイテム インプットっていうものが渡されていて プロパティとしてはデートがあってデー トっていうのはお勧めしたい商品を絞る ために使われる日付っていうものが入れ られてえ飛ばされてるということが分かる と思いますはい で他にはですねこのようにツールフロン ファンクションで作るっていうこともある んですけれども同じようにですね デコレーターを使うっていうこともでき ますとデコレーターの方が結構シンプルに 書けるので私は結構デコレーターを使って 書くことが多いですとでデコレーター何を すればいいかというとデコターっていうの はま関数の前にですねアマークツールなん ちゃらかんちゃらっていうものがあってで それを使ってえっとこのツールってのは何 ができるかっていうものをえドッ ストリングで与えるんですねな先ほどと 同じにするとレコメンドアイテムツールっ ていうものがあったら中身は同じですね プリントデイトとAppっていうものを 返しますとプリントデイトしてApple っていうものを返しますとででやることと してはおすめ商品を教えてくれます全く 同じ内容ですねでこのツールの名前って いうものはデコレーターの引数として レコメンドアイテムとして渡していると いうところですで同じようにですね ツールズの一覧として入れてでこれをえ 実行してみ ましょうはいこれデコレーター使った場合 です ね実行するものは全部同じですで同じよう にこれも実行できますという風にデコレー ターってかなりこうシンプルにかけてで ファンクションの中のドックストリングス とかを使ってくれるので結構あの家読性と かもう悪くないかなという風には思います 先ほどと同じようにですねこレコメンド アイテムってものはちゃんと選んでくれた んですけれどもレコメンドアイテムに渡し ているデートっていうのは2021年10 月15日という意味の分からない日付を 渡してしまっていますとこれはなぜかと言 とまもちろんそのおすすめ商品を教えて くださいって言ってるので勝手に日付を 決めて聞いてしまっているというところ ですね はいでデコレーターの方もですね同じよう にファンクションを見てみるとえっとこう いう風になるという感じですねただあの 先ほどと同じようにですねパダンティック とか使っていないのでプロパティの パラメーターとかは適当になってしまって いるというような感じになりますただ今回 の場合はですねこうデコレーターの場合は フロムファンクションの方を使ったこっち の場合ですねこのフロムファンクションを 使った時と違ってきちんとデートを入れて くれているっていうことが特徴的かなと いう風には思いますフロンファンクション を使った場合っていうのはパダンティック を渡さないとデートっていうものに対して ファッションを入れたりとかよく分から ないものを入れたりすることがあったと 思うんですけれどもデコレーターを使った 場合はこのデートっていうものを渡した時 にきちんとこうデートを返してくれるよう な情報っていうものを渡せてくれている ような感じですねいずれにせを正しい共同 を求めるためにはこのままあまり情報を 与えないで実行するってのは適切ではない ので特に自社ツールサービスとして提供 する側としてはですねなのでそういう意味 ではきちんとバイダンティックなどを使っ て適切な情報を渡しながら関数っていう ものを渡していく必要があるかなという風 に思いますなのでえっと先ほどと同じよう にですねデコレーターを使った場合も パイナティックの情報っていうものを渡す ことができるのでデコレーターの引き数に アーグススキーマていうものを渡してで そのパイランティックの情報を渡すことで 適切な答えを返すことができるようになる というところです同じようにですねま結果 も変わらないので はいまこういう風に変えてきました ちょっと答えがどんどんどんどん変わって きてますApple製品だったりとか AppleStoreとかオンライン ショップとかうんまここら辺に関しては 本当に適切な答えがまだ返ってきてない なっていうような状態だとは思います エージェントのファンクションを見るとえ きちんとファナティックで渡した情報って いうのが渡っていることが分かると思い ますこのようにですねこのデートっていう ものはデートっていう引き数はお勧めし たい商品を絞るために使われる日付ですっ ていうのが渡っているというところです もう少しですね今までこうおすめの商品を 教えてくださいっていう風に言っていたの でデートっていうものが1月10日であっ たりとかよくわかんない日付になっていた のではないかっていうことを推測してでは 昨日のおすすめ商品を教えてくださいって いうものを聞いてみますてそうするとどう なるかと言うとえ昨日のおすめ商品を教え てくださいって言ってるのにレコメンド アイテムに渡されてるのは2021の10 月20日っていうものが渡されれてること が分かりますとチャットGPTにこう昨日 とか今日とか昨日とか渡したら日付を ちゃんと入れてくれるのかなと期待するっ ていうことがあると思うんですけれども 実際はそんな入れてくれないっていうこと がまこの結果から分かるということですね もう少し例えばディスクリプションとかを 適切にすればうまくいくのかもしれないん ですけど今回は違う手段でえっと解決 しようと思いますで今回どういう風に解決 するかと言うとデートタイムを使って 新しい日付けを取得するような関数自社 ツールってものを設けようと思います ゲットデートっていうツールっていうもの を作ってでそのツールは何をするかという とま今日や昨日など日付を取得する時に 使います引き数には今日を起点として何日 か前をNで与えますとでここのそのドック ストリングスにですねこう引数に関する 情報を書いてるんですけども実際はですね パダンティックで引き数の説明した方が ベタだとは思いますただえっとドック スリンに書いてツールの説明として与える だけでも結構チャットGPTは賢いので うまく判断してくれるということですでお 見せしますはいこの日付関数を入れると どうなるかと言うとこういう風な感じです ねはい今日のおすめの商品を教えてくださ いっていう風にするとtodayて書い てき来てこれもうまく動いてないですね こういうことが結構ありますとうまく動か ないことがあるとでもう1回実行してみ ましょうかはいでもならではですね ちょっと30分で終える予定が46分に なってしまったんですがもう少しで終わる ので続けます前回のやつだとですね直接 レコメンドアイテムを呼び出してデートに 対してtoデイていうものを渡してしまっ てたんですけれども今回はうまく動いてい てまずは日付を取得するためにゲットデイ トっていうものを呼び出しますとで今日な ので今日からの起点のえN日前だったらN に0を渡せばいいということが分かるとだ からゲットデートに0を渡して帰ってきた ものが2023年の9月30日っていう ものが帰ってきてで9月30日のえお勧め 商品は何ですがま書いてくるものは全部 AppleなのでAppleってものが 帰ってきてることが分かると思います同じ ようにですねじゃあどういう ファンクションが渡されてたかっていうの をお見せするとサクっとですねで今回あの ファンクション2つ渡されていて レコメンドアイテムっていう ファンクションとゲットデイトっていう ファンクションが渡されていますで それぞれのファンクションの説明がこの ように与えられているということが分かり ますもう少しツールを複雑にしていって ですね奇数日だったらオレンジ偶数日だっ たらえAppleっていうものを返すよう なツールにちょっとだけレコメンド アイテムを変えみようと思い ますはいではえこれを実行するとですね 今日はえ9月30日なのでもちろん9月 30日偶数日ですね偶数日なので Appleが返ってくるきちんと帰ってき ますねAppleが帰ってきましたでは 昨日の場合はどうなのか 昨日はい昨日の場合は29日なので1日前 ってものをゲットデイトで取得して29日 ってものが書いていますで29日を使って え昨日のおすめ商品オレンジっていうもの を取ることができるというところ ですやとうまく動きました ねでもう少しだけちょっと時間が1時間 ぐらい喋ってしまうような感になるんです けれどもう少しだけお話させてくださいで これだけだともちろんまだまだ連携が 少ないかなっていうところがあってで次に じゃあAppleだったら100円 オレンジだったら200円っていうような ものを商品の値段を返すような関数って いうものを組み込んでみましょうでツール としては元々グビだったらAppleキビ だったらオレンジを返すようなものとあと は日付を取得するツールであとは今回定義 したAppleとオレンジAppleだっ たら100円オレンジだったら200円 っていうのを返すツールっていうものを 定義しますでこれでエージェントのですね おすめの商品の値段まで教えてくださいっ ていうことをやるとそうするとまず最初に え昨日なのでゲットデートでN=1を渡し て1日前のデートを取ってきますで9月 29日ですで次にレコメンドアイテムって いうツールを呼び出してレコメンド アイテムにえ9月29日を渡してで最後に ですねアイテムプライスっていうので アイテムネームをえオレンジにとして渡し てでオレンジはは200円なのでえ昨日の おすめ商品であるオレンジの値段は 200円ですっていう最終的な答えが返っ てきましたというところになりますだいぶ 柔軟なものができるようになってきたって いうことが理解できると思いますで他には ですね最後なんですけれども取得した結果 を吐き出したいとかデータベースに 書き込みたいとかあったりすると思うん ですけどもそういうことももちろん簡単に できますと基本的にはファンクションが あってそのファンクション中身は自分で 書いていくので何でもすることができると いうところですねちょっとあの output.tchっていうところに 書き込むようなものを記事的にですね データベースに書き込んでいるようなもの として紹介しようと思いますで今回は さらに追加するツールとしてはですね セーブデータっていうツールを追加します とセーブデータっていうものは何なのかと いうとここにも説明書いてあるんです けれども日付と商品名と商品の値段を 受け取ってデータベースに書き込みますっ ていうようなものをツールとして作りまし たデータベースといながらもアウトプット テキストにただ書き込むだけのものになる んですけどもデートアイテムネーム アイテムプライスを書き込むだけのツール となりますま実際に自社ツールを使う時に はここにSQL分であったりとかを書いて データベスに書き込むとかをやったりする ことになると思いますこちらもですね ちょっと簡易的にですねフダンティックを 使わずにえドックストリングだけで何を やるかってのを渡して書き込めるかどう かってのをお見せしていこうと思いますで 同様にですね同じように何をしたいかと 言うと今日のおすめ商品の値段を調べて データベースに書き込んでくださいって いうことを実行し ますで最初に動くものとしてはまず日付を 取得するゲットデイトが動いてN=0で 今日の日付を取ります9月30日ですと9 月30日が取れたら9月30日の レコメンドアイテムは何ですかていうので レコメンドアイテムのツールを起動して 書いてきたものがAppleですとであ次 にやることしてはAppleの値段は いくらですかていうものをアイテム プライスに聞いてアイテムプライスが返し てきた答えが100円ですとで100円 っっていうものをえセーブデータに渡して セーブデータに渡すものとしてはデートと アイテムネームとアイテムプライスこれは 日付と商品目と商品の値段を受け取 りっていう風に書いてあるのでこういう ようなものを基数として与えて データベースに書き込みますていうことを この操作でやるということですねなので 細かいことを書いた方がミスは少ないん ですけれどもあんまり書かなくても動いて くれるっていうのがまやっぱりこう チャットGPTのうまいところかなという 風には思いますで最終的に帰ってきたこと としては今日のえおすすめ商品の値段は 100円ですとでデータベースに正常に 書き込まれましたっていうので データベースではないんですけどれも テキストファイルっていうものを中身見て みましょうと今日の日付2023年9月 30日でおすすめの商品Appleで最終 的に100円っていうのが書き込まれた ことが確認できましたとはいとても長く なってしまったんですけれどもこちらで テモは終わりとさせていただきたいと思い ますはい私の発表は以上となります ありがとうございました\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001b[0m\n"
     ]
    },
    {
     "ename": "InvalidRequestError",
     "evalue": "This model's maximum context length is 4097 tokens. However, your messages resulted in 19305 tokens. Please reduce the length of the messages.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msummarize_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[43myoutube\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/lib/python3.11/site-packages/langchain/chains/base.py:292\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    291\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 292\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    293\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    294\u001b[0m final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[1;32m    295\u001b[0m     inputs, outputs, return_only_outputs\n\u001b[1;32m    296\u001b[0m )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/lib/python3.11/site-packages/langchain/chains/base.py:286\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    279\u001b[0m run_manager \u001b[38;5;241m=\u001b[39m callback_manager\u001b[38;5;241m.\u001b[39mon_chain_start(\n\u001b[1;32m    280\u001b[0m     dumpd(\u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    281\u001b[0m     inputs,\n\u001b[1;32m    282\u001b[0m     name\u001b[38;5;241m=\u001b[39mrun_name,\n\u001b[1;32m    283\u001b[0m )\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    285\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 286\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    287\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    288\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[1;32m    289\u001b[0m     )\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    291\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/lib/python3.11/site-packages/langchain/chains/combine_documents/base.py:105\u001b[0m, in \u001b[0;36mBaseCombineDocumentsChain._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;66;03m# Other keys are assumed to be needed for LLM prediction\u001b[39;00m\n\u001b[1;32m    104\u001b[0m other_keys \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m inputs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_key}\n\u001b[0;32m--> 105\u001b[0m output, extra_return_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcombine_docs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_run_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mother_keys\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m extra_return_dict[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_key] \u001b[38;5;241m=\u001b[39m output\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m extra_return_dict\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/lib/python3.11/site-packages/langchain/chains/combine_documents/refine.py:151\u001b[0m, in \u001b[0;36mRefineDocumentsChain.combine_docs\u001b[0;34m(self, docs, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Combine by mapping first chain over all, then stuffing into final chain.\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \n\u001b[1;32m    140\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;124;03m    element returned is a dictionary of other keys to return.\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    150\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_initial_inputs(docs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 151\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitial_llm_chain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    152\u001b[0m refine_steps \u001b[38;5;241m=\u001b[39m [res]\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m docs[\u001b[38;5;241m1\u001b[39m:]:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/lib/python3.11/site-packages/langchain/chains/llm.py:257\u001b[0m, in \u001b[0;36mLLMChain.predict\u001b[0;34m(self, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, callbacks: Callbacks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m    243\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Format prompt with kwargs and pass to LLM.\u001b[39;00m\n\u001b[1;32m    244\u001b[0m \n\u001b[1;32m    245\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;124;03m            completion = llm.predict(adjective=\"funny\")\u001b[39;00m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 257\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_key]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/lib/python3.11/site-packages/langchain/chains/base.py:292\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    291\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 292\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    293\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    294\u001b[0m final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[1;32m    295\u001b[0m     inputs, outputs, return_only_outputs\n\u001b[1;32m    296\u001b[0m )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/lib/python3.11/site-packages/langchain/chains/base.py:286\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    279\u001b[0m run_manager \u001b[38;5;241m=\u001b[39m callback_manager\u001b[38;5;241m.\u001b[39mon_chain_start(\n\u001b[1;32m    280\u001b[0m     dumpd(\u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    281\u001b[0m     inputs,\n\u001b[1;32m    282\u001b[0m     name\u001b[38;5;241m=\u001b[39mrun_name,\n\u001b[1;32m    283\u001b[0m )\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    285\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 286\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    287\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    288\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[1;32m    289\u001b[0m     )\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    291\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/lib/python3.11/site-packages/langchain/chains/llm.py:93\u001b[0m, in \u001b[0;36mLLMChain._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call\u001b[39m(\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     90\u001b[0m     inputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[1;32m     91\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     92\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m---> 93\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_outputs(response)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/lib/python3.11/site-packages/langchain/chains/llm.py:103\u001b[0m, in \u001b[0;36mLLMChain.generate\u001b[0;34m(self, input_list, run_manager)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Generate LLM result from inputs.\"\"\"\u001b[39;00m\n\u001b[1;32m    102\u001b[0m prompts, stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_prompts(input_list, run_manager\u001b[38;5;241m=\u001b[39mrun_manager)\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/lib/python3.11/site-packages/langchain/chat_models/base.py:458\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    452\u001b[0m     prompts: List[PromptValue],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    456\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    457\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m--> 458\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/lib/python3.11/site-packages/langchain/chat_models/base.py:348\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[1;32m    346\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n\u001b[1;32m    347\u001b[0m             run_managers[i]\u001b[38;5;241m.\u001b[39mon_llm_error(e)\n\u001b[0;32m--> 348\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    349\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    350\u001b[0m     LLMResult(generations\u001b[38;5;241m=\u001b[39m[res\u001b[38;5;241m.\u001b[39mgenerations], llm_output\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39mllm_output)\n\u001b[1;32m    351\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[1;32m    352\u001b[0m ]\n\u001b[1;32m    353\u001b[0m llm_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine_llm_outputs([res\u001b[38;5;241m.\u001b[39mllm_output \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results])\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/lib/python3.11/site-packages/langchain/chat_models/base.py:338\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[1;32m    336\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    337\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 338\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    344\u001b[0m         )\n\u001b[1;32m    345\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    346\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/lib/python3.11/site-packages/langchain/chat_models/base.py:490\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    486\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    487\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAsked to cache, but no cache found at `langchain.cache`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    488\u001b[0m     )\n\u001b[1;32m    489\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported:\n\u001b[0;32m--> 490\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    494\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/lib/python3.11/site-packages/langchain/chat_models/openai.py:343\u001b[0m, in \u001b[0;36mChatOpenAI._generate\u001b[0;34m(self, messages, stop, run_manager, stream, **kwargs)\u001b[0m\n\u001b[1;32m    341\u001b[0m message_dicts, params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_message_dicts(messages, stop)\n\u001b[1;32m    342\u001b[0m params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs}\n\u001b[0;32m--> 343\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletion_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessage_dicts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_chat_result(response)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/lib/python3.11/site-packages/langchain/chat_models/openai.py:282\u001b[0m, in \u001b[0;36mChatOpenAI.completion_with_retry\u001b[0;34m(self, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_completion_with_retry\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_completion_with_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/lib/python3.11/site-packages/tenacity/__init__.py:289\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_f\u001b[39m(\u001b[38;5;241m*\u001b[39margs: t\u001b[38;5;241m.\u001b[39mAny, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: t\u001b[38;5;241m.\u001b[39mAny) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m t\u001b[38;5;241m.\u001b[39mAny:\n\u001b[0;32m--> 289\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/lib/python3.11/site-packages/tenacity/__init__.py:379\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    377\u001b[0m retry_state \u001b[38;5;241m=\u001b[39m RetryCallState(retry_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, fn\u001b[38;5;241m=\u001b[39mfn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 379\u001b[0m     do \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    381\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/lib/python3.11/site-packages/tenacity/__init__.py:314\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    312\u001b[0m is_explicit_retry \u001b[38;5;241m=\u001b[39m fut\u001b[38;5;241m.\u001b[39mfailed \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fut\u001b[38;5;241m.\u001b[39mexception(), TryAgain)\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (is_explicit_retry \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry(retry_state)):\n\u001b[0;32m--> 314\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfut\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafter(retry_state)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/lib/python3.11/concurrent/futures/_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/lib/python3.11/concurrent/futures/_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/lib/python3.11/site-packages/tenacity/__init__.py:382\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    381\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 382\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[1;32m    384\u001b[0m         retry_state\u001b[38;5;241m.\u001b[39mset_exception(sys\u001b[38;5;241m.\u001b[39mexc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/lib/python3.11/site-packages/langchain/chat_models/openai.py:280\u001b[0m, in \u001b[0;36mChatOpenAI.completion_with_retry.<locals>._completion_with_retry\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_completion_with_retry\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m--> 280\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/lib/python3.11/site-packages/openai/api_resources/chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TryAgain \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m>\u001b[39m start \u001b[38;5;241m+\u001b[39m timeout:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/lib/python3.11/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m     )\n\u001b[0;32m--> 153\u001b[0m     response, _, api_key \u001b[38;5;241m=\u001b[39m \u001b[43mrequestor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m         \u001b[38;5;66;03m# must be an iterator\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/lib/python3.11/site-packages/openai/api_requestor.py:298\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    279\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    286\u001b[0m     request_timeout: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    287\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m    288\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_raw(\n\u001b[1;32m    289\u001b[0m         method\u001b[38;5;241m.\u001b[39mlower(),\n\u001b[1;32m    290\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    296\u001b[0m         request_timeout\u001b[38;5;241m=\u001b[39mrequest_timeout,\n\u001b[1;32m    297\u001b[0m     )\n\u001b[0;32m--> 298\u001b[0m     resp, got_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp, got_stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/lib/python3.11/site-packages/openai/api_requestor.py:700\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    692\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    693\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    694\u001b[0m             line, result\u001b[38;5;241m.\u001b[39mstatus_code, result\u001b[38;5;241m.\u001b[39mheaders, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    695\u001b[0m         )\n\u001b[1;32m    696\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m parse_stream(result\u001b[38;5;241m.\u001b[39miter_lines())\n\u001b[1;32m    697\u001b[0m     ), \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m--> 700\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response_line\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    703\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    704\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    706\u001b[0m         \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    707\u001b[0m     )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/lib/python3.11/site-packages/openai/api_requestor.py:765\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    763\u001b[0m stream_error \u001b[38;5;241m=\u001b[39m stream \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mdata\n\u001b[1;32m    764\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream_error \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m rcode \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[0;32m--> 765\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_error_response(\n\u001b[1;32m    766\u001b[0m         rbody, rcode, resp\u001b[38;5;241m.\u001b[39mdata, rheaders, stream_error\u001b[38;5;241m=\u001b[39mstream_error\n\u001b[1;32m    767\u001b[0m     )\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[0;31mInvalidRequestError\u001b[0m: This model's maximum context length is 4097 tokens. However, your messages resulted in 19305 tokens. Please reduce the length of the messages."
     ]
    }
   ],
   "source": [
    "summarize_chain(youtube)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bb9fbbb8-a1bd-459b-adb1-b75c7463d708",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_youtube = YoutubeLoader.from_youtube_url(\n",
    "   youtube_url=\"https://www.youtube.com/watch?v=I2UZutRrtEE\",\n",
    "   language=\"ja\"\n",
    ").load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7f7c237a-59df-4d18-96ff-6c12171b19bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RefineDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\"では早速なんですけれども始めさせて いただきます私からはラングチェイン エージェントを使って自社ツールと チャットGPTを連携するというタイトル で発表させていただきますChatGPT 自体は皆さんご存知のように非常に優れた 能力を持っていますが最新のデータに アクセスできないとか特定の数学的な推論 が得意でないなどいくつかの課題が存在し ますこれらの課題は自社プロダクトに チャートGPTを導入するなどチャット GPTを社会実装しようとした際に解決し なければなりません今回お伝えするラグ チェインエイジェントを導入すると ChatGPTと外部ツールをうまく連携 させることができるようになりChat GPTが抱える課題を克服しチットGPT の可能性をさらに広げることができます 本日はラングチェインエージェントをどう 活用することでチャットGPTの能力を 拡張できるのか具体的にご紹介していき ますそれでは始めていきますこちらが私の プロフィールとなります内容はいつもと 同じなのでスキップさせていただきます はいでは具体的な話に入る前にですね今回 のテーマの結論に先に触れておきます結論 なんですけれどもラグチェインには様々な エージェントの種類が存在するが自社 ツールとチャットGPTを効果的に連結 する際汎用的なエージェントタイプである ゼロショットリアクトまたはオAI ファンクションを利用することが簡単と なりますゼロショットリアクトとOpen AIファンクションを比較するとOpen AIファンクションの方がチットGPT からより適切かつ精度の高い答えを 引き出しやすくなっていますこちらはデモ のでお見せしますねでそしてえっとここで ChatGPTと自社ツール連携で非常に 重要となるものとしてツールの説明という ものがありますと通常のプロンプトチャト GPTを使う時のプロンプトと同様に ツールの特性や機能をChatGPTに 正確かつ効果的に伝えることで自社ツール とチャットGPTの連携の成功率が格段に 向上していきますこのポイントに着目し ながら具体的な方法論について今日は 深掘りしていきたいと思いますそれでは これらのポイントを年頭にきつつ今回の 発表をお聞きください本日の発表は以下の 3つのセクションから構成されています 初めにチットGPTの基本的な概要につい て触れます次にラングチェイン エイジェントの特徴について紹介し最後に デモンストレーションを行いますデモでは 特にツールの説明について着目して いただけると幸いですそれでは最初の トピックに移りましょうここではチット GPTの全体的な特徴を振り返っていき ますすでにご存知の内容も多いと思うん ですけれども一般的なはチャットGPTの 性質っていうものをご紹介していきます チットGPTは実用的な大規模言語モデル llmで現在多くのビジネスに活用されて きています例えばベネッセ ホールディングスでは車内AIChat ベネッセGPTを開発しグループ社員 1.5万人に向けて提供しているという ようなプレスを出していたりとか立メカ 大学では大学の英語事業において機械翻訳 とChatGPTを組み合わせたサービス が試験導入されているであったりとか他に も色々なサービスがチャトGPTを 組み込み始めておりChatGPTの実用 化っていうものがすごい勢いで広がってい ますChatGPTを活用する際によく 言われることとしてはチャットGPTから 良い結果回答を得るためには良い質問が 必要であるということですでこれは プロンプトエンジニアリングと呼ばれる 領域で今最も伸びている業種の1つと言え ますプロンプトエンジニアリングではどの ような項目をプロンプトに入れるべきか またプロンプトを複数回うまく使いこ なくして良い回答をるテクニックなどが 研究開発されていますリアクトであったり とかいろんなことを聞いたことあると思う んですけれどもプロンプトの種類っていう のがどんどんどんど開発されているという ことですでチャットGPTの活用は多に 渡っておりその可能性は広がりつつあり ますでプロンプトエンジニアリングの テクニックを活用することでチャット GPTとの適切なコミュニケーションが 可能になりますプロンプト エンジニアリングでは色々なテクニックが 存在するのですが今回はプロンプト エンジニアリング自体がメインのテーマで はないのでプロンプトエジライニングの中 で抑えるべき基本的な項目とそしてよく 使われるまフーショットプロンティングと 呼ばれるような手法を簡単にだけ紹介して いきますはいまず基礎として抑えていき たいこととしてプロンプトに何を与える べきかっていうものをいくつか紹介して いきますで1点目としては具体的で明確に 質問することですで例えばその日本の歴史 において重要な出来事は何ですかという 質問よりも日本の戦国時代における重要な 出来事について教えてくださいという具体 的に質問し方が的確なコ答が得られますと で2点目に状況やコンテクストを明示する ことですて背景情報があるとチャット GPTはコンテクストをより理解し適切な 回答が返ってきますとで3点目期待する 回答の形式を指定するとこれにより望む 情報が整理されて帰ってきますリスト形式 で返してくださいであったりとか ジェイソン形式で返してくださいであっ たりとかまそういうことを質問する時に プロンプトの中に入れるということですね で4点目範囲を限定すること範囲が広す すぎると回答も後半で一般的になりがちに なりますなので範囲を狭めるということが 重要となってきますで最後5点目自性や 認証を明確にすることですと例えば子供で も分かるようにしてくださいとか中学生で も分かるようにしてくださいとかなんか そういう風にどの視点で書て思ってみるか を示したりであったりとか何年の情報が 欲しいとかそういうことを指定することに よって回答が明確なものが帰ってきやすく なるということですで次にプロンティ テクニックの1つののフューショット プロンティについて簡単に説明します フューショットプロンティはモデルに少数 の例を示すことで特定のタスクの解決方法 を学習させるアプローチになりますこれに よりモデルは様々な問に対して適切な回答 を生成することができますここに例として 上げてるんですけれども例えばレストラン 最高でしたこれは感情ポジティブですこの 映画は本当に時間の無駄だった感情 ネガティブですというようにいくつかの例 を与えて出したいものでそれぞれの文に 対しての感情っていうものをこのように 並べていきますてで最後に聞きたいものと してそのサービスは非常に遅く不満ですっ ていうものがあった時にどんな感情で すかっていうことを聞くと感情ネガティブ という風に返ってくるというところですで こういう風にすることによってモデルって いうものが新しい文章がポジティブか ネガティブかっていうのをま過去の例を元 に判断することができるようになるという ことですでこの方法によってですねフュー ショットプロンティはモデルに多様な タスクを効率的に学習させることができ 柔軟な対応が可能になってくるということ でですでここまでいくつかのプロンティの テクニックであったりとかをお話ししてき ましたもちろん他にもたくさんあってです ねチェインオブソツであったりとかあと セルフアスクであったりとかいろんなもの があるんですけれども今回のメインテーマ ではないので一旦プロンティグの話はここ で終わりにしてでここでちょっと一息つい てですねこれらのテクニックが持つ限界に ついて考えてみましょうでまず1点目なん ですけれどもプロンプトのテクニックは 日々進化し開発されていますとこれによっ てチットGPTは多様なタスクや質問に 対応でできるようになってきていますただ 全ての作業やタスクをチャットGPTに 依存すること自体が現実的ではありません とえ例えば先ほどの例で出てきた文章から の感情抽出に関してはチャートGPTに 無理やりさせることが適切かと言われると そうでもないかもしれないAWSコプリン のような勘定分析に特化した学習をして いるAPIっていうものがあってそれを 使った方がいい結果が返ってくるかもしれ ませんっていうのがまず1つ目ですねで次 に2点目としてそのChatGPTが持つ 情報っていうものは訓練データに限定され ていてチットGPTはそれ以外のデータに ついては知らないというところですなので えっとチャットGPTは過去のデータで 学習されておりその学習データ以降に出て きた情報に関してはチットGPTに尋ね られませんとよく言われるものとしては 2021年のデータですかねまでのデータ で学習してるので例えば2022年であっ たりとか2023年のデータについて聞い たとしてもチャットGPTがうまく答え られないというようなところですね最新の 価格的な研究であったりとかニュース記事 とか特定の地域の天気情報であったりとか チットGPTの訓練データに含まれてい ないような情報っていうものはChat GPTだけでは取得できませんし インターネットにあるデータだけではなく て例えば今回のテーマである自社のツール と連携するっていう時のためには自社の データを使いたいみたいな話とかあると 思うんですけれども自社データについては チャットGPTが知るわけもないという\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary.\n",
      "We have provided an existing summary up to a certain point: The speaker introduces the topic of integrating their company's tool with ChatGPT using a tool called LangChain Agent. They discuss the limitations of ChatGPT, such as the inability to access the latest data and the lack of proficiency in certain mathematical inferences. They explain that LangChain Agent can overcome these challenges by effectively integrating ChatGPT with external tools. The presentation is divided into three sections: an overview of ChatGPT, the features of LangChain Agent, and a demonstration. They also briefly mention prompt engineering techniques for improving the quality of responses from ChatGPT. However, they acknowledge that not all tasks can rely solely on ChatGPT and that the model's knowledge is limited to the training data. They highlight the need for additional sources of data, such as the company's own data, when integrating ChatGPT with their tool.\n",
      "We have the opportunity to refine the existing summary (only if needed) with some more context below.\n",
      "------------\n",
      "とか特定の地域の天気情報であったりとか チットGPTの訓練データに含まれてい ないような情報っていうものはChat GPTだけでは取得できませんし インターネットにあるデータだけではなく て例えば今回のテーマである自社のツール と連携するっていう時のためには自社の データを使いたいみたいな話とかあると 思うんですけれども自社データについては チャットGPTが知るわけもないという ことでえっとChatGPTに自社の データについて聞いたとしてもChat GPTはもちろん答えることができません とこれらのチャGPTの限界を理解する ことでチットGPTの適切な使用方法で あったりとかそれらをどのようなシナリオ で活用するべきかっていうのが見えてくる ということですねでChatgpdの概要 の最後なんですけれどもChatgpdや その他大記号言語モデルllm自体の課題 をこちらにまとめますでまず1点目なん ですけれども先ほどと被るんですが ChatGPTは最新の情報にアクセスが できないと例えば為替や株価のように国 一刻と変化していく情報に対してチト GPTははリアルタイムで対応することが できませんで2つ目の課題としては ChatGPTが独自の情報源にアクセス する能力を持たないということです企業の データベースに保存されている顧客名簿で あったりとか特定のプライベートな情報に はアクセスすることができませんで3つ目 に水論の正確性に課題があるというところ ですチャットGPTは時折り簡単な算術 計算でさえも間違えることがありますこれ は特に正確な情報や結果が求められる タスクにおいて大きな問題となりますねで そして最後にチャットgpdができない こととかのデータが足りないんだったら ファインチューニングすればいいんじゃ ないかっていうような意見もあると思うん ですけれどもファインチューニングする ことによって汎用性が劣化してしまうと いうことがありますとでChatGPTを 特定のタスク例えば自社データを食わせる であったりとか特定のタスクに特化した データを食わせてファインチューニング すると他の多様なタスクに対する性能が 低下すると言われていますでこれらの課題 を解決するための1つの手段として今回お 話しするラングチェインエージェントって いうものがありますでここここからは ラングチェインエイジェントを使って チットGPTの性能を生かしつつ苦手な ものは他のツールで解決していくっていう ことについてお話ししていきますで参考 までにですねここにバッと上げている課題 に関してはMrKLシステムズていう有名 な論文があってそ論文から引っ張ってきた ものとなりますMrKLシステムズって いうのはミラクルシステムズと呼ぶもので チャットGPTと他のツールを連携して どんどんどんどん課題を解いていくって いうことを提示しているロムとなってい ますそれではラングチェインエージェント についてのトピックに移っていきますまず ラングチェインエージェントの前にですね ラングチェインとは何かと言うとラング チェインとは言語モデルを利用する アプリケーションのためのフレームワーク ですでラングチェインについては前回の 勉強会でもご紹介しているので基礎的な 内容を知りたい方はYouTubeで前回 の勉強会の動画をご覧くださいでラング チェインエージェントはラングチェインの 中の1つの機能なんですけれどもラング チェインの中でも非常に面白くて重要な 役割を果していますランチェの主なタスク は次にどんなアクションを取るべきかを大 記号言語モデルllmに決定させそれを 実行するということですで具体的な プロセスは以下の通りですとまず各ツール ができることと質問を指定したレスポンス のフォーマットでllmに送信します聞き ますとチットGPTなどのllmに聞き ますそしてllmChatGPTから帰っ てきたレスポンスをパースして次の アクションを決めるということをしますで このプロセスによってラングチェインジと はユーザーの4級に応じて効率的かつ正確 なアクションを実行できるようになって いるというところですでここでラング チェインエージェントがどのように動く かっていうもののイメージを具体的な例と して1つ持ってきましたま正確に正しい 動き方をしてるわけではないんですけれど も大体こういうような動きをするんだよっ ていうこともご理解ください例えばチット GPTに対してコミュニケーションを取る のがラングチェインのエージェントとなる んですけれどもラングチェイン エージェントにですねまずこう今日東京で で出かける時時に適切な服装は何ですかて いうのを聞きますでそうするとラング チェインエージェントが聞きたい内容今日 東京で出かける時に適切な服装っていう ものとあと自分が持っているツールって いうものをプロンプトに入れてチャット GPTに聞いてくれますとで自分が持っ てるツールっていうものは例えば Google検索のツールっていうも持っ てますとGoogle検索のツールでは 最新の情報を引っ張ってくることができ ますと私が持ってるのはGoogle検索 のツールで最新の情報が引っ張ってこれ ますそしてで今回聞質問としては東京で 出かける時に適切な服装って何でかていう ものを聞きますとでその時にチャット GPTはどのように返してくるかというと でまずは検索ツールでインプットは東京の 気温っっていうもので調べなさいっていう ものをエージェントの方に返してきますで エージェントはチャットGPTからから 教えてもらったじゃあえ検索ツールを使え ばいいのかっていうところで検索ツールを 使おうとしますでインプットとしては チャトGPTが教えてくれたように東京の 気温っていうものをインプットとして入れ てで検索ツールから帰ってきた22度って いうものを変してもらいますとでそして またえっとチャットGPTにえこのツール に入れた答えってものが22°でした次何 すればいいんですかであったりとか最終的 にどうなんですすかっていうのをチャット GPTに聞いてチャットGPTが十分な 情報を得たっていう風に判断するとでは 22°なので薄の長袖でがいいでしょうっ ていうものをエージェントとしに返してで あとはえ答えとしてラングチェインの エージェントが東京は22度なので素の 長袖でがいいでしょうっていうものをその まま返してくるというような流れになり ます特徴的なものとしてはチャットGPT だと今日の天気であったりとか東京の天気 であったりていうものは取れないんですね でそこをGoogle検索のツールって いうものを利用することによって新しい データっていうのを取れるようにしてると いうところですねもう1つ押えておきたい こととしてはこの問を解く時に自分が持っ ているツールっていうもの一覧を渡して どのツールを使えばいいかっていうのこと 自体もチャットGPTに判断してもらうっ ていうところが面白いところとなってい ますはいでこれがラングチェイン エージェントリアクトフレームワークとか 呼ばれたりするようなやり方ですねはい これらのこと全部ラングチェインの エージェントがやってくれるというところ ですでラングチェインエージェントって いうものは様々なタイプのエージェントが 用意されていますとここでエージェントの タイプっていうものを紹介するんです けれども解きたい課題に応じて エージェントを使い分けることによって 精度の高い回答を得られるようになると いうことですここで6個ほど上げています でまず1番汎用的なものとしてはゼロ ショットリアクトエージェントというもの ですでこのエージェントはリアクト フレームワークを利用してツールの説明に 基づいてどのツールを使用すべきか判断し ます先ほどの例で出てきたものと同じです ねこれによって特定のトレーニングデータ なしで多様なツールの適切なこう利用が 可能になってきます次にストラクチャード インプットリアクタエージェントですで このエージェントは複数の入力を使う エージェントを活用することができますで これによってより複雑なツールの理由用が 簡単になりタスクの効率が向上しますと 続いてOpenAIファンクション エージェントですこのエージェントはオ AIのファンクションコーリングの機能を 使っており関数が呼び出されるタイミング であったりとかを検出したりとか適切な 入力を関数に渡すような微調整がえオープ AI自体チットGPT自体がされていて それを使うことができますとOpenAI のえファンクションコーリングこの エージェントが使うOpenAIの ファンクションコーリングについてはこの 後のスライドでもう少し詳しく説明します で次にコンバーションエージェントですで このエージェントは会話での使用目的とし て設計されています何かを聞いて何か答え を出すっていうようなま単純なチャット GPTで何かこう答えを作ってくださいと かそういうのとは違くて会話的な インタラクションを通じて効果的な コミュニケーションを可能にするような エージェントとなっていますそして次に あげるものとしてはセルフアクwith sarchエージェントですねでそこの エージェントはですねセルフアクという 質問を自問自としながら分割することに よって正しい解を導き出す方法を使って\n",
      "------------\n",
      "Given the new context, refine the original summary.\n",
      "If the context isn't useful, return the original summary.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary.\n",
      "We have provided an existing summary up to a certain point: The speaker discusses the limitations of ChatGPT, such as the inability to access the latest data and the lack of proficiency in certain mathematical inferences. They explain that integrating ChatGPT with external tools, such as their company's own data, can overcome these challenges. They introduce LangChain Agent as a tool for effectively integrating ChatGPT with external tools and outline its features. The presentation also briefly touches on prompt engineering techniques for improving response quality from ChatGPT. However, the speaker acknowledges that not all tasks can rely solely on ChatGPT and highlights the need for additional sources of data.\n",
      "We have the opportunity to refine the existing summary (only if needed) with some more context below.\n",
      "------------\n",
      "GPTで何かこう答えを作ってくださいと かそういうのとは違くて会話的な インタラクションを通じて効果的な コミュニケーションを可能にするような エージェントとなっていますそして次に あげるものとしてはセルフアクwith sarchエージェントですねでそこの エージェントはですねセルフアクという 質問を自問自としながら分割することに よって正しい解を導き出す方法を使って 情報を検索するエージェントですセルフア クっていうプロンティグの技術があるん ですねまそれを使ってちゃんとした正しい 答えを導き出すエージェントとなってい ますで最後に紹介するものがリアクト ドキュメントストアエージェントですで このエージェントはドックストア ドキュメントストアですねと対話するため にリアクトフレームワークを使用してき ますえこれによって文書の管理であったり とか検索が一元化されて効率的に情報 アクセスが可能となりますこちらに関して はまた今後の勉強会でも取り扱っていき たいかなという風に思ってるんですけれど も文書検索管理っていうものに特化した エージェントとなっていますで以上がラン チェインエージェントの各エージェントの 使用となりますでそれぞれのタイプが 異なるシナリオやタスクに適しており ラングチェインの柔軟性と多様性を象徴し ているものとなります今回のセッションで はですね最も汎用的なゼロショット リアクトとチャットGPT自体に色々判断 させるファンクションコーリングを使った オープAIファンクション2を利用して いき ますでは先ほど説明を省いてしまったん ですけれどもOpenAIファンクション コーリンググっていうのはOpenAI ファンクションコーリングじゃないですね OpenAIファンクションですね OpenAIファンクションとは何か エージェントタイプの1つであるOpen AIファンクションとは何かについてお 話ししますこちらはChatGPTを提供 しているOpenAIのファンクション コーリングという機能を利用していますで ファンクションコーリングっていうものは 2023年の6月にリリースされた機能で ラングチェインエージェントが担っていっ たツールを渡してチャットGPTに聞いて 次のステップを決定するやり取りってい ものをチットGPT自体が行えるように ファインチューニングされているものと なりますでこの機能では東京の天気を教え てくれというような先ほどと同じように ですね質問と共にどういう関数を持って いるのかその関数の説明をチトGPTに 直接投げるということをやりますなので 先ほどのラングチェインエイジェントが やってることと同じようなことをやれる ようになっていてチットGPTが ファンクションをどのように受け取るのか そのファンクションのパラメータであっ たりとか説明とかをよりチャトGPTが 理解しやすいようにAPIとして受け取る ことができるようになっているのでより 適切な判断をチャットGPTがしやすく なっているというところがメリットとなり ますなので今メリットをお話ししてしまっ たんですけれどもファンクション コーリングを使うメリットとしては ChatGPTにツールの挙動をより正確 に伝えやすくなっているというところで これによってChatGPTが機能の ツールのえファンクションの使用や動作を より正確に理解しやすくなっていて適切な 判断をしやすくなっているとていうのとで もう1つのメリットとしてはチャット GPTっていうものがラングチェイン エージェンドって元々チャットGPTが 返してきた個体を利用者が頑張って定期 表現を使って解析する必要があったんです がそれをする必要がなくなったっていう ところが利点としてありますとでチャット GPTが実際にラングチェインを使って どのツールを使えばいいですかていうのを 聞くんですけどそれをどのようにパースし てるかというとこのように頑張ってですね えっとレギュラーエクスプレッションを 使って正規表現を使ってパースしたりとか して次のアクションを決めてたりするって いうのがラングチェが今までやっていた ことであるとでこういうパースをしなきゃ いけないっていうことをしなくて済む つまりパースしなきゃいけなかったので今 まではそのパースすることでえっとうまく パースできなくてミスってしまうっていう こともあったんですけどそういうことが なくなるっていうことが期待されるという ところです はいはいちょっと駆け足になってしまった んですがここまでで20分ぐらいかかって しまいましたねえここからがレモに入り ますで実際にですねラングチェイン エージェントを使ってチャトGPTと自社 ツールを連結するような感じのえデモって いうものをお見せしていきますで使う エージェントとしてはゼロショット リアクトとオーエファンクションを使って いきますであとは今回のプレゼンの冒頭の 方でもお話ししたようにChatGPTに ツールの説明をどのように渡せばいいのか であったりとかその辺りを持ち替えて いただければ幸いです はいではではやっていきますちょっと時間 がなくなってきたので駆け足でいきますね でまずは設定ファイル読んでいきますこれ 何をやってるかと言うとえOpenAIの APIキーであったりとかを読んでいます でまずはですねえっとゼロショットの方を 見せしていきたいんですがおマジないとし てですねおじないというかま前回の勉強会 と同じようにですねラングチェイン エージェントを使うためのやり方をお見せ していきますで実際今回使うモデルとして はチットOpenAPAIというか ChatGPTのえGPT3.5のtbo 0613というものを使っていきますで 外部のツールとしてはGoogleサーチ のAPIっていうものを今回用意しました ここであのサプAPIっていうものを書い ているものがえGoogleのAPIと なりますで聞きたい質問としては今日の 東京と北海道の天気を調べて東京から 北海道の出張で来ていくべきを教えて くださいっていうものを聞きたいと思い ますでラングチェインエージェント自体を 走らせてみますでこれがゼロショット リアクトエージェントを使った場合どの ようになるかっていうのをお見せしますで エージェントタイプに関しては イニシャライズエージェントの エージェントっていうえ引数に対して エージェントタイプのこのゼロショット リアクトディスクリプションていうものを 渡すとエージェントを選択することができ ますちなみになんですけれどもえこれって ただあの文字列が返ってくるだけですかね あのゼロショットリアクト ディスクリプションていうものが返って くるだけのものになりますなので文字列で 与えても同じですはいでは実行してみ ましょうチトgpdはもちろん今日の天気 とか今日の東京とか北海道の天気っていう のは知らないので来ていくべき服装って いうことは分からないわけですね気温も 分からないのででこれでラングチェイン エージェントが私はGoogle検索の ツールを持ってますよでそれを使って使う ことができますでこの問題課題っていう ものを解くためにはどうすればいいですか てのを聞くっていうことですねでここで ざーっと出てきてるんですけれども実際に 書いてきた答えとしてはtheWisto isCloudyaboutcrear withtempof歌詞になっちゃって ますけどまこのように帰ってきますと 英語で帰ってきちゃってますねでこういう 風にえどんなアドレスをれ切ればいい かっていうものがちゃんと帰ってきてい ますと前にやった時はそんなに綺麗に帰っ てきてなかったんですけれども今回は うまく帰ってきていますはいこちらがゼロ ショットリアクトディスクリプションで やった場合の結果になりますでどういう ことをやってるかっていうのなこの辺りを 見ていただくといいのかなという風には 思いますでチットGPTにまずラング チェインエージェントが問題とツールを 渡してチットGPTに何をすればいい かっていうのを聞きますでチャットGPT から帰ってきた答えとしては次の アクションとしてはサーチをしてください ですサーチのインプットとしてはウザー 東京todayていうものを渡してくださ いっていうのを渡してますで次の アクションとしてはサーチをしてください でそのインプットとしてはウザ北海道 todayていうものを渡すようにして くださいとで最終的にその帰ってきた答 っていうものをチャットGPTに渡して 最終的な文が出てくるということですはい でこれが1つ目ですねアエージェント タイプ1つ目のえゼロショットリアクト ディスクリプションで元々ラングチェイン エイジェントがリアクトフレームワークで ツールを渡したりとかしてチャットGPT とうまく連携しながら外部ツールを使う ようにしたえ機能となっていますでこれが ですねえ最近出てきた6月にリリースされ たOpenAIのファンクションコーリン グっていうものを使うとどうなるかって いうのをお見せします はいでOpenAIファンクション OpenAIのファンクションコーリング を使うためにはエージェントタイプの OpenAIファンクションズっていう ものを渡しますでそうするとえこのように 動きますで実際にやってることとしては ラングチェインエージェントがOpen\n",
      "------------\n",
      "Given the new context, refine the original summary.\n",
      "If the context isn't useful, return the original summary.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary.\n",
      "We have provided an existing summary up to a certain point: The speaker discusses the limitations of ChatGPT, such as the inability to access the latest data and the lack of proficiency in certain mathematical inferences. They explain that integrating ChatGPT with external tools, such as their company's own data and the Google Search API, can overcome these challenges. They introduce LangChain Agent as a tool for effectively integrating ChatGPT with external tools and outline its features. The presentation also briefly touches on prompt engineering techniques for improving response quality from ChatGPT. However, the speaker acknowledges that not all tasks can rely solely on ChatGPT and highlights the need for additional sources of data. The speaker also introduces the concept of OpenAI Function Calling, which allows ChatGPT to better understand and utilize external tools for more accurate responses. Overall, the LangChain Agent demonstrates the flexibility and diversity of integrating different agent types for various scenarios and tasks.\n",
      "We have the opportunity to refine the existing summary (only if needed) with some more context below.\n",
      "------------\n",
      "たOpenAIのファンクションコーリン グっていうものを使うとどうなるかって いうのをお見せします はいでOpenAIファンクション OpenAIのファンクションコーリング を使うためにはエージェントタイプの OpenAIファンクションズっていう ものを渡しますでそうするとえこのように 動きますで実際にやってることとしては ラングチェインエージェントがOpen AIのファンクションコーリングっていう ものを使ってうまくチャットGPTと やり取りしながら答えを導き出していくっ ていうことをやっていますはい出てきた 答えはこちらですねで同じようにですね どのようにやっているかっていうものは ここら辺の途中で出てきているんです けれども途中結果でえサーチとしてはえ クエリー東京の今日の天気っていうものを 調べてくださいでサーチっていうツルを 使って今日の北海道今日の天気っていう ものを調べてくださいでこれらが帰ってき た答えっていうものをえチャットGPTに 返してチャトGPTがその与えられた情報 を元に東京の今日の天気は曇りですが後に は晴れる予報ですで気温は接し30°歌 86°でコス確率はどうのこうのっていう ものがあってであとは東京は暑くなる可能 性があるので軽い服装が適しています ただし北海道は比較的涼しいので ジャケットなどを持っていくことがお勧め しますというような感じに帰ってきてます ま見て分かると思うんですけれどもま日本 語にな質問が日本語だったので日本語で ちゃんと返してくれるっていうのは もちろんのことなんですけれども書いてき た答えっていうものに関してより詳しく 返してくれているっていうことが分かると 思いますなので使ってみた所管としては ですねここで言うオAIファンクションの ファンクションコーリングっていうのの ファンクションっていうのはラング チェインエージェントでいうツールと同じ なんですけれどもそのファンクションで あったりとかツールを渡す時にですね渡し て何かを判断判させたいチャットGPTに 判断してもらいたいっていう時はえ エージェントタイプゼロショットリアクト ディスクリプションよりもエージェント タイプオAIファンクションの方がより いい結果が返ってきやすいっていうことが 分かると思い ますもう少しあの詳しく見ていきます ちなみにですねOpenAIにどんな ファンクションを渡してるかっていうのは イニシャライズエージェントのところで エージェントを定義してるんですけども そのエージェントの中からエージェントっ ていうものとファンクションズってものを 実行するとどんなえファンクションが渡さ れてかっていうのを見ることができますで 今回渡されたファンクションっていうのは ネームサーチっていうファンクションが 渡されていてどんなことができるかって いうのでサチエンジンですっていうような ものをやってますであとはパラメーターと してはこういうものを渡していきますって いうのが分かりますとはいでここまでが 基本的なラングチェインエージェントを 使って外部ツールを連携するっていうお話 をしてきましたとで次にですねえ自社で 作ったツールっていうものを連携させ るっていところについてお見せしていき ますで一旦はですねレコメンドアイテムっ ていうものを考えてみようと思いますで ここ何をやりたいかって言うとレコメンド アイテムまこの中身はほとんど意味のない ものになってるんですけれどもレコメンド アイテムっていう関数を自社で持っていて でレコメンドアイテムっていうものは自社 のデータベースなどにアクセスして日付を 持ったにこの日のレコメンドっていうもの はこういうものですっていうものを返す ような関数っていうところになりますとな のでえっとこのレコメンドアイテムって いうところをこの関数ををえChat GPTのフローの中に組み込みたいって いうことをやっていきますでどのように ラングチェインエージェントを使って ChatGPTに連携すればいいかという とツールっていうものにえ変換していく 必要がありますとでレコメンドアイテム ツールっていうものをえツールfrom ファンクションズっていうものを使って どのようなファンクションを実行したい ですかレコメンドアイテムっていう ファンクションを実行したいですまこう いう風にですねこの今回のあまり意味の ないファンクションなんですけれどもこれ を実行しますとでツールの名前としてはえ レコメンドアイテムっていうものを渡し ますでツールのディスクリプション何を やってくれるかっていうことに関してはお すめの商品を教えてくれますっていうのを ツールとして定義するというところです はいでこれをちょっとツールズっていうま ツールまとめて渡さないといけないで ツールの配列の中に入れておきます実際に ですねラングチェインエージェントにどの ようにツールを渡せばいいかっていうとま 先ほどもカラっとやってたんですけれども このツール1覧っていうのを最初に渡して 引数として渡しているのでまこのようにし てどんなツールが使えるかっていうものを ラングチェインのAに渡しでチャット GPTと連携していきますはいでえっと 今回聞きたいこととしてはえおすすめの 商品を教えてくださいっていうものを投げ てみようと思いますで使うエージェントと しては先ほどゼロシトリアクトよりもより いい結果が返ってきたオーエ ファンクションズってものを選びます はいはいでは実行し ますはいで書いてきたものとしてはですね コメドアイテムってものが実行されて withファッションという謎のものをえ 入力に入れてで実際この引数がですね デートの中にファッションが入ってで プリントファッションっていうところでこ でファッションが出てきてしまってるとで ただおすめの商品は今回レコメンド アイテムで書いてきたAppleですって いうのが書いてきてることが分かると思い ますはい見て分かるようにですねなんか よくわからない引数は与えてしまってる なっていうところがありますでこを どんどん解決していこうと思いますで次に やることとしては今回なんでこのように変 なファッションとかいう引数を与えて しまったかというと引数に関する情報が ないんですね与えられてないというところ になりますとなので引数何与えればいいん ですかみたいなところが情報としてないが ゆえにチャットGPTもレコメンド アイテムを使うことは分かるとレコメンド アイテムを使えばいいのは分かるんだけど レコメンドアイテムに対してちょっと 分からないからカテゴリー情報でも渡して みようかなっていうのでファッションを 渡してしまっているというような状態に なりますで例えばまファンクションを見た としても今回使ってるファンクションに 関してはレコメンドアイテムでおすめの 商品を教えてくれますでパラメーターの 情報は全くありませんっていう状態なので どんなパラメーターを渡せばいいかって いうのはオープAIファンクションは 分からないというところですねじゃあこれ に対してどうすればいいかっていうのをお 見せしますでえっと結構簡単でしてパダ ティックっていうものをご存知ですかね こう最近えっとファストAPIとかですか ねこう結構パであったりとかそのヒントを 与えるっていうことがまPython主流 になってきてると思うんですけれども フダンティックを使っていきますでえっと ご注意していただきたいこととしては ファインディッてもうV2が出てるんです けれどもV2を使うとラングチェイン エージェントを動きませんとなので パティックV1を指定して方に関する情報 をえ与えるためのそのベイスモデルとか フィールドを使ってえやっていきますで これ何をやってるかと言うとま今回の インプットに対してデイトっていうものが ありますがデイトていうものはお勧めした 商品を絞るために使われる日付ですって いうものを与えていますこれをえっと アーグススキーマ先ほどのツールを定義 する時にアグススキーマっていう引きを 使ってこのレコメンドアイテムインットっ ていうベースモデルから継承した レコメンドアイテムインプットっていう インプットの報引数の情報を持ったクラ スっていうものを渡すということをします とでこうするとどうなるかっていうのをお 見せしていき ますはいじゃあどう変わる かいきますはい実行します全く同じですね 実行するものとしてはで今回はレコメンド アイテムっていうものに対して先ほどと 同じレコメンドアイテムっていうものが 選ばれましたとコアイテムに対してデイト が2020年の12月1日っていうものを 渡しているっていうことが分かりますで それによってですね気付がちゃんと渡して くれたっていうことがわか分かるわけです ねで今回あのここであのデートっていう ものはディスクリプションでお勧めしたい 商品を絞るために使われる日付っていう ことを伝えたのでチャットGPTの方があ これは日付のことなんだっていうところで 引数はファッションのようなカテゴリーを 渡すんではなくてデートの引数っていう ものを渡すことができてるというところ ですはいでこちらがデトのまあ2022年 の12月1日もはや日付が意味が分から ないですけれどもこういうものが渡されて いるというところですねでおすめ商品は Appleですという風にでこういう風に\n",
      "------------\n",
      "Given the new context, refine the original summary.\n",
      "If the context isn't useful, return the original summary.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary.\n",
      "We have provided an existing summary up to a certain point: The speaker demonstrates the use of OpenAI Function Calling to integrate external tools with ChatGPT and improve response quality. They explain how LangChain Agent effectively utilizes this feature and provides more detailed and accurate responses in Japanese. Prompt engineering techniques are also mentioned for enhancing ChatGPT's performance. The need for additional data sources is highlighted, and the concept of OpenAI Function Calling is introduced to enhance ChatGPT's understanding and utilization of external tools. Overall, the LangChain Agent showcases the flexibility and diversity of integrating different agent types for various tasks.\n",
      "We have the opportunity to refine the existing summary (only if needed) with some more context below.\n",
      "------------\n",
      "ことを伝えたのでチャットGPTの方があ これは日付のことなんだっていうところで 引数はファッションのようなカテゴリーを 渡すんではなくてデートの引数っていう ものを渡すことができてるというところ ですはいでこちらがデトのまあ2022年 の12月1日もはや日付が意味が分から ないですけれどもこういうものが渡されて いるというところですねでおすめ商品は Appleですという風にでこういう風に ですねこうツールの説明をどんどん どんどん入れていってええ解決していく 必要があるというところですねで同じよう にですねちょっとエージェントの ファンクションがどのように渡されるてる かっていうのをお見せしますとで今回渡さ れたのはレコメンドアイテムインプトって いうのをえパイダンテックの方で定義して 渡しているのでえ実際にえっと ファンクションOpenAIのえ ファンクションコーリングにどのように 渡されてるかというとパラメーターとして ですねこういう風なレコメンドアイテム インプットっていうものが渡されていて プロパティとしてはデートがあってデー トっていうのはお勧めしたい商品を絞る ために使われる日付っていうものが入れ られてえ飛ばされてるということが分かる と思いますはい で他にはですねこのようにツールフロン ファンクションで作るっていうこともある んですけれども同じようにですね デコレーターを使うっていうこともでき ますとデコレーターの方が結構シンプルに 書けるので私は結構デコレーターを使って 書くことが多いですとでデコレーター何を すればいいかというとデコターっていうの はま関数の前にですねアマークツールなん ちゃらかんちゃらっていうものがあってで それを使ってえっとこのツールってのは何 ができるかっていうものをえドッ ストリングで与えるんですねな先ほどと 同じにするとレコメンドアイテムツールっ ていうものがあったら中身は同じですね プリントデイトとAppっていうものを 返しますとプリントデイトしてApple っていうものを返しますとででやることと してはおすめ商品を教えてくれます全く 同じ内容ですねでこのツールの名前って いうものはデコレーターの引数として レコメンドアイテムとして渡していると いうところですで同じようにですね ツールズの一覧として入れてでこれをえ 実行してみ ましょうはいこれデコレーター使った場合 です ね実行するものは全部同じですで同じよう にこれも実行できますという風にデコレー ターってかなりこうシンプルにかけてで ファンクションの中のドックストリングス とかを使ってくれるので結構あの家読性と かもう悪くないかなという風には思います 先ほどと同じようにですねこレコメンド アイテムってものはちゃんと選んでくれた んですけれどもレコメンドアイテムに渡し ているデートっていうのは2021年10 月15日という意味の分からない日付を 渡してしまっていますとこれはなぜかと言 とまもちろんそのおすすめ商品を教えて くださいって言ってるので勝手に日付を 決めて聞いてしまっているというところ ですね はいでデコレーターの方もですね同じよう にファンクションを見てみるとえっとこう いう風になるという感じですねただあの 先ほどと同じようにですねパダンティック とか使っていないのでプロパティの パラメーターとかは適当になってしまって いるというような感じになりますただ今回 の場合はですねこうデコレーターの場合は フロムファンクションの方を使ったこっち の場合ですねこのフロムファンクションを 使った時と違ってきちんとデートを入れて くれているっていうことが特徴的かなと いう風には思いますフロンファンクション を使った場合っていうのはパダンティック を渡さないとデートっていうものに対して ファッションを入れたりとかよく分から ないものを入れたりすることがあったと 思うんですけれどもデコレーターを使った 場合はこのデートっていうものを渡した時 にきちんとこうデートを返してくれるよう な情報っていうものを渡せてくれている ような感じですねいずれにせを正しい共同 を求めるためにはこのままあまり情報を 与えないで実行するってのは適切ではない ので特に自社ツールサービスとして提供 する側としてはですねなのでそういう意味 ではきちんとバイダンティックなどを使っ て適切な情報を渡しながら関数っていう ものを渡していく必要があるかなという風 に思いますなのでえっと先ほどと同じよう にですねデコレーターを使った場合も パイナティックの情報っていうものを渡す ことができるのでデコレーターの引き数に アーグススキーマていうものを渡してで そのパイランティックの情報を渡すことで 適切な答えを返すことができるようになる というところです同じようにですねま結果 も変わらないので はいまこういう風に変えてきました ちょっと答えがどんどんどんどん変わって きてますApple製品だったりとか AppleStoreとかオンライン ショップとかうんまここら辺に関しては 本当に適切な答えがまだ返ってきてない なっていうような状態だとは思います エージェントのファンクションを見るとえ きちんとファナティックで渡した情報って いうのが渡っていることが分かると思い ますこのようにですねこのデートっていう ものはデートっていう引き数はお勧めし たい商品を絞るために使われる日付ですっ ていうのが渡っているというところです もう少しですね今までこうおすめの商品を 教えてくださいっていう風に言っていたの でデートっていうものが1月10日であっ たりとかよくわかんない日付になっていた のではないかっていうことを推測してでは 昨日のおすすめ商品を教えてくださいって いうものを聞いてみますてそうするとどう なるかと言うとえ昨日のおすめ商品を教え てくださいって言ってるのにレコメンド アイテムに渡されてるのは2021の10 月20日っていうものが渡されれてること が分かりますとチャットGPTにこう昨日 とか今日とか昨日とか渡したら日付を ちゃんと入れてくれるのかなと期待するっ ていうことがあると思うんですけれども 実際はそんな入れてくれないっていうこと がまこの結果から分かるということですね もう少し例えばディスクリプションとかを 適切にすればうまくいくのかもしれないん ですけど今回は違う手段でえっと解決 しようと思いますで今回どういう風に解決 するかと言うとデートタイムを使って 新しい日付けを取得するような関数自社 ツールってものを設けようと思います ゲットデートっていうツールっていうもの を作ってでそのツールは何をするかという とま今日や昨日など日付を取得する時に 使います引き数には今日を起点として何日 か前をNで与えますとでここのそのドック ストリングスにですねこう引数に関する 情報を書いてるんですけども実際はですね パダンティックで引き数の説明した方が ベタだとは思いますただえっとドック スリンに書いてツールの説明として与える だけでも結構チャットGPTは賢いので うまく判断してくれるということですでお 見せしますはいこの日付関数を入れると どうなるかと言うとこういう風な感じです ねはい今日のおすめの商品を教えてくださ いっていう風にするとtodayて書い てき来てこれもうまく動いてないですね こういうことが結構ありますとうまく動か ないことがあるとでもう1回実行してみ ましょうかはいでもならではですね ちょっと30分で終える予定が46分に なってしまったんですがもう少しで終わる ので続けます前回のやつだとですね直接 レコメンドアイテムを呼び出してデートに 対してtoデイていうものを渡してしまっ てたんですけれども今回はうまく動いてい てまずは日付を取得するためにゲットデイ トっていうものを呼び出しますとで今日な ので今日からの起点のえN日前だったらN に0を渡せばいいということが分かるとだ からゲットデートに0を渡して帰ってきた ものが2023年の9月30日っていう ものが帰ってきてで9月30日のえお勧め 商品は何ですがま書いてくるものは全部 AppleなのでAppleってものが 帰ってきてることが分かると思います同じ ようにですねじゃあどういう ファンクションが渡されてたかっていうの をお見せするとサクっとですねで今回あの ファンクション2つ渡されていて レコメンドアイテムっていう ファンクションとゲットデイトっていう ファンクションが渡されていますで それぞれのファンクションの説明がこの ように与えられているということが分かり ますもう少しツールを複雑にしていって ですね奇数日だったらオレンジ偶数日だっ たらえAppleっていうものを返すよう なツールにちょっとだけレコメンド アイテムを変えみようと思い ますはいではえこれを実行するとですね 今日はえ9月30日なのでもちろん9月 30日偶数日ですね偶数日なので Appleが返ってくるきちんと帰ってき ますねAppleが帰ってきましたでは 昨日の場合はどうなのか 昨日はい昨日の場合は29日なので1日前 ってものをゲットデイトで取得して29日 ってものが書いていますで29日を使って え昨日のおすめ商品オレンジっていうもの を取ることができるというところ ですやとうまく動きました ねでもう少しだけちょっと時間が1時間 ぐらい喋ってしまうような感になるんです\n",
      "------------\n",
      "Given the new context, refine the original summary.\n",
      "If the context isn't useful, return the original summary.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary.\n",
      "We have provided an existing summary up to a certain point: The speaker demonstrates the use of OpenAI Function Calling to integrate external tools with ChatGPT and improve response quality. They explain how LangChain Agent effectively utilizes this feature and provides more detailed and accurate responses in Japanese. Prompt engineering techniques are also mentioned for enhancing ChatGPT's performance. The need for additional data sources is highlighted, and the concept of OpenAI Function Calling is introduced to enhance ChatGPT's understanding and utilization of external tools. The LangChain Agent showcases the flexibility and diversity of integrating different agent types for various tasks. The speaker also discusses the use of decorators and the importance of providing accurate information to functions for obtaining correct responses. They introduce a new tool called \"GetDate\" that can be used to retrieve the current date and improve the accuracy of recommended products based on the date.\n",
      "We have the opportunity to refine the existing summary (only if needed) with some more context below.\n",
      "------------\n",
      "Appleが返ってくるきちんと帰ってき ますねAppleが帰ってきましたでは 昨日の場合はどうなのか 昨日はい昨日の場合は29日なので1日前 ってものをゲットデイトで取得して29日 ってものが書いていますで29日を使って え昨日のおすめ商品オレンジっていうもの を取ることができるというところ ですやとうまく動きました ねでもう少しだけちょっと時間が1時間 ぐらい喋ってしまうような感になるんです けれどもう少しだけお話させてくださいで これだけだともちろんまだまだ連携が 少ないかなっていうところがあってで次に じゃあAppleだったら100円 オレンジだったら200円っていうような ものを商品の値段を返すような関数って いうものを組み込んでみましょうでツール としては元々グビだったらAppleキビ だったらオレンジを返すようなものとあと は日付を取得するツールであとは今回定義 したAppleとオレンジAppleだっ たら100円オレンジだったら200円 っていうのを返すツールっていうものを 定義しますでこれでエージェントのですね おすめの商品の値段まで教えてくださいっ ていうことをやるとそうするとまず最初に え昨日なのでゲットデートでN=1を渡し て1日前のデートを取ってきますで9月 29日ですで次にレコメンドアイテムって いうツールを呼び出してレコメンド アイテムにえ9月29日を渡してで最後に ですねアイテムプライスっていうので アイテムネームをえオレンジにとして渡し てでオレンジはは200円なのでえ昨日の おすめ商品であるオレンジの値段は 200円ですっていう最終的な答えが返っ てきましたというところになりますだいぶ 柔軟なものができるようになってきたって いうことが理解できると思いますで他には ですね最後なんですけれども取得した結果 を吐き出したいとかデータベースに 書き込みたいとかあったりすると思うん ですけどもそういうことももちろん簡単に できますと基本的にはファンクションが あってそのファンクション中身は自分で 書いていくので何でもすることができると いうところですねちょっとあの output.tchっていうところに 書き込むようなものを記事的にですね データベースに書き込んでいるようなもの として紹介しようと思いますで今回は さらに追加するツールとしてはですね セーブデータっていうツールを追加します とセーブデータっていうものは何なのかと いうとここにも説明書いてあるんです けれども日付と商品名と商品の値段を 受け取ってデータベースに書き込みますっ ていうようなものをツールとして作りまし たデータベースといながらもアウトプット テキストにただ書き込むだけのものになる んですけどもデートアイテムネーム アイテムプライスを書き込むだけのツール となりますま実際に自社ツールを使う時に はここにSQL分であったりとかを書いて データベスに書き込むとかをやったりする ことになると思いますこちらもですね ちょっと簡易的にですねフダンティックを 使わずにえドックストリングだけで何を やるかってのを渡して書き込めるかどう かってのをお見せしていこうと思いますで 同様にですね同じように何をしたいかと 言うと今日のおすめ商品の値段を調べて データベースに書き込んでくださいって いうことを実行し ますで最初に動くものとしてはまず日付を 取得するゲットデイトが動いてN=0で 今日の日付を取ります9月30日ですと9 月30日が取れたら9月30日の レコメンドアイテムは何ですかていうので レコメンドアイテムのツールを起動して 書いてきたものがAppleですとであ次 にやることしてはAppleの値段は いくらですかていうものをアイテム プライスに聞いてアイテムプライスが返し てきた答えが100円ですとで100円 っっていうものをえセーブデータに渡して セーブデータに渡すものとしてはデートと アイテムネームとアイテムプライスこれは 日付と商品目と商品の値段を受け取 りっていう風に書いてあるのでこういう ようなものを基数として与えて データベースに書き込みますていうことを この操作でやるということですねなので 細かいことを書いた方がミスは少ないん ですけれどもあんまり書かなくても動いて くれるっていうのがまやっぱりこう チャットGPTのうまいところかなという 風には思いますで最終的に帰ってきたこと としては今日のえおすすめ商品の値段は 100円ですとでデータベースに正常に 書き込まれましたっていうので データベースではないんですけどれも テキストファイルっていうものを中身見て みましょうと今日の日付2023年9月 30日でおすすめの商品Appleで最終 的に100円っていうのが書き込まれた ことが確認できましたとはいとても長く なってしまったんですけれどもこちらで テモは終わりとさせていただきたいと思い ますはい私の発表は以上となります ありがとうございました\n",
      "------------\n",
      "Given the new context, refine the original summary.\n",
      "If the context isn't useful, return the original summary.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "CPU times: user 56.2 ms, sys: 12.5 ms, total: 68.6 ms\n",
      "Wall time: 1min 53s\n"
     ]
    }
   ],
   "source": [
    "%time summary_output = summarize_chain(split_youtube)[\"output_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8210327b-96ce-49d8-9b58-eb2a86085aec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The speaker demonstrates the use of OpenAI Function Calling to integrate external tools with ChatGPT and improve response quality. They explain how LangChain Agent effectively utilizes this feature and provides more detailed and accurate responses in Japanese. Prompt engineering techniques are also mentioned for enhancing ChatGPT\\'s performance. The need for additional data sources and the concept of OpenAI Function Calling are highlighted. The LangChain Agent showcases the flexibility of integrating different agent types. The speaker introduces a new tool called \"GetDate\" that retrieves the current date and improves the accuracy of recommended products based on the date. They also discuss the use of decorators and the importance of providing accurate information to functions for obtaining correct responses. The speaker introduces a new tool called \"SaveData\" that writes date, item name, and item price to a database. They showcase how this tool can be used to record recommended product prices.'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bef9e481-ddd2-4273-918d-abfcfcada0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "summarize_prompt_template = \"\"\"以下の文章を簡潔に要約してください。:\n",
    "\n",
    "{text}\n",
    "\n",
    "要約:\"\"\"\n",
    "\n",
    "map_prompt = PromptTemplate(template=summarize_prompt_template, input_variables=[\"text\"])\n",
    "\n",
    "summarize_chain = load_summarize_chain(\n",
    "    llm=llm,\n",
    "    chain_type=\"map_reduce\",\n",
    "    verbose=True,\n",
    "    map_prompt=map_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "792be826-b42a-4fbc-92b6-71f182a5de71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MapReduceDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m以下の文章を簡潔に要約してください。:\n",
      "\n",
      "では早速なんですけれども始めさせて いただきます私からはラングチェイン エージェントを使って自社ツールと チャットGPTを連携するというタイトル で発表させていただきますChatGPT 自体は皆さんご存知のように非常に優れた 能力を持っていますが最新のデータに アクセスできないとか特定の数学的な推論 が得意でないなどいくつかの課題が存在し ますこれらの課題は自社プロダクトに チャートGPTを導入するなどチャット GPTを社会実装しようとした際に解決し なければなりません今回お伝えするラグ チェインエイジェントを導入すると ChatGPTと外部ツールをうまく連携 させることができるようになりChat GPTが抱える課題を克服しチットGPT の可能性をさらに広げることができます 本日はラングチェインエージェントをどう 活用することでチャットGPTの能力を 拡張できるのか具体的にご紹介していき ますそれでは始めていきますこちらが私の プロフィールとなります内容はいつもと 同じなのでスキップさせていただきます はいでは具体的な話に入る前にですね今回 のテーマの結論に先に触れておきます結論 なんですけれどもラグチェインには様々な エージェントの種類が存在するが自社 ツールとチャットGPTを効果的に連結 する際汎用的なエージェントタイプである ゼロショットリアクトまたはオAI ファンクションを利用することが簡単と なりますゼロショットリアクトとOpen AIファンクションを比較するとOpen AIファンクションの方がチットGPT からより適切かつ精度の高い答えを 引き出しやすくなっていますこちらはデモ のでお見せしますねでそしてえっとここで ChatGPTと自社ツール連携で非常に 重要となるものとしてツールの説明という ものがありますと通常のプロンプトチャト GPTを使う時のプロンプトと同様に ツールの特性や機能をChatGPTに 正確かつ効果的に伝えることで自社ツール とチャットGPTの連携の成功率が格段に 向上していきますこのポイントに着目し ながら具体的な方法論について今日は 深掘りしていきたいと思いますそれでは これらのポイントを年頭にきつつ今回の 発表をお聞きください本日の発表は以下の 3つのセクションから構成されています 初めにチットGPTの基本的な概要につい て触れます次にラングチェイン エイジェントの特徴について紹介し最後に デモンストレーションを行いますデモでは 特にツールの説明について着目して いただけると幸いですそれでは最初の トピックに移りましょうここではチット GPTの全体的な特徴を振り返っていき ますすでにご存知の内容も多いと思うん ですけれども一般的なはチャットGPTの 性質っていうものをご紹介していきます チットGPTは実用的な大規模言語モデル llmで現在多くのビジネスに活用されて きています例えばベネッセ ホールディングスでは車内AIChat ベネッセGPTを開発しグループ社員 1.5万人に向けて提供しているという ようなプレスを出していたりとか立メカ 大学では大学の英語事業において機械翻訳 とChatGPTを組み合わせたサービス が試験導入されているであったりとか他に も色々なサービスがチャトGPTを 組み込み始めておりChatGPTの実用 化っていうものがすごい勢いで広がってい ますChatGPTを活用する際によく 言われることとしてはチャットGPTから 良い結果回答を得るためには良い質問が 必要であるということですでこれは プロンプトエンジニアリングと呼ばれる 領域で今最も伸びている業種の1つと言え ますプロンプトエンジニアリングではどの ような項目をプロンプトに入れるべきか またプロンプトを複数回うまく使いこ なくして良い回答をるテクニックなどが 研究開発されていますリアクトであったり とかいろんなことを聞いたことあると思う んですけれどもプロンプトの種類っていう のがどんどんどんど開発されているという ことですでチャットGPTの活用は多に 渡っておりその可能性は広がりつつあり ますでプロンプトエンジニアリングの テクニックを活用することでチャット GPTとの適切なコミュニケーションが 可能になりますプロンプト エンジニアリングでは色々なテクニックが 存在するのですが今回はプロンプト エンジニアリング自体がメインのテーマで はないのでプロンプトエジライニングの中 で抑えるべき基本的な項目とそしてよく 使われるまフーショットプロンティングと 呼ばれるような手法を簡単にだけ紹介して いきますはいまず基礎として抑えていき たいこととしてプロンプトに何を与える べきかっていうものをいくつか紹介して いきますで1点目としては具体的で明確に 質問することですで例えばその日本の歴史 において重要な出来事は何ですかという 質問よりも日本の戦国時代における重要な 出来事について教えてくださいという具体 的に質問し方が的確なコ答が得られますと で2点目に状況やコンテクストを明示する ことですて背景情報があるとチャット GPTはコンテクストをより理解し適切な 回答が返ってきますとで3点目期待する 回答の形式を指定するとこれにより望む 情報が整理されて帰ってきますリスト形式 で返してくださいであったりとか ジェイソン形式で返してくださいであっ たりとかまそういうことを質問する時に プロンプトの中に入れるということですね で4点目範囲を限定すること範囲が広す すぎると回答も後半で一般的になりがちに なりますなので範囲を狭めるということが 重要となってきますで最後5点目自性や 認証を明確にすることですと例えば子供で も分かるようにしてくださいとか中学生で も分かるようにしてくださいとかなんか そういう風にどの視点で書て思ってみるか を示したりであったりとか何年の情報が 欲しいとかそういうことを指定することに よって回答が明確なものが帰ってきやすく なるということですで次にプロンティ テクニックの1つののフューショット プロンティについて簡単に説明します フューショットプロンティはモデルに少数 の例を示すことで特定のタスクの解決方法 を学習させるアプローチになりますこれに よりモデルは様々な問に対して適切な回答 を生成することができますここに例として 上げてるんですけれども例えばレストラン 最高でしたこれは感情ポジティブですこの 映画は本当に時間の無駄だった感情 ネガティブですというようにいくつかの例 を与えて出したいものでそれぞれの文に 対しての感情っていうものをこのように 並べていきますてで最後に聞きたいものと してそのサービスは非常に遅く不満ですっ ていうものがあった時にどんな感情で すかっていうことを聞くと感情ネガティブ という風に返ってくるというところですで こういう風にすることによってモデルって いうものが新しい文章がポジティブか ネガティブかっていうのをま過去の例を元 に判断することができるようになるという ことですでこの方法によってですねフュー ショットプロンティはモデルに多様な タスクを効率的に学習させることができ 柔軟な対応が可能になってくるということ でですでここまでいくつかのプロンティの テクニックであったりとかをお話ししてき ましたもちろん他にもたくさんあってです ねチェインオブソツであったりとかあと セルフアスクであったりとかいろんなもの があるんですけれども今回のメインテーマ ではないので一旦プロンティグの話はここ で終わりにしてでここでちょっと一息つい てですねこれらのテクニックが持つ限界に ついて考えてみましょうでまず1点目なん ですけれどもプロンプトのテクニックは 日々進化し開発されていますとこれによっ てチットGPTは多様なタスクや質問に 対応でできるようになってきていますただ 全ての作業やタスクをチャットGPTに 依存すること自体が現実的ではありません とえ例えば先ほどの例で出てきた文章から の感情抽出に関してはチャートGPTに 無理やりさせることが適切かと言われると そうでもないかもしれないAWSコプリン のような勘定分析に特化した学習をして いるAPIっていうものがあってそれを 使った方がいい結果が返ってくるかもしれ ませんっていうのがまず1つ目ですねで次 に2点目としてそのChatGPTが持つ 情報っていうものは訓練データに限定され ていてチットGPTはそれ以外のデータに ついては知らないというところですなので えっとチャットGPTは過去のデータで 学習されておりその学習データ以降に出て きた情報に関してはチットGPTに尋ね られませんとよく言われるものとしては 2021年のデータですかねまでのデータ で学習してるので例えば2022年であっ たりとか2023年のデータについて聞い たとしてもチャットGPTがうまく答え られないというようなところですね最新の 価格的な研究であったりとかニュース記事 とか特定の地域の天気情報であったりとか チットGPTの訓練データに含まれてい ないような情報っていうものはChat GPTだけでは取得できませんし インターネットにあるデータだけではなく て例えば今回のテーマである自社のツール と連携するっていう時のためには自社の データを使いたいみたいな話とかあると 思うんですけれども自社データについては チャットGPTが知るわけもないという\n",
      "\n",
      "要約:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m以下の文章を簡潔に要約してください。:\n",
      "\n",
      "とか特定の地域の天気情報であったりとか チットGPTの訓練データに含まれてい ないような情報っていうものはChat GPTだけでは取得できませんし インターネットにあるデータだけではなく て例えば今回のテーマである自社のツール と連携するっていう時のためには自社の データを使いたいみたいな話とかあると 思うんですけれども自社データについては チャットGPTが知るわけもないという ことでえっとChatGPTに自社の データについて聞いたとしてもChat GPTはもちろん答えることができません とこれらのチャGPTの限界を理解する ことでチットGPTの適切な使用方法で あったりとかそれらをどのようなシナリオ で活用するべきかっていうのが見えてくる ということですねでChatgpdの概要 の最後なんですけれどもChatgpdや その他大記号言語モデルllm自体の課題 をこちらにまとめますでまず1点目なん ですけれども先ほどと被るんですが ChatGPTは最新の情報にアクセスが できないと例えば為替や株価のように国 一刻と変化していく情報に対してチト GPTははリアルタイムで対応することが できませんで2つ目の課題としては ChatGPTが独自の情報源にアクセス する能力を持たないということです企業の データベースに保存されている顧客名簿で あったりとか特定のプライベートな情報に はアクセスすることができませんで3つ目 に水論の正確性に課題があるというところ ですチャットGPTは時折り簡単な算術 計算でさえも間違えることがありますこれ は特に正確な情報や結果が求められる タスクにおいて大きな問題となりますねで そして最後にチャットgpdができない こととかのデータが足りないんだったら ファインチューニングすればいいんじゃ ないかっていうような意見もあると思うん ですけれどもファインチューニングする ことによって汎用性が劣化してしまうと いうことがありますとでChatGPTを 特定のタスク例えば自社データを食わせる であったりとか特定のタスクに特化した データを食わせてファインチューニング すると他の多様なタスクに対する性能が 低下すると言われていますでこれらの課題 を解決するための1つの手段として今回お 話しするラングチェインエージェントって いうものがありますでここここからは ラングチェインエイジェントを使って チットGPTの性能を生かしつつ苦手な ものは他のツールで解決していくっていう ことについてお話ししていきますで参考 までにですねここにバッと上げている課題 に関してはMrKLシステムズていう有名 な論文があってそ論文から引っ張ってきた ものとなりますMrKLシステムズって いうのはミラクルシステムズと呼ぶもので チャットGPTと他のツールを連携して どんどんどんどん課題を解いていくって いうことを提示しているロムとなってい ますそれではラングチェインエージェント についてのトピックに移っていきますまず ラングチェインエージェントの前にですね ラングチェインとは何かと言うとラング チェインとは言語モデルを利用する アプリケーションのためのフレームワーク ですでラングチェインについては前回の 勉強会でもご紹介しているので基礎的な 内容を知りたい方はYouTubeで前回 の勉強会の動画をご覧くださいでラング チェインエージェントはラングチェインの 中の1つの機能なんですけれどもラング チェインの中でも非常に面白くて重要な 役割を果していますランチェの主なタスク は次にどんなアクションを取るべきかを大 記号言語モデルllmに決定させそれを 実行するということですで具体的な プロセスは以下の通りですとまず各ツール ができることと質問を指定したレスポンス のフォーマットでllmに送信します聞き ますとチットGPTなどのllmに聞き ますそしてllmChatGPTから帰っ てきたレスポンスをパースして次の アクションを決めるということをしますで このプロセスによってラングチェインジと はユーザーの4級に応じて効率的かつ正確 なアクションを実行できるようになって いるというところですでここでラング チェインエージェントがどのように動く かっていうもののイメージを具体的な例と して1つ持ってきましたま正確に正しい 動き方をしてるわけではないんですけれど も大体こういうような動きをするんだよっ ていうこともご理解ください例えばチット GPTに対してコミュニケーションを取る のがラングチェインのエージェントとなる んですけれどもラングチェイン エージェントにですねまずこう今日東京で で出かける時時に適切な服装は何ですかて いうのを聞きますでそうするとラング チェインエージェントが聞きたい内容今日 東京で出かける時に適切な服装っていう ものとあと自分が持っているツールって いうものをプロンプトに入れてチャット GPTに聞いてくれますとで自分が持っ てるツールっていうものは例えば Google検索のツールっていうも持っ てますとGoogle検索のツールでは 最新の情報を引っ張ってくることができ ますと私が持ってるのはGoogle検索 のツールで最新の情報が引っ張ってこれ ますそしてで今回聞質問としては東京で 出かける時に適切な服装って何でかていう ものを聞きますとでその時にチャット GPTはどのように返してくるかというと でまずは検索ツールでインプットは東京の 気温っっていうもので調べなさいっていう ものをエージェントの方に返してきますで エージェントはチャットGPTからから 教えてもらったじゃあえ検索ツールを使え ばいいのかっていうところで検索ツールを 使おうとしますでインプットとしては チャトGPTが教えてくれたように東京の 気温っていうものをインプットとして入れ てで検索ツールから帰ってきた22度って いうものを変してもらいますとでそして またえっとチャットGPTにえこのツール に入れた答えってものが22°でした次何 すればいいんですかであったりとか最終的 にどうなんですすかっていうのをチャット GPTに聞いてチャットGPTが十分な 情報を得たっていう風に判断するとでは 22°なので薄の長袖でがいいでしょうっ ていうものをエージェントとしに返してで あとはえ答えとしてラングチェインの エージェントが東京は22度なので素の 長袖でがいいでしょうっていうものをその まま返してくるというような流れになり ます特徴的なものとしてはチャットGPT だと今日の天気であったりとか東京の天気 であったりていうものは取れないんですね でそこをGoogle検索のツールって いうものを利用することによって新しい データっていうのを取れるようにしてると いうところですねもう1つ押えておきたい こととしてはこの問を解く時に自分が持っ ているツールっていうもの一覧を渡して どのツールを使えばいいかっていうのこと 自体もチャットGPTに判断してもらうっ ていうところが面白いところとなってい ますはいでこれがラングチェイン エージェントリアクトフレームワークとか 呼ばれたりするようなやり方ですねはい これらのこと全部ラングチェインの エージェントがやってくれるというところ ですでラングチェインエージェントって いうものは様々なタイプのエージェントが 用意されていますとここでエージェントの タイプっていうものを紹介するんです けれども解きたい課題に応じて エージェントを使い分けることによって 精度の高い回答を得られるようになると いうことですここで6個ほど上げています でまず1番汎用的なものとしてはゼロ ショットリアクトエージェントというもの ですでこのエージェントはリアクト フレームワークを利用してツールの説明に 基づいてどのツールを使用すべきか判断し ます先ほどの例で出てきたものと同じです ねこれによって特定のトレーニングデータ なしで多様なツールの適切なこう利用が 可能になってきます次にストラクチャード インプットリアクタエージェントですで このエージェントは複数の入力を使う エージェントを活用することができますで これによってより複雑なツールの理由用が 簡単になりタスクの効率が向上しますと 続いてOpenAIファンクション エージェントですこのエージェントはオ AIのファンクションコーリングの機能を 使っており関数が呼び出されるタイミング であったりとかを検出したりとか適切な 入力を関数に渡すような微調整がえオープ AI自体チットGPT自体がされていて それを使うことができますとOpenAI のえファンクションコーリングこの エージェントが使うOpenAIの ファンクションコーリングについてはこの 後のスライドでもう少し詳しく説明します で次にコンバーションエージェントですで このエージェントは会話での使用目的とし て設計されています何かを聞いて何か答え を出すっていうようなま単純なチャット GPTで何かこう答えを作ってくださいと かそういうのとは違くて会話的な インタラクションを通じて効果的な コミュニケーションを可能にするような エージェントとなっていますそして次に あげるものとしてはセルフアクwith sarchエージェントですねでそこの エージェントはですねセルフアクという 質問を自問自としながら分割することに よって正しい解を導き出す方法を使って\n",
      "\n",
      "要約:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m以下の文章を簡潔に要約してください。:\n",
      "\n",
      "GPTで何かこう答えを作ってくださいと かそういうのとは違くて会話的な インタラクションを通じて効果的な コミュニケーションを可能にするような エージェントとなっていますそして次に あげるものとしてはセルフアクwith sarchエージェントですねでそこの エージェントはですねセルフアクという 質問を自問自としながら分割することに よって正しい解を導き出す方法を使って 情報を検索するエージェントですセルフア クっていうプロンティグの技術があるん ですねまそれを使ってちゃんとした正しい 答えを導き出すエージェントとなってい ますで最後に紹介するものがリアクト ドキュメントストアエージェントですで このエージェントはドックストア ドキュメントストアですねと対話するため にリアクトフレームワークを使用してき ますえこれによって文書の管理であったり とか検索が一元化されて効率的に情報 アクセスが可能となりますこちらに関して はまた今後の勉強会でも取り扱っていき たいかなという風に思ってるんですけれど も文書検索管理っていうものに特化した エージェントとなっていますで以上がラン チェインエージェントの各エージェントの 使用となりますでそれぞれのタイプが 異なるシナリオやタスクに適しており ラングチェインの柔軟性と多様性を象徴し ているものとなります今回のセッションで はですね最も汎用的なゼロショット リアクトとチャットGPT自体に色々判断 させるファンクションコーリングを使った オープAIファンクション2を利用して いき ますでは先ほど説明を省いてしまったん ですけれどもOpenAIファンクション コーリンググっていうのはOpenAI ファンクションコーリングじゃないですね OpenAIファンクションですね OpenAIファンクションとは何か エージェントタイプの1つであるOpen AIファンクションとは何かについてお 話ししますこちらはChatGPTを提供 しているOpenAIのファンクション コーリングという機能を利用していますで ファンクションコーリングっていうものは 2023年の6月にリリースされた機能で ラングチェインエージェントが担っていっ たツールを渡してチャットGPTに聞いて 次のステップを決定するやり取りってい ものをチットGPT自体が行えるように ファインチューニングされているものと なりますでこの機能では東京の天気を教え てくれというような先ほどと同じように ですね質問と共にどういう関数を持って いるのかその関数の説明をチトGPTに 直接投げるということをやりますなので 先ほどのラングチェインエイジェントが やってることと同じようなことをやれる ようになっていてチットGPTが ファンクションをどのように受け取るのか そのファンクションのパラメータであっ たりとか説明とかをよりチャトGPTが 理解しやすいようにAPIとして受け取る ことができるようになっているのでより 適切な判断をチャットGPTがしやすく なっているというところがメリットとなり ますなので今メリットをお話ししてしまっ たんですけれどもファンクション コーリングを使うメリットとしては ChatGPTにツールの挙動をより正確 に伝えやすくなっているというところで これによってChatGPTが機能の ツールのえファンクションの使用や動作を より正確に理解しやすくなっていて適切な 判断をしやすくなっているとていうのとで もう1つのメリットとしてはチャット GPTっていうものがラングチェイン エージェンドって元々チャットGPTが 返してきた個体を利用者が頑張って定期 表現を使って解析する必要があったんです がそれをする必要がなくなったっていう ところが利点としてありますとでチャット GPTが実際にラングチェインを使って どのツールを使えばいいですかていうのを 聞くんですけどそれをどのようにパースし てるかというとこのように頑張ってですね えっとレギュラーエクスプレッションを 使って正規表現を使ってパースしたりとか して次のアクションを決めてたりするって いうのがラングチェが今までやっていた ことであるとでこういうパースをしなきゃ いけないっていうことをしなくて済む つまりパースしなきゃいけなかったので今 まではそのパースすることでえっとうまく パースできなくてミスってしまうっていう こともあったんですけどそういうことが なくなるっていうことが期待されるという ところです はいはいちょっと駆け足になってしまった んですがここまでで20分ぐらいかかって しまいましたねえここからがレモに入り ますで実際にですねラングチェイン エージェントを使ってチャトGPTと自社 ツールを連結するような感じのえデモって いうものをお見せしていきますで使う エージェントとしてはゼロショット リアクトとオーエファンクションを使って いきますであとは今回のプレゼンの冒頭の 方でもお話ししたようにChatGPTに ツールの説明をどのように渡せばいいのか であったりとかその辺りを持ち替えて いただければ幸いです はいではではやっていきますちょっと時間 がなくなってきたので駆け足でいきますね でまずは設定ファイル読んでいきますこれ 何をやってるかと言うとえOpenAIの APIキーであったりとかを読んでいます でまずはですねえっとゼロショットの方を 見せしていきたいんですがおマジないとし てですねおじないというかま前回の勉強会 と同じようにですねラングチェイン エージェントを使うためのやり方をお見せ していきますで実際今回使うモデルとして はチットOpenAPAIというか ChatGPTのえGPT3.5のtbo 0613というものを使っていきますで 外部のツールとしてはGoogleサーチ のAPIっていうものを今回用意しました ここであのサプAPIっていうものを書い ているものがえGoogleのAPIと なりますで聞きたい質問としては今日の 東京と北海道の天気を調べて東京から 北海道の出張で来ていくべきを教えて くださいっていうものを聞きたいと思い ますでラングチェインエージェント自体を 走らせてみますでこれがゼロショット リアクトエージェントを使った場合どの ようになるかっていうのをお見せしますで エージェントタイプに関しては イニシャライズエージェントの エージェントっていうえ引数に対して エージェントタイプのこのゼロショット リアクトディスクリプションていうものを 渡すとエージェントを選択することができ ますちなみになんですけれどもえこれって ただあの文字列が返ってくるだけですかね あのゼロショットリアクト ディスクリプションていうものが返って くるだけのものになりますなので文字列で 与えても同じですはいでは実行してみ ましょうチトgpdはもちろん今日の天気 とか今日の東京とか北海道の天気っていう のは知らないので来ていくべき服装って いうことは分からないわけですね気温も 分からないのででこれでラングチェイン エージェントが私はGoogle検索の ツールを持ってますよでそれを使って使う ことができますでこの問題課題っていう ものを解くためにはどうすればいいですか てのを聞くっていうことですねでここで ざーっと出てきてるんですけれども実際に 書いてきた答えとしてはtheWisto isCloudyaboutcrear withtempof歌詞になっちゃって ますけどまこのように帰ってきますと 英語で帰ってきちゃってますねでこういう 風にえどんなアドレスをれ切ればいい かっていうものがちゃんと帰ってきてい ますと前にやった時はそんなに綺麗に帰っ てきてなかったんですけれども今回は うまく帰ってきていますはいこちらがゼロ ショットリアクトディスクリプションで やった場合の結果になりますでどういう ことをやってるかっていうのなこの辺りを 見ていただくといいのかなという風には 思いますでチットGPTにまずラング チェインエージェントが問題とツールを 渡してチットGPTに何をすればいい かっていうのを聞きますでチャットGPT から帰ってきた答えとしては次の アクションとしてはサーチをしてください ですサーチのインプットとしてはウザー 東京todayていうものを渡してくださ いっていうのを渡してますで次の アクションとしてはサーチをしてください でそのインプットとしてはウザ北海道 todayていうものを渡すようにして くださいとで最終的にその帰ってきた答 っていうものをチャットGPTに渡して 最終的な文が出てくるということですはい でこれが1つ目ですねアエージェント タイプ1つ目のえゼロショットリアクト ディスクリプションで元々ラングチェイン エイジェントがリアクトフレームワークで ツールを渡したりとかしてチャットGPT とうまく連携しながら外部ツールを使う ようにしたえ機能となっていますでこれが ですねえ最近出てきた6月にリリースされ たOpenAIのファンクションコーリン グっていうものを使うとどうなるかって いうのをお見せします はいでOpenAIファンクション OpenAIのファンクションコーリング を使うためにはエージェントタイプの OpenAIファンクションズっていう ものを渡しますでそうするとえこのように 動きますで実際にやってることとしては ラングチェインエージェントがOpen\n",
      "\n",
      "要約:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m以下の文章を簡潔に要約してください。:\n",
      "\n",
      "たOpenAIのファンクションコーリン グっていうものを使うとどうなるかって いうのをお見せします はいでOpenAIファンクション OpenAIのファンクションコーリング を使うためにはエージェントタイプの OpenAIファンクションズっていう ものを渡しますでそうするとえこのように 動きますで実際にやってることとしては ラングチェインエージェントがOpen AIのファンクションコーリングっていう ものを使ってうまくチャットGPTと やり取りしながら答えを導き出していくっ ていうことをやっていますはい出てきた 答えはこちらですねで同じようにですね どのようにやっているかっていうものは ここら辺の途中で出てきているんです けれども途中結果でえサーチとしてはえ クエリー東京の今日の天気っていうものを 調べてくださいでサーチっていうツルを 使って今日の北海道今日の天気っていう ものを調べてくださいでこれらが帰ってき た答えっていうものをえチャットGPTに 返してチャトGPTがその与えられた情報 を元に東京の今日の天気は曇りですが後に は晴れる予報ですで気温は接し30°歌 86°でコス確率はどうのこうのっていう ものがあってであとは東京は暑くなる可能 性があるので軽い服装が適しています ただし北海道は比較的涼しいので ジャケットなどを持っていくことがお勧め しますというような感じに帰ってきてます ま見て分かると思うんですけれどもま日本 語にな質問が日本語だったので日本語で ちゃんと返してくれるっていうのは もちろんのことなんですけれども書いてき た答えっていうものに関してより詳しく 返してくれているっていうことが分かると 思いますなので使ってみた所管としては ですねここで言うオAIファンクションの ファンクションコーリングっていうのの ファンクションっていうのはラング チェインエージェントでいうツールと同じ なんですけれどもそのファンクションで あったりとかツールを渡す時にですね渡し て何かを判断判させたいチャットGPTに 判断してもらいたいっていう時はえ エージェントタイプゼロショットリアクト ディスクリプションよりもエージェント タイプオAIファンクションの方がより いい結果が返ってきやすいっていうことが 分かると思い ますもう少しあの詳しく見ていきます ちなみにですねOpenAIにどんな ファンクションを渡してるかっていうのは イニシャライズエージェントのところで エージェントを定義してるんですけども そのエージェントの中からエージェントっ ていうものとファンクションズってものを 実行するとどんなえファンクションが渡さ れてかっていうのを見ることができますで 今回渡されたファンクションっていうのは ネームサーチっていうファンクションが 渡されていてどんなことができるかって いうのでサチエンジンですっていうような ものをやってますであとはパラメーターと してはこういうものを渡していきますって いうのが分かりますとはいでここまでが 基本的なラングチェインエージェントを 使って外部ツールを連携するっていうお話 をしてきましたとで次にですねえ自社で 作ったツールっていうものを連携させ るっていところについてお見せしていき ますで一旦はですねレコメンドアイテムっ ていうものを考えてみようと思いますで ここ何をやりたいかって言うとレコメンド アイテムまこの中身はほとんど意味のない ものになってるんですけれどもレコメンド アイテムっていう関数を自社で持っていて でレコメンドアイテムっていうものは自社 のデータベースなどにアクセスして日付を 持ったにこの日のレコメンドっていうもの はこういうものですっていうものを返す ような関数っていうところになりますとな のでえっとこのレコメンドアイテムって いうところをこの関数ををえChat GPTのフローの中に組み込みたいって いうことをやっていきますでどのように ラングチェインエージェントを使って ChatGPTに連携すればいいかという とツールっていうものにえ変換していく 必要がありますとでレコメンドアイテム ツールっていうものをえツールfrom ファンクションズっていうものを使って どのようなファンクションを実行したい ですかレコメンドアイテムっていう ファンクションを実行したいですまこう いう風にですねこの今回のあまり意味の ないファンクションなんですけれどもこれ を実行しますとでツールの名前としてはえ レコメンドアイテムっていうものを渡し ますでツールのディスクリプション何を やってくれるかっていうことに関してはお すめの商品を教えてくれますっていうのを ツールとして定義するというところです はいでこれをちょっとツールズっていうま ツールまとめて渡さないといけないで ツールの配列の中に入れておきます実際に ですねラングチェインエージェントにどの ようにツールを渡せばいいかっていうとま 先ほどもカラっとやってたんですけれども このツール1覧っていうのを最初に渡して 引数として渡しているのでまこのようにし てどんなツールが使えるかっていうものを ラングチェインのAに渡しでチャット GPTと連携していきますはいでえっと 今回聞きたいこととしてはえおすすめの 商品を教えてくださいっていうものを投げ てみようと思いますで使うエージェントと しては先ほどゼロシトリアクトよりもより いい結果が返ってきたオーエ ファンクションズってものを選びます はいはいでは実行し ますはいで書いてきたものとしてはですね コメドアイテムってものが実行されて withファッションという謎のものをえ 入力に入れてで実際この引数がですね デートの中にファッションが入ってで プリントファッションっていうところでこ でファッションが出てきてしまってるとで ただおすめの商品は今回レコメンド アイテムで書いてきたAppleですって いうのが書いてきてることが分かると思い ますはい見て分かるようにですねなんか よくわからない引数は与えてしまってる なっていうところがありますでこを どんどん解決していこうと思いますで次に やることとしては今回なんでこのように変 なファッションとかいう引数を与えて しまったかというと引数に関する情報が ないんですね与えられてないというところ になりますとなので引数何与えればいいん ですかみたいなところが情報としてないが ゆえにチャットGPTもレコメンド アイテムを使うことは分かるとレコメンド アイテムを使えばいいのは分かるんだけど レコメンドアイテムに対してちょっと 分からないからカテゴリー情報でも渡して みようかなっていうのでファッションを 渡してしまっているというような状態に なりますで例えばまファンクションを見た としても今回使ってるファンクションに 関してはレコメンドアイテムでおすめの 商品を教えてくれますでパラメーターの 情報は全くありませんっていう状態なので どんなパラメーターを渡せばいいかって いうのはオープAIファンクションは 分からないというところですねじゃあこれ に対してどうすればいいかっていうのをお 見せしますでえっと結構簡単でしてパダ ティックっていうものをご存知ですかね こう最近えっとファストAPIとかですか ねこう結構パであったりとかそのヒントを 与えるっていうことがまPython主流 になってきてると思うんですけれども フダンティックを使っていきますでえっと ご注意していただきたいこととしては ファインディッてもうV2が出てるんです けれどもV2を使うとラングチェイン エージェントを動きませんとなので パティックV1を指定して方に関する情報 をえ与えるためのそのベイスモデルとか フィールドを使ってえやっていきますで これ何をやってるかと言うとま今回の インプットに対してデイトっていうものが ありますがデイトていうものはお勧めした 商品を絞るために使われる日付ですって いうものを与えていますこれをえっと アーグススキーマ先ほどのツールを定義 する時にアグススキーマっていう引きを 使ってこのレコメンドアイテムインットっ ていうベースモデルから継承した レコメンドアイテムインプットっていう インプットの報引数の情報を持ったクラ スっていうものを渡すということをします とでこうするとどうなるかっていうのをお 見せしていき ますはいじゃあどう変わる かいきますはい実行します全く同じですね 実行するものとしてはで今回はレコメンド アイテムっていうものに対して先ほどと 同じレコメンドアイテムっていうものが 選ばれましたとコアイテムに対してデイト が2020年の12月1日っていうものを 渡しているっていうことが分かりますで それによってですね気付がちゃんと渡して くれたっていうことがわか分かるわけです ねで今回あのここであのデートっていう ものはディスクリプションでお勧めしたい 商品を絞るために使われる日付っていう ことを伝えたのでチャットGPTの方があ これは日付のことなんだっていうところで 引数はファッションのようなカテゴリーを 渡すんではなくてデートの引数っていう ものを渡すことができてるというところ ですはいでこちらがデトのまあ2022年 の12月1日もはや日付が意味が分から ないですけれどもこういうものが渡されて いるというところですねでおすめ商品は Appleですという風にでこういう風に\n",
      "\n",
      "要約:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m以下の文章を簡潔に要約してください。:\n",
      "\n",
      "ことを伝えたのでチャットGPTの方があ これは日付のことなんだっていうところで 引数はファッションのようなカテゴリーを 渡すんではなくてデートの引数っていう ものを渡すことができてるというところ ですはいでこちらがデトのまあ2022年 の12月1日もはや日付が意味が分から ないですけれどもこういうものが渡されて いるというところですねでおすめ商品は Appleですという風にでこういう風に ですねこうツールの説明をどんどん どんどん入れていってええ解決していく 必要があるというところですねで同じよう にですねちょっとエージェントの ファンクションがどのように渡されるてる かっていうのをお見せしますとで今回渡さ れたのはレコメンドアイテムインプトって いうのをえパイダンテックの方で定義して 渡しているのでえ実際にえっと ファンクションOpenAIのえ ファンクションコーリングにどのように 渡されてるかというとパラメーターとして ですねこういう風なレコメンドアイテム インプットっていうものが渡されていて プロパティとしてはデートがあってデー トっていうのはお勧めしたい商品を絞る ために使われる日付っていうものが入れ られてえ飛ばされてるということが分かる と思いますはい で他にはですねこのようにツールフロン ファンクションで作るっていうこともある んですけれども同じようにですね デコレーターを使うっていうこともでき ますとデコレーターの方が結構シンプルに 書けるので私は結構デコレーターを使って 書くことが多いですとでデコレーター何を すればいいかというとデコターっていうの はま関数の前にですねアマークツールなん ちゃらかんちゃらっていうものがあってで それを使ってえっとこのツールってのは何 ができるかっていうものをえドッ ストリングで与えるんですねな先ほどと 同じにするとレコメンドアイテムツールっ ていうものがあったら中身は同じですね プリントデイトとAppっていうものを 返しますとプリントデイトしてApple っていうものを返しますとででやることと してはおすめ商品を教えてくれます全く 同じ内容ですねでこのツールの名前って いうものはデコレーターの引数として レコメンドアイテムとして渡していると いうところですで同じようにですね ツールズの一覧として入れてでこれをえ 実行してみ ましょうはいこれデコレーター使った場合 です ね実行するものは全部同じですで同じよう にこれも実行できますという風にデコレー ターってかなりこうシンプルにかけてで ファンクションの中のドックストリングス とかを使ってくれるので結構あの家読性と かもう悪くないかなという風には思います 先ほどと同じようにですねこレコメンド アイテムってものはちゃんと選んでくれた んですけれどもレコメンドアイテムに渡し ているデートっていうのは2021年10 月15日という意味の分からない日付を 渡してしまっていますとこれはなぜかと言 とまもちろんそのおすすめ商品を教えて くださいって言ってるので勝手に日付を 決めて聞いてしまっているというところ ですね はいでデコレーターの方もですね同じよう にファンクションを見てみるとえっとこう いう風になるという感じですねただあの 先ほどと同じようにですねパダンティック とか使っていないのでプロパティの パラメーターとかは適当になってしまって いるというような感じになりますただ今回 の場合はですねこうデコレーターの場合は フロムファンクションの方を使ったこっち の場合ですねこのフロムファンクションを 使った時と違ってきちんとデートを入れて くれているっていうことが特徴的かなと いう風には思いますフロンファンクション を使った場合っていうのはパダンティック を渡さないとデートっていうものに対して ファッションを入れたりとかよく分から ないものを入れたりすることがあったと 思うんですけれどもデコレーターを使った 場合はこのデートっていうものを渡した時 にきちんとこうデートを返してくれるよう な情報っていうものを渡せてくれている ような感じですねいずれにせを正しい共同 を求めるためにはこのままあまり情報を 与えないで実行するってのは適切ではない ので特に自社ツールサービスとして提供 する側としてはですねなのでそういう意味 ではきちんとバイダンティックなどを使っ て適切な情報を渡しながら関数っていう ものを渡していく必要があるかなという風 に思いますなのでえっと先ほどと同じよう にですねデコレーターを使った場合も パイナティックの情報っていうものを渡す ことができるのでデコレーターの引き数に アーグススキーマていうものを渡してで そのパイランティックの情報を渡すことで 適切な答えを返すことができるようになる というところです同じようにですねま結果 も変わらないので はいまこういう風に変えてきました ちょっと答えがどんどんどんどん変わって きてますApple製品だったりとか AppleStoreとかオンライン ショップとかうんまここら辺に関しては 本当に適切な答えがまだ返ってきてない なっていうような状態だとは思います エージェントのファンクションを見るとえ きちんとファナティックで渡した情報って いうのが渡っていることが分かると思い ますこのようにですねこのデートっていう ものはデートっていう引き数はお勧めし たい商品を絞るために使われる日付ですっ ていうのが渡っているというところです もう少しですね今までこうおすめの商品を 教えてくださいっていう風に言っていたの でデートっていうものが1月10日であっ たりとかよくわかんない日付になっていた のではないかっていうことを推測してでは 昨日のおすすめ商品を教えてくださいって いうものを聞いてみますてそうするとどう なるかと言うとえ昨日のおすめ商品を教え てくださいって言ってるのにレコメンド アイテムに渡されてるのは2021の10 月20日っていうものが渡されれてること が分かりますとチャットGPTにこう昨日 とか今日とか昨日とか渡したら日付を ちゃんと入れてくれるのかなと期待するっ ていうことがあると思うんですけれども 実際はそんな入れてくれないっていうこと がまこの結果から分かるということですね もう少し例えばディスクリプションとかを 適切にすればうまくいくのかもしれないん ですけど今回は違う手段でえっと解決 しようと思いますで今回どういう風に解決 するかと言うとデートタイムを使って 新しい日付けを取得するような関数自社 ツールってものを設けようと思います ゲットデートっていうツールっていうもの を作ってでそのツールは何をするかという とま今日や昨日など日付を取得する時に 使います引き数には今日を起点として何日 か前をNで与えますとでここのそのドック ストリングスにですねこう引数に関する 情報を書いてるんですけども実際はですね パダンティックで引き数の説明した方が ベタだとは思いますただえっとドック スリンに書いてツールの説明として与える だけでも結構チャットGPTは賢いので うまく判断してくれるということですでお 見せしますはいこの日付関数を入れると どうなるかと言うとこういう風な感じです ねはい今日のおすめの商品を教えてくださ いっていう風にするとtodayて書い てき来てこれもうまく動いてないですね こういうことが結構ありますとうまく動か ないことがあるとでもう1回実行してみ ましょうかはいでもならではですね ちょっと30分で終える予定が46分に なってしまったんですがもう少しで終わる ので続けます前回のやつだとですね直接 レコメンドアイテムを呼び出してデートに 対してtoデイていうものを渡してしまっ てたんですけれども今回はうまく動いてい てまずは日付を取得するためにゲットデイ トっていうものを呼び出しますとで今日な ので今日からの起点のえN日前だったらN に0を渡せばいいということが分かるとだ からゲットデートに0を渡して帰ってきた ものが2023年の9月30日っていう ものが帰ってきてで9月30日のえお勧め 商品は何ですがま書いてくるものは全部 AppleなのでAppleってものが 帰ってきてることが分かると思います同じ ようにですねじゃあどういう ファンクションが渡されてたかっていうの をお見せするとサクっとですねで今回あの ファンクション2つ渡されていて レコメンドアイテムっていう ファンクションとゲットデイトっていう ファンクションが渡されていますで それぞれのファンクションの説明がこの ように与えられているということが分かり ますもう少しツールを複雑にしていって ですね奇数日だったらオレンジ偶数日だっ たらえAppleっていうものを返すよう なツールにちょっとだけレコメンド アイテムを変えみようと思い ますはいではえこれを実行するとですね 今日はえ9月30日なのでもちろん9月 30日偶数日ですね偶数日なので Appleが返ってくるきちんと帰ってき ますねAppleが帰ってきましたでは 昨日の場合はどうなのか 昨日はい昨日の場合は29日なので1日前 ってものをゲットデイトで取得して29日 ってものが書いていますで29日を使って え昨日のおすめ商品オレンジっていうもの を取ることができるというところ ですやとうまく動きました ねでもう少しだけちょっと時間が1時間 ぐらい喋ってしまうような感になるんです\n",
      "\n",
      "要約:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m以下の文章を簡潔に要約してください。:\n",
      "\n",
      "Appleが返ってくるきちんと帰ってき ますねAppleが帰ってきましたでは 昨日の場合はどうなのか 昨日はい昨日の場合は29日なので1日前 ってものをゲットデイトで取得して29日 ってものが書いていますで29日を使って え昨日のおすめ商品オレンジっていうもの を取ることができるというところ ですやとうまく動きました ねでもう少しだけちょっと時間が1時間 ぐらい喋ってしまうような感になるんです けれどもう少しだけお話させてくださいで これだけだともちろんまだまだ連携が 少ないかなっていうところがあってで次に じゃあAppleだったら100円 オレンジだったら200円っていうような ものを商品の値段を返すような関数って いうものを組み込んでみましょうでツール としては元々グビだったらAppleキビ だったらオレンジを返すようなものとあと は日付を取得するツールであとは今回定義 したAppleとオレンジAppleだっ たら100円オレンジだったら200円 っていうのを返すツールっていうものを 定義しますでこれでエージェントのですね おすめの商品の値段まで教えてくださいっ ていうことをやるとそうするとまず最初に え昨日なのでゲットデートでN=1を渡し て1日前のデートを取ってきますで9月 29日ですで次にレコメンドアイテムって いうツールを呼び出してレコメンド アイテムにえ9月29日を渡してで最後に ですねアイテムプライスっていうので アイテムネームをえオレンジにとして渡し てでオレンジはは200円なのでえ昨日の おすめ商品であるオレンジの値段は 200円ですっていう最終的な答えが返っ てきましたというところになりますだいぶ 柔軟なものができるようになってきたって いうことが理解できると思いますで他には ですね最後なんですけれども取得した結果 を吐き出したいとかデータベースに 書き込みたいとかあったりすると思うん ですけどもそういうことももちろん簡単に できますと基本的にはファンクションが あってそのファンクション中身は自分で 書いていくので何でもすることができると いうところですねちょっとあの output.tchっていうところに 書き込むようなものを記事的にですね データベースに書き込んでいるようなもの として紹介しようと思いますで今回は さらに追加するツールとしてはですね セーブデータっていうツールを追加します とセーブデータっていうものは何なのかと いうとここにも説明書いてあるんです けれども日付と商品名と商品の値段を 受け取ってデータベースに書き込みますっ ていうようなものをツールとして作りまし たデータベースといながらもアウトプット テキストにただ書き込むだけのものになる んですけどもデートアイテムネーム アイテムプライスを書き込むだけのツール となりますま実際に自社ツールを使う時に はここにSQL分であったりとかを書いて データベスに書き込むとかをやったりする ことになると思いますこちらもですね ちょっと簡易的にですねフダンティックを 使わずにえドックストリングだけで何を やるかってのを渡して書き込めるかどう かってのをお見せしていこうと思いますで 同様にですね同じように何をしたいかと 言うと今日のおすめ商品の値段を調べて データベースに書き込んでくださいって いうことを実行し ますで最初に動くものとしてはまず日付を 取得するゲットデイトが動いてN=0で 今日の日付を取ります9月30日ですと9 月30日が取れたら9月30日の レコメンドアイテムは何ですかていうので レコメンドアイテムのツールを起動して 書いてきたものがAppleですとであ次 にやることしてはAppleの値段は いくらですかていうものをアイテム プライスに聞いてアイテムプライスが返し てきた答えが100円ですとで100円 っっていうものをえセーブデータに渡して セーブデータに渡すものとしてはデートと アイテムネームとアイテムプライスこれは 日付と商品目と商品の値段を受け取 りっていう風に書いてあるのでこういう ようなものを基数として与えて データベースに書き込みますていうことを この操作でやるということですねなので 細かいことを書いた方がミスは少ないん ですけれどもあんまり書かなくても動いて くれるっていうのがまやっぱりこう チャットGPTのうまいところかなという 風には思いますで最終的に帰ってきたこと としては今日のえおすすめ商品の値段は 100円ですとでデータベースに正常に 書き込まれましたっていうので データベースではないんですけどれも テキストファイルっていうものを中身見て みましょうと今日の日付2023年9月 30日でおすすめの商品Appleで最終 的に100円っていうのが書き込まれた ことが確認できましたとはいとても長く なってしまったんですけれどもこちらで テモは終わりとさせていただきたいと思い ますはい私の発表は以上となります ありがとうございました\n",
      "\n",
      "要約:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\"本発表では、ラングチェインエージェントを使用して自社ツールとチャットGPTを連携させる方法について説明されています。チャットGPTは優れた能力を持っているが、最新のデータにアクセスできないなどの課題があるため、ラングチェインエージェントを導入することでこれらの課題を解決し、チャットGPTの可能性を広げることができると述べられています。プロンプトエンジニアリングやフューショットプロンティなどのテクニックも紹介されていますが、チャットGPTにすべてのタスクを依存することは現実的ではなく、最新の情報には限界があると指摘されています。\n",
      "\n",
      "Chat GPTは、特定の地域の天気情報や他のデータを取得できないため、自社のツールと連携する際には自社のデータを使用する必要がある。また、Chat GPTは最新の情報にアクセスできないため、為替や株価のようにリアルタイムに変化する情報に対応できない。さらに、企業のデータベースやプライベートな情報にはアクセスできないため、正確性にも課題がある。これらの課題を解決するためには、ラングチェインエージェントを使用してChat GPTと他のツールを連携させることができる。\n",
      "\n",
      "GPTは会話的なインタラクションを通じて効果的なコミュニケーションを可能にするエージェントであり、セルフアクションやリアクトドキュメントストアといった機能も持っている。また、OpenAIファンクションコーリングを使用することで、ツールの挙動を正確に伝えることができる。\n",
      "\n",
      "OpenAIのファンクションコーリングを使って、OpenAIのファンクションコーリングを使ってチャットGPTとやり取りしながら回答を導き出すことができる。具体的には、東京の今日の天気やおすすめ商品などの情報を取得して返答することができる。また、パラメーター情報を渡すことで、より具体的な結果を得ることができる。パディングを使用して情報を与えることもできる。\n",
      "\n",
      "チャットGPTは日付を引数として受け取ることができ、デートの引数を使っておすすめ商品を返すことができる。デコレーターやツールフロンファンクションも使えるが、デコレーターの方がシンプルで使いやすい。ただし、日付を正しく渡す必要がある。また、ゲットデートというツールを使って日付を取得し、それを使っておすすめ商品を返すこともできる。\n",
      "\n",
      "Appleが返ってきたので、昨日のおすすめ商品を取得するために日付を利用し、オレンジの値段を取得しました。また、関数を組み込んで商品の値段を返すツールを追加しました。さらに、データベースに書き込むツールやセーブデータのツールも作成しました。最終的に、今日のおすすめ商品の値段をデータベースに正常に書き込みました。\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "summary_output = summarize_chain(split_youtube)[\"output_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2689a91b-cc84-4289-9425-97ef5050d03c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"This presentation discusses the use of LangChain Agent to integrate a company's own tools with Chat GPT. Chat GPT has limitations such as lack of access to real-time data and inability to access private information. LangChain Agent helps overcome these limitations and expands the potential of Chat GPT. Techniques like prompt engineering and fusion-shot prompting are introduced, but relying solely on Chat GPT for all tasks is not realistic. The presentation highlights the need to use LangChain Agent to connect Chat GPT with other tools. OpenAI's function calling is used to accurately convey tool behavior and obtain specific results. Chat GPT can receive date inputs and provide recommendations based on them. Decorators and tool function front-end can be used, with decorators being simpler and more user-friendly. The presentation showcases the use of date inputs to retrieve recommended products and obtain prices. Additionally, tools for writing to databases and saving data are created, successfully writing today's recommended product prices to the database.\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade72201-29f4-41ec-9e19-6f10955812fc",
   "metadata": {},
   "source": [
    "## QA Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "39c9a03f-2fae-4c2f-85df-81b9e76d1a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.question_answering import load_qa_chain\n",
    "\n",
    "qa_chain = load_qa_chain(llm=llm, chain_type=\"map_reduce\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8ca56c-ffd0-4f30-82ff-857de13cece1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MapReduceDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "では早速なんですけれども始めさせて いただきます私からはラングチェイン エージェントを使って自社ツールと チャットGPTを連携するというタイトル で発表させていただきますChatGPT 自体は皆さんご存知のように非常に優れた 能力を持っていますが最新のデータに アクセスできないとか特定の数学的な推論 が得意でないなどいくつかの課題が存在し ますこれらの課題は自社プロダクトに チャートGPTを導入するなどチャット GPTを社会実装しようとした際に解決し なければなりません今回お伝えするラグ チェインエイジェントを導入すると ChatGPTと外部ツールをうまく連携 させることができるようになりChat GPTが抱える課題を克服しチットGPT の可能性をさらに広げることができます 本日はラングチェインエージェントをどう 活用することでチャットGPTの能力を 拡張できるのか具体的にご紹介していき ますそれでは始めていきますこちらが私の プロフィールとなります内容はいつもと 同じなのでスキップさせていただきます はいでは具体的な話に入る前にですね今回 のテーマの結論に先に触れておきます結論 なんですけれどもラグチェインには様々な エージェントの種類が存在するが自社 ツールとチャットGPTを効果的に連結 する際汎用的なエージェントタイプである ゼロショットリアクトまたはオAI ファンクションを利用することが簡単と なりますゼロショットリアクトとOpen AIファンクションを比較するとOpen AIファンクションの方がチットGPT からより適切かつ精度の高い答えを 引き出しやすくなっていますこちらはデモ のでお見せしますねでそしてえっとここで ChatGPTと自社ツール連携で非常に 重要となるものとしてツールの説明という ものがありますと通常のプロンプトチャト GPTを使う時のプロンプトと同様に ツールの特性や機能をChatGPTに 正確かつ効果的に伝えることで自社ツール とチャットGPTの連携の成功率が格段に 向上していきますこのポイントに着目し ながら具体的な方法論について今日は 深掘りしていきたいと思いますそれでは これらのポイントを年頭にきつつ今回の 発表をお聞きください本日の発表は以下の 3つのセクションから構成されています 初めにチットGPTの基本的な概要につい て触れます次にラングチェイン エイジェントの特徴について紹介し最後に デモンストレーションを行いますデモでは 特にツールの説明について着目して いただけると幸いですそれでは最初の トピックに移りましょうここではチット GPTの全体的な特徴を振り返っていき ますすでにご存知の内容も多いと思うん ですけれども一般的なはチャットGPTの 性質っていうものをご紹介していきます チットGPTは実用的な大規模言語モデル llmで現在多くのビジネスに活用されて きています例えばベネッセ ホールディングスでは車内AIChat ベネッセGPTを開発しグループ社員 1.5万人に向けて提供しているという ようなプレスを出していたりとか立メカ 大学では大学の英語事業において機械翻訳 とChatGPTを組み合わせたサービス が試験導入されているであったりとか他に も色々なサービスがチャトGPTを 組み込み始めておりChatGPTの実用 化っていうものがすごい勢いで広がってい ますChatGPTを活用する際によく 言われることとしてはチャットGPTから 良い結果回答を得るためには良い質問が 必要であるということですでこれは プロンプトエンジニアリングと呼ばれる 領域で今最も伸びている業種の1つと言え ますプロンプトエンジニアリングではどの ような項目をプロンプトに入れるべきか またプロンプトを複数回うまく使いこ なくして良い回答をるテクニックなどが 研究開発されていますリアクトであったり とかいろんなことを聞いたことあると思う んですけれどもプロンプトの種類っていう のがどんどんどんど開発されているという ことですでチャットGPTの活用は多に 渡っておりその可能性は広がりつつあり ますでプロンプトエンジニアリングの テクニックを活用することでチャット GPTとの適切なコミュニケーションが 可能になりますプロンプト エンジニアリングでは色々なテクニックが 存在するのですが今回はプロンプト エンジニアリング自体がメインのテーマで はないのでプロンプトエジライニングの中 で抑えるべき基本的な項目とそしてよく 使われるまフーショットプロンティングと 呼ばれるような手法を簡単にだけ紹介して いきますはいまず基礎として抑えていき たいこととしてプロンプトに何を与える べきかっていうものをいくつか紹介して いきますで1点目としては具体的で明確に 質問することですで例えばその日本の歴史 において重要な出来事は何ですかという 質問よりも日本の戦国時代における重要な 出来事について教えてくださいという具体 的に質問し方が的確なコ答が得られますと で2点目に状況やコンテクストを明示する ことですて背景情報があるとチャット GPTはコンテクストをより理解し適切な 回答が返ってきますとで3点目期待する 回答の形式を指定するとこれにより望む 情報が整理されて帰ってきますリスト形式 で返してくださいであったりとか ジェイソン形式で返してくださいであっ たりとかまそういうことを質問する時に プロンプトの中に入れるということですね で4点目範囲を限定すること範囲が広す すぎると回答も後半で一般的になりがちに なりますなので範囲を狭めるということが 重要となってきますで最後5点目自性や 認証を明確にすることですと例えば子供で も分かるようにしてくださいとか中学生で も分かるようにしてくださいとかなんか そういう風にどの視点で書て思ってみるか を示したりであったりとか何年の情報が 欲しいとかそういうことを指定することに よって回答が明確なものが帰ってきやすく なるということですで次にプロンティ テクニックの1つののフューショット プロンティについて簡単に説明します フューショットプロンティはモデルに少数 の例を示すことで特定のタスクの解決方法 を学習させるアプローチになりますこれに よりモデルは様々な問に対して適切な回答 を生成することができますここに例として 上げてるんですけれども例えばレストラン 最高でしたこれは感情ポジティブですこの 映画は本当に時間の無駄だった感情 ネガティブですというようにいくつかの例 を与えて出したいものでそれぞれの文に 対しての感情っていうものをこのように 並べていきますてで最後に聞きたいものと してそのサービスは非常に遅く不満ですっ ていうものがあった時にどんな感情で すかっていうことを聞くと感情ネガティブ という風に返ってくるというところですで こういう風にすることによってモデルって いうものが新しい文章がポジティブか ネガティブかっていうのをま過去の例を元 に判断することができるようになるという ことですでこの方法によってですねフュー ショットプロンティはモデルに多様な タスクを効率的に学習させることができ 柔軟な対応が可能になってくるということ でですでここまでいくつかのプロンティの テクニックであったりとかをお話ししてき ましたもちろん他にもたくさんあってです ねチェインオブソツであったりとかあと セルフアスクであったりとかいろんなもの があるんですけれども今回のメインテーマ ではないので一旦プロンティグの話はここ で終わりにしてでここでちょっと一息つい てですねこれらのテクニックが持つ限界に ついて考えてみましょうでまず1点目なん ですけれどもプロンプトのテクニックは 日々進化し開発されていますとこれによっ てチットGPTは多様なタスクや質問に 対応でできるようになってきていますただ 全ての作業やタスクをチャットGPTに 依存すること自体が現実的ではありません とえ例えば先ほどの例で出てきた文章から の感情抽出に関してはチャートGPTに 無理やりさせることが適切かと言われると そうでもないかもしれないAWSコプリン のような勘定分析に特化した学習をして いるAPIっていうものがあってそれを 使った方がいい結果が返ってくるかもしれ ませんっていうのがまず1つ目ですねで次 に2点目としてそのChatGPTが持つ 情報っていうものは訓練データに限定され ていてチットGPTはそれ以外のデータに ついては知らないというところですなので えっとチャットGPTは過去のデータで 学習されておりその学習データ以降に出て きた情報に関してはチットGPTに尋ね られませんとよく言われるものとしては 2021年のデータですかねまでのデータ で学習してるので例えば2022年であっ たりとか2023年のデータについて聞い たとしてもチャットGPTがうまく答え られないというようなところですね最新の 価格的な研究であったりとかニュース記事 とか特定の地域の天気情報であったりとか チットGPTの訓練データに含まれてい ないような情報っていうものはChat GPTだけでは取得できませんし インターネットにあるデータだけではなく て例えば今回のテーマである自社のツール と連携するっていう時のためには自社の データを使いたいみたいな話とかあると 思うんですけれども自社データについては チャットGPTが知るわけもないという\n",
      "Human: ChatGPTが不得意なことを教えて\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "とか特定の地域の天気情報であったりとか チットGPTの訓練データに含まれてい ないような情報っていうものはChat GPTだけでは取得できませんし インターネットにあるデータだけではなく て例えば今回のテーマである自社のツール と連携するっていう時のためには自社の データを使いたいみたいな話とかあると 思うんですけれども自社データについては チャットGPTが知るわけもないという ことでえっとChatGPTに自社の データについて聞いたとしてもChat GPTはもちろん答えることができません とこれらのチャGPTの限界を理解する ことでチットGPTの適切な使用方法で あったりとかそれらをどのようなシナリオ で活用するべきかっていうのが見えてくる ということですねでChatgpdの概要 の最後なんですけれどもChatgpdや その他大記号言語モデルllm自体の課題 をこちらにまとめますでまず1点目なん ですけれども先ほどと被るんですが ChatGPTは最新の情報にアクセスが できないと例えば為替や株価のように国 一刻と変化していく情報に対してチト GPTははリアルタイムで対応することが できませんで2つ目の課題としては ChatGPTが独自の情報源にアクセス する能力を持たないということです企業の データベースに保存されている顧客名簿で あったりとか特定のプライベートな情報に はアクセスすることができませんで3つ目 に水論の正確性に課題があるというところ ですチャットGPTは時折り簡単な算術 計算でさえも間違えることがありますこれ は特に正確な情報や結果が求められる タスクにおいて大きな問題となりますねで そして最後にチャットgpdができない こととかのデータが足りないんだったら ファインチューニングすればいいんじゃ ないかっていうような意見もあると思うん ですけれどもファインチューニングする ことによって汎用性が劣化してしまうと いうことがありますとでChatGPTを 特定のタスク例えば自社データを食わせる であったりとか特定のタスクに特化した データを食わせてファインチューニング すると他の多様なタスクに対する性能が 低下すると言われていますでこれらの課題 を解決するための1つの手段として今回お 話しするラングチェインエージェントって いうものがありますでここここからは ラングチェインエイジェントを使って チットGPTの性能を生かしつつ苦手な ものは他のツールで解決していくっていう ことについてお話ししていきますで参考 までにですねここにバッと上げている課題 に関してはMrKLシステムズていう有名 な論文があってそ論文から引っ張ってきた ものとなりますMrKLシステムズって いうのはミラクルシステムズと呼ぶもので チャットGPTと他のツールを連携して どんどんどんどん課題を解いていくって いうことを提示しているロムとなってい ますそれではラングチェインエージェント についてのトピックに移っていきますまず ラングチェインエージェントの前にですね ラングチェインとは何かと言うとラング チェインとは言語モデルを利用する アプリケーションのためのフレームワーク ですでラングチェインについては前回の 勉強会でもご紹介しているので基礎的な 内容を知りたい方はYouTubeで前回 の勉強会の動画をご覧くださいでラング チェインエージェントはラングチェインの 中の1つの機能なんですけれどもラング チェインの中でも非常に面白くて重要な 役割を果していますランチェの主なタスク は次にどんなアクションを取るべきかを大 記号言語モデルllmに決定させそれを 実行するということですで具体的な プロセスは以下の通りですとまず各ツール ができることと質問を指定したレスポンス のフォーマットでllmに送信します聞き ますとチットGPTなどのllmに聞き ますそしてllmChatGPTから帰っ てきたレスポンスをパースして次の アクションを決めるということをしますで このプロセスによってラングチェインジと はユーザーの4級に応じて効率的かつ正確 なアクションを実行できるようになって いるというところですでここでラング チェインエージェントがどのように動く かっていうもののイメージを具体的な例と して1つ持ってきましたま正確に正しい 動き方をしてるわけではないんですけれど も大体こういうような動きをするんだよっ ていうこともご理解ください例えばチット GPTに対してコミュニケーションを取る のがラングチェインのエージェントとなる んですけれどもラングチェイン エージェントにですねまずこう今日東京で で出かける時時に適切な服装は何ですかて いうのを聞きますでそうするとラング チェインエージェントが聞きたい内容今日 東京で出かける時に適切な服装っていう ものとあと自分が持っているツールって いうものをプロンプトに入れてチャット GPTに聞いてくれますとで自分が持っ てるツールっていうものは例えば Google検索のツールっていうも持っ てますとGoogle検索のツールでは 最新の情報を引っ張ってくることができ ますと私が持ってるのはGoogle検索 のツールで最新の情報が引っ張ってこれ ますそしてで今回聞質問としては東京で 出かける時に適切な服装って何でかていう ものを聞きますとでその時にチャット GPTはどのように返してくるかというと でまずは検索ツールでインプットは東京の 気温っっていうもので調べなさいっていう ものをエージェントの方に返してきますで エージェントはチャットGPTからから 教えてもらったじゃあえ検索ツールを使え ばいいのかっていうところで検索ツールを 使おうとしますでインプットとしては チャトGPTが教えてくれたように東京の 気温っていうものをインプットとして入れ てで検索ツールから帰ってきた22度って いうものを変してもらいますとでそして またえっとチャットGPTにえこのツール に入れた答えってものが22°でした次何 すればいいんですかであったりとか最終的 にどうなんですすかっていうのをチャット GPTに聞いてチャットGPTが十分な 情報を得たっていう風に判断するとでは 22°なので薄の長袖でがいいでしょうっ ていうものをエージェントとしに返してで あとはえ答えとしてラングチェインの エージェントが東京は22度なので素の 長袖でがいいでしょうっていうものをその まま返してくるというような流れになり ます特徴的なものとしてはチャットGPT だと今日の天気であったりとか東京の天気 であったりていうものは取れないんですね でそこをGoogle検索のツールって いうものを利用することによって新しい データっていうのを取れるようにしてると いうところですねもう1つ押えておきたい こととしてはこの問を解く時に自分が持っ ているツールっていうもの一覧を渡して どのツールを使えばいいかっていうのこと 自体もチャットGPTに判断してもらうっ ていうところが面白いところとなってい ますはいでこれがラングチェイン エージェントリアクトフレームワークとか 呼ばれたりするようなやり方ですねはい これらのこと全部ラングチェインの エージェントがやってくれるというところ ですでラングチェインエージェントって いうものは様々なタイプのエージェントが 用意されていますとここでエージェントの タイプっていうものを紹介するんです けれども解きたい課題に応じて エージェントを使い分けることによって 精度の高い回答を得られるようになると いうことですここで6個ほど上げています でまず1番汎用的なものとしてはゼロ ショットリアクトエージェントというもの ですでこのエージェントはリアクト フレームワークを利用してツールの説明に 基づいてどのツールを使用すべきか判断し ます先ほどの例で出てきたものと同じです ねこれによって特定のトレーニングデータ なしで多様なツールの適切なこう利用が 可能になってきます次にストラクチャード インプットリアクタエージェントですで このエージェントは複数の入力を使う エージェントを活用することができますで これによってより複雑なツールの理由用が 簡単になりタスクの効率が向上しますと 続いてOpenAIファンクション エージェントですこのエージェントはオ AIのファンクションコーリングの機能を 使っており関数が呼び出されるタイミング であったりとかを検出したりとか適切な 入力を関数に渡すような微調整がえオープ AI自体チットGPT自体がされていて それを使うことができますとOpenAI のえファンクションコーリングこの エージェントが使うOpenAIの ファンクションコーリングについてはこの 後のスライドでもう少し詳しく説明します で次にコンバーションエージェントですで このエージェントは会話での使用目的とし て設計されています何かを聞いて何か答え を出すっていうようなま単純なチャット GPTで何かこう答えを作ってくださいと かそういうのとは違くて会話的な インタラクションを通じて効果的な コミュニケーションを可能にするような エージェントとなっていますそして次に あげるものとしてはセルフアクwith sarchエージェントですねでそこの エージェントはですねセルフアクという 質問を自問自としながら分割することに よって正しい解を導き出す方法を使って\n",
      "Human: ChatGPTが不得意なことを教えて\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "GPTで何かこう答えを作ってくださいと かそういうのとは違くて会話的な インタラクションを通じて効果的な コミュニケーションを可能にするような エージェントとなっていますそして次に あげるものとしてはセルフアクwith sarchエージェントですねでそこの エージェントはですねセルフアクという 質問を自問自としながら分割することに よって正しい解を導き出す方法を使って 情報を検索するエージェントですセルフア クっていうプロンティグの技術があるん ですねまそれを使ってちゃんとした正しい 答えを導き出すエージェントとなってい ますで最後に紹介するものがリアクト ドキュメントストアエージェントですで このエージェントはドックストア ドキュメントストアですねと対話するため にリアクトフレームワークを使用してき ますえこれによって文書の管理であったり とか検索が一元化されて効率的に情報 アクセスが可能となりますこちらに関して はまた今後の勉強会でも取り扱っていき たいかなという風に思ってるんですけれど も文書検索管理っていうものに特化した エージェントとなっていますで以上がラン チェインエージェントの各エージェントの 使用となりますでそれぞれのタイプが 異なるシナリオやタスクに適しており ラングチェインの柔軟性と多様性を象徴し ているものとなります今回のセッションで はですね最も汎用的なゼロショット リアクトとチャットGPT自体に色々判断 させるファンクションコーリングを使った オープAIファンクション2を利用して いき ますでは先ほど説明を省いてしまったん ですけれどもOpenAIファンクション コーリンググっていうのはOpenAI ファンクションコーリングじゃないですね OpenAIファンクションですね OpenAIファンクションとは何か エージェントタイプの1つであるOpen AIファンクションとは何かについてお 話ししますこちらはChatGPTを提供 しているOpenAIのファンクション コーリングという機能を利用していますで ファンクションコーリングっていうものは 2023年の6月にリリースされた機能で ラングチェインエージェントが担っていっ たツールを渡してチャットGPTに聞いて 次のステップを決定するやり取りってい ものをチットGPT自体が行えるように ファインチューニングされているものと なりますでこの機能では東京の天気を教え てくれというような先ほどと同じように ですね質問と共にどういう関数を持って いるのかその関数の説明をチトGPTに 直接投げるということをやりますなので 先ほどのラングチェインエイジェントが やってることと同じようなことをやれる ようになっていてチットGPTが ファンクションをどのように受け取るのか そのファンクションのパラメータであっ たりとか説明とかをよりチャトGPTが 理解しやすいようにAPIとして受け取る ことができるようになっているのでより 適切な判断をチャットGPTがしやすく なっているというところがメリットとなり ますなので今メリットをお話ししてしまっ たんですけれどもファンクション コーリングを使うメリットとしては ChatGPTにツールの挙動をより正確 に伝えやすくなっているというところで これによってChatGPTが機能の ツールのえファンクションの使用や動作を より正確に理解しやすくなっていて適切な 判断をしやすくなっているとていうのとで もう1つのメリットとしてはチャット GPTっていうものがラングチェイン エージェンドって元々チャットGPTが 返してきた個体を利用者が頑張って定期 表現を使って解析する必要があったんです がそれをする必要がなくなったっていう ところが利点としてありますとでチャット GPTが実際にラングチェインを使って どのツールを使えばいいですかていうのを 聞くんですけどそれをどのようにパースし てるかというとこのように頑張ってですね えっとレギュラーエクスプレッションを 使って正規表現を使ってパースしたりとか して次のアクションを決めてたりするって いうのがラングチェが今までやっていた ことであるとでこういうパースをしなきゃ いけないっていうことをしなくて済む つまりパースしなきゃいけなかったので今 まではそのパースすることでえっとうまく パースできなくてミスってしまうっていう こともあったんですけどそういうことが なくなるっていうことが期待されるという ところです はいはいちょっと駆け足になってしまった んですがここまでで20分ぐらいかかって しまいましたねえここからがレモに入り ますで実際にですねラングチェイン エージェントを使ってチャトGPTと自社 ツールを連結するような感じのえデモって いうものをお見せしていきますで使う エージェントとしてはゼロショット リアクトとオーエファンクションを使って いきますであとは今回のプレゼンの冒頭の 方でもお話ししたようにChatGPTに ツールの説明をどのように渡せばいいのか であったりとかその辺りを持ち替えて いただければ幸いです はいではではやっていきますちょっと時間 がなくなってきたので駆け足でいきますね でまずは設定ファイル読んでいきますこれ 何をやってるかと言うとえOpenAIの APIキーであったりとかを読んでいます でまずはですねえっとゼロショットの方を 見せしていきたいんですがおマジないとし てですねおじないというかま前回の勉強会 と同じようにですねラングチェイン エージェントを使うためのやり方をお見せ していきますで実際今回使うモデルとして はチットOpenAPAIというか ChatGPTのえGPT3.5のtbo 0613というものを使っていきますで 外部のツールとしてはGoogleサーチ のAPIっていうものを今回用意しました ここであのサプAPIっていうものを書い ているものがえGoogleのAPIと なりますで聞きたい質問としては今日の 東京と北海道の天気を調べて東京から 北海道の出張で来ていくべきを教えて くださいっていうものを聞きたいと思い ますでラングチェインエージェント自体を 走らせてみますでこれがゼロショット リアクトエージェントを使った場合どの ようになるかっていうのをお見せしますで エージェントタイプに関しては イニシャライズエージェントの エージェントっていうえ引数に対して エージェントタイプのこのゼロショット リアクトディスクリプションていうものを 渡すとエージェントを選択することができ ますちなみになんですけれどもえこれって ただあの文字列が返ってくるだけですかね あのゼロショットリアクト ディスクリプションていうものが返って くるだけのものになりますなので文字列で 与えても同じですはいでは実行してみ ましょうチトgpdはもちろん今日の天気 とか今日の東京とか北海道の天気っていう のは知らないので来ていくべき服装って いうことは分からないわけですね気温も 分からないのででこれでラングチェイン エージェントが私はGoogle検索の ツールを持ってますよでそれを使って使う ことができますでこの問題課題っていう ものを解くためにはどうすればいいですか てのを聞くっていうことですねでここで ざーっと出てきてるんですけれども実際に 書いてきた答えとしてはtheWisto isCloudyaboutcrear withtempof歌詞になっちゃって ますけどまこのように帰ってきますと 英語で帰ってきちゃってますねでこういう 風にえどんなアドレスをれ切ればいい かっていうものがちゃんと帰ってきてい ますと前にやった時はそんなに綺麗に帰っ てきてなかったんですけれども今回は うまく帰ってきていますはいこちらがゼロ ショットリアクトディスクリプションで やった場合の結果になりますでどういう ことをやってるかっていうのなこの辺りを 見ていただくといいのかなという風には 思いますでチットGPTにまずラング チェインエージェントが問題とツールを 渡してチットGPTに何をすればいい かっていうのを聞きますでチャットGPT から帰ってきた答えとしては次の アクションとしてはサーチをしてください ですサーチのインプットとしてはウザー 東京todayていうものを渡してくださ いっていうのを渡してますで次の アクションとしてはサーチをしてください でそのインプットとしてはウザ北海道 todayていうものを渡すようにして くださいとで最終的にその帰ってきた答 っていうものをチャットGPTに渡して 最終的な文が出てくるということですはい でこれが1つ目ですねアエージェント タイプ1つ目のえゼロショットリアクト ディスクリプションで元々ラングチェイン エイジェントがリアクトフレームワークで ツールを渡したりとかしてチャットGPT とうまく連携しながら外部ツールを使う ようにしたえ機能となっていますでこれが ですねえ最近出てきた6月にリリースされ たOpenAIのファンクションコーリン グっていうものを使うとどうなるかって いうのをお見せします はいでOpenAIファンクション OpenAIのファンクションコーリング を使うためにはエージェントタイプの OpenAIファンクションズっていう ものを渡しますでそうするとえこのように 動きますで実際にやってることとしては ラングチェインエージェントがOpen\n",
      "Human: ChatGPTが不得意なことを教えて\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "たOpenAIのファンクションコーリン グっていうものを使うとどうなるかって いうのをお見せします はいでOpenAIファンクション OpenAIのファンクションコーリング を使うためにはエージェントタイプの OpenAIファンクションズっていう ものを渡しますでそうするとえこのように 動きますで実際にやってることとしては ラングチェインエージェントがOpen AIのファンクションコーリングっていう ものを使ってうまくチャットGPTと やり取りしながら答えを導き出していくっ ていうことをやっていますはい出てきた 答えはこちらですねで同じようにですね どのようにやっているかっていうものは ここら辺の途中で出てきているんです けれども途中結果でえサーチとしてはえ クエリー東京の今日の天気っていうものを 調べてくださいでサーチっていうツルを 使って今日の北海道今日の天気っていう ものを調べてくださいでこれらが帰ってき た答えっていうものをえチャットGPTに 返してチャトGPTがその与えられた情報 を元に東京の今日の天気は曇りですが後に は晴れる予報ですで気温は接し30°歌 86°でコス確率はどうのこうのっていう ものがあってであとは東京は暑くなる可能 性があるので軽い服装が適しています ただし北海道は比較的涼しいので ジャケットなどを持っていくことがお勧め しますというような感じに帰ってきてます ま見て分かると思うんですけれどもま日本 語にな質問が日本語だったので日本語で ちゃんと返してくれるっていうのは もちろんのことなんですけれども書いてき た答えっていうものに関してより詳しく 返してくれているっていうことが分かると 思いますなので使ってみた所管としては ですねここで言うオAIファンクションの ファンクションコーリングっていうのの ファンクションっていうのはラング チェインエージェントでいうツールと同じ なんですけれどもそのファンクションで あったりとかツールを渡す時にですね渡し て何かを判断判させたいチャットGPTに 判断してもらいたいっていう時はえ エージェントタイプゼロショットリアクト ディスクリプションよりもエージェント タイプオAIファンクションの方がより いい結果が返ってきやすいっていうことが 分かると思い ますもう少しあの詳しく見ていきます ちなみにですねOpenAIにどんな ファンクションを渡してるかっていうのは イニシャライズエージェントのところで エージェントを定義してるんですけども そのエージェントの中からエージェントっ ていうものとファンクションズってものを 実行するとどんなえファンクションが渡さ れてかっていうのを見ることができますで 今回渡されたファンクションっていうのは ネームサーチっていうファンクションが 渡されていてどんなことができるかって いうのでサチエンジンですっていうような ものをやってますであとはパラメーターと してはこういうものを渡していきますって いうのが分かりますとはいでここまでが 基本的なラングチェインエージェントを 使って外部ツールを連携するっていうお話 をしてきましたとで次にですねえ自社で 作ったツールっていうものを連携させ るっていところについてお見せしていき ますで一旦はですねレコメンドアイテムっ ていうものを考えてみようと思いますで ここ何をやりたいかって言うとレコメンド アイテムまこの中身はほとんど意味のない ものになってるんですけれどもレコメンド アイテムっていう関数を自社で持っていて でレコメンドアイテムっていうものは自社 のデータベースなどにアクセスして日付を 持ったにこの日のレコメンドっていうもの はこういうものですっていうものを返す ような関数っていうところになりますとな のでえっとこのレコメンドアイテムって いうところをこの関数ををえChat GPTのフローの中に組み込みたいって いうことをやっていきますでどのように ラングチェインエージェントを使って ChatGPTに連携すればいいかという とツールっていうものにえ変換していく 必要がありますとでレコメンドアイテム ツールっていうものをえツールfrom ファンクションズっていうものを使って どのようなファンクションを実行したい ですかレコメンドアイテムっていう ファンクションを実行したいですまこう いう風にですねこの今回のあまり意味の ないファンクションなんですけれどもこれ を実行しますとでツールの名前としてはえ レコメンドアイテムっていうものを渡し ますでツールのディスクリプション何を やってくれるかっていうことに関してはお すめの商品を教えてくれますっていうのを ツールとして定義するというところです はいでこれをちょっとツールズっていうま ツールまとめて渡さないといけないで ツールの配列の中に入れておきます実際に ですねラングチェインエージェントにどの ようにツールを渡せばいいかっていうとま 先ほどもカラっとやってたんですけれども このツール1覧っていうのを最初に渡して 引数として渡しているのでまこのようにし てどんなツールが使えるかっていうものを ラングチェインのAに渡しでチャット GPTと連携していきますはいでえっと 今回聞きたいこととしてはえおすすめの 商品を教えてくださいっていうものを投げ てみようと思いますで使うエージェントと しては先ほどゼロシトリアクトよりもより いい結果が返ってきたオーエ ファンクションズってものを選びます はいはいでは実行し ますはいで書いてきたものとしてはですね コメドアイテムってものが実行されて withファッションという謎のものをえ 入力に入れてで実際この引数がですね デートの中にファッションが入ってで プリントファッションっていうところでこ でファッションが出てきてしまってるとで ただおすめの商品は今回レコメンド アイテムで書いてきたAppleですって いうのが書いてきてることが分かると思い ますはい見て分かるようにですねなんか よくわからない引数は与えてしまってる なっていうところがありますでこを どんどん解決していこうと思いますで次に やることとしては今回なんでこのように変 なファッションとかいう引数を与えて しまったかというと引数に関する情報が ないんですね与えられてないというところ になりますとなので引数何与えればいいん ですかみたいなところが情報としてないが ゆえにチャットGPTもレコメンド アイテムを使うことは分かるとレコメンド アイテムを使えばいいのは分かるんだけど レコメンドアイテムに対してちょっと 分からないからカテゴリー情報でも渡して みようかなっていうのでファッションを 渡してしまっているというような状態に なりますで例えばまファンクションを見た としても今回使ってるファンクションに 関してはレコメンドアイテムでおすめの 商品を教えてくれますでパラメーターの 情報は全くありませんっていう状態なので どんなパラメーターを渡せばいいかって いうのはオープAIファンクションは 分からないというところですねじゃあこれ に対してどうすればいいかっていうのをお 見せしますでえっと結構簡単でしてパダ ティックっていうものをご存知ですかね こう最近えっとファストAPIとかですか ねこう結構パであったりとかそのヒントを 与えるっていうことがまPython主流 になってきてると思うんですけれども フダンティックを使っていきますでえっと ご注意していただきたいこととしては ファインディッてもうV2が出てるんです けれどもV2を使うとラングチェイン エージェントを動きませんとなので パティックV1を指定して方に関する情報 をえ与えるためのそのベイスモデルとか フィールドを使ってえやっていきますで これ何をやってるかと言うとま今回の インプットに対してデイトっていうものが ありますがデイトていうものはお勧めした 商品を絞るために使われる日付ですって いうものを与えていますこれをえっと アーグススキーマ先ほどのツールを定義 する時にアグススキーマっていう引きを 使ってこのレコメンドアイテムインットっ ていうベースモデルから継承した レコメンドアイテムインプットっていう インプットの報引数の情報を持ったクラ スっていうものを渡すということをします とでこうするとどうなるかっていうのをお 見せしていき ますはいじゃあどう変わる かいきますはい実行します全く同じですね 実行するものとしてはで今回はレコメンド アイテムっていうものに対して先ほどと 同じレコメンドアイテムっていうものが 選ばれましたとコアイテムに対してデイト が2020年の12月1日っていうものを 渡しているっていうことが分かりますで それによってですね気付がちゃんと渡して くれたっていうことがわか分かるわけです ねで今回あのここであのデートっていう ものはディスクリプションでお勧めしたい 商品を絞るために使われる日付っていう ことを伝えたのでチャットGPTの方があ これは日付のことなんだっていうところで 引数はファッションのようなカテゴリーを 渡すんではなくてデートの引数っていう ものを渡すことができてるというところ ですはいでこちらがデトのまあ2022年 の12月1日もはや日付が意味が分から ないですけれどもこういうものが渡されて いるというところですねでおすめ商品は Appleですという風にでこういう風に\n",
      "Human: ChatGPTが不得意なことを教えて\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "ことを伝えたのでチャットGPTの方があ これは日付のことなんだっていうところで 引数はファッションのようなカテゴリーを 渡すんではなくてデートの引数っていう ものを渡すことができてるというところ ですはいでこちらがデトのまあ2022年 の12月1日もはや日付が意味が分から ないですけれどもこういうものが渡されて いるというところですねでおすめ商品は Appleですという風にでこういう風に ですねこうツールの説明をどんどん どんどん入れていってええ解決していく 必要があるというところですねで同じよう にですねちょっとエージェントの ファンクションがどのように渡されるてる かっていうのをお見せしますとで今回渡さ れたのはレコメンドアイテムインプトって いうのをえパイダンテックの方で定義して 渡しているのでえ実際にえっと ファンクションOpenAIのえ ファンクションコーリングにどのように 渡されてるかというとパラメーターとして ですねこういう風なレコメンドアイテム インプットっていうものが渡されていて プロパティとしてはデートがあってデー トっていうのはお勧めしたい商品を絞る ために使われる日付っていうものが入れ られてえ飛ばされてるということが分かる と思いますはい で他にはですねこのようにツールフロン ファンクションで作るっていうこともある んですけれども同じようにですね デコレーターを使うっていうこともでき ますとデコレーターの方が結構シンプルに 書けるので私は結構デコレーターを使って 書くことが多いですとでデコレーター何を すればいいかというとデコターっていうの はま関数の前にですねアマークツールなん ちゃらかんちゃらっていうものがあってで それを使ってえっとこのツールってのは何 ができるかっていうものをえドッ ストリングで与えるんですねな先ほどと 同じにするとレコメンドアイテムツールっ ていうものがあったら中身は同じですね プリントデイトとAppっていうものを 返しますとプリントデイトしてApple っていうものを返しますとででやることと してはおすめ商品を教えてくれます全く 同じ内容ですねでこのツールの名前って いうものはデコレーターの引数として レコメンドアイテムとして渡していると いうところですで同じようにですね ツールズの一覧として入れてでこれをえ 実行してみ ましょうはいこれデコレーター使った場合 です ね実行するものは全部同じですで同じよう にこれも実行できますという風にデコレー ターってかなりこうシンプルにかけてで ファンクションの中のドックストリングス とかを使ってくれるので結構あの家読性と かもう悪くないかなという風には思います 先ほどと同じようにですねこレコメンド アイテムってものはちゃんと選んでくれた んですけれどもレコメンドアイテムに渡し ているデートっていうのは2021年10 月15日という意味の分からない日付を 渡してしまっていますとこれはなぜかと言 とまもちろんそのおすすめ商品を教えて くださいって言ってるので勝手に日付を 決めて聞いてしまっているというところ ですね はいでデコレーターの方もですね同じよう にファンクションを見てみるとえっとこう いう風になるという感じですねただあの 先ほどと同じようにですねパダンティック とか使っていないのでプロパティの パラメーターとかは適当になってしまって いるというような感じになりますただ今回 の場合はですねこうデコレーターの場合は フロムファンクションの方を使ったこっち の場合ですねこのフロムファンクションを 使った時と違ってきちんとデートを入れて くれているっていうことが特徴的かなと いう風には思いますフロンファンクション を使った場合っていうのはパダンティック を渡さないとデートっていうものに対して ファッションを入れたりとかよく分から ないものを入れたりすることがあったと 思うんですけれどもデコレーターを使った 場合はこのデートっていうものを渡した時 にきちんとこうデートを返してくれるよう な情報っていうものを渡せてくれている ような感じですねいずれにせを正しい共同 を求めるためにはこのままあまり情報を 与えないで実行するってのは適切ではない ので特に自社ツールサービスとして提供 する側としてはですねなのでそういう意味 ではきちんとバイダンティックなどを使っ て適切な情報を渡しながら関数っていう ものを渡していく必要があるかなという風 に思いますなのでえっと先ほどと同じよう にですねデコレーターを使った場合も パイナティックの情報っていうものを渡す ことができるのでデコレーターの引き数に アーグススキーマていうものを渡してで そのパイランティックの情報を渡すことで 適切な答えを返すことができるようになる というところです同じようにですねま結果 も変わらないので はいまこういう風に変えてきました ちょっと答えがどんどんどんどん変わって きてますApple製品だったりとか AppleStoreとかオンライン ショップとかうんまここら辺に関しては 本当に適切な答えがまだ返ってきてない なっていうような状態だとは思います エージェントのファンクションを見るとえ きちんとファナティックで渡した情報って いうのが渡っていることが分かると思い ますこのようにですねこのデートっていう ものはデートっていう引き数はお勧めし たい商品を絞るために使われる日付ですっ ていうのが渡っているというところです もう少しですね今までこうおすめの商品を 教えてくださいっていう風に言っていたの でデートっていうものが1月10日であっ たりとかよくわかんない日付になっていた のではないかっていうことを推測してでは 昨日のおすすめ商品を教えてくださいって いうものを聞いてみますてそうするとどう なるかと言うとえ昨日のおすめ商品を教え てくださいって言ってるのにレコメンド アイテムに渡されてるのは2021の10 月20日っていうものが渡されれてること が分かりますとチャットGPTにこう昨日 とか今日とか昨日とか渡したら日付を ちゃんと入れてくれるのかなと期待するっ ていうことがあると思うんですけれども 実際はそんな入れてくれないっていうこと がまこの結果から分かるということですね もう少し例えばディスクリプションとかを 適切にすればうまくいくのかもしれないん ですけど今回は違う手段でえっと解決 しようと思いますで今回どういう風に解決 するかと言うとデートタイムを使って 新しい日付けを取得するような関数自社 ツールってものを設けようと思います ゲットデートっていうツールっていうもの を作ってでそのツールは何をするかという とま今日や昨日など日付を取得する時に 使います引き数には今日を起点として何日 か前をNで与えますとでここのそのドック ストリングスにですねこう引数に関する 情報を書いてるんですけども実際はですね パダンティックで引き数の説明した方が ベタだとは思いますただえっとドック スリンに書いてツールの説明として与える だけでも結構チャットGPTは賢いので うまく判断してくれるということですでお 見せしますはいこの日付関数を入れると どうなるかと言うとこういう風な感じです ねはい今日のおすめの商品を教えてくださ いっていう風にするとtodayて書い てき来てこれもうまく動いてないですね こういうことが結構ありますとうまく動か ないことがあるとでもう1回実行してみ ましょうかはいでもならではですね ちょっと30分で終える予定が46分に なってしまったんですがもう少しで終わる ので続けます前回のやつだとですね直接 レコメンドアイテムを呼び出してデートに 対してtoデイていうものを渡してしまっ てたんですけれども今回はうまく動いてい てまずは日付を取得するためにゲットデイ トっていうものを呼び出しますとで今日な ので今日からの起点のえN日前だったらN に0を渡せばいいということが分かるとだ からゲットデートに0を渡して帰ってきた ものが2023年の9月30日っていう ものが帰ってきてで9月30日のえお勧め 商品は何ですがま書いてくるものは全部 AppleなのでAppleってものが 帰ってきてることが分かると思います同じ ようにですねじゃあどういう ファンクションが渡されてたかっていうの をお見せするとサクっとですねで今回あの ファンクション2つ渡されていて レコメンドアイテムっていう ファンクションとゲットデイトっていう ファンクションが渡されていますで それぞれのファンクションの説明がこの ように与えられているということが分かり ますもう少しツールを複雑にしていって ですね奇数日だったらオレンジ偶数日だっ たらえAppleっていうものを返すよう なツールにちょっとだけレコメンド アイテムを変えみようと思い ますはいではえこれを実行するとですね 今日はえ9月30日なのでもちろん9月 30日偶数日ですね偶数日なので Appleが返ってくるきちんと帰ってき ますねAppleが帰ってきましたでは 昨日の場合はどうなのか 昨日はい昨日の場合は29日なので1日前 ってものをゲットデイトで取得して29日 ってものが書いていますで29日を使って え昨日のおすめ商品オレンジっていうもの を取ることができるというところ ですやとうまく動きました ねでもう少しだけちょっと時間が1時間 ぐらい喋ってしまうような感になるんです\n",
      "Human: ChatGPTが不得意なことを教えて\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "Appleが返ってくるきちんと帰ってき ますねAppleが帰ってきましたでは 昨日の場合はどうなのか 昨日はい昨日の場合は29日なので1日前 ってものをゲットデイトで取得して29日 ってものが書いていますで29日を使って え昨日のおすめ商品オレンジっていうもの を取ることができるというところ ですやとうまく動きました ねでもう少しだけちょっと時間が1時間 ぐらい喋ってしまうような感になるんです けれどもう少しだけお話させてくださいで これだけだともちろんまだまだ連携が 少ないかなっていうところがあってで次に じゃあAppleだったら100円 オレンジだったら200円っていうような ものを商品の値段を返すような関数って いうものを組み込んでみましょうでツール としては元々グビだったらAppleキビ だったらオレンジを返すようなものとあと は日付を取得するツールであとは今回定義 したAppleとオレンジAppleだっ たら100円オレンジだったら200円 っていうのを返すツールっていうものを 定義しますでこれでエージェントのですね おすめの商品の値段まで教えてくださいっ ていうことをやるとそうするとまず最初に え昨日なのでゲットデートでN=1を渡し て1日前のデートを取ってきますで9月 29日ですで次にレコメンドアイテムって いうツールを呼び出してレコメンド アイテムにえ9月29日を渡してで最後に ですねアイテムプライスっていうので アイテムネームをえオレンジにとして渡し てでオレンジはは200円なのでえ昨日の おすめ商品であるオレンジの値段は 200円ですっていう最終的な答えが返っ てきましたというところになりますだいぶ 柔軟なものができるようになってきたって いうことが理解できると思いますで他には ですね最後なんですけれども取得した結果 を吐き出したいとかデータベースに 書き込みたいとかあったりすると思うん ですけどもそういうことももちろん簡単に できますと基本的にはファンクションが あってそのファンクション中身は自分で 書いていくので何でもすることができると いうところですねちょっとあの output.tchっていうところに 書き込むようなものを記事的にですね データベースに書き込んでいるようなもの として紹介しようと思いますで今回は さらに追加するツールとしてはですね セーブデータっていうツールを追加します とセーブデータっていうものは何なのかと いうとここにも説明書いてあるんです けれども日付と商品名と商品の値段を 受け取ってデータベースに書き込みますっ ていうようなものをツールとして作りまし たデータベースといながらもアウトプット テキストにただ書き込むだけのものになる んですけどもデートアイテムネーム アイテムプライスを書き込むだけのツール となりますま実際に自社ツールを使う時に はここにSQL分であったりとかを書いて データベスに書き込むとかをやったりする ことになると思いますこちらもですね ちょっと簡易的にですねフダンティックを 使わずにえドックストリングだけで何を やるかってのを渡して書き込めるかどう かってのをお見せしていこうと思いますで 同様にですね同じように何をしたいかと 言うと今日のおすめ商品の値段を調べて データベースに書き込んでくださいって いうことを実行し ますで最初に動くものとしてはまず日付を 取得するゲットデイトが動いてN=0で 今日の日付を取ります9月30日ですと9 月30日が取れたら9月30日の レコメンドアイテムは何ですかていうので レコメンドアイテムのツールを起動して 書いてきたものがAppleですとであ次 にやることしてはAppleの値段は いくらですかていうものをアイテム プライスに聞いてアイテムプライスが返し てきた答えが100円ですとで100円 っっていうものをえセーブデータに渡して セーブデータに渡すものとしてはデートと アイテムネームとアイテムプライスこれは 日付と商品目と商品の値段を受け取 りっていう風に書いてあるのでこういう ようなものを基数として与えて データベースに書き込みますていうことを この操作でやるということですねなので 細かいことを書いた方がミスは少ないん ですけれどもあんまり書かなくても動いて くれるっていうのがまやっぱりこう チャットGPTのうまいところかなという 風には思いますで最終的に帰ってきたこと としては今日のえおすすめ商品の値段は 100円ですとでデータベースに正常に 書き込まれましたっていうので データベースではないんですけどれも テキストファイルっていうものを中身見て みましょうと今日の日付2023年9月 30日でおすすめの商品Appleで最終 的に100円っていうのが書き込まれた ことが確認できましたとはいとても長く なってしまったんですけれどもこちらで テモは終わりとさせていただきたいと思い ますはい私の発表は以上となります ありがとうございました\n",
      "Human: ChatGPTが不得意なことを教えて\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "qa_output = qa_chain(\n",
    "    {\n",
    "        \"input_documents\": split_youtube,\n",
    "        \"question\": \"ChatGPTが不得意なことを教えて\",\n",
    "    },\n",
    "    return_only_outputs=True,\n",
    ")[\"output_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "faedb445-daa6-4c93-83f3-ce93e0ec5a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatGPTが不得意なことは以下のような点です：\n",
      "1. 最新の情報にアクセスできない\n",
      "2. 独自の情報源にアクセスできない\n",
      "3. 正確性に課題がある\n",
      "4. データが足りない場合のファインチューニングの劣化\n",
      "5. ゼロショットリアクトによる回答の精度の制約\n",
      "6. 文脈の把握の難しさ\n",
      "7. 不正確な情報の提供\n",
      "8. コンテキストの理解\n",
      "9. ファクトチェックの不足\n",
      "10. センシティブなトピックへの対応\n",
      "11. ユーザーの意図の理解\n",
      "12. 長文への対応\n",
      "13. 文脈の欠落\n",
      "14. 高度な専門知識\n",
      "15. 偏った情報の引用\n",
      "16. 意図の誤解\n",
      "17. 倫理的な問題\n",
      "18. 文脈に基づく情報の欠落\n",
      "19. 誤った情報の生成\n",
      "20. 倫理的な問題\n",
      "21. 意図の解釈の困難さ\n",
      "\n",
      "以上が、ChatGPTが不得意とされる点の一部です。\n"
     ]
    }
   ],
   "source": [
    "print(qa_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
