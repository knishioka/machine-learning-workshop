{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8051b35d-212e-414b-979f-26c28797b13f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: youtube-transcript-api in /Users/ken/.pyenv/versions/3.11.5/lib/python3.11/site-packages (0.6.1)\n",
      "Requirement already satisfied: requests in /Users/ken/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from youtube-transcript-api) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/ken/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from requests->youtube-transcript-api) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/ken/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from requests->youtube-transcript-api) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/ken/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from requests->youtube-transcript-api) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ken/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from requests->youtube-transcript-api) (2023.7.22)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install youtube-transcript-api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78fecfc3-dcc5-47fe-8feb-84dc2cfbcc30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tiktoken in /Users/ken/.pyenv/versions/3.11.5/lib/python3.11/site-packages (0.5.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/ken/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from tiktoken) (2023.10.3)\n",
      "Requirement already satisfied: requests>=2.26.0 in /Users/ken/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from tiktoken) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/ken/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/ken/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/ken/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ken/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken) (2023.7.22)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c975ebce-9155-4c3a-aee6-242187020413",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba9ec2d6-b307-4b6b-b50c-e075e90f44ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.7, model=\"gpt-3.5-turbo-0613\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63319b4d-d351-4352-af87-68cddb5dc49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.chains.summarize import load_summarize_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ae2586a-09c9-4ce4-9456-303acf9034d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = load_qa_chain(llm=llm, chain_type=\"map_reduce\", verbose=True)\n",
    "summarize_chain = load_summarize_chain(llm=llm, chain_type=\"map_reduce\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8ac8ce9-7360-4c39-881a-c865e6ab5ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "loader = PyPDFLoader(\"/Users/ken/Downloads/2303.12712.pdf\")\n",
    "pages = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb1956d5-c2d2-43f2-a3b9-02a05cc4f4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import YoutubeLoader\n",
    "loader = YoutubeLoader.from_youtube_url(\n",
    "   youtube_url=\"https://www.youtube.com/watch?v=I2UZutRrtEE\",\n",
    "   language=\"ja\"\n",
    ")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "974eb208-8a1f-44df-b4bb-5a3085374a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MapReduceDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\"では早速なんですけれども始めさせて いただきます私からはラングチェイン エージェントを使って自社ツールと チャットGPTを連携するというタイトル で発表させていただきますChatGPT 自体は皆さんご存知のように非常に優れた 能力を持っていますが最新のデータに アクセスできないとか特定の数学的な推論 が得意でないなどいくつかの課題が存在し ますこれらの課題は自社プロダクトに チャートGPTを導入するなどチャット GPTを社会実装しようとした際に解決し なければなりません今回お伝えするラグ チェインエイジェントを導入すると ChatGPTと外部ツールをうまく連携 させることができるようになりChat GPTが抱える課題を克服しチットGPT の可能性をさらに広げることができます 本日はラングチェインエージェントをどう 活用することでチャットGPTの能力を 拡張できるのか具体的にご紹介していき ますそれでは始めていきますこちらが私の プロフィールとなります内容はいつもと 同じなのでスキップさせていただきます はいでは具体的な話に入る前にですね今回 のテーマの結論に先に触れておきます結論 なんですけれどもラグチェインには様々な エージェントの種類が存在するが自社 ツールとチャットGPTを効果的に連結 する際汎用的なエージェントタイプである ゼロショットリアクトまたはオAI ファンクションを利用することが簡単と なりますゼロショットリアクトとOpen AIファンクションを比較するとOpen AIファンクションの方がチットGPT からより適切かつ精度の高い答えを 引き出しやすくなっていますこちらはデモ のでお見せしますねでそしてえっとここで ChatGPTと自社ツール連携で非常に 重要となるものとしてツールの説明という ものがありますと通常のプロンプトチャト GPTを使う時のプロンプトと同様に ツールの特性や機能をChatGPTに 正確かつ効果的に伝えることで自社ツール とチャットGPTの連携の成功率が格段に 向上していきますこのポイントに着目し ながら具体的な方法論について今日は 深掘りしていきたいと思いますそれでは これらのポイントを年頭にきつつ今回の 発表をお聞きください本日の発表は以下の 3つのセクションから構成されています 初めにチットGPTの基本的な概要につい て触れます次にラングチェイン エイジェントの特徴について紹介し最後に デモンストレーションを行いますデモでは 特にツールの説明について着目して いただけると幸いですそれでは最初の トピックに移りましょうここではチット GPTの全体的な特徴を振り返っていき ますすでにご存知の内容も多いと思うん ですけれども一般的なはチャットGPTの 性質っていうものをご紹介していきます チットGPTは実用的な大規模言語モデル llmで現在多くのビジネスに活用されて きています例えばベネッセ ホールディングスでは車内AIChat ベネッセGPTを開発しグループ社員 1.5万人に向けて提供しているという ようなプレスを出していたりとか立メカ 大学では大学の英語事業において機械翻訳 とChatGPTを組み合わせたサービス が試験導入されているであったりとか他に も色々なサービスがチャトGPTを 組み込み始めておりChatGPTの実用 化っていうものがすごい勢いで広がってい ますChatGPTを活用する際によく 言われることとしてはチャットGPTから 良い結果回答を得るためには良い質問が 必要であるということですでこれは プロンプトエンジニアリングと呼ばれる 領域で今最も伸びている業種の1つと言え ますプロンプトエンジニアリングではどの ような項目をプロンプトに入れるべきか またプロンプトを複数回うまく使いこ なくして良い回答をるテクニックなどが 研究開発されていますリアクトであったり とかいろんなことを聞いたことあると思う んですけれどもプロンプトの種類っていう のがどんどんどんど開発されているという ことですでチャットGPTの活用は多に 渡っておりその可能性は広がりつつあり ますでプロンプトエンジニアリングの テクニックを活用することでチャット GPTとの適切なコミュニケーションが 可能になりますプロンプト エンジニアリングでは色々なテクニックが 存在するのですが今回はプロンプト エンジニアリング自体がメインのテーマで はないのでプロンプトエジライニングの中 で抑えるべき基本的な項目とそしてよく 使われるまフーショットプロンティングと 呼ばれるような手法を簡単にだけ紹介して いきますはいまず基礎として抑えていき たいこととしてプロンプトに何を与える べきかっていうものをいくつか紹介して いきますで1点目としては具体的で明確に 質問することですで例えばその日本の歴史 において重要な出来事は何ですかという 質問よりも日本の戦国時代における重要な 出来事について教えてくださいという具体 的に質問し方が的確なコ答が得られますと で2点目に状況やコンテクストを明示する ことですて背景情報があるとチャット GPTはコンテクストをより理解し適切な 回答が返ってきますとで3点目期待する 回答の形式を指定するとこれにより望む 情報が整理されて帰ってきますリスト形式 で返してくださいであったりとか ジェイソン形式で返してくださいであっ たりとかまそういうことを質問する時に プロンプトの中に入れるということですね で4点目範囲を限定すること範囲が広す すぎると回答も後半で一般的になりがちに なりますなので範囲を狭めるということが 重要となってきますで最後5点目自性や 認証を明確にすることですと例えば子供で も分かるようにしてくださいとか中学生で も分かるようにしてくださいとかなんか そういう風にどの視点で書て思ってみるか を示したりであったりとか何年の情報が 欲しいとかそういうことを指定することに よって回答が明確なものが帰ってきやすく なるということですで次にプロンティ テクニックの1つののフューショット プロンティについて簡単に説明します フューショットプロンティはモデルに少数 の例を示すことで特定のタスクの解決方法 を学習させるアプローチになりますこれに よりモデルは様々な問に対して適切な回答 を生成することができますここに例として 上げてるんですけれども例えばレストラン 最高でしたこれは感情ポジティブですこの 映画は本当に時間の無駄だった感情 ネガティブですというようにいくつかの例 を与えて出したいものでそれぞれの文に 対しての感情っていうものをこのように 並べていきますてで最後に聞きたいものと してそのサービスは非常に遅く不満ですっ ていうものがあった時にどんな感情で すかっていうことを聞くと感情ネガティブ という風に返ってくるというところですで こういう風にすることによってモデルって いうものが新しい文章がポジティブか ネガティブかっていうのをま過去の例を元 に判断することができるようになるという ことですでこの方法によってですねフュー ショットプロンティはモデルに多様な タスクを効率的に学習させることができ 柔軟な対応が可能になってくるということ でですでここまでいくつかのプロンティの テクニックであったりとかをお話ししてき ましたもちろん他にもたくさんあってです ねチェインオブソツであったりとかあと セルフアスクであったりとかいろんなもの があるんですけれども今回のメインテーマ ではないので一旦プロンティグの話はここ で終わりにしてでここでちょっと一息つい てですねこれらのテクニックが持つ限界に ついて考えてみましょうでまず1点目なん ですけれどもプロンプトのテクニックは 日々進化し開発されていますとこれによっ てチットGPTは多様なタスクや質問に 対応でできるようになってきていますただ 全ての作業やタスクをチャットGPTに 依存すること自体が現実的ではありません とえ例えば先ほどの例で出てきた文章から の感情抽出に関してはチャートGPTに 無理やりさせることが適切かと言われると そうでもないかもしれないAWSコプリン のような勘定分析に特化した学習をして いるAPIっていうものがあってそれを 使った方がいい結果が返ってくるかもしれ ませんっていうのがまず1つ目ですねで次 に2点目としてそのChatGPTが持つ 情報っていうものは訓練データに限定され ていてチットGPTはそれ以外のデータに ついては知らないというところですなので えっとチャットGPTは過去のデータで 学習されておりその学習データ以降に出て きた情報に関してはチットGPTに尋ね られませんとよく言われるものとしては 2021年のデータですかねまでのデータ で学習してるので例えば2022年であっ たりとか2023年のデータについて聞い たとしてもチャットGPTがうまく答え られないというようなところですね最新の 価格的な研究であったりとかニュース記事 とか特定の地域の天気情報であったりとか チットGPTの訓練データに含まれてい ないような情報っていうものはChat GPTだけでは取得できませんし インターネットにあるデータだけではなく て例えば今回のテーマである自社のツール と連携するっていう時のためには自社の データを使いたいみたいな話とかあると 思うんですけれども自社データについては チャットGPTが知るわけもないという ことでえっとChatGPTに自社の データについて聞いたとしてもChat GPTはもちろん答えることができません とこれらのチャGPTの限界を理解する ことでチットGPTの適切な使用方法で あったりとかそれらをどのようなシナリオ で活用するべきかっていうのが見えてくる ということですねでChatgpdの概要 の最後なんですけれどもChatgpdや その他大記号言語モデルllm自体の課題 をこちらにまとめますでまず1点目なん ですけれども先ほどと被るんですが ChatGPTは最新の情報にアクセスが できないと例えば為替や株価のように国 一刻と変化していく情報に対してチト GPTははリアルタイムで対応することが できませんで2つ目の課題としては ChatGPTが独自の情報源にアクセス する能力を持たないということです企業の データベースに保存されている顧客名簿で あったりとか特定のプライベートな情報に はアクセスすることができませんで3つ目 に水論の正確性に課題があるというところ ですチャットGPTは時折り簡単な算術 計算でさえも間違えることがありますこれ は特に正確な情報や結果が求められる タスクにおいて大きな問題となりますねで そして最後にチャットgpdができない こととかのデータが足りないんだったら ファインチューニングすればいいんじゃ ないかっていうような意見もあると思うん ですけれどもファインチューニングする ことによって汎用性が劣化してしまうと いうことがありますとでChatGPTを 特定のタスク例えば自社データを食わせる であったりとか特定のタスクに特化した データを食わせてファインチューニング すると他の多様なタスクに対する性能が 低下すると言われていますでこれらの課題 を解決するための1つの手段として今回お 話しするラングチェインエージェントって いうものがありますでここここからは ラングチェインエイジェントを使って チットGPTの性能を生かしつつ苦手な ものは他のツールで解決していくっていう ことについてお話ししていきますで参考 までにですねここにバッと上げている課題 に関してはMrKLシステムズていう有名 な論文があってそ論文から引っ張ってきた ものとなりますMrKLシステムズって いうのはミラクルシステムズと呼ぶもので チャットGPTと他のツールを連携して どんどんどんどん課題を解いていくって いうことを提示しているロムとなってい ますそれではラングチェインエージェント についてのトピックに移っていきますまず ラングチェインエージェントの前にですね ラングチェインとは何かと言うとラング チェインとは言語モデルを利用する アプリケーションのためのフレームワーク ですでラングチェインについては前回の 勉強会でもご紹介しているので基礎的な 内容を知りたい方はYouTubeで前回 の勉強会の動画をご覧くださいでラング チェインエージェントはラングチェインの 中の1つの機能なんですけれどもラング チェインの中でも非常に面白くて重要な 役割を果していますランチェの主なタスク は次にどんなアクションを取るべきかを大 記号言語モデルllmに決定させそれを 実行するということですで具体的な プロセスは以下の通りですとまず各ツール ができることと質問を指定したレスポンス のフォーマットでllmに送信します聞き ますとチットGPTなどのllmに聞き ますそしてllmChatGPTから帰っ てきたレスポンスをパースして次の アクションを決めるということをしますで このプロセスによってラングチェインジと はユーザーの4級に応じて効率的かつ正確 なアクションを実行できるようになって いるというところですでここでラング チェインエージェントがどのように動く かっていうもののイメージを具体的な例と して1つ持ってきましたま正確に正しい 動き方をしてるわけではないんですけれど も大体こういうような動きをするんだよっ ていうこともご理解ください例えばチット GPTに対してコミュニケーションを取る のがラングチェインのエージェントとなる んですけれどもラングチェイン エージェントにですねまずこう今日東京で で出かける時時に適切な服装は何ですかて いうのを聞きますでそうするとラング チェインエージェントが聞きたい内容今日 東京で出かける時に適切な服装っていう ものとあと自分が持っているツールって いうものをプロンプトに入れてチャット GPTに聞いてくれますとで自分が持っ てるツールっていうものは例えば Google検索のツールっていうも持っ てますとGoogle検索のツールでは 最新の情報を引っ張ってくることができ ますと私が持ってるのはGoogle検索 のツールで最新の情報が引っ張ってこれ ますそしてで今回聞質問としては東京で 出かける時に適切な服装って何でかていう ものを聞きますとでその時にチャット GPTはどのように返してくるかというと でまずは検索ツールでインプットは東京の 気温っっていうもので調べなさいっていう ものをエージェントの方に返してきますで エージェントはチャットGPTからから 教えてもらったじゃあえ検索ツールを使え ばいいのかっていうところで検索ツールを 使おうとしますでインプットとしては チャトGPTが教えてくれたように東京の 気温っていうものをインプットとして入れ てで検索ツールから帰ってきた22度って いうものを変してもらいますとでそして またえっとチャットGPTにえこのツール に入れた答えってものが22°でした次何 すればいいんですかであったりとか最終的 にどうなんですすかっていうのをチャット GPTに聞いてチャットGPTが十分な 情報を得たっていう風に判断するとでは 22°なので薄の長袖でがいいでしょうっ ていうものをエージェントとしに返してで あとはえ答えとしてラングチェインの エージェントが東京は22度なので素の 長袖でがいいでしょうっていうものをその まま返してくるというような流れになり ます特徴的なものとしてはチャットGPT だと今日の天気であったりとか東京の天気 であったりていうものは取れないんですね でそこをGoogle検索のツールって いうものを利用することによって新しい データっていうのを取れるようにしてると いうところですねもう1つ押えておきたい こととしてはこの問を解く時に自分が持っ ているツールっていうもの一覧を渡して どのツールを使えばいいかっていうのこと 自体もチャットGPTに判断してもらうっ ていうところが面白いところとなってい ますはいでこれがラングチェイン エージェントリアクトフレームワークとか 呼ばれたりするようなやり方ですねはい これらのこと全部ラングチェインの エージェントがやってくれるというところ ですでラングチェインエージェントって いうものは様々なタイプのエージェントが 用意されていますとここでエージェントの タイプっていうものを紹介するんです けれども解きたい課題に応じて エージェントを使い分けることによって 精度の高い回答を得られるようになると いうことですここで6個ほど上げています でまず1番汎用的なものとしてはゼロ ショットリアクトエージェントというもの ですでこのエージェントはリアクト フレームワークを利用してツールの説明に 基づいてどのツールを使用すべきか判断し ます先ほどの例で出てきたものと同じです ねこれによって特定のトレーニングデータ なしで多様なツールの適切なこう利用が 可能になってきます次にストラクチャード インプットリアクタエージェントですで このエージェントは複数の入力を使う エージェントを活用することができますで これによってより複雑なツールの理由用が 簡単になりタスクの効率が向上しますと 続いてOpenAIファンクション エージェントですこのエージェントはオ AIのファンクションコーリングの機能を 使っており関数が呼び出されるタイミング であったりとかを検出したりとか適切な 入力を関数に渡すような微調整がえオープ AI自体チットGPT自体がされていて それを使うことができますとOpenAI のえファンクションコーリングこの エージェントが使うOpenAIの ファンクションコーリングについてはこの 後のスライドでもう少し詳しく説明します で次にコンバーションエージェントですで このエージェントは会話での使用目的とし て設計されています何かを聞いて何か答え を出すっていうようなま単純なチャット GPTで何かこう答えを作ってくださいと かそういうのとは違くて会話的な インタラクションを通じて効果的な コミュニケーションを可能にするような エージェントとなっていますそして次に あげるものとしてはセルフアクwith sarchエージェントですねでそこの エージェントはですねセルフアクという 質問を自問自としながら分割することに よって正しい解を導き出す方法を使って 情報を検索するエージェントですセルフア クっていうプロンティグの技術があるん ですねまそれを使ってちゃんとした正しい 答えを導き出すエージェントとなってい ますで最後に紹介するものがリアクト ドキュメントストアエージェントですで このエージェントはドックストア ドキュメントストアですねと対話するため にリアクトフレームワークを使用してき ますえこれによって文書の管理であったり とか検索が一元化されて効率的に情報 アクセスが可能となりますこちらに関して はまた今後の勉強会でも取り扱っていき たいかなという風に思ってるんですけれど も文書検索管理っていうものに特化した エージェントとなっていますで以上がラン チェインエージェントの各エージェントの 使用となりますでそれぞれのタイプが 異なるシナリオやタスクに適しており ラングチェインの柔軟性と多様性を象徴し ているものとなります今回のセッションで はですね最も汎用的なゼロショット リアクトとチャットGPT自体に色々判断 させるファンクションコーリングを使った オープAIファンクション2を利用して いき ますでは先ほど説明を省いてしまったん ですけれどもOpenAIファンクション コーリンググっていうのはOpenAI ファンクションコーリングじゃないですね OpenAIファンクションですね OpenAIファンクションとは何か エージェントタイプの1つであるOpen AIファンクションとは何かについてお 話ししますこちらはChatGPTを提供 しているOpenAIのファンクション コーリングという機能を利用していますで ファンクションコーリングっていうものは 2023年の6月にリリースされた機能で ラングチェインエージェントが担っていっ たツールを渡してチャットGPTに聞いて 次のステップを決定するやり取りってい ものをチットGPT自体が行えるように ファインチューニングされているものと なりますでこの機能では東京の天気を教え てくれというような先ほどと同じように ですね質問と共にどういう関数を持って いるのかその関数の説明をチトGPTに 直接投げるということをやりますなので 先ほどのラングチェインエイジェントが やってることと同じようなことをやれる ようになっていてチットGPTが ファンクションをどのように受け取るのか そのファンクションのパラメータであっ たりとか説明とかをよりチャトGPTが 理解しやすいようにAPIとして受け取る ことができるようになっているのでより 適切な判断をチャットGPTがしやすく なっているというところがメリットとなり ますなので今メリットをお話ししてしまっ たんですけれどもファンクション コーリングを使うメリットとしては ChatGPTにツールの挙動をより正確 に伝えやすくなっているというところで これによってChatGPTが機能の ツールのえファンクションの使用や動作を より正確に理解しやすくなっていて適切な 判断をしやすくなっているとていうのとで もう1つのメリットとしてはチャット GPTっていうものがラングチェイン エージェンドって元々チャットGPTが 返してきた個体を利用者が頑張って定期 表現を使って解析する必要があったんです がそれをする必要がなくなったっていう ところが利点としてありますとでチャット GPTが実際にラングチェインを使って どのツールを使えばいいですかていうのを 聞くんですけどそれをどのようにパースし てるかというとこのように頑張ってですね えっとレギュラーエクスプレッションを 使って正規表現を使ってパースしたりとか して次のアクションを決めてたりするって いうのがラングチェが今までやっていた ことであるとでこういうパースをしなきゃ いけないっていうことをしなくて済む つまりパースしなきゃいけなかったので今 まではそのパースすることでえっとうまく パースできなくてミスってしまうっていう こともあったんですけどそういうことが なくなるっていうことが期待されるという ところです はいはいちょっと駆け足になってしまった んですがここまでで20分ぐらいかかって しまいましたねえここからがレモに入り ますで実際にですねラングチェイン エージェントを使ってチャトGPTと自社 ツールを連結するような感じのえデモって いうものをお見せしていきますで使う エージェントとしてはゼロショット リアクトとオーエファンクションを使って いきますであとは今回のプレゼンの冒頭の 方でもお話ししたようにChatGPTに ツールの説明をどのように渡せばいいのか であったりとかその辺りを持ち替えて いただければ幸いです はいではではやっていきますちょっと時間 がなくなってきたので駆け足でいきますね でまずは設定ファイル読んでいきますこれ 何をやってるかと言うとえOpenAIの APIキーであったりとかを読んでいます でまずはですねえっとゼロショットの方を 見せしていきたいんですがおマジないとし てですねおじないというかま前回の勉強会 と同じようにですねラングチェイン エージェントを使うためのやり方をお見せ していきますで実際今回使うモデルとして はチットOpenAPAIというか ChatGPTのえGPT3.5のtbo 0613というものを使っていきますで 外部のツールとしてはGoogleサーチ のAPIっていうものを今回用意しました ここであのサプAPIっていうものを書い ているものがえGoogleのAPIと なりますで聞きたい質問としては今日の 東京と北海道の天気を調べて東京から 北海道の出張で来ていくべきを教えて くださいっていうものを聞きたいと思い ますでラングチェインエージェント自体を 走らせてみますでこれがゼロショット リアクトエージェントを使った場合どの ようになるかっていうのをお見せしますで エージェントタイプに関しては イニシャライズエージェントの エージェントっていうえ引数に対して エージェントタイプのこのゼロショット リアクトディスクリプションていうものを 渡すとエージェントを選択することができ ますちなみになんですけれどもえこれって ただあの文字列が返ってくるだけですかね あのゼロショットリアクト ディスクリプションていうものが返って くるだけのものになりますなので文字列で 与えても同じですはいでは実行してみ ましょうチトgpdはもちろん今日の天気 とか今日の東京とか北海道の天気っていう のは知らないので来ていくべき服装って いうことは分からないわけですね気温も 分からないのででこれでラングチェイン エージェントが私はGoogle検索の ツールを持ってますよでそれを使って使う ことができますでこの問題課題っていう ものを解くためにはどうすればいいですか てのを聞くっていうことですねでここで ざーっと出てきてるんですけれども実際に 書いてきた答えとしてはtheWisto isCloudyaboutcrear withtempof歌詞になっちゃって ますけどまこのように帰ってきますと 英語で帰ってきちゃってますねでこういう 風にえどんなアドレスをれ切ればいい かっていうものがちゃんと帰ってきてい ますと前にやった時はそんなに綺麗に帰っ てきてなかったんですけれども今回は うまく帰ってきていますはいこちらがゼロ ショットリアクトディスクリプションで やった場合の結果になりますでどういう ことをやってるかっていうのなこの辺りを 見ていただくといいのかなという風には 思いますでチットGPTにまずラング チェインエージェントが問題とツールを 渡してチットGPTに何をすればいい かっていうのを聞きますでチャットGPT から帰ってきた答えとしては次の アクションとしてはサーチをしてください ですサーチのインプットとしてはウザー 東京todayていうものを渡してくださ いっていうのを渡してますで次の アクションとしてはサーチをしてください でそのインプットとしてはウザ北海道 todayていうものを渡すようにして くださいとで最終的にその帰ってきた答 っていうものをチャットGPTに渡して 最終的な文が出てくるということですはい でこれが1つ目ですねアエージェント タイプ1つ目のえゼロショットリアクト ディスクリプションで元々ラングチェイン エイジェントがリアクトフレームワークで ツールを渡したりとかしてチャットGPT とうまく連携しながら外部ツールを使う ようにしたえ機能となっていますでこれが ですねえ最近出てきた6月にリリースされ たOpenAIのファンクションコーリン グっていうものを使うとどうなるかって いうのをお見せします はいでOpenAIファンクション OpenAIのファンクションコーリング を使うためにはエージェントタイプの OpenAIファンクションズっていう ものを渡しますでそうするとえこのように 動きますで実際にやってることとしては ラングチェインエージェントがOpen AIのファンクションコーリングっていう ものを使ってうまくチャットGPTと やり取りしながら答えを導き出していくっ ていうことをやっていますはい出てきた 答えはこちらですねで同じようにですね どのようにやっているかっていうものは ここら辺の途中で出てきているんです けれども途中結果でえサーチとしてはえ クエリー東京の今日の天気っていうものを 調べてくださいでサーチっていうツルを 使って今日の北海道今日の天気っていう ものを調べてくださいでこれらが帰ってき た答えっていうものをえチャットGPTに 返してチャトGPTがその与えられた情報 を元に東京の今日の天気は曇りですが後に は晴れる予報ですで気温は接し30°歌 86°でコス確率はどうのこうのっていう ものがあってであとは東京は暑くなる可能 性があるので軽い服装が適しています ただし北海道は比較的涼しいので ジャケットなどを持っていくことがお勧め しますというような感じに帰ってきてます ま見て分かると思うんですけれどもま日本 語にな質問が日本語だったので日本語で ちゃんと返してくれるっていうのは もちろんのことなんですけれども書いてき た答えっていうものに関してより詳しく 返してくれているっていうことが分かると 思いますなので使ってみた所管としては ですねここで言うオAIファンクションの ファンクションコーリングっていうのの ファンクションっていうのはラング チェインエージェントでいうツールと同じ なんですけれどもそのファンクションで あったりとかツールを渡す時にですね渡し て何かを判断判させたいチャットGPTに 判断してもらいたいっていう時はえ エージェントタイプゼロショットリアクト ディスクリプションよりもエージェント タイプオAIファンクションの方がより いい結果が返ってきやすいっていうことが 分かると思い ますもう少しあの詳しく見ていきます ちなみにですねOpenAIにどんな ファンクションを渡してるかっていうのは イニシャライズエージェントのところで エージェントを定義してるんですけども そのエージェントの中からエージェントっ ていうものとファンクションズってものを 実行するとどんなえファンクションが渡さ れてかっていうのを見ることができますで 今回渡されたファンクションっていうのは ネームサーチっていうファンクションが 渡されていてどんなことができるかって いうのでサチエンジンですっていうような ものをやってますであとはパラメーターと してはこういうものを渡していきますって いうのが分かりますとはいでここまでが 基本的なラングチェインエージェントを 使って外部ツールを連携するっていうお話 をしてきましたとで次にですねえ自社で 作ったツールっていうものを連携させ るっていところについてお見せしていき ますで一旦はですねレコメンドアイテムっ ていうものを考えてみようと思いますで ここ何をやりたいかって言うとレコメンド アイテムまこの中身はほとんど意味のない ものになってるんですけれどもレコメンド アイテムっていう関数を自社で持っていて でレコメンドアイテムっていうものは自社 のデータベースなどにアクセスして日付を 持ったにこの日のレコメンドっていうもの はこういうものですっていうものを返す ような関数っていうところになりますとな のでえっとこのレコメンドアイテムって いうところをこの関数ををえChat GPTのフローの中に組み込みたいって いうことをやっていきますでどのように ラングチェインエージェントを使って ChatGPTに連携すればいいかという とツールっていうものにえ変換していく 必要がありますとでレコメンドアイテム ツールっていうものをえツールfrom ファンクションズっていうものを使って どのようなファンクションを実行したい ですかレコメンドアイテムっていう ファンクションを実行したいですまこう いう風にですねこの今回のあまり意味の ないファンクションなんですけれどもこれ を実行しますとでツールの名前としてはえ レコメンドアイテムっていうものを渡し ますでツールのディスクリプション何を やってくれるかっていうことに関してはお すめの商品を教えてくれますっていうのを ツールとして定義するというところです はいでこれをちょっとツールズっていうま ツールまとめて渡さないといけないで ツールの配列の中に入れておきます実際に ですねラングチェインエージェントにどの ようにツールを渡せばいいかっていうとま 先ほどもカラっとやってたんですけれども このツール1覧っていうのを最初に渡して 引数として渡しているのでまこのようにし てどんなツールが使えるかっていうものを ラングチェインのAに渡しでチャット GPTと連携していきますはいでえっと 今回聞きたいこととしてはえおすすめの 商品を教えてくださいっていうものを投げ てみようと思いますで使うエージェントと しては先ほどゼロシトリアクトよりもより いい結果が返ってきたオーエ ファンクションズってものを選びます はいはいでは実行し ますはいで書いてきたものとしてはですね コメドアイテムってものが実行されて withファッションという謎のものをえ 入力に入れてで実際この引数がですね デートの中にファッションが入ってで プリントファッションっていうところでこ でファッションが出てきてしまってるとで ただおすめの商品は今回レコメンド アイテムで書いてきたAppleですって いうのが書いてきてることが分かると思い ますはい見て分かるようにですねなんか よくわからない引数は与えてしまってる なっていうところがありますでこを どんどん解決していこうと思いますで次に やることとしては今回なんでこのように変 なファッションとかいう引数を与えて しまったかというと引数に関する情報が ないんですね与えられてないというところ になりますとなので引数何与えればいいん ですかみたいなところが情報としてないが ゆえにチャットGPTもレコメンド アイテムを使うことは分かるとレコメンド アイテムを使えばいいのは分かるんだけど レコメンドアイテムに対してちょっと 分からないからカテゴリー情報でも渡して みようかなっていうのでファッションを 渡してしまっているというような状態に なりますで例えばまファンクションを見た としても今回使ってるファンクションに 関してはレコメンドアイテムでおすめの 商品を教えてくれますでパラメーターの 情報は全くありませんっていう状態なので どんなパラメーターを渡せばいいかって いうのはオープAIファンクションは 分からないというところですねじゃあこれ に対してどうすればいいかっていうのをお 見せしますでえっと結構簡単でしてパダ ティックっていうものをご存知ですかね こう最近えっとファストAPIとかですか ねこう結構パであったりとかそのヒントを 与えるっていうことがまPython主流 になってきてると思うんですけれども フダンティックを使っていきますでえっと ご注意していただきたいこととしては ファインディッてもうV2が出てるんです けれどもV2を使うとラングチェイン エージェントを動きませんとなので パティックV1を指定して方に関する情報 をえ与えるためのそのベイスモデルとか フィールドを使ってえやっていきますで これ何をやってるかと言うとま今回の インプットに対してデイトっていうものが ありますがデイトていうものはお勧めした 商品を絞るために使われる日付ですって いうものを与えていますこれをえっと アーグススキーマ先ほどのツールを定義 する時にアグススキーマっていう引きを 使ってこのレコメンドアイテムインットっ ていうベースモデルから継承した レコメンドアイテムインプットっていう インプットの報引数の情報を持ったクラ スっていうものを渡すということをします とでこうするとどうなるかっていうのをお 見せしていき ますはいじゃあどう変わる かいきますはい実行します全く同じですね 実行するものとしてはで今回はレコメンド アイテムっていうものに対して先ほどと 同じレコメンドアイテムっていうものが 選ばれましたとコアイテムに対してデイト が2020年の12月1日っていうものを 渡しているっていうことが分かりますで それによってですね気付がちゃんと渡して くれたっていうことがわか分かるわけです ねで今回あのここであのデートっていう ものはディスクリプションでお勧めしたい 商品を絞るために使われる日付っていう ことを伝えたのでチャットGPTの方があ これは日付のことなんだっていうところで 引数はファッションのようなカテゴリーを 渡すんではなくてデートの引数っていう ものを渡すことができてるというところ ですはいでこちらがデトのまあ2022年 の12月1日もはや日付が意味が分から ないですけれどもこういうものが渡されて いるというところですねでおすめ商品は Appleですという風にでこういう風に ですねこうツールの説明をどんどん どんどん入れていってええ解決していく 必要があるというところですねで同じよう にですねちょっとエージェントの ファンクションがどのように渡されるてる かっていうのをお見せしますとで今回渡さ れたのはレコメンドアイテムインプトって いうのをえパイダンテックの方で定義して 渡しているのでえ実際にえっと ファンクションOpenAIのえ ファンクションコーリングにどのように 渡されてるかというとパラメーターとして ですねこういう風なレコメンドアイテム インプットっていうものが渡されていて プロパティとしてはデートがあってデー トっていうのはお勧めしたい商品を絞る ために使われる日付っていうものが入れ られてえ飛ばされてるということが分かる と思いますはい で他にはですねこのようにツールフロン ファンクションで作るっていうこともある んですけれども同じようにですね デコレーターを使うっていうこともでき ますとデコレーターの方が結構シンプルに 書けるので私は結構デコレーターを使って 書くことが多いですとでデコレーター何を すればいいかというとデコターっていうの はま関数の前にですねアマークツールなん ちゃらかんちゃらっていうものがあってで それを使ってえっとこのツールってのは何 ができるかっていうものをえドッ ストリングで与えるんですねな先ほどと 同じにするとレコメンドアイテムツールっ ていうものがあったら中身は同じですね プリントデイトとAppっていうものを 返しますとプリントデイトしてApple っていうものを返しますとででやることと してはおすめ商品を教えてくれます全く 同じ内容ですねでこのツールの名前って いうものはデコレーターの引数として レコメンドアイテムとして渡していると いうところですで同じようにですね ツールズの一覧として入れてでこれをえ 実行してみ ましょうはいこれデコレーター使った場合 です ね実行するものは全部同じですで同じよう にこれも実行できますという風にデコレー ターってかなりこうシンプルにかけてで ファンクションの中のドックストリングス とかを使ってくれるので結構あの家読性と かもう悪くないかなという風には思います 先ほどと同じようにですねこレコメンド アイテムってものはちゃんと選んでくれた んですけれどもレコメンドアイテムに渡し ているデートっていうのは2021年10 月15日という意味の分からない日付を 渡してしまっていますとこれはなぜかと言 とまもちろんそのおすすめ商品を教えて くださいって言ってるので勝手に日付を 決めて聞いてしまっているというところ ですね はいでデコレーターの方もですね同じよう にファンクションを見てみるとえっとこう いう風になるという感じですねただあの 先ほどと同じようにですねパダンティック とか使っていないのでプロパティの パラメーターとかは適当になってしまって いるというような感じになりますただ今回 の場合はですねこうデコレーターの場合は フロムファンクションの方を使ったこっち の場合ですねこのフロムファンクションを 使った時と違ってきちんとデートを入れて くれているっていうことが特徴的かなと いう風には思いますフロンファンクション を使った場合っていうのはパダンティック を渡さないとデートっていうものに対して ファッションを入れたりとかよく分から ないものを入れたりすることがあったと 思うんですけれどもデコレーターを使った 場合はこのデートっていうものを渡した時 にきちんとこうデートを返してくれるよう な情報っていうものを渡せてくれている ような感じですねいずれにせを正しい共同 を求めるためにはこのままあまり情報を 与えないで実行するってのは適切ではない ので特に自社ツールサービスとして提供 する側としてはですねなのでそういう意味 ではきちんとバイダンティックなどを使っ て適切な情報を渡しながら関数っていう ものを渡していく必要があるかなという風 に思いますなのでえっと先ほどと同じよう にですねデコレーターを使った場合も パイナティックの情報っていうものを渡す ことができるのでデコレーターの引き数に アーグススキーマていうものを渡してで そのパイランティックの情報を渡すことで 適切な答えを返すことができるようになる というところです同じようにですねま結果 も変わらないので はいまこういう風に変えてきました ちょっと答えがどんどんどんどん変わって きてますApple製品だったりとか AppleStoreとかオンライン ショップとかうんまここら辺に関しては 本当に適切な答えがまだ返ってきてない なっていうような状態だとは思います エージェントのファンクションを見るとえ きちんとファナティックで渡した情報って いうのが渡っていることが分かると思い ますこのようにですねこのデートっていう ものはデートっていう引き数はお勧めし たい商品を絞るために使われる日付ですっ ていうのが渡っているというところです もう少しですね今までこうおすめの商品を 教えてくださいっていう風に言っていたの でデートっていうものが1月10日であっ たりとかよくわかんない日付になっていた のではないかっていうことを推測してでは 昨日のおすすめ商品を教えてくださいって いうものを聞いてみますてそうするとどう なるかと言うとえ昨日のおすめ商品を教え てくださいって言ってるのにレコメンド アイテムに渡されてるのは2021の10 月20日っていうものが渡されれてること が分かりますとチャットGPTにこう昨日 とか今日とか昨日とか渡したら日付を ちゃんと入れてくれるのかなと期待するっ ていうことがあると思うんですけれども 実際はそんな入れてくれないっていうこと がまこの結果から分かるということですね もう少し例えばディスクリプションとかを 適切にすればうまくいくのかもしれないん ですけど今回は違う手段でえっと解決 しようと思いますで今回どういう風に解決 するかと言うとデートタイムを使って 新しい日付けを取得するような関数自社 ツールってものを設けようと思います ゲットデートっていうツールっていうもの を作ってでそのツールは何をするかという とま今日や昨日など日付を取得する時に 使います引き数には今日を起点として何日 か前をNで与えますとでここのそのドック ストリングスにですねこう引数に関する 情報を書いてるんですけども実際はですね パダンティックで引き数の説明した方が ベタだとは思いますただえっとドック スリンに書いてツールの説明として与える だけでも結構チャットGPTは賢いので うまく判断してくれるということですでお 見せしますはいこの日付関数を入れると どうなるかと言うとこういう風な感じです ねはい今日のおすめの商品を教えてくださ いっていう風にするとtodayて書い てき来てこれもうまく動いてないですね こういうことが結構ありますとうまく動か ないことがあるとでもう1回実行してみ ましょうかはいでもならではですね ちょっと30分で終える予定が46分に なってしまったんですがもう少しで終わる ので続けます前回のやつだとですね直接 レコメンドアイテムを呼び出してデートに 対してtoデイていうものを渡してしまっ てたんですけれども今回はうまく動いてい てまずは日付を取得するためにゲットデイ トっていうものを呼び出しますとで今日な ので今日からの起点のえN日前だったらN に0を渡せばいいということが分かるとだ からゲットデートに0を渡して帰ってきた ものが2023年の9月30日っていう ものが帰ってきてで9月30日のえお勧め 商品は何ですがま書いてくるものは全部 AppleなのでAppleってものが 帰ってきてることが分かると思います同じ ようにですねじゃあどういう ファンクションが渡されてたかっていうの をお見せするとサクっとですねで今回あの ファンクション2つ渡されていて レコメンドアイテムっていう ファンクションとゲットデイトっていう ファンクションが渡されていますで それぞれのファンクションの説明がこの ように与えられているということが分かり ますもう少しツールを複雑にしていって ですね奇数日だったらオレンジ偶数日だっ たらえAppleっていうものを返すよう なツールにちょっとだけレコメンド アイテムを変えみようと思い ますはいではえこれを実行するとですね 今日はえ9月30日なのでもちろん9月 30日偶数日ですね偶数日なので Appleが返ってくるきちんと帰ってき ますねAppleが帰ってきましたでは 昨日の場合はどうなのか 昨日はい昨日の場合は29日なので1日前 ってものをゲットデイトで取得して29日 ってものが書いていますで29日を使って え昨日のおすめ商品オレンジっていうもの を取ることができるというところ ですやとうまく動きました ねでもう少しだけちょっと時間が1時間 ぐらい喋ってしまうような感になるんです けれどもう少しだけお話させてくださいで これだけだともちろんまだまだ連携が 少ないかなっていうところがあってで次に じゃあAppleだったら100円 オレンジだったら200円っていうような ものを商品の値段を返すような関数って いうものを組み込んでみましょうでツール としては元々グビだったらAppleキビ だったらオレンジを返すようなものとあと は日付を取得するツールであとは今回定義 したAppleとオレンジAppleだっ たら100円オレンジだったら200円 っていうのを返すツールっていうものを 定義しますでこれでエージェントのですね おすめの商品の値段まで教えてくださいっ ていうことをやるとそうするとまず最初に え昨日なのでゲットデートでN=1を渡し て1日前のデートを取ってきますで9月 29日ですで次にレコメンドアイテムって いうツールを呼び出してレコメンド アイテムにえ9月29日を渡してで最後に ですねアイテムプライスっていうので アイテムネームをえオレンジにとして渡し てでオレンジはは200円なのでえ昨日の おすめ商品であるオレンジの値段は 200円ですっていう最終的な答えが返っ てきましたというところになりますだいぶ 柔軟なものができるようになってきたって いうことが理解できると思いますで他には ですね最後なんですけれども取得した結果 を吐き出したいとかデータベースに 書き込みたいとかあったりすると思うん ですけどもそういうことももちろん簡単に できますと基本的にはファンクションが あってそのファンクション中身は自分で 書いていくので何でもすることができると いうところですねちょっとあの output.tchっていうところに 書き込むようなものを記事的にですね データベースに書き込んでいるようなもの として紹介しようと思いますで今回は さらに追加するツールとしてはですね セーブデータっていうツールを追加します とセーブデータっていうものは何なのかと いうとここにも説明書いてあるんです けれども日付と商品名と商品の値段を 受け取ってデータベースに書き込みますっ ていうようなものをツールとして作りまし たデータベースといながらもアウトプット テキストにただ書き込むだけのものになる んですけどもデートアイテムネーム アイテムプライスを書き込むだけのツール となりますま実際に自社ツールを使う時に はここにSQL分であったりとかを書いて データベスに書き込むとかをやったりする ことになると思いますこちらもですね ちょっと簡易的にですねフダンティックを 使わずにえドックストリングだけで何を やるかってのを渡して書き込めるかどう かってのをお見せしていこうと思いますで 同様にですね同じように何をしたいかと 言うと今日のおすめ商品の値段を調べて データベースに書き込んでくださいって いうことを実行し ますで最初に動くものとしてはまず日付を 取得するゲットデイトが動いてN=0で 今日の日付を取ります9月30日ですと9 月30日が取れたら9月30日の レコメンドアイテムは何ですかていうので レコメンドアイテムのツールを起動して 書いてきたものがAppleですとであ次 にやることしてはAppleの値段は いくらですかていうものをアイテム プライスに聞いてアイテムプライスが返し てきた答えが100円ですとで100円 っっていうものをえセーブデータに渡して セーブデータに渡すものとしてはデートと アイテムネームとアイテムプライスこれは 日付と商品目と商品の値段を受け取 りっていう風に書いてあるのでこういう ようなものを基数として与えて データベースに書き込みますていうことを この操作でやるということですねなので 細かいことを書いた方がミスは少ないん ですけれどもあんまり書かなくても動いて くれるっていうのがまやっぱりこう チャットGPTのうまいところかなという 風には思いますで最終的に帰ってきたこと としては今日のえおすすめ商品の値段は 100円ですとでデータベースに正常に 書き込まれましたっていうので データベースではないんですけどれも テキストファイルっていうものを中身見て みましょうと今日の日付2023年9月 30日でおすすめの商品Appleで最終 的に100円っていうのが書き込まれた ことが確認できましたとはいとても長く なってしまったんですけれどもこちらで テモは終わりとさせていただきたいと思い ますはい私の発表は以上となります ありがとうございました\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001b[0m\n"
     ]
    },
    {
     "ename": "InvalidRequestError",
     "evalue": "This model's maximum context length is 4097 tokens. However, your messages resulted in 19305 tokens. Please reduce the length of the messages.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msummarize_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/lib/python3.11/site-packages/langchain/chains/base.py:292\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    291\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 292\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    293\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    294\u001b[0m final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[1;32m    295\u001b[0m     inputs, outputs, return_only_outputs\n\u001b[1;32m    296\u001b[0m )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/lib/python3.11/site-packages/langchain/chains/base.py:286\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    279\u001b[0m run_manager \u001b[38;5;241m=\u001b[39m callback_manager\u001b[38;5;241m.\u001b[39mon_chain_start(\n\u001b[1;32m    280\u001b[0m     dumpd(\u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    281\u001b[0m     inputs,\n\u001b[1;32m    282\u001b[0m     name\u001b[38;5;241m=\u001b[39mrun_name,\n\u001b[1;32m    283\u001b[0m )\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    285\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 286\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    287\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    288\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[1;32m    289\u001b[0m     )\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    291\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/lib/python3.11/site-packages/langchain/chains/combine_documents/base.py:105\u001b[0m, in \u001b[0;36mBaseCombineDocumentsChain._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;66;03m# Other keys are assumed to be needed for LLM prediction\u001b[39;00m\n\u001b[1;32m    104\u001b[0m other_keys \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m inputs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_key}\n\u001b[0;32m--> 105\u001b[0m output, extra_return_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcombine_docs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_run_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mother_keys\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m extra_return_dict[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_key] \u001b[38;5;241m=\u001b[39m output\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m extra_return_dict\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/lib/python3.11/site-packages/langchain/chains/combine_documents/map_reduce.py:209\u001b[0m, in \u001b[0;36mMapReduceDocumentsChain.combine_docs\u001b[0;34m(self, docs, token_max, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcombine_docs\u001b[39m(\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    199\u001b[0m     docs: List[Document],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    203\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mdict\u001b[39m]:\n\u001b[1;32m    204\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Combine documents in a map reduce manner.\u001b[39;00m\n\u001b[1;32m    205\u001b[0m \n\u001b[1;32m    206\u001b[0m \u001b[38;5;124;03m    Combine by mapping first chain over all documents, then reducing the results.\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;124;03m    This reducing can be done recursively if needed (if there are many documents).\u001b[39;00m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 209\u001b[0m     map_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm_chain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# FYI - this is parallelized and so it is fast.\u001b[39;49;00m\n\u001b[1;32m    211\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdocument_variable_name\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpage_content\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m     question_result_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_chain\u001b[38;5;241m.\u001b[39moutput_key\n\u001b[1;32m    215\u001b[0m     result_docs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    216\u001b[0m         Document(page_content\u001b[38;5;241m=\u001b[39mr[question_result_key], metadata\u001b[38;5;241m=\u001b[39mdocs[i]\u001b[38;5;241m.\u001b[39mmetadata)\n\u001b[1;32m    217\u001b[0m         \u001b[38;5;66;03m# This uses metadata from the docs, and the textual results from `results`\u001b[39;00m\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i, r \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(map_results)\n\u001b[1;32m    219\u001b[0m     ]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/lib/python3.11/site-packages/langchain/chains/llm.py:191\u001b[0m, in \u001b[0;36mLLMChain.apply\u001b[0;34m(self, input_list, callbacks)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    190\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 191\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    192\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_outputs(response)\n\u001b[1;32m    193\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: outputs})\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/lib/python3.11/site-packages/langchain/chains/llm.py:188\u001b[0m, in \u001b[0;36mLLMChain.apply\u001b[0;34m(self, input_list, callbacks)\u001b[0m\n\u001b[1;32m    183\u001b[0m run_manager \u001b[38;5;241m=\u001b[39m callback_manager\u001b[38;5;241m.\u001b[39mon_chain_start(\n\u001b[1;32m    184\u001b[0m     dumpd(\u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    185\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_list\u001b[39m\u001b[38;5;124m\"\u001b[39m: input_list},\n\u001b[1;32m    186\u001b[0m )\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 188\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    190\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/lib/python3.11/site-packages/langchain/chains/llm.py:103\u001b[0m, in \u001b[0;36mLLMChain.generate\u001b[0;34m(self, input_list, run_manager)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Generate LLM result from inputs.\"\"\"\u001b[39;00m\n\u001b[1;32m    102\u001b[0m prompts, stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_prompts(input_list, run_manager\u001b[38;5;241m=\u001b[39mrun_manager)\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/lib/python3.11/site-packages/langchain/chat_models/base.py:458\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    452\u001b[0m     prompts: List[PromptValue],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    456\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    457\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m--> 458\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/lib/python3.11/site-packages/langchain/chat_models/base.py:348\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[1;32m    346\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n\u001b[1;32m    347\u001b[0m             run_managers[i]\u001b[38;5;241m.\u001b[39mon_llm_error(e)\n\u001b[0;32m--> 348\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    349\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    350\u001b[0m     LLMResult(generations\u001b[38;5;241m=\u001b[39m[res\u001b[38;5;241m.\u001b[39mgenerations], llm_output\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39mllm_output)\n\u001b[1;32m    351\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[1;32m    352\u001b[0m ]\n\u001b[1;32m    353\u001b[0m llm_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine_llm_outputs([res\u001b[38;5;241m.\u001b[39mllm_output \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results])\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/lib/python3.11/site-packages/langchain/chat_models/base.py:338\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[1;32m    336\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    337\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 338\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    344\u001b[0m         )\n\u001b[1;32m    345\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    346\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/lib/python3.11/site-packages/langchain/chat_models/base.py:490\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    486\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    487\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAsked to cache, but no cache found at `langchain.cache`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    488\u001b[0m     )\n\u001b[1;32m    489\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported:\n\u001b[0;32m--> 490\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    494\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/lib/python3.11/site-packages/langchain/chat_models/openai.py:343\u001b[0m, in \u001b[0;36mChatOpenAI._generate\u001b[0;34m(self, messages, stop, run_manager, stream, **kwargs)\u001b[0m\n\u001b[1;32m    341\u001b[0m message_dicts, params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_message_dicts(messages, stop)\n\u001b[1;32m    342\u001b[0m params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs}\n\u001b[0;32m--> 343\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletion_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessage_dicts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_chat_result(response)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/lib/python3.11/site-packages/langchain/chat_models/openai.py:282\u001b[0m, in \u001b[0;36mChatOpenAI.completion_with_retry\u001b[0;34m(self, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_completion_with_retry\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_completion_with_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/lib/python3.11/site-packages/tenacity/__init__.py:289\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_f\u001b[39m(\u001b[38;5;241m*\u001b[39margs: t\u001b[38;5;241m.\u001b[39mAny, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: t\u001b[38;5;241m.\u001b[39mAny) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m t\u001b[38;5;241m.\u001b[39mAny:\n\u001b[0;32m--> 289\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/lib/python3.11/site-packages/tenacity/__init__.py:379\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    377\u001b[0m retry_state \u001b[38;5;241m=\u001b[39m RetryCallState(retry_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, fn\u001b[38;5;241m=\u001b[39mfn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 379\u001b[0m     do \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    381\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/lib/python3.11/site-packages/tenacity/__init__.py:314\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    312\u001b[0m is_explicit_retry \u001b[38;5;241m=\u001b[39m fut\u001b[38;5;241m.\u001b[39mfailed \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fut\u001b[38;5;241m.\u001b[39mexception(), TryAgain)\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (is_explicit_retry \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry(retry_state)):\n\u001b[0;32m--> 314\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfut\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafter(retry_state)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/lib/python3.11/concurrent/futures/_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/lib/python3.11/concurrent/futures/_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/lib/python3.11/site-packages/tenacity/__init__.py:382\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    381\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 382\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[1;32m    384\u001b[0m         retry_state\u001b[38;5;241m.\u001b[39mset_exception(sys\u001b[38;5;241m.\u001b[39mexc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/lib/python3.11/site-packages/langchain/chat_models/openai.py:280\u001b[0m, in \u001b[0;36mChatOpenAI.completion_with_retry.<locals>._completion_with_retry\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_completion_with_retry\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m--> 280\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/lib/python3.11/site-packages/openai/api_resources/chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TryAgain \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m>\u001b[39m start \u001b[38;5;241m+\u001b[39m timeout:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/lib/python3.11/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m     )\n\u001b[0;32m--> 153\u001b[0m     response, _, api_key \u001b[38;5;241m=\u001b[39m \u001b[43mrequestor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m         \u001b[38;5;66;03m# must be an iterator\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/lib/python3.11/site-packages/openai/api_requestor.py:298\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    279\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    286\u001b[0m     request_timeout: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    287\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m    288\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_raw(\n\u001b[1;32m    289\u001b[0m         method\u001b[38;5;241m.\u001b[39mlower(),\n\u001b[1;32m    290\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    296\u001b[0m         request_timeout\u001b[38;5;241m=\u001b[39mrequest_timeout,\n\u001b[1;32m    297\u001b[0m     )\n\u001b[0;32m--> 298\u001b[0m     resp, got_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp, got_stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/lib/python3.11/site-packages/openai/api_requestor.py:700\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    692\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    693\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    694\u001b[0m             line, result\u001b[38;5;241m.\u001b[39mstatus_code, result\u001b[38;5;241m.\u001b[39mheaders, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    695\u001b[0m         )\n\u001b[1;32m    696\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m parse_stream(result\u001b[38;5;241m.\u001b[39miter_lines())\n\u001b[1;32m    697\u001b[0m     ), \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m--> 700\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response_line\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    703\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    704\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    706\u001b[0m         \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    707\u001b[0m     )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/lib/python3.11/site-packages/openai/api_requestor.py:765\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    763\u001b[0m stream_error \u001b[38;5;241m=\u001b[39m stream \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mdata\n\u001b[1;32m    764\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream_error \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m rcode \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[0;32m--> 765\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_error_response(\n\u001b[1;32m    766\u001b[0m         rbody, rcode, resp\u001b[38;5;241m.\u001b[39mdata, rheaders, stream_error\u001b[38;5;241m=\u001b[39mstream_error\n\u001b[1;32m    767\u001b[0m     )\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[0;31mInvalidRequestError\u001b[0m: This model's maximum context length is 4097 tokens. However, your messages resulted in 19305 tokens. Please reduce the length of the messages."
     ]
    }
   ],
   "source": [
    "summarize_chain(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c80550c-3365-4985-a658-2a5dd5bba3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16f02582-07f8-4b80-8082-21ac7772aaae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MapReduceDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\"では早速なんですけれども始めさせて いただきます私からはラングチェイン エージェントを使って自社ツールと チャットGPTを連携するというタイトル で発表させていただきますChatGPT 自体は皆さんご存知のように非常に優れた 能力を持っていますが最新のデータに アクセスできないとか特定の数学的な推論 が得意でないなどいくつかの課題が存在し ますこれらの課題は自社プロダクトに チャートGPTを導入するなどチャット GPTを社会実装しようとした際に解決し なければなりません今回お伝えするラグ チェインエイジェントを導入すると ChatGPTと外部ツールをうまく連携 させることができるようになりChat GPTが抱える課題を克服しチットGPT の可能性をさらに広げることができます 本日はラングチェインエージェントをどう 活用することでチャットGPTの能力を 拡張できるのか具体的にご紹介していき ますそれでは始めていきますこちらが私の プロフィールとなります内容はいつもと 同じなのでスキップさせていただきます はいでは具体的な話に入る前にですね今回 のテーマの結論に先に触れておきます結論 なんですけれどもラグチェインには様々な エージェントの種類が存在するが自社 ツールとチャットGPTを効果的に連結 する際汎用的なエージェントタイプである ゼロショットリアクトまたはオAI ファンクションを利用することが簡単と なりますゼロショットリアクトとOpen AIファンクションを比較するとOpen AIファンクションの方がチットGPT からより適切かつ精度の高い答えを 引き出しやすくなっていますこちらはデモ のでお見せしますねでそしてえっとここで ChatGPTと自社ツール連携で非常に 重要となるものとしてツールの説明という ものがありますと通常のプロンプトチャト GPTを使う時のプロンプトと同様に ツールの特性や機能をChatGPTに 正確かつ効果的に伝えることで自社ツール とチャットGPTの連携の成功率が格段に 向上していきますこのポイントに着目し ながら具体的な方法論について今日は 深掘りしていきたいと思いますそれでは これらのポイントを年頭にきつつ今回の 発表をお聞きください本日の発表は以下の 3つのセクションから構成されています 初めにチットGPTの基本的な概要につい て触れます次にラングチェイン エイジェントの特徴について紹介し最後に デモンストレーションを行いますデモでは 特にツールの説明について着目して いただけると幸いですそれでは最初の トピックに移りましょうここではチット GPTの全体的な特徴を振り返っていき ますすでにご存知の内容も多いと思うん ですけれども一般的なはチャットGPTの 性質っていうものをご紹介していきます チットGPTは実用的な大規模言語モデル llmで現在多くのビジネスに活用されて きています例えばベネッセ ホールディングスでは車内AIChat ベネッセGPTを開発しグループ社員 1.5万人に向けて提供しているという ようなプレスを出していたりとか立メカ 大学では大学の英語事業において機械翻訳 とChatGPTを組み合わせたサービス が試験導入されているであったりとか他に も色々なサービスがチャトGPTを 組み込み始めておりChatGPTの実用 化っていうものがすごい勢いで広がってい ますChatGPTを活用する際によく 言われることとしてはチャットGPTから 良い結果回答を得るためには良い質問が 必要であるということですでこれは プロンプトエンジニアリングと呼ばれる 領域で今最も伸びている業種の1つと言え ますプロンプトエンジニアリングではどの ような項目をプロンプトに入れるべきか またプロンプトを複数回うまく使いこ なくして良い回答をるテクニックなどが 研究開発されていますリアクトであったり とかいろんなことを聞いたことあると思う んですけれどもプロンプトの種類っていう のがどんどんどんど開発されているという ことですでチャットGPTの活用は多に 渡っておりその可能性は広がりつつあり ますでプロンプトエンジニアリングの テクニックを活用することでチャット GPTとの適切なコミュニケーションが 可能になりますプロンプト エンジニアリングでは色々なテクニックが 存在するのですが今回はプロンプト エンジニアリング自体がメインのテーマで はないのでプロンプトエジライニングの中 で抑えるべき基本的な項目とそしてよく 使われるまフーショットプロンティングと 呼ばれるような手法を簡単にだけ紹介して いきますはいまず基礎として抑えていき たいこととしてプロンプトに何を与える べきかっていうものをいくつか紹介して いきますで1点目としては具体的で明確に 質問することですで例えばその日本の歴史 において重要な出来事は何ですかという 質問よりも日本の戦国時代における重要な 出来事について教えてくださいという具体 的に質問し方が的確なコ答が得られますと で2点目に状況やコンテクストを明示する ことですて背景情報があるとチャット GPTはコンテクストをより理解し適切な 回答が返ってきますとで3点目期待する 回答の形式を指定するとこれにより望む 情報が整理されて帰ってきますリスト形式 で返してくださいであったりとか ジェイソン形式で返してくださいであっ たりとかまそういうことを質問する時に プロンプトの中に入れるということですね で4点目範囲を限定すること範囲が広す すぎると回答も後半で一般的になりがちに なりますなので範囲を狭めるということが 重要となってきますで最後5点目自性や 認証を明確にすることですと例えば子供で も分かるようにしてくださいとか中学生で も分かるようにしてくださいとかなんか そういう風にどの視点で書て思ってみるか を示したりであったりとか何年の情報が 欲しいとかそういうことを指定することに よって回答が明確なものが帰ってきやすく なるということですで次にプロンティ テクニックの1つののフューショット プロンティについて簡単に説明します フューショットプロンティはモデルに少数 の例を示すことで特定のタスクの解決方法 を学習させるアプローチになりますこれに よりモデルは様々な問に対して適切な回答 を生成することができますここに例として 上げてるんですけれども例えばレストラン 最高でしたこれは感情ポジティブですこの 映画は本当に時間の無駄だった感情 ネガティブですというようにいくつかの例 を与えて出したいものでそれぞれの文に 対しての感情っていうものをこのように 並べていきますてで最後に聞きたいものと してそのサービスは非常に遅く不満ですっ ていうものがあった時にどんな感情で すかっていうことを聞くと感情ネガティブ という風に返ってくるというところですで こういう風にすることによってモデルって いうものが新しい文章がポジティブか ネガティブかっていうのをま過去の例を元 に判断することができるようになるという ことですでこの方法によってですねフュー ショットプロンティはモデルに多様な タスクを効率的に学習させることができ 柔軟な対応が可能になってくるということ でですでここまでいくつかのプロンティの テクニックであったりとかをお話ししてき ましたもちろん他にもたくさんあってです ねチェインオブソツであったりとかあと セルフアスクであったりとかいろんなもの があるんですけれども今回のメインテーマ ではないので一旦プロンティグの話はここ で終わりにしてでここでちょっと一息つい てですねこれらのテクニックが持つ限界に ついて考えてみましょうでまず1点目なん ですけれどもプロンプトのテクニックは 日々進化し開発されていますとこれによっ てチットGPTは多様なタスクや質問に 対応でできるようになってきていますただ 全ての作業やタスクをチャットGPTに 依存すること自体が現実的ではありません とえ例えば先ほどの例で出てきた文章から の感情抽出に関してはチャートGPTに 無理やりさせることが適切かと言われると そうでもないかもしれないAWSコプリン のような勘定分析に特化した学習をして いるAPIっていうものがあってそれを 使った方がいい結果が返ってくるかもしれ ませんっていうのがまず1つ目ですねで次 に2点目としてそのChatGPTが持つ 情報っていうものは訓練データに限定され ていてチットGPTはそれ以外のデータに ついては知らないというところですなので えっとチャットGPTは過去のデータで 学習されておりその学習データ以降に出て きた情報に関してはチットGPTに尋ね られませんとよく言われるものとしては 2021年のデータですかねまでのデータ で学習してるので例えば2022年であっ たりとか2023年のデータについて聞い たとしてもチャットGPTがうまく答え られないというようなところですね最新の 価格的な研究であったりとかニュース記事 とか特定の地域の天気情報であったりとか チットGPTの訓練データに含まれてい ないような情報っていうものはChat GPTだけでは取得できませんし インターネットにあるデータだけではなく て例えば今回のテーマである自社のツール と連携するっていう時のためには自社の データを使いたいみたいな話とかあると 思うんですけれども自社データについては チャットGPTが知るわけもないという\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\"とか特定の地域の天気情報であったりとか チットGPTの訓練データに含まれてい ないような情報っていうものはChat GPTだけでは取得できませんし インターネットにあるデータだけではなく て例えば今回のテーマである自社のツール と連携するっていう時のためには自社の データを使いたいみたいな話とかあると 思うんですけれども自社データについては チャットGPTが知るわけもないという ことでえっとChatGPTに自社の データについて聞いたとしてもChat GPTはもちろん答えることができません とこれらのチャGPTの限界を理解する ことでチットGPTの適切な使用方法で あったりとかそれらをどのようなシナリオ で活用するべきかっていうのが見えてくる ということですねでChatgpdの概要 の最後なんですけれどもChatgpdや その他大記号言語モデルllm自体の課題 をこちらにまとめますでまず1点目なん ですけれども先ほどと被るんですが ChatGPTは最新の情報にアクセスが できないと例えば為替や株価のように国 一刻と変化していく情報に対してチト GPTははリアルタイムで対応することが できませんで2つ目の課題としては ChatGPTが独自の情報源にアクセス する能力を持たないということです企業の データベースに保存されている顧客名簿で あったりとか特定のプライベートな情報に はアクセスすることができませんで3つ目 に水論の正確性に課題があるというところ ですチャットGPTは時折り簡単な算術 計算でさえも間違えることがありますこれ は特に正確な情報や結果が求められる タスクにおいて大きな問題となりますねで そして最後にチャットgpdができない こととかのデータが足りないんだったら ファインチューニングすればいいんじゃ ないかっていうような意見もあると思うん ですけれどもファインチューニングする ことによって汎用性が劣化してしまうと いうことがありますとでChatGPTを 特定のタスク例えば自社データを食わせる であったりとか特定のタスクに特化した データを食わせてファインチューニング すると他の多様なタスクに対する性能が 低下すると言われていますでこれらの課題 を解決するための1つの手段として今回お 話しするラングチェインエージェントって いうものがありますでここここからは ラングチェインエイジェントを使って チットGPTの性能を生かしつつ苦手な ものは他のツールで解決していくっていう ことについてお話ししていきますで参考 までにですねここにバッと上げている課題 に関してはMrKLシステムズていう有名 な論文があってそ論文から引っ張ってきた ものとなりますMrKLシステムズって いうのはミラクルシステムズと呼ぶもので チャットGPTと他のツールを連携して どんどんどんどん課題を解いていくって いうことを提示しているロムとなってい ますそれではラングチェインエージェント についてのトピックに移っていきますまず ラングチェインエージェントの前にですね ラングチェインとは何かと言うとラング チェインとは言語モデルを利用する アプリケーションのためのフレームワーク ですでラングチェインについては前回の 勉強会でもご紹介しているので基礎的な 内容を知りたい方はYouTubeで前回 の勉強会の動画をご覧くださいでラング チェインエージェントはラングチェインの 中の1つの機能なんですけれどもラング チェインの中でも非常に面白くて重要な 役割を果していますランチェの主なタスク は次にどんなアクションを取るべきかを大 記号言語モデルllmに決定させそれを 実行するということですで具体的な プロセスは以下の通りですとまず各ツール ができることと質問を指定したレスポンス のフォーマットでllmに送信します聞き ますとチットGPTなどのllmに聞き ますそしてllmChatGPTから帰っ てきたレスポンスをパースして次の アクションを決めるということをしますで このプロセスによってラングチェインジと はユーザーの4級に応じて効率的かつ正確 なアクションを実行できるようになって いるというところですでここでラング チェインエージェントがどのように動く かっていうもののイメージを具体的な例と して1つ持ってきましたま正確に正しい 動き方をしてるわけではないんですけれど も大体こういうような動きをするんだよっ ていうこともご理解ください例えばチット GPTに対してコミュニケーションを取る のがラングチェインのエージェントとなる んですけれどもラングチェイン エージェントにですねまずこう今日東京で で出かける時時に適切な服装は何ですかて いうのを聞きますでそうするとラング チェインエージェントが聞きたい内容今日 東京で出かける時に適切な服装っていう ものとあと自分が持っているツールって いうものをプロンプトに入れてチャット GPTに聞いてくれますとで自分が持っ てるツールっていうものは例えば Google検索のツールっていうも持っ てますとGoogle検索のツールでは 最新の情報を引っ張ってくることができ ますと私が持ってるのはGoogle検索 のツールで最新の情報が引っ張ってこれ ますそしてで今回聞質問としては東京で 出かける時に適切な服装って何でかていう ものを聞きますとでその時にチャット GPTはどのように返してくるかというと でまずは検索ツールでインプットは東京の 気温っっていうもので調べなさいっていう ものをエージェントの方に返してきますで エージェントはチャットGPTからから 教えてもらったじゃあえ検索ツールを使え ばいいのかっていうところで検索ツールを 使おうとしますでインプットとしては チャトGPTが教えてくれたように東京の 気温っていうものをインプットとして入れ てで検索ツールから帰ってきた22度って いうものを変してもらいますとでそして またえっとチャットGPTにえこのツール に入れた答えってものが22°でした次何 すればいいんですかであったりとか最終的 にどうなんですすかっていうのをチャット GPTに聞いてチャットGPTが十分な 情報を得たっていう風に判断するとでは 22°なので薄の長袖でがいいでしょうっ ていうものをエージェントとしに返してで あとはえ答えとしてラングチェインの エージェントが東京は22度なので素の 長袖でがいいでしょうっていうものをその まま返してくるというような流れになり ます特徴的なものとしてはチャットGPT だと今日の天気であったりとか東京の天気 であったりていうものは取れないんですね でそこをGoogle検索のツールって いうものを利用することによって新しい データっていうのを取れるようにしてると いうところですねもう1つ押えておきたい こととしてはこの問を解く時に自分が持っ ているツールっていうもの一覧を渡して どのツールを使えばいいかっていうのこと 自体もチャットGPTに判断してもらうっ ていうところが面白いところとなってい ますはいでこれがラングチェイン エージェントリアクトフレームワークとか 呼ばれたりするようなやり方ですねはい これらのこと全部ラングチェインの エージェントがやってくれるというところ ですでラングチェインエージェントって いうものは様々なタイプのエージェントが 用意されていますとここでエージェントの タイプっていうものを紹介するんです けれども解きたい課題に応じて エージェントを使い分けることによって 精度の高い回答を得られるようになると いうことですここで6個ほど上げています でまず1番汎用的なものとしてはゼロ ショットリアクトエージェントというもの ですでこのエージェントはリアクト フレームワークを利用してツールの説明に 基づいてどのツールを使用すべきか判断し ます先ほどの例で出てきたものと同じです ねこれによって特定のトレーニングデータ なしで多様なツールの適切なこう利用が 可能になってきます次にストラクチャード インプットリアクタエージェントですで このエージェントは複数の入力を使う エージェントを活用することができますで これによってより複雑なツールの理由用が 簡単になりタスクの効率が向上しますと 続いてOpenAIファンクション エージェントですこのエージェントはオ AIのファンクションコーリングの機能を 使っており関数が呼び出されるタイミング であったりとかを検出したりとか適切な 入力を関数に渡すような微調整がえオープ AI自体チットGPT自体がされていて それを使うことができますとOpenAI のえファンクションコーリングこの エージェントが使うOpenAIの ファンクションコーリングについてはこの 後のスライドでもう少し詳しく説明します で次にコンバーションエージェントですで このエージェントは会話での使用目的とし て設計されています何かを聞いて何か答え を出すっていうようなま単純なチャット GPTで何かこう答えを作ってくださいと かそういうのとは違くて会話的な インタラクションを通じて効果的な コミュニケーションを可能にするような エージェントとなっていますそして次に あげるものとしてはセルフアクwith sarchエージェントですねでそこの エージェントはですねセルフアクという 質問を自問自としながら分割することに よって正しい解を導き出す方法を使って\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\"GPTで何かこう答えを作ってくださいと かそういうのとは違くて会話的な インタラクションを通じて効果的な コミュニケーションを可能にするような エージェントとなっていますそして次に あげるものとしてはセルフアクwith sarchエージェントですねでそこの エージェントはですねセルフアクという 質問を自問自としながら分割することに よって正しい解を導き出す方法を使って 情報を検索するエージェントですセルフア クっていうプロンティグの技術があるん ですねまそれを使ってちゃんとした正しい 答えを導き出すエージェントとなってい ますで最後に紹介するものがリアクト ドキュメントストアエージェントですで このエージェントはドックストア ドキュメントストアですねと対話するため にリアクトフレームワークを使用してき ますえこれによって文書の管理であったり とか検索が一元化されて効率的に情報 アクセスが可能となりますこちらに関して はまた今後の勉強会でも取り扱っていき たいかなという風に思ってるんですけれど も文書検索管理っていうものに特化した エージェントとなっていますで以上がラン チェインエージェントの各エージェントの 使用となりますでそれぞれのタイプが 異なるシナリオやタスクに適しており ラングチェインの柔軟性と多様性を象徴し ているものとなります今回のセッションで はですね最も汎用的なゼロショット リアクトとチャットGPT自体に色々判断 させるファンクションコーリングを使った オープAIファンクション2を利用して いき ますでは先ほど説明を省いてしまったん ですけれどもOpenAIファンクション コーリンググっていうのはOpenAI ファンクションコーリングじゃないですね OpenAIファンクションですね OpenAIファンクションとは何か エージェントタイプの1つであるOpen AIファンクションとは何かについてお 話ししますこちらはChatGPTを提供 しているOpenAIのファンクション コーリングという機能を利用していますで ファンクションコーリングっていうものは 2023年の6月にリリースされた機能で ラングチェインエージェントが担っていっ たツールを渡してチャットGPTに聞いて 次のステップを決定するやり取りってい ものをチットGPT自体が行えるように ファインチューニングされているものと なりますでこの機能では東京の天気を教え てくれというような先ほどと同じように ですね質問と共にどういう関数を持って いるのかその関数の説明をチトGPTに 直接投げるということをやりますなので 先ほどのラングチェインエイジェントが やってることと同じようなことをやれる ようになっていてチットGPTが ファンクションをどのように受け取るのか そのファンクションのパラメータであっ たりとか説明とかをよりチャトGPTが 理解しやすいようにAPIとして受け取る ことができるようになっているのでより 適切な判断をチャットGPTがしやすく なっているというところがメリットとなり ますなので今メリットをお話ししてしまっ たんですけれどもファンクション コーリングを使うメリットとしては ChatGPTにツールの挙動をより正確 に伝えやすくなっているというところで これによってChatGPTが機能の ツールのえファンクションの使用や動作を より正確に理解しやすくなっていて適切な 判断をしやすくなっているとていうのとで もう1つのメリットとしてはチャット GPTっていうものがラングチェイン エージェンドって元々チャットGPTが 返してきた個体を利用者が頑張って定期 表現を使って解析する必要があったんです がそれをする必要がなくなったっていう ところが利点としてありますとでチャット GPTが実際にラングチェインを使って どのツールを使えばいいですかていうのを 聞くんですけどそれをどのようにパースし てるかというとこのように頑張ってですね えっとレギュラーエクスプレッションを 使って正規表現を使ってパースしたりとか して次のアクションを決めてたりするって いうのがラングチェが今までやっていた ことであるとでこういうパースをしなきゃ いけないっていうことをしなくて済む つまりパースしなきゃいけなかったので今 まではそのパースすることでえっとうまく パースできなくてミスってしまうっていう こともあったんですけどそういうことが なくなるっていうことが期待されるという ところです はいはいちょっと駆け足になってしまった んですがここまでで20分ぐらいかかって しまいましたねえここからがレモに入り ますで実際にですねラングチェイン エージェントを使ってチャトGPTと自社 ツールを連結するような感じのえデモって いうものをお見せしていきますで使う エージェントとしてはゼロショット リアクトとオーエファンクションを使って いきますであとは今回のプレゼンの冒頭の 方でもお話ししたようにChatGPTに ツールの説明をどのように渡せばいいのか であったりとかその辺りを持ち替えて いただければ幸いです はいではではやっていきますちょっと時間 がなくなってきたので駆け足でいきますね でまずは設定ファイル読んでいきますこれ 何をやってるかと言うとえOpenAIの APIキーであったりとかを読んでいます でまずはですねえっとゼロショットの方を 見せしていきたいんですがおマジないとし てですねおじないというかま前回の勉強会 と同じようにですねラングチェイン エージェントを使うためのやり方をお見せ していきますで実際今回使うモデルとして はチットOpenAPAIというか ChatGPTのえGPT3.5のtbo 0613というものを使っていきますで 外部のツールとしてはGoogleサーチ のAPIっていうものを今回用意しました ここであのサプAPIっていうものを書い ているものがえGoogleのAPIと なりますで聞きたい質問としては今日の 東京と北海道の天気を調べて東京から 北海道の出張で来ていくべきを教えて くださいっていうものを聞きたいと思い ますでラングチェインエージェント自体を 走らせてみますでこれがゼロショット リアクトエージェントを使った場合どの ようになるかっていうのをお見せしますで エージェントタイプに関しては イニシャライズエージェントの エージェントっていうえ引数に対して エージェントタイプのこのゼロショット リアクトディスクリプションていうものを 渡すとエージェントを選択することができ ますちなみになんですけれどもえこれって ただあの文字列が返ってくるだけですかね あのゼロショットリアクト ディスクリプションていうものが返って くるだけのものになりますなので文字列で 与えても同じですはいでは実行してみ ましょうチトgpdはもちろん今日の天気 とか今日の東京とか北海道の天気っていう のは知らないので来ていくべき服装って いうことは分からないわけですね気温も 分からないのででこれでラングチェイン エージェントが私はGoogle検索の ツールを持ってますよでそれを使って使う ことができますでこの問題課題っていう ものを解くためにはどうすればいいですか てのを聞くっていうことですねでここで ざーっと出てきてるんですけれども実際に 書いてきた答えとしてはtheWisto isCloudyaboutcrear withtempof歌詞になっちゃって ますけどまこのように帰ってきますと 英語で帰ってきちゃってますねでこういう 風にえどんなアドレスをれ切ればいい かっていうものがちゃんと帰ってきてい ますと前にやった時はそんなに綺麗に帰っ てきてなかったんですけれども今回は うまく帰ってきていますはいこちらがゼロ ショットリアクトディスクリプションで やった場合の結果になりますでどういう ことをやってるかっていうのなこの辺りを 見ていただくといいのかなという風には 思いますでチットGPTにまずラング チェインエージェントが問題とツールを 渡してチットGPTに何をすればいい かっていうのを聞きますでチャットGPT から帰ってきた答えとしては次の アクションとしてはサーチをしてください ですサーチのインプットとしてはウザー 東京todayていうものを渡してくださ いっていうのを渡してますで次の アクションとしてはサーチをしてください でそのインプットとしてはウザ北海道 todayていうものを渡すようにして くださいとで最終的にその帰ってきた答 っていうものをチャットGPTに渡して 最終的な文が出てくるということですはい でこれが1つ目ですねアエージェント タイプ1つ目のえゼロショットリアクト ディスクリプションで元々ラングチェイン エイジェントがリアクトフレームワークで ツールを渡したりとかしてチャットGPT とうまく連携しながら外部ツールを使う ようにしたえ機能となっていますでこれが ですねえ最近出てきた6月にリリースされ たOpenAIのファンクションコーリン グっていうものを使うとどうなるかって いうのをお見せします はいでOpenAIファンクション OpenAIのファンクションコーリング を使うためにはエージェントタイプの OpenAIファンクションズっていう ものを渡しますでそうするとえこのように 動きますで実際にやってることとしては ラングチェインエージェントがOpen\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\"たOpenAIのファンクションコーリン グっていうものを使うとどうなるかって いうのをお見せします はいでOpenAIファンクション OpenAIのファンクションコーリング を使うためにはエージェントタイプの OpenAIファンクションズっていう ものを渡しますでそうするとえこのように 動きますで実際にやってることとしては ラングチェインエージェントがOpen AIのファンクションコーリングっていう ものを使ってうまくチャットGPTと やり取りしながら答えを導き出していくっ ていうことをやっていますはい出てきた 答えはこちらですねで同じようにですね どのようにやっているかっていうものは ここら辺の途中で出てきているんです けれども途中結果でえサーチとしてはえ クエリー東京の今日の天気っていうものを 調べてくださいでサーチっていうツルを 使って今日の北海道今日の天気っていう ものを調べてくださいでこれらが帰ってき た答えっていうものをえチャットGPTに 返してチャトGPTがその与えられた情報 を元に東京の今日の天気は曇りですが後に は晴れる予報ですで気温は接し30°歌 86°でコス確率はどうのこうのっていう ものがあってであとは東京は暑くなる可能 性があるので軽い服装が適しています ただし北海道は比較的涼しいので ジャケットなどを持っていくことがお勧め しますというような感じに帰ってきてます ま見て分かると思うんですけれどもま日本 語にな質問が日本語だったので日本語で ちゃんと返してくれるっていうのは もちろんのことなんですけれども書いてき た答えっていうものに関してより詳しく 返してくれているっていうことが分かると 思いますなので使ってみた所管としては ですねここで言うオAIファンクションの ファンクションコーリングっていうのの ファンクションっていうのはラング チェインエージェントでいうツールと同じ なんですけれどもそのファンクションで あったりとかツールを渡す時にですね渡し て何かを判断判させたいチャットGPTに 判断してもらいたいっていう時はえ エージェントタイプゼロショットリアクト ディスクリプションよりもエージェント タイプオAIファンクションの方がより いい結果が返ってきやすいっていうことが 分かると思い ますもう少しあの詳しく見ていきます ちなみにですねOpenAIにどんな ファンクションを渡してるかっていうのは イニシャライズエージェントのところで エージェントを定義してるんですけども そのエージェントの中からエージェントっ ていうものとファンクションズってものを 実行するとどんなえファンクションが渡さ れてかっていうのを見ることができますで 今回渡されたファンクションっていうのは ネームサーチっていうファンクションが 渡されていてどんなことができるかって いうのでサチエンジンですっていうような ものをやってますであとはパラメーターと してはこういうものを渡していきますって いうのが分かりますとはいでここまでが 基本的なラングチェインエージェントを 使って外部ツールを連携するっていうお話 をしてきましたとで次にですねえ自社で 作ったツールっていうものを連携させ るっていところについてお見せしていき ますで一旦はですねレコメンドアイテムっ ていうものを考えてみようと思いますで ここ何をやりたいかって言うとレコメンド アイテムまこの中身はほとんど意味のない ものになってるんですけれどもレコメンド アイテムっていう関数を自社で持っていて でレコメンドアイテムっていうものは自社 のデータベースなどにアクセスして日付を 持ったにこの日のレコメンドっていうもの はこういうものですっていうものを返す ような関数っていうところになりますとな のでえっとこのレコメンドアイテムって いうところをこの関数ををえChat GPTのフローの中に組み込みたいって いうことをやっていきますでどのように ラングチェインエージェントを使って ChatGPTに連携すればいいかという とツールっていうものにえ変換していく 必要がありますとでレコメンドアイテム ツールっていうものをえツールfrom ファンクションズっていうものを使って どのようなファンクションを実行したい ですかレコメンドアイテムっていう ファンクションを実行したいですまこう いう風にですねこの今回のあまり意味の ないファンクションなんですけれどもこれ を実行しますとでツールの名前としてはえ レコメンドアイテムっていうものを渡し ますでツールのディスクリプション何を やってくれるかっていうことに関してはお すめの商品を教えてくれますっていうのを ツールとして定義するというところです はいでこれをちょっとツールズっていうま ツールまとめて渡さないといけないで ツールの配列の中に入れておきます実際に ですねラングチェインエージェントにどの ようにツールを渡せばいいかっていうとま 先ほどもカラっとやってたんですけれども このツール1覧っていうのを最初に渡して 引数として渡しているのでまこのようにし てどんなツールが使えるかっていうものを ラングチェインのAに渡しでチャット GPTと連携していきますはいでえっと 今回聞きたいこととしてはえおすすめの 商品を教えてくださいっていうものを投げ てみようと思いますで使うエージェントと しては先ほどゼロシトリアクトよりもより いい結果が返ってきたオーエ ファンクションズってものを選びます はいはいでは実行し ますはいで書いてきたものとしてはですね コメドアイテムってものが実行されて withファッションという謎のものをえ 入力に入れてで実際この引数がですね デートの中にファッションが入ってで プリントファッションっていうところでこ でファッションが出てきてしまってるとで ただおすめの商品は今回レコメンド アイテムで書いてきたAppleですって いうのが書いてきてることが分かると思い ますはい見て分かるようにですねなんか よくわからない引数は与えてしまってる なっていうところがありますでこを どんどん解決していこうと思いますで次に やることとしては今回なんでこのように変 なファッションとかいう引数を与えて しまったかというと引数に関する情報が ないんですね与えられてないというところ になりますとなので引数何与えればいいん ですかみたいなところが情報としてないが ゆえにチャットGPTもレコメンド アイテムを使うことは分かるとレコメンド アイテムを使えばいいのは分かるんだけど レコメンドアイテムに対してちょっと 分からないからカテゴリー情報でも渡して みようかなっていうのでファッションを 渡してしまっているというような状態に なりますで例えばまファンクションを見た としても今回使ってるファンクションに 関してはレコメンドアイテムでおすめの 商品を教えてくれますでパラメーターの 情報は全くありませんっていう状態なので どんなパラメーターを渡せばいいかって いうのはオープAIファンクションは 分からないというところですねじゃあこれ に対してどうすればいいかっていうのをお 見せしますでえっと結構簡単でしてパダ ティックっていうものをご存知ですかね こう最近えっとファストAPIとかですか ねこう結構パであったりとかそのヒントを 与えるっていうことがまPython主流 になってきてると思うんですけれども フダンティックを使っていきますでえっと ご注意していただきたいこととしては ファインディッてもうV2が出てるんです けれどもV2を使うとラングチェイン エージェントを動きませんとなので パティックV1を指定して方に関する情報 をえ与えるためのそのベイスモデルとか フィールドを使ってえやっていきますで これ何をやってるかと言うとま今回の インプットに対してデイトっていうものが ありますがデイトていうものはお勧めした 商品を絞るために使われる日付ですって いうものを与えていますこれをえっと アーグススキーマ先ほどのツールを定義 する時にアグススキーマっていう引きを 使ってこのレコメンドアイテムインットっ ていうベースモデルから継承した レコメンドアイテムインプットっていう インプットの報引数の情報を持ったクラ スっていうものを渡すということをします とでこうするとどうなるかっていうのをお 見せしていき ますはいじゃあどう変わる かいきますはい実行します全く同じですね 実行するものとしてはで今回はレコメンド アイテムっていうものに対して先ほどと 同じレコメンドアイテムっていうものが 選ばれましたとコアイテムに対してデイト が2020年の12月1日っていうものを 渡しているっていうことが分かりますで それによってですね気付がちゃんと渡して くれたっていうことがわか分かるわけです ねで今回あのここであのデートっていう ものはディスクリプションでお勧めしたい 商品を絞るために使われる日付っていう ことを伝えたのでチャットGPTの方があ これは日付のことなんだっていうところで 引数はファッションのようなカテゴリーを 渡すんではなくてデートの引数っていう ものを渡すことができてるというところ ですはいでこちらがデトのまあ2022年 の12月1日もはや日付が意味が分から ないですけれどもこういうものが渡されて いるというところですねでおすめ商品は Appleですという風にでこういう風に\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\"ことを伝えたのでチャットGPTの方があ これは日付のことなんだっていうところで 引数はファッションのようなカテゴリーを 渡すんではなくてデートの引数っていう ものを渡すことができてるというところ ですはいでこちらがデトのまあ2022年 の12月1日もはや日付が意味が分から ないですけれどもこういうものが渡されて いるというところですねでおすめ商品は Appleですという風にでこういう風に ですねこうツールの説明をどんどん どんどん入れていってええ解決していく 必要があるというところですねで同じよう にですねちょっとエージェントの ファンクションがどのように渡されるてる かっていうのをお見せしますとで今回渡さ れたのはレコメンドアイテムインプトって いうのをえパイダンテックの方で定義して 渡しているのでえ実際にえっと ファンクションOpenAIのえ ファンクションコーリングにどのように 渡されてるかというとパラメーターとして ですねこういう風なレコメンドアイテム インプットっていうものが渡されていて プロパティとしてはデートがあってデー トっていうのはお勧めしたい商品を絞る ために使われる日付っていうものが入れ られてえ飛ばされてるということが分かる と思いますはい で他にはですねこのようにツールフロン ファンクションで作るっていうこともある んですけれども同じようにですね デコレーターを使うっていうこともでき ますとデコレーターの方が結構シンプルに 書けるので私は結構デコレーターを使って 書くことが多いですとでデコレーター何を すればいいかというとデコターっていうの はま関数の前にですねアマークツールなん ちゃらかんちゃらっていうものがあってで それを使ってえっとこのツールってのは何 ができるかっていうものをえドッ ストリングで与えるんですねな先ほどと 同じにするとレコメンドアイテムツールっ ていうものがあったら中身は同じですね プリントデイトとAppっていうものを 返しますとプリントデイトしてApple っていうものを返しますとででやることと してはおすめ商品を教えてくれます全く 同じ内容ですねでこのツールの名前って いうものはデコレーターの引数として レコメンドアイテムとして渡していると いうところですで同じようにですね ツールズの一覧として入れてでこれをえ 実行してみ ましょうはいこれデコレーター使った場合 です ね実行するものは全部同じですで同じよう にこれも実行できますという風にデコレー ターってかなりこうシンプルにかけてで ファンクションの中のドックストリングス とかを使ってくれるので結構あの家読性と かもう悪くないかなという風には思います 先ほどと同じようにですねこレコメンド アイテムってものはちゃんと選んでくれた んですけれどもレコメンドアイテムに渡し ているデートっていうのは2021年10 月15日という意味の分からない日付を 渡してしまっていますとこれはなぜかと言 とまもちろんそのおすすめ商品を教えて くださいって言ってるので勝手に日付を 決めて聞いてしまっているというところ ですね はいでデコレーターの方もですね同じよう にファンクションを見てみるとえっとこう いう風になるという感じですねただあの 先ほどと同じようにですねパダンティック とか使っていないのでプロパティの パラメーターとかは適当になってしまって いるというような感じになりますただ今回 の場合はですねこうデコレーターの場合は フロムファンクションの方を使ったこっち の場合ですねこのフロムファンクションを 使った時と違ってきちんとデートを入れて くれているっていうことが特徴的かなと いう風には思いますフロンファンクション を使った場合っていうのはパダンティック を渡さないとデートっていうものに対して ファッションを入れたりとかよく分から ないものを入れたりすることがあったと 思うんですけれどもデコレーターを使った 場合はこのデートっていうものを渡した時 にきちんとこうデートを返してくれるよう な情報っていうものを渡せてくれている ような感じですねいずれにせを正しい共同 を求めるためにはこのままあまり情報を 与えないで実行するってのは適切ではない ので特に自社ツールサービスとして提供 する側としてはですねなのでそういう意味 ではきちんとバイダンティックなどを使っ て適切な情報を渡しながら関数っていう ものを渡していく必要があるかなという風 に思いますなのでえっと先ほどと同じよう にですねデコレーターを使った場合も パイナティックの情報っていうものを渡す ことができるのでデコレーターの引き数に アーグススキーマていうものを渡してで そのパイランティックの情報を渡すことで 適切な答えを返すことができるようになる というところです同じようにですねま結果 も変わらないので はいまこういう風に変えてきました ちょっと答えがどんどんどんどん変わって きてますApple製品だったりとか AppleStoreとかオンライン ショップとかうんまここら辺に関しては 本当に適切な答えがまだ返ってきてない なっていうような状態だとは思います エージェントのファンクションを見るとえ きちんとファナティックで渡した情報って いうのが渡っていることが分かると思い ますこのようにですねこのデートっていう ものはデートっていう引き数はお勧めし たい商品を絞るために使われる日付ですっ ていうのが渡っているというところです もう少しですね今までこうおすめの商品を 教えてくださいっていう風に言っていたの でデートっていうものが1月10日であっ たりとかよくわかんない日付になっていた のではないかっていうことを推測してでは 昨日のおすすめ商品を教えてくださいって いうものを聞いてみますてそうするとどう なるかと言うとえ昨日のおすめ商品を教え てくださいって言ってるのにレコメンド アイテムに渡されてるのは2021の10 月20日っていうものが渡されれてること が分かりますとチャットGPTにこう昨日 とか今日とか昨日とか渡したら日付を ちゃんと入れてくれるのかなと期待するっ ていうことがあると思うんですけれども 実際はそんな入れてくれないっていうこと がまこの結果から分かるということですね もう少し例えばディスクリプションとかを 適切にすればうまくいくのかもしれないん ですけど今回は違う手段でえっと解決 しようと思いますで今回どういう風に解決 するかと言うとデートタイムを使って 新しい日付けを取得するような関数自社 ツールってものを設けようと思います ゲットデートっていうツールっていうもの を作ってでそのツールは何をするかという とま今日や昨日など日付を取得する時に 使います引き数には今日を起点として何日 か前をNで与えますとでここのそのドック ストリングスにですねこう引数に関する 情報を書いてるんですけども実際はですね パダンティックで引き数の説明した方が ベタだとは思いますただえっとドック スリンに書いてツールの説明として与える だけでも結構チャットGPTは賢いので うまく判断してくれるということですでお 見せしますはいこの日付関数を入れると どうなるかと言うとこういう風な感じです ねはい今日のおすめの商品を教えてくださ いっていう風にするとtodayて書い てき来てこれもうまく動いてないですね こういうことが結構ありますとうまく動か ないことがあるとでもう1回実行してみ ましょうかはいでもならではですね ちょっと30分で終える予定が46分に なってしまったんですがもう少しで終わる ので続けます前回のやつだとですね直接 レコメンドアイテムを呼び出してデートに 対してtoデイていうものを渡してしまっ てたんですけれども今回はうまく動いてい てまずは日付を取得するためにゲットデイ トっていうものを呼び出しますとで今日な ので今日からの起点のえN日前だったらN に0を渡せばいいということが分かるとだ からゲットデートに0を渡して帰ってきた ものが2023年の9月30日っていう ものが帰ってきてで9月30日のえお勧め 商品は何ですがま書いてくるものは全部 AppleなのでAppleってものが 帰ってきてることが分かると思います同じ ようにですねじゃあどういう ファンクションが渡されてたかっていうの をお見せするとサクっとですねで今回あの ファンクション2つ渡されていて レコメンドアイテムっていう ファンクションとゲットデイトっていう ファンクションが渡されていますで それぞれのファンクションの説明がこの ように与えられているということが分かり ますもう少しツールを複雑にしていって ですね奇数日だったらオレンジ偶数日だっ たらえAppleっていうものを返すよう なツールにちょっとだけレコメンド アイテムを変えみようと思い ますはいではえこれを実行するとですね 今日はえ9月30日なのでもちろん9月 30日偶数日ですね偶数日なので Appleが返ってくるきちんと帰ってき ますねAppleが帰ってきましたでは 昨日の場合はどうなのか 昨日はい昨日の場合は29日なので1日前 ってものをゲットデイトで取得して29日 ってものが書いていますで29日を使って え昨日のおすめ商品オレンジっていうもの を取ることができるというところ ですやとうまく動きました ねでもう少しだけちょっと時間が1時間 ぐらい喋ってしまうような感になるんです\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\"Appleが返ってくるきちんと帰ってき ますねAppleが帰ってきましたでは 昨日の場合はどうなのか 昨日はい昨日の場合は29日なので1日前 ってものをゲットデイトで取得して29日 ってものが書いていますで29日を使って え昨日のおすめ商品オレンジっていうもの を取ることができるというところ ですやとうまく動きました ねでもう少しだけちょっと時間が1時間 ぐらい喋ってしまうような感になるんです けれどもう少しだけお話させてくださいで これだけだともちろんまだまだ連携が 少ないかなっていうところがあってで次に じゃあAppleだったら100円 オレンジだったら200円っていうような ものを商品の値段を返すような関数って いうものを組み込んでみましょうでツール としては元々グビだったらAppleキビ だったらオレンジを返すようなものとあと は日付を取得するツールであとは今回定義 したAppleとオレンジAppleだっ たら100円オレンジだったら200円 っていうのを返すツールっていうものを 定義しますでこれでエージェントのですね おすめの商品の値段まで教えてくださいっ ていうことをやるとそうするとまず最初に え昨日なのでゲットデートでN=1を渡し て1日前のデートを取ってきますで9月 29日ですで次にレコメンドアイテムって いうツールを呼び出してレコメンド アイテムにえ9月29日を渡してで最後に ですねアイテムプライスっていうので アイテムネームをえオレンジにとして渡し てでオレンジはは200円なのでえ昨日の おすめ商品であるオレンジの値段は 200円ですっていう最終的な答えが返っ てきましたというところになりますだいぶ 柔軟なものができるようになってきたって いうことが理解できると思いますで他には ですね最後なんですけれども取得した結果 を吐き出したいとかデータベースに 書き込みたいとかあったりすると思うん ですけどもそういうことももちろん簡単に できますと基本的にはファンクションが あってそのファンクション中身は自分で 書いていくので何でもすることができると いうところですねちょっとあの output.tchっていうところに 書き込むようなものを記事的にですね データベースに書き込んでいるようなもの として紹介しようと思いますで今回は さらに追加するツールとしてはですね セーブデータっていうツールを追加します とセーブデータっていうものは何なのかと いうとここにも説明書いてあるんです けれども日付と商品名と商品の値段を 受け取ってデータベースに書き込みますっ ていうようなものをツールとして作りまし たデータベースといながらもアウトプット テキストにただ書き込むだけのものになる んですけどもデートアイテムネーム アイテムプライスを書き込むだけのツール となりますま実際に自社ツールを使う時に はここにSQL分であったりとかを書いて データベスに書き込むとかをやったりする ことになると思いますこちらもですね ちょっと簡易的にですねフダンティックを 使わずにえドックストリングだけで何を やるかってのを渡して書き込めるかどう かってのをお見せしていこうと思いますで 同様にですね同じように何をしたいかと 言うと今日のおすめ商品の値段を調べて データベースに書き込んでくださいって いうことを実行し ますで最初に動くものとしてはまず日付を 取得するゲットデイトが動いてN=0で 今日の日付を取ります9月30日ですと9 月30日が取れたら9月30日の レコメンドアイテムは何ですかていうので レコメンドアイテムのツールを起動して 書いてきたものがAppleですとであ次 にやることしてはAppleの値段は いくらですかていうものをアイテム プライスに聞いてアイテムプライスが返し てきた答えが100円ですとで100円 っっていうものをえセーブデータに渡して セーブデータに渡すものとしてはデートと アイテムネームとアイテムプライスこれは 日付と商品目と商品の値段を受け取 りっていう風に書いてあるのでこういう ようなものを基数として与えて データベースに書き込みますていうことを この操作でやるということですねなので 細かいことを書いた方がミスは少ないん ですけれどもあんまり書かなくても動いて くれるっていうのがまやっぱりこう チャットGPTのうまいところかなという 風には思いますで最終的に帰ってきたこと としては今日のえおすすめ商品の値段は 100円ですとでデータベースに正常に 書き込まれましたっていうので データベースではないんですけどれも テキストファイルっていうものを中身見て みましょうと今日の日付2023年9月 30日でおすすめの商品Appleで最終 的に100円っていうのが書き込まれた ことが確認できましたとはいとても長く なってしまったんですけれどもこちらで テモは終わりとさせていただきたいと思い ますはい私の発表は以上となります ありがとうございました\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\"The speaker introduces the topic of integrating the company's tool with ChatGPT using a tool called LangChain Agent. They highlight the limitations of ChatGPT, such as the inability to access real-time data and limitations in certain mathematical inferences. The LangChain Agent aims to address these challenges and enhance ChatGPT's capabilities by effectively integrating it with external tools. The presentation will cover the basics of ChatGPT, the features of LangChain Agent, and a demonstration of the integration. The speaker also discusses prompt engineering techniques, such as providing specific and clear questions, specifying context and expected answer format, and limiting the scope of the response. However, they acknowledge that prompt techniques have their limitations and that ChatGPT's knowledge is limited to its training data and cannot access real-time or company-specific data.\n",
      "\n",
      "The text discusses the limitations of Chat GPT in obtaining information that is not included in its training data, such as specific weather information or data from a company's own tools. It also highlights the challenges of accessing real-time information, private data, and ensuring accuracy. To address these limitations, the text introduces the concept of a LangChain agent, which utilizes language models to determine appropriate actions and can integrate with other tools to solve specific tasks. Different types of agents, such as zero-shot reactor, structured input reactor, OpenAI function, conversation, and self-act with search agents, are mentioned as solutions for specific task requirements.\n",
      "\n",
      "The text discusses three different agents used in GPT: the conversational interaction agent, the self-act with search agent, and the react document store agent. These agents enable effective communication and information retrieval through conversation. The presentation also mentions the use of OpenAI's function calling feature to enhance the capabilities of ChatGPT, providing more accurate tool behavior and eliminating the need for manual analysis of responses. The demo showcases the use of zero-shot react and OpenAI function calling in combination with ChatGPT to connect external tools and retrieve information.\n",
      "\n",
      "This text discusses the use of OpenAI's Function Calling feature to interact with the ChatGPT language model. It explains how the Function Calling feature allows the model to retrieve and process information from external tools or functions. The example provided demonstrates how the model uses a recommendation tool to generate a response based on the given input. Additionally, the text mentions the use of the Python library \"fastapi\" and \"Pydantic\" to handle parameter information for the Function Calling feature.\n",
      "\n",
      "The passage discusses the use of a chatbot model called \"Chat GPT\" to provide recommendations for fashion items based on a given date parameter. It mentions the use of a decorator function and the passing of arguments to the function. The author also introduces a new tool called \"Get Date\" that retrieves the current date or a specified number of days before the current date. The author demonstrates how the tool can be used to generate recommendations based on the retrieved date. The passage emphasizes the importance of providing accurate and appropriate information to ensure the chatbot's effectiveness.\n",
      "\n",
      "The summary is not provided in the text.\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "summarize_output = summarize_chain(docs)[\"output_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59d7f698-6c85-4b86-8c41-0f2b66baf1d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The text discusses the limitations of ChatGPT and introduces the LangChain Agent as a solution to enhance its capabilities by integrating it with external tools. It discusses prompt engineering techniques, acknowledges the limitations of prompt techniques, and highlights the importance of accurate information. The text also mentions different types of agents used in GPT, the use of OpenAI\\'s function calling feature, and the use of the Python library \"fastapi\" and \"Pydantic.\" It concludes with a demonstration of using the ChatGPT model with external tools to provide recommendations based on a given date parameter.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "39c9a03f-2fae-4c2f-85df-81b9e76d1a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MapReduceDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "では早速なんですけれども始めさせて いただきます私からはラングチェイン エージェントを使って自社ツールと チャットGPTを連携するというタイトル で発表させていただきますChatGPT 自体は皆さんご存知のように非常に優れた 能力を持っていますが最新のデータに アクセスできないとか特定の数学的な推論 が得意でないなどいくつかの課題が存在し ますこれらの課題は自社プロダクトに チャートGPTを導入するなどチャット GPTを社会実装しようとした際に解決し なければなりません今回お伝えするラグ チェインエイジェントを導入すると ChatGPTと外部ツールをうまく連携 させることができるようになりChat GPTが抱える課題を克服しチットGPT の可能性をさらに広げることができます 本日はラングチェインエージェントをどう 活用することでチャットGPTの能力を 拡張できるのか具体的にご紹介していき ますそれでは始めていきますこちらが私の プロフィールとなります内容はいつもと 同じなのでスキップさせていただきます はいでは具体的な話に入る前にですね今回 のテーマの結論に先に触れておきます結論 なんですけれどもラグチェインには様々な エージェントの種類が存在するが自社 ツールとチャットGPTを効果的に連結 する際汎用的なエージェントタイプである ゼロショットリアクトまたはオAI ファンクションを利用することが簡単と なりますゼロショットリアクトとOpen AIファンクションを比較するとOpen AIファンクションの方がチットGPT からより適切かつ精度の高い答えを 引き出しやすくなっていますこちらはデモ のでお見せしますねでそしてえっとここで ChatGPTと自社ツール連携で非常に 重要となるものとしてツールの説明という ものがありますと通常のプロンプトチャト GPTを使う時のプロンプトと同様に ツールの特性や機能をChatGPTに 正確かつ効果的に伝えることで自社ツール とチャットGPTの連携の成功率が格段に 向上していきますこのポイントに着目し ながら具体的な方法論について今日は 深掘りしていきたいと思いますそれでは これらのポイントを年頭にきつつ今回の 発表をお聞きください本日の発表は以下の 3つのセクションから構成されています 初めにチットGPTの基本的な概要につい て触れます次にラングチェイン エイジェントの特徴について紹介し最後に デモンストレーションを行いますデモでは 特にツールの説明について着目して いただけると幸いですそれでは最初の トピックに移りましょうここではチット GPTの全体的な特徴を振り返っていき ますすでにご存知の内容も多いと思うん ですけれども一般的なはチャットGPTの 性質っていうものをご紹介していきます チットGPTは実用的な大規模言語モデル llmで現在多くのビジネスに活用されて きています例えばベネッセ ホールディングスでは車内AIChat ベネッセGPTを開発しグループ社員 1.5万人に向けて提供しているという ようなプレスを出していたりとか立メカ 大学では大学の英語事業において機械翻訳 とChatGPTを組み合わせたサービス が試験導入されているであったりとか他に も色々なサービスがチャトGPTを 組み込み始めておりChatGPTの実用 化っていうものがすごい勢いで広がってい ますChatGPTを活用する際によく 言われることとしてはチャットGPTから 良い結果回答を得るためには良い質問が 必要であるということですでこれは プロンプトエンジニアリングと呼ばれる 領域で今最も伸びている業種の1つと言え ますプロンプトエンジニアリングではどの ような項目をプロンプトに入れるべきか またプロンプトを複数回うまく使いこ なくして良い回答をるテクニックなどが 研究開発されていますリアクトであったり とかいろんなことを聞いたことあると思う んですけれどもプロンプトの種類っていう のがどんどんどんど開発されているという ことですでチャットGPTの活用は多に 渡っておりその可能性は広がりつつあり ますでプロンプトエンジニアリングの テクニックを活用することでチャット GPTとの適切なコミュニケーションが 可能になりますプロンプト エンジニアリングでは色々なテクニックが 存在するのですが今回はプロンプト エンジニアリング自体がメインのテーマで はないのでプロンプトエジライニングの中 で抑えるべき基本的な項目とそしてよく 使われるまフーショットプロンティングと 呼ばれるような手法を簡単にだけ紹介して いきますはいまず基礎として抑えていき たいこととしてプロンプトに何を与える べきかっていうものをいくつか紹介して いきますで1点目としては具体的で明確に 質問することですで例えばその日本の歴史 において重要な出来事は何ですかという 質問よりも日本の戦国時代における重要な 出来事について教えてくださいという具体 的に質問し方が的確なコ答が得られますと で2点目に状況やコンテクストを明示する ことですて背景情報があるとチャット GPTはコンテクストをより理解し適切な 回答が返ってきますとで3点目期待する 回答の形式を指定するとこれにより望む 情報が整理されて帰ってきますリスト形式 で返してくださいであったりとか ジェイソン形式で返してくださいであっ たりとかまそういうことを質問する時に プロンプトの中に入れるということですね で4点目範囲を限定すること範囲が広す すぎると回答も後半で一般的になりがちに なりますなので範囲を狭めるということが 重要となってきますで最後5点目自性や 認証を明確にすることですと例えば子供で も分かるようにしてくださいとか中学生で も分かるようにしてくださいとかなんか そういう風にどの視点で書て思ってみるか を示したりであったりとか何年の情報が 欲しいとかそういうことを指定することに よって回答が明確なものが帰ってきやすく なるということですで次にプロンティ テクニックの1つののフューショット プロンティについて簡単に説明します フューショットプロンティはモデルに少数 の例を示すことで特定のタスクの解決方法 を学習させるアプローチになりますこれに よりモデルは様々な問に対して適切な回答 を生成することができますここに例として 上げてるんですけれども例えばレストラン 最高でしたこれは感情ポジティブですこの 映画は本当に時間の無駄だった感情 ネガティブですというようにいくつかの例 を与えて出したいものでそれぞれの文に 対しての感情っていうものをこのように 並べていきますてで最後に聞きたいものと してそのサービスは非常に遅く不満ですっ ていうものがあった時にどんな感情で すかっていうことを聞くと感情ネガティブ という風に返ってくるというところですで こういう風にすることによってモデルって いうものが新しい文章がポジティブか ネガティブかっていうのをま過去の例を元 に判断することができるようになるという ことですでこの方法によってですねフュー ショットプロンティはモデルに多様な タスクを効率的に学習させることができ 柔軟な対応が可能になってくるということ でですでここまでいくつかのプロンティの テクニックであったりとかをお話ししてき ましたもちろん他にもたくさんあってです ねチェインオブソツであったりとかあと セルフアスクであったりとかいろんなもの があるんですけれども今回のメインテーマ ではないので一旦プロンティグの話はここ で終わりにしてでここでちょっと一息つい てですねこれらのテクニックが持つ限界に ついて考えてみましょうでまず1点目なん ですけれどもプロンプトのテクニックは 日々進化し開発されていますとこれによっ てチットGPTは多様なタスクや質問に 対応でできるようになってきていますただ 全ての作業やタスクをチャットGPTに 依存すること自体が現実的ではありません とえ例えば先ほどの例で出てきた文章から の感情抽出に関してはチャートGPTに 無理やりさせることが適切かと言われると そうでもないかもしれないAWSコプリン のような勘定分析に特化した学習をして いるAPIっていうものがあってそれを 使った方がいい結果が返ってくるかもしれ ませんっていうのがまず1つ目ですねで次 に2点目としてそのChatGPTが持つ 情報っていうものは訓練データに限定され ていてチットGPTはそれ以外のデータに ついては知らないというところですなので えっとチャットGPTは過去のデータで 学習されておりその学習データ以降に出て きた情報に関してはチットGPTに尋ね られませんとよく言われるものとしては 2021年のデータですかねまでのデータ で学習してるので例えば2022年であっ たりとか2023年のデータについて聞い たとしてもチャットGPTがうまく答え られないというようなところですね最新の 価格的な研究であったりとかニュース記事 とか特定の地域の天気情報であったりとか チットGPTの訓練データに含まれてい ないような情報っていうものはChat GPTだけでは取得できませんし インターネットにあるデータだけではなく て例えば今回のテーマである自社のツール と連携するっていう時のためには自社の データを使いたいみたいな話とかあると 思うんですけれども自社データについては チャットGPTが知るわけもないという\n",
      "Human: ChatGPTが不得意なことを教えて\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "とか特定の地域の天気情報であったりとか チットGPTの訓練データに含まれてい ないような情報っていうものはChat GPTだけでは取得できませんし インターネットにあるデータだけではなく て例えば今回のテーマである自社のツール と連携するっていう時のためには自社の データを使いたいみたいな話とかあると 思うんですけれども自社データについては チャットGPTが知るわけもないという ことでえっとChatGPTに自社の データについて聞いたとしてもChat GPTはもちろん答えることができません とこれらのチャGPTの限界を理解する ことでチットGPTの適切な使用方法で あったりとかそれらをどのようなシナリオ で活用するべきかっていうのが見えてくる ということですねでChatgpdの概要 の最後なんですけれどもChatgpdや その他大記号言語モデルllm自体の課題 をこちらにまとめますでまず1点目なん ですけれども先ほどと被るんですが ChatGPTは最新の情報にアクセスが できないと例えば為替や株価のように国 一刻と変化していく情報に対してチト GPTははリアルタイムで対応することが できませんで2つ目の課題としては ChatGPTが独自の情報源にアクセス する能力を持たないということです企業の データベースに保存されている顧客名簿で あったりとか特定のプライベートな情報に はアクセスすることができませんで3つ目 に水論の正確性に課題があるというところ ですチャットGPTは時折り簡単な算術 計算でさえも間違えることがありますこれ は特に正確な情報や結果が求められる タスクにおいて大きな問題となりますねで そして最後にチャットgpdができない こととかのデータが足りないんだったら ファインチューニングすればいいんじゃ ないかっていうような意見もあると思うん ですけれどもファインチューニングする ことによって汎用性が劣化してしまうと いうことがありますとでChatGPTを 特定のタスク例えば自社データを食わせる であったりとか特定のタスクに特化した データを食わせてファインチューニング すると他の多様なタスクに対する性能が 低下すると言われていますでこれらの課題 を解決するための1つの手段として今回お 話しするラングチェインエージェントって いうものがありますでここここからは ラングチェインエイジェントを使って チットGPTの性能を生かしつつ苦手な ものは他のツールで解決していくっていう ことについてお話ししていきますで参考 までにですねここにバッと上げている課題 に関してはMrKLシステムズていう有名 な論文があってそ論文から引っ張ってきた ものとなりますMrKLシステムズって いうのはミラクルシステムズと呼ぶもので チャットGPTと他のツールを連携して どんどんどんどん課題を解いていくって いうことを提示しているロムとなってい ますそれではラングチェインエージェント についてのトピックに移っていきますまず ラングチェインエージェントの前にですね ラングチェインとは何かと言うとラング チェインとは言語モデルを利用する アプリケーションのためのフレームワーク ですでラングチェインについては前回の 勉強会でもご紹介しているので基礎的な 内容を知りたい方はYouTubeで前回 の勉強会の動画をご覧くださいでラング チェインエージェントはラングチェインの 中の1つの機能なんですけれどもラング チェインの中でも非常に面白くて重要な 役割を果していますランチェの主なタスク は次にどんなアクションを取るべきかを大 記号言語モデルllmに決定させそれを 実行するということですで具体的な プロセスは以下の通りですとまず各ツール ができることと質問を指定したレスポンス のフォーマットでllmに送信します聞き ますとチットGPTなどのllmに聞き ますそしてllmChatGPTから帰っ てきたレスポンスをパースして次の アクションを決めるということをしますで このプロセスによってラングチェインジと はユーザーの4級に応じて効率的かつ正確 なアクションを実行できるようになって いるというところですでここでラング チェインエージェントがどのように動く かっていうもののイメージを具体的な例と して1つ持ってきましたま正確に正しい 動き方をしてるわけではないんですけれど も大体こういうような動きをするんだよっ ていうこともご理解ください例えばチット GPTに対してコミュニケーションを取る のがラングチェインのエージェントとなる んですけれどもラングチェイン エージェントにですねまずこう今日東京で で出かける時時に適切な服装は何ですかて いうのを聞きますでそうするとラング チェインエージェントが聞きたい内容今日 東京で出かける時に適切な服装っていう ものとあと自分が持っているツールって いうものをプロンプトに入れてチャット GPTに聞いてくれますとで自分が持っ てるツールっていうものは例えば Google検索のツールっていうも持っ てますとGoogle検索のツールでは 最新の情報を引っ張ってくることができ ますと私が持ってるのはGoogle検索 のツールで最新の情報が引っ張ってこれ ますそしてで今回聞質問としては東京で 出かける時に適切な服装って何でかていう ものを聞きますとでその時にチャット GPTはどのように返してくるかというと でまずは検索ツールでインプットは東京の 気温っっていうもので調べなさいっていう ものをエージェントの方に返してきますで エージェントはチャットGPTからから 教えてもらったじゃあえ検索ツールを使え ばいいのかっていうところで検索ツールを 使おうとしますでインプットとしては チャトGPTが教えてくれたように東京の 気温っていうものをインプットとして入れ てで検索ツールから帰ってきた22度って いうものを変してもらいますとでそして またえっとチャットGPTにえこのツール に入れた答えってものが22°でした次何 すればいいんですかであったりとか最終的 にどうなんですすかっていうのをチャット GPTに聞いてチャットGPTが十分な 情報を得たっていう風に判断するとでは 22°なので薄の長袖でがいいでしょうっ ていうものをエージェントとしに返してで あとはえ答えとしてラングチェインの エージェントが東京は22度なので素の 長袖でがいいでしょうっていうものをその まま返してくるというような流れになり ます特徴的なものとしてはチャットGPT だと今日の天気であったりとか東京の天気 であったりていうものは取れないんですね でそこをGoogle検索のツールって いうものを利用することによって新しい データっていうのを取れるようにしてると いうところですねもう1つ押えておきたい こととしてはこの問を解く時に自分が持っ ているツールっていうもの一覧を渡して どのツールを使えばいいかっていうのこと 自体もチャットGPTに判断してもらうっ ていうところが面白いところとなってい ますはいでこれがラングチェイン エージェントリアクトフレームワークとか 呼ばれたりするようなやり方ですねはい これらのこと全部ラングチェインの エージェントがやってくれるというところ ですでラングチェインエージェントって いうものは様々なタイプのエージェントが 用意されていますとここでエージェントの タイプっていうものを紹介するんです けれども解きたい課題に応じて エージェントを使い分けることによって 精度の高い回答を得られるようになると いうことですここで6個ほど上げています でまず1番汎用的なものとしてはゼロ ショットリアクトエージェントというもの ですでこのエージェントはリアクト フレームワークを利用してツールの説明に 基づいてどのツールを使用すべきか判断し ます先ほどの例で出てきたものと同じです ねこれによって特定のトレーニングデータ なしで多様なツールの適切なこう利用が 可能になってきます次にストラクチャード インプットリアクタエージェントですで このエージェントは複数の入力を使う エージェントを活用することができますで これによってより複雑なツールの理由用が 簡単になりタスクの効率が向上しますと 続いてOpenAIファンクション エージェントですこのエージェントはオ AIのファンクションコーリングの機能を 使っており関数が呼び出されるタイミング であったりとかを検出したりとか適切な 入力を関数に渡すような微調整がえオープ AI自体チットGPT自体がされていて それを使うことができますとOpenAI のえファンクションコーリングこの エージェントが使うOpenAIの ファンクションコーリングについてはこの 後のスライドでもう少し詳しく説明します で次にコンバーションエージェントですで このエージェントは会話での使用目的とし て設計されています何かを聞いて何か答え を出すっていうようなま単純なチャット GPTで何かこう答えを作ってくださいと かそういうのとは違くて会話的な インタラクションを通じて効果的な コミュニケーションを可能にするような エージェントとなっていますそして次に あげるものとしてはセルフアクwith sarchエージェントですねでそこの エージェントはですねセルフアクという 質問を自問自としながら分割することに よって正しい解を導き出す方法を使って\n",
      "Human: ChatGPTが不得意なことを教えて\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "GPTで何かこう答えを作ってくださいと かそういうのとは違くて会話的な インタラクションを通じて効果的な コミュニケーションを可能にするような エージェントとなっていますそして次に あげるものとしてはセルフアクwith sarchエージェントですねでそこの エージェントはですねセルフアクという 質問を自問自としながら分割することに よって正しい解を導き出す方法を使って 情報を検索するエージェントですセルフア クっていうプロンティグの技術があるん ですねまそれを使ってちゃんとした正しい 答えを導き出すエージェントとなってい ますで最後に紹介するものがリアクト ドキュメントストアエージェントですで このエージェントはドックストア ドキュメントストアですねと対話するため にリアクトフレームワークを使用してき ますえこれによって文書の管理であったり とか検索が一元化されて効率的に情報 アクセスが可能となりますこちらに関して はまた今後の勉強会でも取り扱っていき たいかなという風に思ってるんですけれど も文書検索管理っていうものに特化した エージェントとなっていますで以上がラン チェインエージェントの各エージェントの 使用となりますでそれぞれのタイプが 異なるシナリオやタスクに適しており ラングチェインの柔軟性と多様性を象徴し ているものとなります今回のセッションで はですね最も汎用的なゼロショット リアクトとチャットGPT自体に色々判断 させるファンクションコーリングを使った オープAIファンクション2を利用して いき ますでは先ほど説明を省いてしまったん ですけれどもOpenAIファンクション コーリンググっていうのはOpenAI ファンクションコーリングじゃないですね OpenAIファンクションですね OpenAIファンクションとは何か エージェントタイプの1つであるOpen AIファンクションとは何かについてお 話ししますこちらはChatGPTを提供 しているOpenAIのファンクション コーリングという機能を利用していますで ファンクションコーリングっていうものは 2023年の6月にリリースされた機能で ラングチェインエージェントが担っていっ たツールを渡してチャットGPTに聞いて 次のステップを決定するやり取りってい ものをチットGPT自体が行えるように ファインチューニングされているものと なりますでこの機能では東京の天気を教え てくれというような先ほどと同じように ですね質問と共にどういう関数を持って いるのかその関数の説明をチトGPTに 直接投げるということをやりますなので 先ほどのラングチェインエイジェントが やってることと同じようなことをやれる ようになっていてチットGPTが ファンクションをどのように受け取るのか そのファンクションのパラメータであっ たりとか説明とかをよりチャトGPTが 理解しやすいようにAPIとして受け取る ことができるようになっているのでより 適切な判断をチャットGPTがしやすく なっているというところがメリットとなり ますなので今メリットをお話ししてしまっ たんですけれどもファンクション コーリングを使うメリットとしては ChatGPTにツールの挙動をより正確 に伝えやすくなっているというところで これによってChatGPTが機能の ツールのえファンクションの使用や動作を より正確に理解しやすくなっていて適切な 判断をしやすくなっているとていうのとで もう1つのメリットとしてはチャット GPTっていうものがラングチェイン エージェンドって元々チャットGPTが 返してきた個体を利用者が頑張って定期 表現を使って解析する必要があったんです がそれをする必要がなくなったっていう ところが利点としてありますとでチャット GPTが実際にラングチェインを使って どのツールを使えばいいですかていうのを 聞くんですけどそれをどのようにパースし てるかというとこのように頑張ってですね えっとレギュラーエクスプレッションを 使って正規表現を使ってパースしたりとか して次のアクションを決めてたりするって いうのがラングチェが今までやっていた ことであるとでこういうパースをしなきゃ いけないっていうことをしなくて済む つまりパースしなきゃいけなかったので今 まではそのパースすることでえっとうまく パースできなくてミスってしまうっていう こともあったんですけどそういうことが なくなるっていうことが期待されるという ところです はいはいちょっと駆け足になってしまった んですがここまでで20分ぐらいかかって しまいましたねえここからがレモに入り ますで実際にですねラングチェイン エージェントを使ってチャトGPTと自社 ツールを連結するような感じのえデモって いうものをお見せしていきますで使う エージェントとしてはゼロショット リアクトとオーエファンクションを使って いきますであとは今回のプレゼンの冒頭の 方でもお話ししたようにChatGPTに ツールの説明をどのように渡せばいいのか であったりとかその辺りを持ち替えて いただければ幸いです はいではではやっていきますちょっと時間 がなくなってきたので駆け足でいきますね でまずは設定ファイル読んでいきますこれ 何をやってるかと言うとえOpenAIの APIキーであったりとかを読んでいます でまずはですねえっとゼロショットの方を 見せしていきたいんですがおマジないとし てですねおじないというかま前回の勉強会 と同じようにですねラングチェイン エージェントを使うためのやり方をお見せ していきますで実際今回使うモデルとして はチットOpenAPAIというか ChatGPTのえGPT3.5のtbo 0613というものを使っていきますで 外部のツールとしてはGoogleサーチ のAPIっていうものを今回用意しました ここであのサプAPIっていうものを書い ているものがえGoogleのAPIと なりますで聞きたい質問としては今日の 東京と北海道の天気を調べて東京から 北海道の出張で来ていくべきを教えて くださいっていうものを聞きたいと思い ますでラングチェインエージェント自体を 走らせてみますでこれがゼロショット リアクトエージェントを使った場合どの ようになるかっていうのをお見せしますで エージェントタイプに関しては イニシャライズエージェントの エージェントっていうえ引数に対して エージェントタイプのこのゼロショット リアクトディスクリプションていうものを 渡すとエージェントを選択することができ ますちなみになんですけれどもえこれって ただあの文字列が返ってくるだけですかね あのゼロショットリアクト ディスクリプションていうものが返って くるだけのものになりますなので文字列で 与えても同じですはいでは実行してみ ましょうチトgpdはもちろん今日の天気 とか今日の東京とか北海道の天気っていう のは知らないので来ていくべき服装って いうことは分からないわけですね気温も 分からないのででこれでラングチェイン エージェントが私はGoogle検索の ツールを持ってますよでそれを使って使う ことができますでこの問題課題っていう ものを解くためにはどうすればいいですか てのを聞くっていうことですねでここで ざーっと出てきてるんですけれども実際に 書いてきた答えとしてはtheWisto isCloudyaboutcrear withtempof歌詞になっちゃって ますけどまこのように帰ってきますと 英語で帰ってきちゃってますねでこういう 風にえどんなアドレスをれ切ればいい かっていうものがちゃんと帰ってきてい ますと前にやった時はそんなに綺麗に帰っ てきてなかったんですけれども今回は うまく帰ってきていますはいこちらがゼロ ショットリアクトディスクリプションで やった場合の結果になりますでどういう ことをやってるかっていうのなこの辺りを 見ていただくといいのかなという風には 思いますでチットGPTにまずラング チェインエージェントが問題とツールを 渡してチットGPTに何をすればいい かっていうのを聞きますでチャットGPT から帰ってきた答えとしては次の アクションとしてはサーチをしてください ですサーチのインプットとしてはウザー 東京todayていうものを渡してくださ いっていうのを渡してますで次の アクションとしてはサーチをしてください でそのインプットとしてはウザ北海道 todayていうものを渡すようにして くださいとで最終的にその帰ってきた答 っていうものをチャットGPTに渡して 最終的な文が出てくるということですはい でこれが1つ目ですねアエージェント タイプ1つ目のえゼロショットリアクト ディスクリプションで元々ラングチェイン エイジェントがリアクトフレームワークで ツールを渡したりとかしてチャットGPT とうまく連携しながら外部ツールを使う ようにしたえ機能となっていますでこれが ですねえ最近出てきた6月にリリースされ たOpenAIのファンクションコーリン グっていうものを使うとどうなるかって いうのをお見せします はいでOpenAIファンクション OpenAIのファンクションコーリング を使うためにはエージェントタイプの OpenAIファンクションズっていう ものを渡しますでそうするとえこのように 動きますで実際にやってることとしては ラングチェインエージェントがOpen\n",
      "Human: ChatGPTが不得意なことを教えて\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "たOpenAIのファンクションコーリン グっていうものを使うとどうなるかって いうのをお見せします はいでOpenAIファンクション OpenAIのファンクションコーリング を使うためにはエージェントタイプの OpenAIファンクションズっていう ものを渡しますでそうするとえこのように 動きますで実際にやってることとしては ラングチェインエージェントがOpen AIのファンクションコーリングっていう ものを使ってうまくチャットGPTと やり取りしながら答えを導き出していくっ ていうことをやっていますはい出てきた 答えはこちらですねで同じようにですね どのようにやっているかっていうものは ここら辺の途中で出てきているんです けれども途中結果でえサーチとしてはえ クエリー東京の今日の天気っていうものを 調べてくださいでサーチっていうツルを 使って今日の北海道今日の天気っていう ものを調べてくださいでこれらが帰ってき た答えっていうものをえチャットGPTに 返してチャトGPTがその与えられた情報 を元に東京の今日の天気は曇りですが後に は晴れる予報ですで気温は接し30°歌 86°でコス確率はどうのこうのっていう ものがあってであとは東京は暑くなる可能 性があるので軽い服装が適しています ただし北海道は比較的涼しいので ジャケットなどを持っていくことがお勧め しますというような感じに帰ってきてます ま見て分かると思うんですけれどもま日本 語にな質問が日本語だったので日本語で ちゃんと返してくれるっていうのは もちろんのことなんですけれども書いてき た答えっていうものに関してより詳しく 返してくれているっていうことが分かると 思いますなので使ってみた所管としては ですねここで言うオAIファンクションの ファンクションコーリングっていうのの ファンクションっていうのはラング チェインエージェントでいうツールと同じ なんですけれどもそのファンクションで あったりとかツールを渡す時にですね渡し て何かを判断判させたいチャットGPTに 判断してもらいたいっていう時はえ エージェントタイプゼロショットリアクト ディスクリプションよりもエージェント タイプオAIファンクションの方がより いい結果が返ってきやすいっていうことが 分かると思い ますもう少しあの詳しく見ていきます ちなみにですねOpenAIにどんな ファンクションを渡してるかっていうのは イニシャライズエージェントのところで エージェントを定義してるんですけども そのエージェントの中からエージェントっ ていうものとファンクションズってものを 実行するとどんなえファンクションが渡さ れてかっていうのを見ることができますで 今回渡されたファンクションっていうのは ネームサーチっていうファンクションが 渡されていてどんなことができるかって いうのでサチエンジンですっていうような ものをやってますであとはパラメーターと してはこういうものを渡していきますって いうのが分かりますとはいでここまでが 基本的なラングチェインエージェントを 使って外部ツールを連携するっていうお話 をしてきましたとで次にですねえ自社で 作ったツールっていうものを連携させ るっていところについてお見せしていき ますで一旦はですねレコメンドアイテムっ ていうものを考えてみようと思いますで ここ何をやりたいかって言うとレコメンド アイテムまこの中身はほとんど意味のない ものになってるんですけれどもレコメンド アイテムっていう関数を自社で持っていて でレコメンドアイテムっていうものは自社 のデータベースなどにアクセスして日付を 持ったにこの日のレコメンドっていうもの はこういうものですっていうものを返す ような関数っていうところになりますとな のでえっとこのレコメンドアイテムって いうところをこの関数ををえChat GPTのフローの中に組み込みたいって いうことをやっていきますでどのように ラングチェインエージェントを使って ChatGPTに連携すればいいかという とツールっていうものにえ変換していく 必要がありますとでレコメンドアイテム ツールっていうものをえツールfrom ファンクションズっていうものを使って どのようなファンクションを実行したい ですかレコメンドアイテムっていう ファンクションを実行したいですまこう いう風にですねこの今回のあまり意味の ないファンクションなんですけれどもこれ を実行しますとでツールの名前としてはえ レコメンドアイテムっていうものを渡し ますでツールのディスクリプション何を やってくれるかっていうことに関してはお すめの商品を教えてくれますっていうのを ツールとして定義するというところです はいでこれをちょっとツールズっていうま ツールまとめて渡さないといけないで ツールの配列の中に入れておきます実際に ですねラングチェインエージェントにどの ようにツールを渡せばいいかっていうとま 先ほどもカラっとやってたんですけれども このツール1覧っていうのを最初に渡して 引数として渡しているのでまこのようにし てどんなツールが使えるかっていうものを ラングチェインのAに渡しでチャット GPTと連携していきますはいでえっと 今回聞きたいこととしてはえおすすめの 商品を教えてくださいっていうものを投げ てみようと思いますで使うエージェントと しては先ほどゼロシトリアクトよりもより いい結果が返ってきたオーエ ファンクションズってものを選びます はいはいでは実行し ますはいで書いてきたものとしてはですね コメドアイテムってものが実行されて withファッションという謎のものをえ 入力に入れてで実際この引数がですね デートの中にファッションが入ってで プリントファッションっていうところでこ でファッションが出てきてしまってるとで ただおすめの商品は今回レコメンド アイテムで書いてきたAppleですって いうのが書いてきてることが分かると思い ますはい見て分かるようにですねなんか よくわからない引数は与えてしまってる なっていうところがありますでこを どんどん解決していこうと思いますで次に やることとしては今回なんでこのように変 なファッションとかいう引数を与えて しまったかというと引数に関する情報が ないんですね与えられてないというところ になりますとなので引数何与えればいいん ですかみたいなところが情報としてないが ゆえにチャットGPTもレコメンド アイテムを使うことは分かるとレコメンド アイテムを使えばいいのは分かるんだけど レコメンドアイテムに対してちょっと 分からないからカテゴリー情報でも渡して みようかなっていうのでファッションを 渡してしまっているというような状態に なりますで例えばまファンクションを見た としても今回使ってるファンクションに 関してはレコメンドアイテムでおすめの 商品を教えてくれますでパラメーターの 情報は全くありませんっていう状態なので どんなパラメーターを渡せばいいかって いうのはオープAIファンクションは 分からないというところですねじゃあこれ に対してどうすればいいかっていうのをお 見せしますでえっと結構簡単でしてパダ ティックっていうものをご存知ですかね こう最近えっとファストAPIとかですか ねこう結構パであったりとかそのヒントを 与えるっていうことがまPython主流 になってきてると思うんですけれども フダンティックを使っていきますでえっと ご注意していただきたいこととしては ファインディッてもうV2が出てるんです けれどもV2を使うとラングチェイン エージェントを動きませんとなので パティックV1を指定して方に関する情報 をえ与えるためのそのベイスモデルとか フィールドを使ってえやっていきますで これ何をやってるかと言うとま今回の インプットに対してデイトっていうものが ありますがデイトていうものはお勧めした 商品を絞るために使われる日付ですって いうものを与えていますこれをえっと アーグススキーマ先ほどのツールを定義 する時にアグススキーマっていう引きを 使ってこのレコメンドアイテムインットっ ていうベースモデルから継承した レコメンドアイテムインプットっていう インプットの報引数の情報を持ったクラ スっていうものを渡すということをします とでこうするとどうなるかっていうのをお 見せしていき ますはいじゃあどう変わる かいきますはい実行します全く同じですね 実行するものとしてはで今回はレコメンド アイテムっていうものに対して先ほどと 同じレコメンドアイテムっていうものが 選ばれましたとコアイテムに対してデイト が2020年の12月1日っていうものを 渡しているっていうことが分かりますで それによってですね気付がちゃんと渡して くれたっていうことがわか分かるわけです ねで今回あのここであのデートっていう ものはディスクリプションでお勧めしたい 商品を絞るために使われる日付っていう ことを伝えたのでチャットGPTの方があ これは日付のことなんだっていうところで 引数はファッションのようなカテゴリーを 渡すんではなくてデートの引数っていう ものを渡すことができてるというところ ですはいでこちらがデトのまあ2022年 の12月1日もはや日付が意味が分から ないですけれどもこういうものが渡されて いるというところですねでおすめ商品は Appleですという風にでこういう風に\n",
      "Human: ChatGPTが不得意なことを教えて\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "ことを伝えたのでチャットGPTの方があ これは日付のことなんだっていうところで 引数はファッションのようなカテゴリーを 渡すんではなくてデートの引数っていう ものを渡すことができてるというところ ですはいでこちらがデトのまあ2022年 の12月1日もはや日付が意味が分から ないですけれどもこういうものが渡されて いるというところですねでおすめ商品は Appleですという風にでこういう風に ですねこうツールの説明をどんどん どんどん入れていってええ解決していく 必要があるというところですねで同じよう にですねちょっとエージェントの ファンクションがどのように渡されるてる かっていうのをお見せしますとで今回渡さ れたのはレコメンドアイテムインプトって いうのをえパイダンテックの方で定義して 渡しているのでえ実際にえっと ファンクションOpenAIのえ ファンクションコーリングにどのように 渡されてるかというとパラメーターとして ですねこういう風なレコメンドアイテム インプットっていうものが渡されていて プロパティとしてはデートがあってデー トっていうのはお勧めしたい商品を絞る ために使われる日付っていうものが入れ られてえ飛ばされてるということが分かる と思いますはい で他にはですねこのようにツールフロン ファンクションで作るっていうこともある んですけれども同じようにですね デコレーターを使うっていうこともでき ますとデコレーターの方が結構シンプルに 書けるので私は結構デコレーターを使って 書くことが多いですとでデコレーター何を すればいいかというとデコターっていうの はま関数の前にですねアマークツールなん ちゃらかんちゃらっていうものがあってで それを使ってえっとこのツールってのは何 ができるかっていうものをえドッ ストリングで与えるんですねな先ほどと 同じにするとレコメンドアイテムツールっ ていうものがあったら中身は同じですね プリントデイトとAppっていうものを 返しますとプリントデイトしてApple っていうものを返しますとででやることと してはおすめ商品を教えてくれます全く 同じ内容ですねでこのツールの名前って いうものはデコレーターの引数として レコメンドアイテムとして渡していると いうところですで同じようにですね ツールズの一覧として入れてでこれをえ 実行してみ ましょうはいこれデコレーター使った場合 です ね実行するものは全部同じですで同じよう にこれも実行できますという風にデコレー ターってかなりこうシンプルにかけてで ファンクションの中のドックストリングス とかを使ってくれるので結構あの家読性と かもう悪くないかなという風には思います 先ほどと同じようにですねこレコメンド アイテムってものはちゃんと選んでくれた んですけれどもレコメンドアイテムに渡し ているデートっていうのは2021年10 月15日という意味の分からない日付を 渡してしまっていますとこれはなぜかと言 とまもちろんそのおすすめ商品を教えて くださいって言ってるので勝手に日付を 決めて聞いてしまっているというところ ですね はいでデコレーターの方もですね同じよう にファンクションを見てみるとえっとこう いう風になるという感じですねただあの 先ほどと同じようにですねパダンティック とか使っていないのでプロパティの パラメーターとかは適当になってしまって いるというような感じになりますただ今回 の場合はですねこうデコレーターの場合は フロムファンクションの方を使ったこっち の場合ですねこのフロムファンクションを 使った時と違ってきちんとデートを入れて くれているっていうことが特徴的かなと いう風には思いますフロンファンクション を使った場合っていうのはパダンティック を渡さないとデートっていうものに対して ファッションを入れたりとかよく分から ないものを入れたりすることがあったと 思うんですけれどもデコレーターを使った 場合はこのデートっていうものを渡した時 にきちんとこうデートを返してくれるよう な情報っていうものを渡せてくれている ような感じですねいずれにせを正しい共同 を求めるためにはこのままあまり情報を 与えないで実行するってのは適切ではない ので特に自社ツールサービスとして提供 する側としてはですねなのでそういう意味 ではきちんとバイダンティックなどを使っ て適切な情報を渡しながら関数っていう ものを渡していく必要があるかなという風 に思いますなのでえっと先ほどと同じよう にですねデコレーターを使った場合も パイナティックの情報っていうものを渡す ことができるのでデコレーターの引き数に アーグススキーマていうものを渡してで そのパイランティックの情報を渡すことで 適切な答えを返すことができるようになる というところです同じようにですねま結果 も変わらないので はいまこういう風に変えてきました ちょっと答えがどんどんどんどん変わって きてますApple製品だったりとか AppleStoreとかオンライン ショップとかうんまここら辺に関しては 本当に適切な答えがまだ返ってきてない なっていうような状態だとは思います エージェントのファンクションを見るとえ きちんとファナティックで渡した情報って いうのが渡っていることが分かると思い ますこのようにですねこのデートっていう ものはデートっていう引き数はお勧めし たい商品を絞るために使われる日付ですっ ていうのが渡っているというところです もう少しですね今までこうおすめの商品を 教えてくださいっていう風に言っていたの でデートっていうものが1月10日であっ たりとかよくわかんない日付になっていた のではないかっていうことを推測してでは 昨日のおすすめ商品を教えてくださいって いうものを聞いてみますてそうするとどう なるかと言うとえ昨日のおすめ商品を教え てくださいって言ってるのにレコメンド アイテムに渡されてるのは2021の10 月20日っていうものが渡されれてること が分かりますとチャットGPTにこう昨日 とか今日とか昨日とか渡したら日付を ちゃんと入れてくれるのかなと期待するっ ていうことがあると思うんですけれども 実際はそんな入れてくれないっていうこと がまこの結果から分かるということですね もう少し例えばディスクリプションとかを 適切にすればうまくいくのかもしれないん ですけど今回は違う手段でえっと解決 しようと思いますで今回どういう風に解決 するかと言うとデートタイムを使って 新しい日付けを取得するような関数自社 ツールってものを設けようと思います ゲットデートっていうツールっていうもの を作ってでそのツールは何をするかという とま今日や昨日など日付を取得する時に 使います引き数には今日を起点として何日 か前をNで与えますとでここのそのドック ストリングスにですねこう引数に関する 情報を書いてるんですけども実際はですね パダンティックで引き数の説明した方が ベタだとは思いますただえっとドック スリンに書いてツールの説明として与える だけでも結構チャットGPTは賢いので うまく判断してくれるということですでお 見せしますはいこの日付関数を入れると どうなるかと言うとこういう風な感じです ねはい今日のおすめの商品を教えてくださ いっていう風にするとtodayて書い てき来てこれもうまく動いてないですね こういうことが結構ありますとうまく動か ないことがあるとでもう1回実行してみ ましょうかはいでもならではですね ちょっと30分で終える予定が46分に なってしまったんですがもう少しで終わる ので続けます前回のやつだとですね直接 レコメンドアイテムを呼び出してデートに 対してtoデイていうものを渡してしまっ てたんですけれども今回はうまく動いてい てまずは日付を取得するためにゲットデイ トっていうものを呼び出しますとで今日な ので今日からの起点のえN日前だったらN に0を渡せばいいということが分かるとだ からゲットデートに0を渡して帰ってきた ものが2023年の9月30日っていう ものが帰ってきてで9月30日のえお勧め 商品は何ですがま書いてくるものは全部 AppleなのでAppleってものが 帰ってきてることが分かると思います同じ ようにですねじゃあどういう ファンクションが渡されてたかっていうの をお見せするとサクっとですねで今回あの ファンクション2つ渡されていて レコメンドアイテムっていう ファンクションとゲットデイトっていう ファンクションが渡されていますで それぞれのファンクションの説明がこの ように与えられているということが分かり ますもう少しツールを複雑にしていって ですね奇数日だったらオレンジ偶数日だっ たらえAppleっていうものを返すよう なツールにちょっとだけレコメンド アイテムを変えみようと思い ますはいではえこれを実行するとですね 今日はえ9月30日なのでもちろん9月 30日偶数日ですね偶数日なので Appleが返ってくるきちんと帰ってき ますねAppleが帰ってきましたでは 昨日の場合はどうなのか 昨日はい昨日の場合は29日なので1日前 ってものをゲットデイトで取得して29日 ってものが書いていますで29日を使って え昨日のおすめ商品オレンジっていうもの を取ることができるというところ ですやとうまく動きました ねでもう少しだけちょっと時間が1時間 ぐらい喋ってしまうような感になるんです\n",
      "Human: ChatGPTが不得意なことを教えて\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "Appleが返ってくるきちんと帰ってき ますねAppleが帰ってきましたでは 昨日の場合はどうなのか 昨日はい昨日の場合は29日なので1日前 ってものをゲットデイトで取得して29日 ってものが書いていますで29日を使って え昨日のおすめ商品オレンジっていうもの を取ることができるというところ ですやとうまく動きました ねでもう少しだけちょっと時間が1時間 ぐらい喋ってしまうような感になるんです けれどもう少しだけお話させてくださいで これだけだともちろんまだまだ連携が 少ないかなっていうところがあってで次に じゃあAppleだったら100円 オレンジだったら200円っていうような ものを商品の値段を返すような関数って いうものを組み込んでみましょうでツール としては元々グビだったらAppleキビ だったらオレンジを返すようなものとあと は日付を取得するツールであとは今回定義 したAppleとオレンジAppleだっ たら100円オレンジだったら200円 っていうのを返すツールっていうものを 定義しますでこれでエージェントのですね おすめの商品の値段まで教えてくださいっ ていうことをやるとそうするとまず最初に え昨日なのでゲットデートでN=1を渡し て1日前のデートを取ってきますで9月 29日ですで次にレコメンドアイテムって いうツールを呼び出してレコメンド アイテムにえ9月29日を渡してで最後に ですねアイテムプライスっていうので アイテムネームをえオレンジにとして渡し てでオレンジはは200円なのでえ昨日の おすめ商品であるオレンジの値段は 200円ですっていう最終的な答えが返っ てきましたというところになりますだいぶ 柔軟なものができるようになってきたって いうことが理解できると思いますで他には ですね最後なんですけれども取得した結果 を吐き出したいとかデータベースに 書き込みたいとかあったりすると思うん ですけどもそういうことももちろん簡単に できますと基本的にはファンクションが あってそのファンクション中身は自分で 書いていくので何でもすることができると いうところですねちょっとあの output.tchっていうところに 書き込むようなものを記事的にですね データベースに書き込んでいるようなもの として紹介しようと思いますで今回は さらに追加するツールとしてはですね セーブデータっていうツールを追加します とセーブデータっていうものは何なのかと いうとここにも説明書いてあるんです けれども日付と商品名と商品の値段を 受け取ってデータベースに書き込みますっ ていうようなものをツールとして作りまし たデータベースといながらもアウトプット テキストにただ書き込むだけのものになる んですけどもデートアイテムネーム アイテムプライスを書き込むだけのツール となりますま実際に自社ツールを使う時に はここにSQL分であったりとかを書いて データベスに書き込むとかをやったりする ことになると思いますこちらもですね ちょっと簡易的にですねフダンティックを 使わずにえドックストリングだけで何を やるかってのを渡して書き込めるかどう かってのをお見せしていこうと思いますで 同様にですね同じように何をしたいかと 言うと今日のおすめ商品の値段を調べて データベースに書き込んでくださいって いうことを実行し ますで最初に動くものとしてはまず日付を 取得するゲットデイトが動いてN=0で 今日の日付を取ります9月30日ですと9 月30日が取れたら9月30日の レコメンドアイテムは何ですかていうので レコメンドアイテムのツールを起動して 書いてきたものがAppleですとであ次 にやることしてはAppleの値段は いくらですかていうものをアイテム プライスに聞いてアイテムプライスが返し てきた答えが100円ですとで100円 っっていうものをえセーブデータに渡して セーブデータに渡すものとしてはデートと アイテムネームとアイテムプライスこれは 日付と商品目と商品の値段を受け取 りっていう風に書いてあるのでこういう ようなものを基数として与えて データベースに書き込みますていうことを この操作でやるということですねなので 細かいことを書いた方がミスは少ないん ですけれどもあんまり書かなくても動いて くれるっていうのがまやっぱりこう チャットGPTのうまいところかなという 風には思いますで最終的に帰ってきたこと としては今日のえおすすめ商品の値段は 100円ですとでデータベースに正常に 書き込まれましたっていうので データベースではないんですけどれも テキストファイルっていうものを中身見て みましょうと今日の日付2023年9月 30日でおすすめの商品Appleで最終 的に100円っていうのが書き込まれた ことが確認できましたとはいとても長く なってしまったんですけれどもこちらで テモは終わりとさせていただきたいと思い ますはい私の発表は以上となります ありがとうございました\n",
      "Human: ChatGPTが不得意なことを教えて\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Given the following extracted parts of a long document and a question, create a final answer. \n",
      "If you don't know the answer, just say that you don't know. Don't try to make up an answer.\n",
      "______________________\n",
      "ChatGPTは最新のデータにアクセスできないとか、特定の数学的な推論が得意でないなど、いくつかの課題が存在します。また、チャットGPTの訓練データに含まれていない情報や、自社のデータについてはチャットGPTが知ることができません。\n",
      "\n",
      "ChatGPTが不得意なことは以下のようなものです:\n",
      "\n",
      "1. 最新の情報にアクセスできない: 為替や株価のように国際的に変動する情報に対して、リアルタイムで対応することができません。\n",
      "\n",
      "2. 独自の情報源にアクセスできない: 企業のデータベースに保存されている特定のプライベートな情報や顧客名簿などにはアクセスすることができません。\n",
      "\n",
      "3. 精度の問題: 簡単な算術計算でも、時折間違えることがあります。正確な情報や結果が求められるタスクにおいては問題となります。\n",
      "\n",
      "4. データの不足: ChatGPTが持っているデータが不十分な場合、ファインチューニングを行っても汎用性が劣化する可能性があります。特定のタスクや特定のデータに特化したファインチューニングは、他の多様なタスクに対する性能を低下させる可能性があります。\n",
      "\n",
      "ChatGPTの不得意な点は、以下のようなものがあります。\n",
      "\n",
      "1. ドメイン知識の不足: ChatGPTは事前にトレーニングされたモデルであり、特定のドメインについての深い知識を持っていません。そのため、専門的な情報や特定の業界に関する質問には限定的な回答しかできません。\n",
      "\n",
      "2. 矛盾した情報の処理: ChatGPTは過去のトレーニングデータから学習しているため、矛盾した情報を提供することがあります。たとえば、同じ質問に対して異なる答えを返すことがある場合があります。\n",
      "\n",
      "3. 細かい詳細の理解の難しさ: ChatGPTは一度に1つの文脈しか処理できないため、長い文や複雑な文章の意味を完全に理解することは難しい場合があります。そのため、長文や複雑な文脈を持つ質問に対しては、正確な回答を提供することができないことがあります。\n",
      "\n",
      "4. 文脈の欠落: ChatGPTは一度に1つの発言のみを処理するため、会話の文脈を完全に把握することが難しい場合があります。そのため、前の発言に基づいた返答や会話の流れを持つ回答をすることができないことがあります。\n",
      "\n",
      "以上が、ChatGPTの不得意な点です。\n",
      "\n",
      "ChatGPTにとっての課題は、与えられた文脈に基づく正確な情報の理解と、厳密な論理の構築です。また、文脈に基づく情報の欠落や曖昧さに対処することも困難です。したがって、ChatGPTは時に誤った情報を提供したり、論理的に不正確な回答を生成することがあります。また、ChatGPTは倫理的な問題やバイアスを持つ情報を生成することもあります。そのため、生成された内容を慎重に検証する必要があります。\n",
      "\n",
      "ChatGPTは日付の処理や特定の情報を正確に取得することに苦手なところがあります。例えば、日付を適切に入力しても、ChatGPTは自動的に日付を理解して処理するわけではありません。また、特定の情報を要求する場合でも、正確な情報を返すとは限りません。また、長い対話の中で同じ質問を繰り返すと、異なる答えを返すこともあります。ですので、ChatGPTを使用する際は、結果を確認し、適切な情報を提供することが重要です。\n",
      "\n",
      "ChatGPTは以下のような点で苦手とされています：\n",
      "\n",
      "1. 文脈に基づく理解の欠如：ChatGPTは文脈に基づいて応答するため、一度応答した内容を覚えているわけではありません。そのため、会話の流れや過去の発言を適切に把握することができず、矛盾した回答をすることがあります。\n",
      "\n",
      "2. 特定の専門知識の不足：ChatGPTは一般的な知識を持っていますが、特定の専門分野の知識に関しては限定的です。専門的な質問や専門用語に対しては、正確な回答を提供することが難しい場合があります。\n",
      "\n",
      "3. 情報の正確性の保証ができない：ChatGPTはトレーニングデータから学習した情報をもとに応答しますが、それが必ずしも正確性を保証するものではありません。特に時事的な情報や最新の研究結果に関しては、常に最新の情報を提供するわけではありません。\n",
      "\n",
      "4. 倫理的な問題への対応の困難さ：ChatGPTはトレーニングデータに基づいて学習するため、時に不適切な応答や差別的な発言をすることがあります。このような倫理的な問題に対処するためには、適切なフィルタリングや監視が必要です。\n",
      "\n",
      "以上のような点が、ChatGPTが不得意とされる理由です。\n",
      "Human: ChatGPTが不得意なことを教えて\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "qa_output = qa_chain(\n",
    "    {\n",
    "        \"input_documents\": docs,\n",
    "        \"question\": \"ChatGPTが不得意なことを教えて\",\n",
    "    },\n",
    "    return_only_outputs=True,\n",
    ")[\"output_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "faedb445-daa6-4c93-83f3-ce93e0ec5a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatGPTが不得意とされることは以下の通りです：\n",
      "\n",
      "1. 最新の情報へのアクセスができない：ChatGPTはリアルタイムの情報に対応することができず、為替や株価などの国際的に変動する情報に対して最新の情報を提供することができません。\n",
      "\n",
      "2. 独自の情報源へのアクセスができない：ChatGPTは企業のデータベースやプライベートな情報にアクセスすることができず、特定のプライベートな情報や顧客名簿などについての情報を提供することができません。\n",
      "\n",
      "3. 精度の問題：簡単な算術計算でも間違えることがあり、正確な情報や結果が求められるタスクにおいては問題となることがあります。\n",
      "\n",
      "4. データの不足：ChatGPTが持っているデータが不十分な場合、ファインチューニングを行っても汎用性が劣化する可能性があります。特定のタスクやデータに特化したファインチューニングは、他の多様なタスクに対する性能を低下させる可能性があります。\n",
      "\n",
      "5. ドメイン知識の不足：ChatGPTは特定のドメインについての深い知識を持っていないため、専門的な情報や特定の業界に関する質問には限定的な回答しかできません。\n",
      "\n",
      "6. 矛盾した情報の処理：ChatGPTは過去のトレーニングデータから学習しているため、矛盾した情報を提供することがあります。同じ質問に対して異なる答えを返す場合もあります。\n",
      "\n",
      "7. 細かい詳細の理解の難しさ：ChatGPTは一度に1つの文脈しか処理できないため、長い文や複雑な文章の意味を完全に理解することは難しい場合があります。\n",
      "\n",
      "8. 文脈の欠落：ChatGPTは一度に1つの発言のみを処理するため、会話の文脈を完全に把握することが難しい場合があります。そのため、前の発言に基づいた返答や会話の流れを持つ回答をすることができないことがあります。\n",
      "\n",
      "以上がChatGPTが不得意とされる理由です。\n"
     ]
    }
   ],
   "source": [
    "print(qa_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cde702e-1f42-49d5-91cc-eba42fdb00ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
